[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10244",
        "id": 1099225494,
        "node_id": "I_kwDOCVq1mM5BhNmW",
        "number": 10244,
        "title": "unable to find library -latomic when build onnxruntime-web",
        "user": {
            "login": "wikiwen",
            "id": 38649098,
            "node_id": "MDQ6VXNlcjM4NjQ5MDk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38649098?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wikiwen",
            "html_url": "https://github.com/wikiwen",
            "followers_url": "https://api.github.com/users/wikiwen/followers",
            "following_url": "https://api.github.com/users/wikiwen/following{/other_user}",
            "gists_url": "https://api.github.com/users/wikiwen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wikiwen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wikiwen/subscriptions",
            "organizations_url": "https://api.github.com/users/wikiwen/orgs",
            "repos_url": "https://api.github.com/users/wikiwen/repos",
            "events_url": "https://api.github.com/users/wikiwen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wikiwen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "fs-eire",
            "id": 7679871,
            "node_id": "MDQ6VXNlcjc2Nzk4NzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7679871?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fs-eire",
            "html_url": "https://github.com/fs-eire",
            "followers_url": "https://api.github.com/users/fs-eire/followers",
            "following_url": "https://api.github.com/users/fs-eire/following{/other_user}",
            "gists_url": "https://api.github.com/users/fs-eire/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fs-eire/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fs-eire/subscriptions",
            "organizations_url": "https://api.github.com/users/fs-eire/orgs",
            "repos_url": "https://api.github.com/users/fs-eire/repos",
            "events_url": "https://api.github.com/users/fs-eire/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fs-eire/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "fs-eire",
                "id": 7679871,
                "node_id": "MDQ6VXNlcjc2Nzk4NzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7679871?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fs-eire",
                "html_url": "https://github.com/fs-eire",
                "followers_url": "https://api.github.com/users/fs-eire/followers",
                "following_url": "https://api.github.com/users/fs-eire/following{/other_user}",
                "gists_url": "https://api.github.com/users/fs-eire/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fs-eire/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fs-eire/subscriptions",
                "organizations_url": "https://api.github.com/users/fs-eire/orgs",
                "repos_url": "https://api.github.com/users/fs-eire/repos",
                "events_url": "https://api.github.com/users/fs-eire/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fs-eire/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-11T14:24:18Z",
        "updated_at": "2022-01-13T09:23:06Z",
        "closed_at": "2022-01-13T09:23:06Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI try to build onnxruntime-web according to [page](https://github.com/microsoft/onnxruntime/tree/v1.10.0/js#onnxruntime-web).\r\nBut I build failed with `--enable_wasm_threads`.\r\n\r\nI run these commond:\r\n`./build.sh --config Release --build_wasm --skip_tests --disable_wasm_exception_catching --disable_rtti --parallel 24 --enable_wasm_simd --enable_wasm_threads`\r\nbut it raise **wasm-ld: error: unable to find library -latomic**\r\n\r\nThe detailed information is below\r\n```\r\nwasm-ld: error: unable to find library -latomic\r\nem++: error: '/home/work/emsdk/upstream/bin/wasm-ld -o ort-wasm-simd-threaded.wasm CMakeFiles/onnxruntime_webassembly.dir/home/work/onnxruntime/onnxruntime/wasm/api.cc.o external/nsync/libnsync_cpp.a external/protobuf/cmake/libprotobuf-lite.a external/onnx/libonnx.a external/onnx/libonnx_proto.a libonnxruntime_common.a libonnxruntime_flatbuffers.a libonnxruntime_framework.a libonnxruntime_graph.a libonnxruntime_mlas.a libonnxruntime_optimizer.a libonnxruntime_providers.a libonnxruntime_session.a libonnxruntime_util.a external/re2/libre2.a external/protobuf/cmake/libprotobuf-lite.a -latomic -L/home/work/onnxruntime/cmake/external/emsdk/upstream/emscripten/cache/sysroot/lib/wasm32-emscripten /home/work/onnxruntime/cmake/external/emsdk/upstream/emscripten/cache/sysroot/lib/wasm32-emscripten/crtbegin.o -lGL-mt -lal -lhtml5 -lc-mt -lcompiler_rt-mt -lc++-mt-noexcept -lc++abi-mt-noexcept -ldlmalloc-mt -lc_rt_wasm -lsockets-mt -mllvm -combiner-global-alias-analysis=false -mllvm -enable-emscripten-sjlj -mllvm -disable-lsr --allow-undefined-file=/tmp/tmpxa53597v.undefined --import-memory --shared-memory --strip-debug --export-if-defined=stackSave --export-if-defined=stackRestore --export-if-defined=stackAlloc --export-if-defined=__wasm_call_ctors --export-if-defined=__errno_location --export-if-defined=__emscripten_pthread_data_constructor --export-if-defined=__pthread_tsd_run_dtors --export-if-defined=_emscripten_call_on_thread --export-if-defined=_emscripten_main_thread_futex --export-if-defined=_emscripten_thread_init --export-if-defined=emscripten_current_thread_process_queued_calls --export-if-defined=_emscripten_allow_main_runtime_queued_calls --export-if-defined=emscripten_get_global_libc --export-if-defined=emscripten_main_browser_thread_id --export-if-defined=emscripten_main_thread_process_queued_calls --export-if-defined=emscripten_register_main_browser_thread_id --export-if-defined=emscripten_run_in_main_runtime_thread_js --export-if-defined=emscripten_stack_set_limits --export-if-defined=emscripten_sync_run_in_main_thread_2 --export-if-defined=emscripten_sync_run_in_main_thread_4 --export-if-defined=emscripten_tls_init --export-if-defined=pthread_self --export-if-defined=pthread_testcancel --export-if-defined=pthread_exit --export-if-defined=memalign --export-if-defined=malloc --export-if-defined=free --export-if-defined=_get_tzname --export-if-defined=_get_daylight --export-if-defined=_get_timezone --export-if-defined=__start_em_asm --export-if-defined=__stop_em_asm --export-table -z stack-size=5242880 --initial-memory=16777216 --no-entry --max-memory=2147483648 --global-base=1024' failed (returned 1)\r\nCMakeFiles/onnxruntime_webassembly.dir/build.make:114: recipe for target 'ort-wasm-simd-threaded.js' failed\r\nmake[2]: *** [ort-wasm-simd-threaded.js] Error 1\r\nCMakeFiles/Makefile2:1274: recipe for target 'CMakeFiles/onnxruntime_webassembly.dir/all' failed\r\nmake[1]: *** [CMakeFiles/onnxruntime_webassembly.dir/all] Error 2\r\nMakefile:165: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\nTraceback (most recent call last):\r\n  File \"/home/work/onnxruntime/tools/ci_build/build.py\", line 2362, in <module>\r\n    sys.exit(main())\r\n  File \"/home/work/onnxruntime/tools/ci_build/build.py\", line 2282, in main\r\n    build_targets(args, cmake_path, build_dir, configs, num_parallel_jobs, args.target)\r\n  File \"/home/work/onnxruntime/tools/ci_build/build.py\", line 1174, in build_targets\r\n    run_subprocess(cmd_args, env=env)\r\n  File \"/home/work/onnxruntime/tools/ci_build/build.py\", line 639, in run_subprocess\r\n    return run(*args, cwd=cwd, capture_stdout=capture_stdout, shell=shell, env=my_env)\r\n  File \"/home/work/onnxruntime/tools/python/util/run.py\", line 45, in run\r\n    env=env, shell=shell)\r\n  File \"/usr/lib/python3.6/subprocess.py\", line 438, in run\r\n    output=stdout, stderr=stderr)\r\nsubprocess.CalledProcessError: Command '['/home/work/software/cmake-3.22.1-linux-x86_64/bin/cmake', '--build', '/home/work/onnxruntime/build/Linux/Release', '--config', 'Release', '--', '-j24']' returned non-zero exit status 2.\u0012\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: v1.10.0\r\n- Python version: 3.6\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): 7.5\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10244/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10248",
        "id": 1099397267,
        "node_id": "I_kwDOCVq1mM5Bh3iT",
        "number": 10248,
        "title": "Execution Provider bridge for TFLite Delegates for Coral Edge TPUs",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-11T16:44:56Z",
        "updated_at": "2022-12-31T19:38:14Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "ONNX Runtime cannot yet target [Coral](https://coral.ai/) Edge TPU accelerators.\r\n\r\nCoral normally uses Tensorflow Lite with a loadable [TFLite Delegate](https://www.tensorflow.org/lite/performance/delegates) that communicates with the hardware called [libedgetpu](https://github.com/google-coral/libedgetpu).\r\n\r\nIt appears that the goals of ONNX Runtime Execution Providers and TFLite Delegates are similar so perhaps it would be possible to create a wrapper to bridge the APIs ([docs](https://www.tensorflow.org/lite/performance/implementing_delegate)). If such a bridge existed it would be possible to target Edge TPU devices.\r\n\r\nTFLite can also target some of the same accelerators as ONNX Runtime (NNAPI, CoreML, etc.). Having the bridge could also be useful for debugging issues by reproducing them on an alternative code path.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248/reactions",
            "total_count": 4,
            "+1": 4,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10248/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10249",
        "id": 1099411383,
        "node_id": "I_kwDOCVq1mM5Bh6-3",
        "number": 10249,
        "title": "Error when omitting optional inputs within a model local function",
        "user": {
            "login": "jantonguirao",
            "id": 3891217,
            "node_id": "MDQ6VXNlcjM4OTEyMTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3891217?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jantonguirao",
            "html_url": "https://github.com/jantonguirao",
            "followers_url": "https://api.github.com/users/jantonguirao/followers",
            "following_url": "https://api.github.com/users/jantonguirao/following{/other_user}",
            "gists_url": "https://api.github.com/users/jantonguirao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jantonguirao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jantonguirao/subscriptions",
            "organizations_url": "https://api.github.com/users/jantonguirao/orgs",
            "repos_url": "https://api.github.com/users/jantonguirao/repos",
            "events_url": "https://api.github.com/users/jantonguirao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jantonguirao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "gramalingam",
            "id": 10075881,
            "node_id": "MDQ6VXNlcjEwMDc1ODgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/10075881?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gramalingam",
            "html_url": "https://github.com/gramalingam",
            "followers_url": "https://api.github.com/users/gramalingam/followers",
            "following_url": "https://api.github.com/users/gramalingam/following{/other_user}",
            "gists_url": "https://api.github.com/users/gramalingam/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gramalingam/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gramalingam/subscriptions",
            "organizations_url": "https://api.github.com/users/gramalingam/orgs",
            "repos_url": "https://api.github.com/users/gramalingam/repos",
            "events_url": "https://api.github.com/users/gramalingam/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gramalingam/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "gramalingam",
                "id": 10075881,
                "node_id": "MDQ6VXNlcjEwMDc1ODgx",
                "avatar_url": "https://avatars.githubusercontent.com/u/10075881?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gramalingam",
                "html_url": "https://github.com/gramalingam",
                "followers_url": "https://api.github.com/users/gramalingam/followers",
                "following_url": "https://api.github.com/users/gramalingam/following{/other_user}",
                "gists_url": "https://api.github.com/users/gramalingam/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gramalingam/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gramalingam/subscriptions",
                "organizations_url": "https://api.github.com/users/gramalingam/orgs",
                "repos_url": "https://api.github.com/users/gramalingam/repos",
                "events_url": "https://api.github.com/users/gramalingam/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gramalingam/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-11T16:58:59Z",
        "updated_at": "2022-04-08T08:14:53Z",
        "closed_at": "2022-04-08T08:14:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nUsing an operator with not provided optional inputs within a model local function results in an error `\"InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid model. Node input '0x2464d70' is not a graph input, initializer, or output of a previous node.\"`\r\n\r\n**Urgency**\r\nThis slows down the progress of the experiments regarding the ONNX preprocessing working group.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.3 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\nThis code works:\r\n```\r\nm = parser.parse_model('''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 14, \"local\" : 1 ],\r\n  producer_name: \"test\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"Test preprocessing model\"\r\n>\r\nagraph (float[N] x) => (float[N] x_resized)\r\n{\r\n    k2f = Constant <value = float[1] {2.0}> ()\r\n    x_resized = Resize (x, , k2f)\r\n}\r\n''')\r\n\r\nchecker.check_model(m)\r\n# Save the model to a file\r\nsave(m, 'test_ok.onnx')\r\n\r\nsession = onnxruntime.InferenceSession('test_ok.onnx', None)\r\nresult = session.run([], {'x': np.array([1.0, 2.0, 3.0], dtype=np.float32)})\r\nprint(result)\r\n```\r\nproducing\r\n```\r\n[array([1., 1., 2., 2., 3., 3.], dtype=float32)]\r\n```\r\n\r\nHowever, this code fails:\r\n```\r\nm2 = parser.parse_model('''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 14, \"local\" : 1 ],\r\n  producer_name: \"test\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"test\"\r\n>\r\nagraph (float[N] x) => (float[N] x_resized)\r\n{\r\n    x_resized = local.resize_test (x)\r\n}\r\n\r\n<\r\n  opset_import: [ \"\" : 14, \"local\" : 1 ],\r\n  domain: \"local\",\r\n  doc_string: \"test\"\r\n>\r\nresize_test (x) => (x_resized) {\r\n    k2f = Constant <value = float[1] {2.0}> ()\r\n    x_resized = Resize <mode = \\\"linear\\\"> (x, , k2f)\r\n}\r\n''')\r\nchecker.check_model(m2)\r\n# Save the model to a file\r\nsave(m2, 'test_fail.onnx')\r\n\r\nsession = onnxruntime.InferenceSession('test_fail.onnx', None)\r\nresult = session.run([], {'x': np.array([1.0, 2.0, 3.0], dtype=np.float32)})\r\nprint(result)\r\n```\r\nresulting in the following error:\r\n```\r\nInvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid model. Node input '0x2d3a660' is not a graph input, initializer, or output of a previous node.\r\n```\r\n\r\n**Expected behavior**\r\nBoth models should produce same results\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nN/A",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10249/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10250",
        "id": 1099484511,
        "node_id": "I_kwDOCVq1mM5BiM1f",
        "number": 10250,
        "title": "Error about missing type information when nesting model local functions",
        "user": {
            "login": "jantonguirao",
            "id": 3891217,
            "node_id": "MDQ6VXNlcjM4OTEyMTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3891217?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jantonguirao",
            "html_url": "https://github.com/jantonguirao",
            "followers_url": "https://api.github.com/users/jantonguirao/followers",
            "following_url": "https://api.github.com/users/jantonguirao/following{/other_user}",
            "gists_url": "https://api.github.com/users/jantonguirao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jantonguirao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jantonguirao/subscriptions",
            "organizations_url": "https://api.github.com/users/jantonguirao/orgs",
            "repos_url": "https://api.github.com/users/jantonguirao/repos",
            "events_url": "https://api.github.com/users/jantonguirao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jantonguirao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "gramalingam",
            "id": 10075881,
            "node_id": "MDQ6VXNlcjEwMDc1ODgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/10075881?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gramalingam",
            "html_url": "https://github.com/gramalingam",
            "followers_url": "https://api.github.com/users/gramalingam/followers",
            "following_url": "https://api.github.com/users/gramalingam/following{/other_user}",
            "gists_url": "https://api.github.com/users/gramalingam/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gramalingam/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gramalingam/subscriptions",
            "organizations_url": "https://api.github.com/users/gramalingam/orgs",
            "repos_url": "https://api.github.com/users/gramalingam/repos",
            "events_url": "https://api.github.com/users/gramalingam/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gramalingam/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "gramalingam",
                "id": 10075881,
                "node_id": "MDQ6VXNlcjEwMDc1ODgx",
                "avatar_url": "https://avatars.githubusercontent.com/u/10075881?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gramalingam",
                "html_url": "https://github.com/gramalingam",
                "followers_url": "https://api.github.com/users/gramalingam/followers",
                "following_url": "https://api.github.com/users/gramalingam/following{/other_user}",
                "gists_url": "https://api.github.com/users/gramalingam/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gramalingam/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gramalingam/subscriptions",
                "organizations_url": "https://api.github.com/users/gramalingam/orgs",
                "repos_url": "https://api.github.com/users/gramalingam/repos",
                "events_url": "https://api.github.com/users/gramalingam/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gramalingam/received_events",
                "type": "User",
                "site_admin": false
            },
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-11T18:18:07Z",
        "updated_at": "2022-05-11T07:30:09Z",
        "closed_at": "2022-05-11T07:30:09Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nNesting model local functions results in an error `\"Resolve subgraph failed:This is an invalid model. Model input (x1) does not have type information.\"`\r\n\r\n**Urgency**\r\nThis slows down the progress of the experiments regarding the ONNX preprocessing working group.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.3 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n```\r\nm = parser.parse_model('''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 14, \"local\" : 1],\r\n  producer_name: \"test\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"Test preprocessing model\"\r\n>\r\nagraph (uint8[H, W, C] x) => (uint8[H, W, C] x_processed)\r\n{\r\n    x_processed = local.func(x)\r\n}\r\n\r\n<\r\n  opset_import: [ \"\" : 14 ],\r\n  domain: \"local\",\r\n  doc_string: \"function 1\"\r\n>\r\nf1 (x) => (y) {\r\n    y = Identity(x)\r\n}\r\n\r\n<\r\n  opset_import: [ \"\" : 14 ],\r\n  domain: \"local\",\r\n  doc_string: \"function 2\"\r\n>\r\nf2 (x) => (y) {\r\n    y = Identity(x)\r\n}\r\n\r\n<\r\n  opset_import: [ \"\" : 14, \"local\" : 1 ],\r\n  domain: \"local\",\r\n  doc_string: \"Preprocessing function.\"\r\n>\r\nfunc (x) => (y) {\r\n    x1 = local.f1(x)\r\n    y = local.f2(x1)\r\n}\r\n\r\n''')\r\n\r\nchecker.check_model(m)\r\nsave(m, 'test.onnx')\r\n\r\nsession = onnxruntime.InferenceSession('test.onnx', None)\r\n```\r\n\r\n**Expected behavior**\r\nThe model can be run and the nested model local functions are inlined.\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nN/A",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10250/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10251",
        "id": 1099646377,
        "node_id": "PR_kwDOCVq1mM4w0sNk",
        "number": 10251,
        "title": "remove hardcoded type from inplace reshape",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-11T21:46:45Z",
        "updated_at": "2022-01-12T18:00:35Z",
        "closed_at": "2022-01-12T18:00:35Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10251",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10251",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10251.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10251.patch",
            "merged_at": "2022-01-12T18:00:35Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n\r\nThis is required for invoking reshape on tensors of types that are not int64 (e.g `torch.float32`).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10251/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10252",
        "id": 1099713849,
        "node_id": "PR_kwDOCVq1mM4w06Ub",
        "number": 10252,
        "title": "orttraining packaging and ci pipelines to use cuda 11.3",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-11T23:30:53Z",
        "updated_at": "2022-01-13T21:36:55Z",
        "closed_at": "2022-01-13T21:36:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10252",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10252",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10252.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10252.patch",
            "merged_at": "2022-01-13T21:36:33Z"
        },
        "body": "Run orttraining and ortmodule CI pipeline on cuda 11.3.\r\nFix a typo in the cuda 11.3 python packaging docker file.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10252/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10253",
        "id": 1099844208,
        "node_id": "I_kwDOCVq1mM5Bjkpw",
        "number": 10253,
        "title": "Cannot load ort model for onnxruntime-react-native",
        "user": {
            "login": "realphongha",
            "id": 34178149,
            "node_id": "MDQ6VXNlcjM0MTc4MTQ5",
            "avatar_url": "https://avatars.githubusercontent.com/u/34178149?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/realphongha",
            "html_url": "https://github.com/realphongha",
            "followers_url": "https://api.github.com/users/realphongha/followers",
            "following_url": "https://api.github.com/users/realphongha/following{/other_user}",
            "gists_url": "https://api.github.com/users/realphongha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/realphongha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/realphongha/subscriptions",
            "organizations_url": "https://api.github.com/users/realphongha/orgs",
            "repos_url": "https://api.github.com/users/realphongha/repos",
            "events_url": "https://api.github.com/users/realphongha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/realphongha/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "hanbitmyths",
                "id": 35605090,
                "node_id": "MDQ6VXNlcjM1NjA1MDkw",
                "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hanbitmyths",
                "html_url": "https://github.com/hanbitmyths",
                "followers_url": "https://api.github.com/users/hanbitmyths/followers",
                "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
                "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
                "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
                "repos_url": "https://api.github.com/users/hanbitmyths/repos",
                "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-12T03:45:58Z",
        "updated_at": "2022-01-14T07:34:54Z",
        "closed_at": "2022-01-14T07:34:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nI have a .onnx model file and successfully converted it to .ort format using:\r\n```python -m onnxruntime.tools.convert_onnx_models_to_ort model.onnx```\r\nWhen I tried to create inference session with InferenceSession.create(\"model.ort\"), I got an error: \r\n```Error: Can't load a model: Can't create InferenceSession```, but it works perfectly fine with the example ort file from js/react_native/example/src/mnist.ort:\r\n```Session: {\"handler\": {\"inputNames\": [\"flatten_2_input\"], \"outputNames\": [\"Identity\"]}}```\r\n\r\nHow to make it work?\r\nThanks!\r\n\r\n**System information**\r\n- OS Platform and Distribution: Android 10 \r\n- ONNX Runtime installed from (source or binary): yarn add onnxruntime-react-native\r\n- ONNX Runtime version: 1.8.1\r\n- React Native version: 0.66.4\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10253/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10254",
        "id": 1099846113,
        "node_id": "PR_kwDOCVq1mM4w1ULv",
        "number": 10254,
        "title": "Move binary size check to separate pipeline",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-12T03:50:32Z",
        "updated_at": "2022-01-13T03:21:21Z",
        "closed_at": "2022-01-13T03:21:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10254",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10254",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10254.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10254.patch",
            "merged_at": "2022-01-13T03:21:20Z"
        },
        "body": "**Description**\r\nMove binary size check(s) to a separate pipeline. In the future, other binary size-related builds can go here.\r\nAdd publishing of build artifacts for easier analysis.\r\nAdd optional build with debug info.\r\n\r\nExample build: https://dev.azure.com/onnxruntime/onnxruntime/_build/results?buildId=564634&view=results\r\n\r\n**Motivation and Context**\r\nMake it easier (and faster, without all the other builds from the original pipeline) to get binary size builds to analyze.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10254/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10255",
        "id": 1099856527,
        "node_id": "PR_kwDOCVq1mM4w1WMt",
        "number": 10255,
        "title": "Vish/beam search prefix matching",
        "user": {
            "login": "viboga",
            "id": 44417868,
            "node_id": "MDQ6VXNlcjQ0NDE3ODY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/44417868?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viboga",
            "html_url": "https://github.com/viboga",
            "followers_url": "https://api.github.com/users/viboga/followers",
            "following_url": "https://api.github.com/users/viboga/following{/other_user}",
            "gists_url": "https://api.github.com/users/viboga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viboga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viboga/subscriptions",
            "organizations_url": "https://api.github.com/users/viboga/orgs",
            "repos_url": "https://api.github.com/users/viboga/repos",
            "events_url": "https://api.github.com/users/viboga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viboga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-12T04:12:03Z",
        "updated_at": "2022-01-12T04:13:54Z",
        "closed_at": "2022-01-12T04:13:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10255",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10255",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10255.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10255.patch",
            "merged_at": null
        },
        "body": "**Description**: This PR targets required changes to allow prefix matching in beam search OP.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nIn generative models, prefix of the last word needs to be matched with the first word being generated.\r\n\r\n- If it fixes an open issue, please link to the issue here.\r\nNA\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10255/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10256",
        "id": 1099894220,
        "node_id": "PR_kwDOCVq1mM4w1dsw",
        "number": 10256,
        "title": "check check",
        "user": {
            "login": "viboga",
            "id": 44417868,
            "node_id": "MDQ6VXNlcjQ0NDE3ODY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/44417868?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viboga",
            "html_url": "https://github.com/viboga",
            "followers_url": "https://api.github.com/users/viboga/followers",
            "following_url": "https://api.github.com/users/viboga/following{/other_user}",
            "gists_url": "https://api.github.com/users/viboga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viboga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viboga/subscriptions",
            "organizations_url": "https://api.github.com/users/viboga/orgs",
            "repos_url": "https://api.github.com/users/viboga/repos",
            "events_url": "https://api.github.com/users/viboga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viboga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-12T05:24:59Z",
        "updated_at": "2022-01-12T11:28:02Z",
        "closed_at": "2022-01-12T11:28:02Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10256",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10256",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10256.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10256.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10256/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10257",
        "id": 1099969280,
        "node_id": "I_kwDOCVq1mM5BkDMA",
        "number": 10257,
        "title": "how to use docker and onnxruntime deploy onnx model on GPU?",
        "user": {
            "login": "expresschen",
            "id": 18161256,
            "node_id": "MDQ6VXNlcjE4MTYxMjU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/18161256?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/expresschen",
            "html_url": "https://github.com/expresschen",
            "followers_url": "https://api.github.com/users/expresschen/followers",
            "following_url": "https://api.github.com/users/expresschen/following{/other_user}",
            "gists_url": "https://api.github.com/users/expresschen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/expresschen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/expresschen/subscriptions",
            "organizations_url": "https://api.github.com/users/expresschen/orgs",
            "repos_url": "https://api.github.com/users/expresschen/repos",
            "events_url": "https://api.github.com/users/expresschen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/expresschen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-12T07:22:17Z",
        "updated_at": "2022-08-12T08:39:25Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10257/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10258",
        "id": 1100007290,
        "node_id": "PR_kwDOCVq1mM4w10Vg",
        "number": 10258,
        "title": "[WIP] ORT branch for microbench run.",
        "user": {
            "login": "pengwa",
            "id": 10530022,
            "node_id": "MDQ6VXNlcjEwNTMwMDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10530022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pengwa",
            "html_url": "https://github.com/pengwa",
            "followers_url": "https://api.github.com/users/pengwa/followers",
            "following_url": "https://api.github.com/users/pengwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/pengwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pengwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pengwa/subscriptions",
            "organizations_url": "https://api.github.com/users/pengwa/orgs",
            "repos_url": "https://api.github.com/users/pengwa/repos",
            "events_url": "https://api.github.com/users/pengwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pengwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-12T08:09:40Z",
        "updated_at": "2023-04-11T11:37:05Z",
        "closed_at": "2022-04-15T03:14:24Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10258",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10258",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10258.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10258.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10258/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10259",
        "id": 1100025284,
        "node_id": "I_kwDOCVq1mM5BkQ3E",
        "number": 10259,
        "title": "extract_model fails when the model contains a model local function",
        "user": {
            "login": "jantonguirao",
            "id": 3891217,
            "node_id": "MDQ6VXNlcjM4OTEyMTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3891217?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jantonguirao",
            "html_url": "https://github.com/jantonguirao",
            "followers_url": "https://api.github.com/users/jantonguirao/followers",
            "following_url": "https://api.github.com/users/jantonguirao/following{/other_user}",
            "gists_url": "https://api.github.com/users/jantonguirao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jantonguirao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jantonguirao/subscriptions",
            "organizations_url": "https://api.github.com/users/jantonguirao/orgs",
            "repos_url": "https://api.github.com/users/jantonguirao/repos",
            "events_url": "https://api.github.com/users/jantonguirao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jantonguirao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-12T08:26:43Z",
        "updated_at": "2022-01-12T16:20:40Z",
        "closed_at": "2022-01-12T16:20:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n`extract_model` fails on models containing a model local function call in the graph.\r\n\r\nThere is a warning about the local function being an unsupported op (only during the extract_model call), then there is a key error when looking for one of the edges in the graph (see details in the reproduction steps).\r\n\r\n**Urgency**\r\nThis slows down the progress of the experiments regarding the ONNX preprocessing working group.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.3 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n```\r\nimport onnx\r\nimport onnx.checker as checker\r\nimport onnx.parser as parser\r\nfrom onnx import save\r\nimport onnxruntime\r\n\r\nm = parser.parse_model('''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 14, \"local\" : 1],\r\n  producer_name: \"test\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"Test\"\r\n>\r\nagraph (uint8[H, W, C] x) => (uint8[H, W, C] y)\r\n{\r\n    x1 = local.func(x)\r\n    y = Identity(x1)\r\n}\r\n\r\n<\r\n  opset_import: [ \"\" : 14 ],\r\n  domain: \"local\",\r\n  doc_string: \"test\"\r\n>\r\nfunc (a) => (b)\r\n{\r\n    b = Identity(a)\r\n}\r\n''')\r\n\r\nchecker.check_model(m)\r\nsave(m, 'extract_model_bug.onnx')\r\nextracted = onnx.utils.Extractor(m).extract_model(['x1'], ['y'])\r\n```\r\n\r\n```\r\nWarning: Unsupported operator func. No schema registered for this operator.\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n/tmp/ipykernel_3936245/4281959894.py in <module>\r\n     33 checker.check_model(m)\r\n     34 save(m, 'extract_model_bug.onnx')\r\n---> 35 extracted = onnx.utils.Extractor(m).extract_model(['x1'], ['y'])\r\n     36 session = onnxruntime.InferenceSession('extract_model_bug.onnx', None)\r\n\r\n~/git/onnx/onnx/utils.py in extract_model(self, input_names, output_names)\r\n    121             output_names,  # type: List[Text]\r\n    122     ):  # type: (...) -> ModelProto\r\n--> 123         inputs = self._collect_new_inputs(input_names)\r\n    124         outputs = self._collect_new_outputs(output_names)\r\n    125         nodes = self._collect_reachable_nodes(input_names, output_names)\r\n\r\n~/git/onnx/onnx/utils.py in _collect_new_inputs(self, names)\r\n     46 \r\n     47     def _collect_new_inputs(self, names):  # type: (List[Text]) -> List[ValueInfoProto]\r\n---> 48         return self._collect_new_io_core(self.graph.input, names)  # type: ignore\r\n     49 \r\n     50     def _collect_new_outputs(self, names):  # type: (List[Text]) -> List[ValueInfoProto]\r\n\r\n~/git/onnx/onnx/utils.py in _collect_new_io_core(self, original_io, io_names_to_extract)\r\n     39         for name in new_io_names_to_add:\r\n     40             # activation become input or output\r\n---> 41             new_io_tensors.append(self.vimap[name])\r\n     42 \r\n     43         # adjust sequence\r\n\r\nKeyError: 'x1'\r\n\r\n```\r\n\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n[extract_model_bug.zip](https://github.com/microsoft/onnxruntime/files/7852857/extract_model_bug.zip)\r\n\r\n**Expected behavior**\r\nThe extract_model call succeeds and a model containing the subgraph is extracted.\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nN/A",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10259/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10260",
        "id": 1100171957,
        "node_id": "PR_kwDOCVq1mM4w2Wyf",
        "number": 10260,
        "title": "[TVM EP] Rename Standalone TVM (STVM) Execution Provider to TVM EP",
        "user": {
            "login": "vvchernov",
            "id": 28704584,
            "node_id": "MDQ6VXNlcjI4NzA0NTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/28704584?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vvchernov",
            "html_url": "https://github.com/vvchernov",
            "followers_url": "https://api.github.com/users/vvchernov/followers",
            "following_url": "https://api.github.com/users/vvchernov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vvchernov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vvchernov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vvchernov/subscriptions",
            "organizations_url": "https://api.github.com/users/vvchernov/orgs",
            "repos_url": "https://api.github.com/users/vvchernov/repos",
            "events_url": "https://api.github.com/users/vvchernov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vvchernov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 50,
        "created_at": "2022-01-12T10:37:16Z",
        "updated_at": "2022-02-25T08:49:30Z",
        "closed_at": "2022-02-15T09:21:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10260",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10260",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10260.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10260.patch",
            "merged_at": "2022-02-15T09:21:03Z"
        },
        "body": "Rename all mentions of STVM to TVM in the onnx runtime codebase.\r\n\r\nCorrections were done after [PR#10241](https://github.com/microsoft/onnxruntime/pull/10241) and [PR#10211](https://github.com/microsoft/onnxruntime/pull/10211) were merged.\r\n\r\nNotes:\r\n1. Nuphar and TVM EPs building were separated in build and cmake files for convenient further work.\r\n2. New key is used for build TVM EP +Cuda to avoid confusion with CUDA EP. Adding the new key is associated with the following `--use_cuda` usage issues:\r\nUsing the `--use_cuda flag` means that when building a project, you need to build CUDA EP. This is not the right approach if we only want to work with TVM EP. Building CUDA EP is a separate flow that requires its own nuances and dependencies, which are redundant if we only need TVM EP.\r\nAt the `build.py` script level, there are checks for `--cuda_home` and `--cudnn_home` flags, which are not needed for TVM. Also, setting the `--use_cuda` flag turns on a lot of additional logic when running build.py that is not needed for the TVM EP. In order to disable this additional logic, it is necessary to extend conditions if `args.use_cuda`: to if `args.use_cuda` and not `args.use_tvm` in many places. This is not conceptually correct, since these changes for TVM EP need to be made in methods that are specific to CUDA EP.\r\nAdditionally, there are problems using TVM EP via PYTHONPATH and the wheel package. This is because setup.py only supports one EP at a time. If we set `--use_cuda` and `--use_tvm` flags, then only one wheel package for CUDA EP will be built, because this is how the logic of working with providers in `setup.py` is arranged. Also, the condition for the `_ld_preload.py` extension for TVM EP will not be fulfilled, with the help of which the\r\n3. If input shapes are unset and dynamic the ONNX runtime error is raised instead of warning and automatical inferred of dynamic dimension to 1.\r\n4. There are two independent structures with the same name (TVMFuncState) in TVM EP internal code and in tests for TVM prepared by NUPHAR.\r\n\r\nHello @xadupre, can you recheck our updates after your PR?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10260/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10261",
        "id": 1100245688,
        "node_id": "PR_kwDOCVq1mM4w2mXi",
        "number": 10261,
        "title": "quantization tools: change num_bins default value",
        "user": {
            "login": "xusworld",
            "id": 13519244,
            "node_id": "MDQ6VXNlcjEzNTE5MjQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13519244?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xusworld",
            "html_url": "https://github.com/xusworld",
            "followers_url": "https://api.github.com/users/xusworld/followers",
            "following_url": "https://api.github.com/users/xusworld/following{/other_user}",
            "gists_url": "https://api.github.com/users/xusworld/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xusworld/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xusworld/subscriptions",
            "organizations_url": "https://api.github.com/users/xusworld/orgs",
            "repos_url": "https://api.github.com/users/xusworld/repos",
            "events_url": "https://api.github.com/users/xusworld/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xusworld/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-12T11:47:08Z",
        "updated_at": "2022-08-10T00:46:27Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10261",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10261",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10261.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10261.patch",
            "merged_at": null
        },
        "body": "If you set `num_bins = 128` in `create_calibrator`,  then in `get_entropy_threshold` method, \r\n\r\n```\r\ndef get_entropy_threshold(self, histogram, num_quantized_bins):\r\n        ...\r\n        # num_half_quantized_bin = 64, zero_bin_index = 64\r\n        for i in range(num_half_quantized_bin, zero_bin_index + 1, num_half_quantized_bin):\r\n        ...\r\n```\r\nboth `num_half_quantized_bin` and `zero_bin_index `will equals to 64, this loop will execute only once, which is **obviously incorrect**",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10261/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10262",
        "id": 1100657281,
        "node_id": "PR_kwDOCVq1mM4w3730",
        "number": 10262,
        "title": "[WIP] Expose tp handle to custom op",
        "user": {
            "login": "RandySheriffH",
            "id": 48490400,
            "node_id": "MDQ6VXNlcjQ4NDkwNDAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/48490400?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RandySheriffH",
            "html_url": "https://github.com/RandySheriffH",
            "followers_url": "https://api.github.com/users/RandySheriffH/followers",
            "following_url": "https://api.github.com/users/RandySheriffH/following{/other_user}",
            "gists_url": "https://api.github.com/users/RandySheriffH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RandySheriffH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RandySheriffH/subscriptions",
            "organizations_url": "https://api.github.com/users/RandySheriffH/orgs",
            "repos_url": "https://api.github.com/users/RandySheriffH/repos",
            "events_url": "https://api.github.com/users/RandySheriffH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RandySheriffH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-12T18:25:27Z",
        "updated_at": "2022-08-10T00:46:27Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10262",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10262",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10262.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10262.patch",
            "merged_at": null
        },
        "body": "This is a prototype exploring ways to expose the thread pool handle to custom ops.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10262/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10263",
        "id": 1100681517,
        "node_id": "PR_kwDOCVq1mM4w4Awr",
        "number": 10263,
        "title": "Bump numpy from 1.19.2 to 1.21.0 in /tools/ci_build",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-12T18:52:57Z",
        "updated_at": "2022-01-13T01:45:36Z",
        "closed_at": "2022-01-13T01:45:36Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10263",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10263",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10263.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10263.patch",
            "merged_at": "2022-01-13T01:45:35Z"
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.19.2 to 1.21.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.21.0</h2>\n<h1>NumPy 1.21.0 Release Notes</h1>\n<p>The NumPy 1.21.0 release highlights are</p>\n<ul>\n<li>continued SIMD work covering more functions and platforms,</li>\n<li>initial work on the new dtype infrastructure and casting,</li>\n<li>universal2 wheels for Python 3.8 and Python 3.9 on Mac,</li>\n<li>improved documentation,</li>\n<li>improved annotations,</li>\n<li>new <code>PCG64DXSM</code> bitgenerator for random numbers.</li>\n</ul>\n<p>In addition there are the usual large number of bug fixes and other\nimprovements.</p>\n<p>The Python versions supported for this release are 3.7-3.9. Official\nsupport for Python 3.10 will be added when it is released.</p>\n<p>:warning:  Warning: there are unresolved problems compiling NumPy 1.21.0 with gcc-11.1 .</p>\n<ul>\n<li>Optimization level <code>-O3</code> results in many wrong warnings when running the tests.</li>\n<li>On some hardware NumPy will hang in an infinite loop.</li>\n</ul>\n<h2>New functions</h2>\n<h3>Add PCG64DXSM BitGenerator</h3>\n<p>Uses of the PCG64 BitGenerator in a massively-parallel context have\nbeen shown to have statistical weaknesses that were not apparent at the\nfirst release in numpy 1.17. Most users will never observe this weakness\nand are safe to continue to use PCG64. We have introduced a new\nPCG64DXSM BitGenerator that will eventually become the new default\nBitGenerator implementation used by <code>default_rng</code> in future releases.\nPCG64DXSM solves the statistical weakness while preserving the\nperformance and the features of PCG64.</p>\n<p>See <code>upgrading-pcg64</code> for more details.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/18906\">gh-18906</a>)</p>\n<h2>Expired deprecations</h2>\n<ul>\n<li>The <code>shape</code> argument <code>numpy.unravel_index</code> cannot be\npassed as <code>dims</code> keyword argument anymore. (Was deprecated in NumPy\n1.16.)</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/b235f9e701e14ed6f6f6dcba885f7986a833743f\"><code>b235f9e</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/19283\">#19283</a> from charris/prepare-1.21.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/34aebc2824cf8c2bdbe19040b82f98f18557c8ba\"><code>34aebc2</code></a> MAINT: Update 1.21.0-notes.rst</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/493b64bfe9c5396498325b87e5e80e1917555c41\"><code>493b64b</code></a> MAINT: Update 1.21.0-changelog.rst</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/07d7e72ab6880c05b5fdd98482cf88982e778393\"><code>07d7e72</code></a> MAINT: Remove accidentally created directory.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/032fca5e2e9749b152ec56153f476e05efdff287\"><code>032fca5</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/19280\">#19280</a> from charris/backport-19277</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7d25b81025a50cc0368f5727c65e875ca769469a\"><code>7d25b81</code></a> BUG: Fix refcount leak in ResultType</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fa5754e8c159a37fcd9345df261cf82821088ea0\"><code>fa5754e</code></a> BUG: Add missing DECREF in new path</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/61127bb4d46d523b699da1b63abaa5035670da27\"><code>61127bb</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/19268\">#19268</a> from charris/backport-19264</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/143d45fff3ed9e051bdeef7bdb4df38025ea7d1c\"><code>143d45f</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/19269\">#19269</a> from charris/backport-19228</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d80e4738f781a1d206bbc04a2e863299e5f2e104\"><code>d80e473</code></a> BUG: Removed typing for == and != in dtypes</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.19.2...v1.21.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.19.2&new-version=1.21.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10263/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10264",
        "id": 1100964140,
        "node_id": "PR_kwDOCVq1mM4w48qG",
        "number": 10264,
        "title": "Add orttraining rocm 4.5 package",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T00:43:16Z",
        "updated_at": "2022-03-02T20:33:26Z",
        "closed_at": "2022-03-02T20:33:22Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10264",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10264",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10264.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10264.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10264/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10265",
        "id": 1101028469,
        "node_id": "PR_kwDOCVq1mM4w5K8Z",
        "number": 10265,
        "title": "Bump follow-redirects from 1.14.5 to 1.14.7 in /js/node",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-13T01:46:08Z",
        "updated_at": "2022-01-13T17:03:42Z",
        "closed_at": "2022-01-13T17:03:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10265",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10265",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10265.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10265.patch",
            "merged_at": "2022-01-13T17:03:41Z"
        },
        "body": "Bumps [follow-redirects](https://github.com/follow-redirects/follow-redirects) from 1.14.5 to 1.14.7.\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/2ede36d7c60d3acdcd324dcd99a9dbd52e4fb3a6\"><code>2ede36d</code></a> Release version 1.14.7 of the npm package.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/8b347cbcef7c7b72a6e9be20f5710c17d6163c22\"><code>8b347cb</code></a> Drop Cookie header across domains.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/6f5029ae1a0fdab4dc25f6379a5ee303c2319070\"><code>6f5029a</code></a> Release version 1.14.6 of the npm package.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/af706bee57de954414c0bde0a9f33e62beea3e52\"><code>af706be</code></a> Ignore null headers.</li>\n<li>See full diff in <a href=\"https://github.com/follow-redirects/follow-redirects/compare/v1.14.5...v1.14.7\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.5&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10265/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10266",
        "id": 1101028754,
        "node_id": "PR_kwDOCVq1mM4w5LAW",
        "number": 10266,
        "title": "Bump follow-redirects from 1.13.3 to 1.14.7 in /js/web",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-13T01:46:26Z",
        "updated_at": "2022-01-13T17:05:23Z",
        "closed_at": "2022-01-13T17:05:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10266",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10266",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10266.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10266.patch",
            "merged_at": "2022-01-13T17:05:22Z"
        },
        "body": "Bumps [follow-redirects](https://github.com/follow-redirects/follow-redirects) from 1.13.3 to 1.14.7.\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/2ede36d7c60d3acdcd324dcd99a9dbd52e4fb3a6\"><code>2ede36d</code></a> Release version 1.14.7 of the npm package.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/8b347cbcef7c7b72a6e9be20f5710c17d6163c22\"><code>8b347cb</code></a> Drop Cookie header across domains.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/6f5029ae1a0fdab4dc25f6379a5ee303c2319070\"><code>6f5029a</code></a> Release version 1.14.6 of the npm package.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/af706bee57de954414c0bde0a9f33e62beea3e52\"><code>af706be</code></a> Ignore null headers.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/d01ab7a5c5df3617c7a40a03de7af6427fdfac55\"><code>d01ab7a</code></a> Release version 1.14.5 of the npm package.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/40052ea8aa13559becee5795715c1d45b1f0eb76\"><code>40052ea</code></a> Make compatible with Node 17.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/86f7572f9365dadc39f85916259b58973819617f\"><code>86f7572</code></a> Fix: clear internal timer on request abort to avoid leakage</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/2e1eaf0218c5315a2ab27f53964d0535d4dafb51\"><code>2e1eaf0</code></a> Keep Authorization header on subdomain redirects.</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/2ad9e82b6277ae2104f7770e9ff1186cc6da29d4\"><code>2ad9e82</code></a> Carry over Host header on relative redirects (<a href=\"https://github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172\">#172</a>)</li>\n<li><a href=\"https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488\"><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>\n<li>Additional commits viewable in <a href=\"https://github.com/follow-redirects/follow-redirects/compare/v1.13.3...v1.14.7\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.13.3&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10266/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10267",
        "id": 1101088172,
        "node_id": "I_kwDOCVq1mM5BoUWs",
        "number": 10267,
        "title": "much slower in GPU after quantization",
        "user": {
            "login": "Hap-Zhang",
            "id": 32810063,
            "node_id": "MDQ6VXNlcjMyODEwMDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32810063?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Hap-Zhang",
            "html_url": "https://github.com/Hap-Zhang",
            "followers_url": "https://api.github.com/users/Hap-Zhang/followers",
            "following_url": "https://api.github.com/users/Hap-Zhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/Hap-Zhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Hap-Zhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Hap-Zhang/subscriptions",
            "organizations_url": "https://api.github.com/users/Hap-Zhang/orgs",
            "repos_url": "https://api.github.com/users/Hap-Zhang/repos",
            "events_url": "https://api.github.com/users/Hap-Zhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Hap-Zhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-13T02:43:35Z",
        "updated_at": "2022-01-14T02:10:15Z",
        "closed_at": "2022-01-14T02:10:14Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,all\r\n\r\nI quantized a bert-base model to int8 by quantize_dynamic, the command listed as follows:\r\n```\r\nonnx_model_path = \"model.onnx\"\r\nquantized_model_path = onnx_model_path + \"-quantized\"\r\nquantize_dynamic(onnx_model_path, quantized_model_path)\r\n```\r\n\r\nThe original model size:388M\r\nThe quantized model size:98M\r\n\r\nThe reference time in CPU reduced from 259ms to 204ms.However, it increased from 12ms to 232ms. It seems that the GPU（V100） is not successfully used in the background and fp16 is ok with same code. The inference command listed as follows:\r\n```\r\n#onnx_fp16_path = \"model_fp16.onnx\"\r\nonnx_int8_path = \"model.onnx-quantized\"\r\nopt_so = rt.SessionOptions()\r\nopt_so.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nopt_session = rt.InferenceSession(onnx_int8_path, opt_so, ['CUDAExecutionProvider'])\r\ninputs_onnx_op = {'input_ids': input_ids.cpu().numpy(), 'attention_mask': attention_mask.cpu().numpy(), 'token_type_ids': token_type_ids.cpu().numpy()}\r\nopt_onnx_outputs = opt_session.run(None, inputs_onnx_op)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10267/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10268",
        "id": 1101199778,
        "node_id": "PR_kwDOCVq1mM4w5xfS",
        "number": 10268,
        "title": "fix mac compilation error",
        "user": {
            "login": "chenfucn",
            "id": 1316708,
            "node_id": "MDQ6VXNlcjEzMTY3MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1316708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chenfucn",
            "html_url": "https://github.com/chenfucn",
            "followers_url": "https://api.github.com/users/chenfucn/followers",
            "following_url": "https://api.github.com/users/chenfucn/following{/other_user}",
            "gists_url": "https://api.github.com/users/chenfucn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chenfucn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chenfucn/subscriptions",
            "organizations_url": "https://api.github.com/users/chenfucn/orgs",
            "repos_url": "https://api.github.com/users/chenfucn/repos",
            "events_url": "https://api.github.com/users/chenfucn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chenfucn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-13T04:43:11Z",
        "updated_at": "2022-01-18T16:09:33Z",
        "closed_at": "2022-01-18T16:09:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10268",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10268",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10268.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10268.patch",
            "merged_at": "2022-01-18T16:09:28Z"
        },
        "body": "**Description**: Describe your changes.\r\nFix Mac compilation error in new cpuinfo changes\r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10268/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10270",
        "id": 1101288320,
        "node_id": "I_kwDOCVq1mM5BpFOA",
        "number": 10270,
        "title": "Inconsistent inference timing on CPU ",
        "user": {
            "login": "jamjambles",
            "id": 22167615,
            "node_id": "MDQ6VXNlcjIyMTY3NjE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/22167615?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamjambles",
            "html_url": "https://github.com/jamjambles",
            "followers_url": "https://api.github.com/users/jamjambles/followers",
            "following_url": "https://api.github.com/users/jamjambles/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamjambles/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamjambles/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamjambles/subscriptions",
            "organizations_url": "https://api.github.com/users/jamjambles/orgs",
            "repos_url": "https://api.github.com/users/jamjambles/repos",
            "events_url": "https://api.github.com/users/jamjambles/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamjambles/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-13T07:01:07Z",
        "updated_at": "2022-08-12T08:46:27Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI am deploying a model using ONNXRuntime on CPU. It is in an environment with a hard real-time budget of 20ms. The average inference time of the model is ~2ms. I have observed that sometimes the model inference time spikes to >> 20ms which is not acceptable in the deployment environment. More generally there is quite a lot of variance between inference calls in terms of timing which is also a concern. \r\n\r\n**System information**\r\n- Mac OSX 10.15.7\r\n- Processor: 2.4 GHz 8-Core Intel Core i9\r\n- ONNX Runtime version: 1.10.2\r\n- Python version: 3.8.12\r\n\r\n**Additional context**\r\nThese are the session options used to initialise the ORT inference session\r\n```\r\n    sess_options = onnxruntime.SessionOptions()\r\n    sess_options.intra_op_num_threads = 1\r\n    sess_options.inter_op_num_threads = 1\r\n    sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\r\n    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n```\r\n\r\nBelow is an example of inference times per inference call. This shows the inconsistent inference timing and spikes:\r\n![image](https://user-images.githubusercontent.com/22167615/149280014-7e701524-f2b1-485c-a5bc-1483cd7235de.png)\r\nHere is a trace using the profiling tool from onnxruntime, again we can see where the inference locks-up causing a spike:\r\n![image](https://user-images.githubusercontent.com/22167615/149280595-81339285-8223-473b-9d2b-f2da37ee8bd7.png)\r\n\r\nI am looking to learn whether onnxruntime is appropriate for such a use-case. Are there any other options or configurations to ensure stability in inference time? \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10270/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10271",
        "id": 1101375225,
        "node_id": "I_kwDOCVq1mM5Bpab5",
        "number": 10271,
        "title": "Inference: Time in GPU is similar in CPU. GPU not speed up",
        "user": {
            "login": "Tian14267",
            "id": 27938135,
            "node_id": "MDQ6VXNlcjI3OTM4MTM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/27938135?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Tian14267",
            "html_url": "https://github.com/Tian14267",
            "followers_url": "https://api.github.com/users/Tian14267/followers",
            "following_url": "https://api.github.com/users/Tian14267/following{/other_user}",
            "gists_url": "https://api.github.com/users/Tian14267/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Tian14267/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Tian14267/subscriptions",
            "organizations_url": "https://api.github.com/users/Tian14267/orgs",
            "repos_url": "https://api.github.com/users/Tian14267/repos",
            "events_url": "https://api.github.com/users/Tian14267/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Tian14267/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-13T08:36:22Z",
        "updated_at": "2022-08-12T08:39:28Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**GPU not speed up**\r\nWhen I use onnxruntime-gpu to speed up in GPU, I get similar time in CPU. And when I use GPU, GPU memory only use 900Mib, but CPU usage rate increase to 1800%.\r\nHow does it happend ?\r\n\r\n**My code**\r\n```\r\nort_session_acoustic_model = onnxruntime.InferenceSession(\"./FastSpeech.onnx\",providers=['CUDAExecutionProvider'])\r\nort_inputs = {\r\n\t\t\t'speakers': batch[2].cpu().numpy(),\r\n\t\t\t'texts': batch[3].cpu().numpy(),\r\n\t\t\t'src_lens.1': batch[4].cpu().numpy(),\r\n\t\t\t'max_src_len': dummy_input_4.cpu().numpy()\r\n\t\t}\r\noutput = ort_session_acoustic_model.run(None, ort_inputs)\r\n```\r\n\r\n**Versions**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  CentOS 7.9.2009\r\n- ONNX Runtime installed from (source or binary): pip install onnxruntime-gpu==1.9.0\r\n- ONNX Runtime version: 1.9.0\r\n- Python version: 3.6\r\n- GCC/Compiler version (if compiling from source):  gcc version 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC)\r\n- CUDA/cuDNN version: CUDA 11.2\r\n- GPU model and memory:  Tesla P100\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10271/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10272",
        "id": 1101402737,
        "node_id": "PR_kwDOCVq1mM4w6cnb",
        "number": 10272,
        "title": "Fix ATenOp Memory Leak",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T09:03:22Z",
        "updated_at": "2022-01-14T06:54:20Z",
        "closed_at": "2022-01-14T06:54:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10272",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10272",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10272.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10272.patch",
            "merged_at": "2022-01-14T06:54:20Z"
        },
        "body": "Fix a memory leak when calling ATenOp with non-tensor arguments. Previous implementation gets the non-tensor values from DLManagedTensor* dlpack directly. But dlpack's deleter relies on destruction of torch tensor created from it. So if we don't generate a torch tensor from a dlpack, it will be leaked.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10272/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10273",
        "id": 1101424912,
        "node_id": "I_kwDOCVq1mM5BpmkQ",
        "number": 10273,
        "title": "multiple InferenceSession slowdown inference speed",
        "user": {
            "login": "jayden333",
            "id": 31834261,
            "node_id": "MDQ6VXNlcjMxODM0MjYx",
            "avatar_url": "https://avatars.githubusercontent.com/u/31834261?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jayden333",
            "html_url": "https://github.com/jayden333",
            "followers_url": "https://api.github.com/users/jayden333/followers",
            "following_url": "https://api.github.com/users/jayden333/following{/other_user}",
            "gists_url": "https://api.github.com/users/jayden333/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jayden333/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jayden333/subscriptions",
            "organizations_url": "https://api.github.com/users/jayden333/orgs",
            "repos_url": "https://api.github.com/users/jayden333/repos",
            "events_url": "https://api.github.com/users/jayden333/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jayden333/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 13,
        "created_at": "2022-01-13T09:23:22Z",
        "updated_at": "2023-03-09T19:30:01Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nMultiple InferenceSession slowdown inference speed\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux centos 7\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: python3.6.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n\r\nuse this script, when` run_single_sess()`, average time is 31ms, when `run_two_sess()`, average time is 46ms\r\nmodel is download from https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny-yolov2\r\ncpu info: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz, 10 cores for my docker container\r\n\r\n```python\r\nimport time\r\nimport numpy as np\r\nimport onnxruntime as ort\r\n\r\nmodel_path = \"ft_local/tinyyolov2-8.onnx\"\r\n\r\ndef run_two_sess():\r\n    ort_sess1 = ort.InferenceSession(model_path)\r\n    ort_sess2 = ort.InferenceSession(model_path)\r\n    \r\n    warm_up_count = 5\r\n    for i in range(warm_up_count):\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        ort_sess1.run(None, {ort_sess1._inputs_meta[0].name: x})\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        ort_sess2.run(None, {ort_sess2._inputs_meta[0].name: x})\r\n    \r\n    count = 100\r\n    start_total = time.time()\r\n    for i in range(count):\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        start = time.time()\r\n        ort_sess1.run(None, {ort_sess1._inputs_meta[0].name: x})\r\n        print(f\"p1 consumed: {(time.time() - start)*1000}\")\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        start = time.time()\r\n        ort_sess2.run(None, {ort_sess2._inputs_meta[0].name: x})\r\n        print(f\"p2 consumed: {(time.time() - start)*1000}\")\r\n    end_total = time.time()\r\n    print(f\"average time: {(end_total - start_total)*1000/count/2}\")\r\n\r\ndef run_single_sess():\r\n    ort_sess1 = ort.InferenceSession(model_path)\r\n    \r\n    warm_up_count = 5\r\n    for i in range(warm_up_count):\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        ort_sess1.run(None, {ort_sess1._inputs_meta[0].name: x})\r\n    \r\n    count = 100\r\n    start_total = time.time()\r\n    for i in range(count):\r\n        x = np.random.rand(1, 3, 416, 416).astype(\"float32\")\r\n        start = time.time()\r\n        ort_sess1.run(None, {ort_sess1._inputs_meta[0].name: x})\r\n        print(f\"p1 consumed: {(time.time() - start)*1000}\")\r\n    end_total = time.time()\r\n    print(f\"average time: {(end_total - start_total)*1000/count}\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    run_single_sess()\r\n    # run_two_sess\r\n```\r\n\r\n**Expected behavior**\r\nit should cost same time when I use two session, compared with single session\r\n\r\nAppreciate for any help",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10273/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10274",
        "id": 1101744164,
        "node_id": "PR_kwDOCVq1mM4w7nO2",
        "number": 10274,
        "title": "Fuse DQ -> ArgMax into ArgMax",
        "user": {
            "login": "yihonglyu",
            "id": 8860750,
            "node_id": "MDQ6VXNlcjg4NjA3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8860750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yihonglyu",
            "html_url": "https://github.com/yihonglyu",
            "followers_url": "https://api.github.com/users/yihonglyu/followers",
            "following_url": "https://api.github.com/users/yihonglyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/yihonglyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yihonglyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yihonglyu/subscriptions",
            "organizations_url": "https://api.github.com/users/yihonglyu/orgs",
            "repos_url": "https://api.github.com/users/yihonglyu/repos",
            "events_url": "https://api.github.com/users/yihonglyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yihonglyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T13:38:44Z",
        "updated_at": "2022-01-18T22:47:34Z",
        "closed_at": "2022-01-18T22:47:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10274",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10274",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10274.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10274.patch",
            "merged_at": "2022-01-18T22:47:34Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10274/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10275",
        "id": 1101941495,
        "node_id": "I_kwDOCVq1mM5Brkr3",
        "number": 10275,
        "title": "DnnlExecutionProvider is not visible in python API ",
        "user": {
            "login": "magicaltoast",
            "id": 68669235,
            "node_id": "MDQ6VXNlcjY4NjY5MjM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/68669235?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/magicaltoast",
            "html_url": "https://github.com/magicaltoast",
            "followers_url": "https://api.github.com/users/magicaltoast/followers",
            "following_url": "https://api.github.com/users/magicaltoast/following{/other_user}",
            "gists_url": "https://api.github.com/users/magicaltoast/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/magicaltoast/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/magicaltoast/subscriptions",
            "organizations_url": "https://api.github.com/users/magicaltoast/orgs",
            "repos_url": "https://api.github.com/users/magicaltoast/repos",
            "events_url": "https://api.github.com/users/magicaltoast/events{/privacy}",
            "received_events_url": "https://api.github.com/users/magicaltoast/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1630303001,
                "node_id": "MDU6TGFiZWwxNjMwMzAzMDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:oneDNN",
                "name": "ep:oneDNN",
                "color": "0052CC",
                "default": false,
                "description": "questions/issues related to DNNL EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-13T15:31:25Z",
        "updated_at": "2022-11-15T00:27:20Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nDnnlExecutionProvider is not visible in python API after compiling onnxruntime with it.\r\nCreating Inference Session with it causes error ``DnnlExecutionProvider' is not in available provide``\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 21.04\r\n- ONNX Runtime installed from (source or binary): Source\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.8\r\n\r\n\r\n**To Reproduce**\r\n```\r\n./build.sh --use_dnnl  --build_wheel  --build_shared_lib  --config Release\r\ncd build/Linux/Release/dist/\r\npip instsall onnxruntime_dnnl-1.11.0-cp38-cp38-linux_x86_64.whl \r\n>>> import onnxruntime as rt\r\n>>> rt.get_available_providers()\r\n['CPUExecutionProvider']\r\n```\r\nWhen trying to create a model\r\n```py\r\ns=rt.InferenceSession(\"model.onnx\", providers=[\"DnnlExecutionProvider\"])\r\ns.get_providers()\r\n```\r\n```\r\n UserWarning: Specified provider 'DnnlExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\r\n  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\r\n['CPUExecutionProvider']\r\n```\r\n\r\n**Expected behavior**\r\n['CPUExecutionProvider',\"DnnlExecutionProvider\"]\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10275/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10276",
        "id": 1102003247,
        "node_id": "PR_kwDOCVq1mM4w8gWR",
        "number": 10276,
        "title": "Update pytorch-lightning",
        "user": {
            "login": "thiagocrepaldi",
            "id": 5469809,
            "node_id": "MDQ6VXNlcjU0Njk4MDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5469809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thiagocrepaldi",
            "html_url": "https://github.com/thiagocrepaldi",
            "followers_url": "https://api.github.com/users/thiagocrepaldi/followers",
            "following_url": "https://api.github.com/users/thiagocrepaldi/following{/other_user}",
            "gists_url": "https://api.github.com/users/thiagocrepaldi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thiagocrepaldi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thiagocrepaldi/subscriptions",
            "organizations_url": "https://api.github.com/users/thiagocrepaldi/orgs",
            "repos_url": "https://api.github.com/users/thiagocrepaldi/repos",
            "events_url": "https://api.github.com/users/thiagocrepaldi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thiagocrepaldi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T16:24:29Z",
        "updated_at": "2022-01-14T21:49:11Z",
        "closed_at": "2022-01-14T21:49:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10276",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10276",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10276.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10276.patch",
            "merged_at": "2022-01-14T21:49:10Z"
        },
        "body": "pytorch-lightning needs to be updated to fix security issue",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10276/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10277",
        "id": 1102046976,
        "node_id": "PR_kwDOCVq1mM4w8pm0",
        "number": 10277,
        "title": "Bump engine.io from 4.1.1 to 4.1.2 in /js/web",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-13T17:04:19Z",
        "updated_at": "2022-01-14T02:26:04Z",
        "closed_at": "2022-01-14T02:26:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10277",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10277",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10277.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10277.patch",
            "merged_at": "2022-01-14T02:26:03Z"
        },
        "body": "Bumps [engine.io](https://github.com/socketio/engine.io) from 4.1.1 to 4.1.2.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/socketio/engine.io/releases\">engine.io's releases</a>.</em></p>\n<blockquote>\n<h2>4.1.2</h2>\n<p>:warning: This release contains an important security fix :warning:</p>\n<p>A malicious client could send a specially crafted HTTP request, triggering an uncaught exception and killing the Node.js process:</p>\n<blockquote>\n<p>RangeError: Invalid WebSocket frame: RSV2 and RSV3 must be clear\nat Receiver.getInfo (/.../node_modules/ws/lib/receiver.js:176:14)\nat Receiver.startLoop (/.../node_modules/ws/lib/receiver.js:136:22)\nat Receiver._write (/.../node_modules/ws/lib/receiver.js:83:10)\nat writeOrBuffer (internal/streams/writable.js:358:12)</p>\n</blockquote>\n<p>This bug was introduced by <a href=\"https://github.com/socketio/engine.io/commit/f3c291fa613a9d50c924d74293035737fdace4f2\">this commit</a>, included in <code>engine.io@4.0.0</code>, so previous releases are not impacted.</p>\n<p>Thanks to Marcus Wejderot from Mevisio for the responsible disclosure.</p>\n<h3>Bug Fixes</h3>\n<ul>\n<li>properly handle invalid data sent by a malicious websocket client (<a href=\"https://github.com/socketio/engine.io/commit/a70800d7e96da32f6e6622804ef659ebc58659db\">a70800d</a>)</li>\n</ul>\n<h4>Links</h4>\n<ul>\n<li>Diff: <a href=\"https://github.com/socketio/engine.io/compare/4.1.1...4.1.2\">https://github.com/socketio/engine.io/compare/4.1.1...4.1.2</a></li>\n<li>Client release: -</li>\n<li>ws version: <a href=\"https://github.com/websockets/ws/releases/tag/7.4.2\">~7.4.2</a></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/socketio/engine.io/blob/4.1.2/CHANGELOG.md\">engine.io's changelog</a>.</em></p>\n<blockquote>\n<h2><a href=\"https://github.com/socketio/engine.io/compare/4.1.1...4.1.2\">4.1.2</a> (2022-01-11)</h2>\n<p>:warning: This release contains an important security fix :warning:</p>\n<p>A malicious client could send a specially crafted HTTP request, triggering an uncaught exception and killing the Node.js process:</p>\n<blockquote>\n<p>RangeError: Invalid WebSocket frame: RSV2 and RSV3 must be clear\nat Receiver.getInfo (/.../node_modules/ws/lib/receiver.js:176:14)\nat Receiver.startLoop (/.../node_modules/ws/lib/receiver.js:136:22)\nat Receiver._write (/.../node_modules/ws/lib/receiver.js:83:10)\nat writeOrBuffer (internal/streams/writable.js:358:12)</p>\n</blockquote>\n<p>This bug was introduced by <a href=\"https://github.com/socketio/engine.io/commit/f3c291fa613a9d50c924d74293035737fdace4f2\">this commit</a>, included in <code>engine.io@4.0.0</code>, so previous releases are not impacted.</p>\n<p>Thanks to Marcus Wejderot from Mevisio for the responsible disclosure.</p>\n<h3>Bug Fixes</h3>\n<ul>\n<li>properly handle invalid data sent by a malicious websocket client (<a href=\"https://github.com/socketio/engine.io/commit/a70800d7e96da32f6e6622804ef659ebc58659db\">a70800d</a>)</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/socketio/engine.io/commit/c6315af44826b87f6802574f1ef79dfa63777fab\"><code>c6315af</code></a> chore(release): 4.1.2</li>\n<li><a href=\"https://github.com/socketio/engine.io/commit/a70800d7e96da32f6e6622804ef659ebc58659db\"><code>a70800d</code></a> fix: properly handle invalid data sent by a malicious websocket client</li>\n<li>See full diff in <a href=\"https://github.com/socketio/engine.io/compare/4.1.1...4.1.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=engine.io&package-manager=npm_and_yarn&previous-version=4.1.1&new-version=4.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10277/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10278",
        "id": 1102048059,
        "node_id": "I_kwDOCVq1mM5Br-s7",
        "number": 10278,
        "title": "Gemm layer is not quantized with QGemm node but with QLinearMatMul + QLinearAdd",
        "user": {
            "login": "ghost",
            "id": 10137,
            "node_id": "MDQ6VXNlcjEwMTM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ghost",
            "html_url": "https://github.com/ghost",
            "followers_url": "https://api.github.com/users/ghost/followers",
            "following_url": "https://api.github.com/users/ghost/following{/other_user}",
            "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
            "organizations_url": "https://api.github.com/users/ghost/orgs",
            "repos_url": "https://api.github.com/users/ghost/repos",
            "events_url": "https://api.github.com/users/ghost/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ghost/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "yufenglee",
                "id": 30486710,
                "node_id": "MDQ6VXNlcjMwNDg2NzEw",
                "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/yufenglee",
                "html_url": "https://github.com/yufenglee",
                "followers_url": "https://api.github.com/users/yufenglee/followers",
                "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
                "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
                "organizations_url": "https://api.github.com/users/yufenglee/orgs",
                "repos_url": "https://api.github.com/users/yufenglee/repos",
                "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
                "received_events_url": "https://api.github.com/users/yufenglee/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-13T17:05:19Z",
        "updated_at": "2022-04-16T07:55:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\n\r\nI work with a simple onnx network exported from pytorch. The last fully connected layer (with bias) is exported as a Gemm node.\r\nAfter quantization (quantize_static) with the last onnxrt version (1.10)  I was expecting the new QGemm layer but the quantized version is still split in two layers: QLinearMatMul + QLinearAdd\r\nWhy that?\r\nHow to get the more compact version QGemm instead?\r\nThank you and BR,\r\nOcaf\r\n\r\n**System information**\r\n- Linux Ubuntu 18.04:\r\n- ONNX Runtime : 1.10.0\r\n- ONNX  version: 1.9.0\r\n- Python version: 3. 8.10\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10278/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10279",
        "id": 1102097060,
        "node_id": "I_kwDOCVq1mM5BsKqk",
        "number": 10279,
        "title": "C++ inference with IOBinding and DirectML",
        "user": {
            "login": "adepierre",
            "id": 24371370,
            "node_id": "MDQ6VXNlcjI0MzcxMzcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/24371370?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adepierre",
            "html_url": "https://github.com/adepierre",
            "followers_url": "https://api.github.com/users/adepierre/followers",
            "following_url": "https://api.github.com/users/adepierre/following{/other_user}",
            "gists_url": "https://api.github.com/users/adepierre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adepierre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adepierre/subscriptions",
            "organizations_url": "https://api.github.com/users/adepierre/orgs",
            "repos_url": "https://api.github.com/users/adepierre/repos",
            "events_url": "https://api.github.com/users/adepierre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adepierre/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1673018947,
                "node_id": "MDU6TGFiZWwxNjczMDE4OTQ3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:DML",
                "name": "ep:DML",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the DirectML execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 14,
        "created_at": "2022-01-13T17:45:45Z",
        "updated_at": "2022-06-28T20:56:31Z",
        "closed_at": "2022-02-07T20:15:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\n(I'm not sure this is a request, maybe I've juste missed something in the doc, I'm sorry if this is the case but I've looked everywhere and I can't get it to work)\r\n\r\nI'm trying to perform an inference in C++ with both input and output already on the device (as an intermediary step in a process for example). I'm using DirectML as provider, and I've seen that creating DML memory is supported since 1.10, but I can't get the session to run properly.\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using): 1.10 version (nuget in C++ project)\r\n\r\n**Describe the solution you'd like**\r\nI'd like the session to run normally and set the value passed as output to the output of the model, without copy to the CPU.\r\n\r\n**Describe alternatives you've considered**\r\nI've considered getting the data on the CPU and transfer them back to the device, but it adds an overhead.\r\n\r\n**Additional context**\r\nHere is the code I use with this [model.onnx](https://github.com/microsoft/onnxruntime/files/7864780/model.txt) (it's just a Pytorch 4x upsample exported with opset 11) for testing. Everything runs fine until the ``session.Run`` call, where the program just stops.\r\n\r\n```cpp\r\n#include <iostream>\r\n#include <vector>\r\n#include \"onnxruntime_cxx_api.h\"\r\n#include \"dml_provider_factory.h\"\r\n\r\nint main(int argc, char** argv) {\r\n\r\n    const std::string model_s = \"model.onnx\";\r\n    std::basic_string<ORTCHAR_T> model = std::basic_string<ORTCHAR_T>(model_s.begin(), model_s.end());\r\n    \r\n    // onnxruntime setup\r\n    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"batch-model-explorer\");\r\n    Ort::SessionOptions session_options;\r\n    OrtSessionOptionsAppendExecutionProvider_DML(session_options, 0);\r\n    Ort::Session session = Ort::Session(env, model.c_str(), session_options);\r\n\r\n    Ort::IoBinding io_binding = Ort::IoBinding::IoBinding(session);\r\n    Ort::MemoryInfo memory_info(\"DML\", OrtAllocatorType::OrtDeviceAllocator, 0, OrtMemType::OrtMemTypeDefault);\r\n    Ort::RunOptions run_options;\r\n\r\n    // Create input tensor with 0 on device memory\r\n    std::vector<int64_t> input_shape{ 1,3,1000,1000 };\r\n    std::vector<float> input_tensor_values(1*3*1000*1000, 0.0f);\r\n    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(memory_info, input_tensor_values.data(), input_tensor_values.size(), input_shape.data(), 4);\r\n    // bind the tensor to the input of the model\r\n    io_binding.BindInput(\"input\", input_tensor);\r\n\r\n    // Create output tensor on device memory\r\n    std::vector<int64_t> output_shape{ 1,3,4*1000,4*1000 };\r\n    std::vector<float> output_tensor_values(1*3*4000*4000, 0.0f);\r\n    Ort::Value output_tensor = Ort::Value::CreateTensor<float>(memory_info, output_tensor_values.data(), output_tensor_values.size(), output_shape.data(), 4);\r\n    // bind the tensor to the output of the model\r\n    io_binding.BindOutput(\"output\", output_tensor);\r\n    \r\n    try {\r\n        session.Run(run_options, io_binding);\r\n    }\r\n    catch (const Ort::Exception& exception)\r\n    {\r\n        std::cout << \"ERROR running model inference: \" << exception.what() << std::endl;\r\n        return -1;\r\n    }\r\n    catch (const std::exception& exception)\r\n    {\r\n        std::cout << \"ERROR running model inference: \" << exception.what() << std::endl;\r\n        return -1;\r\n    }\r\n\r\n    std::cout << \"Done!\" << std::endl;\r\n\r\n    return 0;\r\n}\r\n\r\n```\r\n\r\nThanks for any help on this!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10279/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10280",
        "id": 1102113492,
        "node_id": "PR_kwDOCVq1mM4w837m",
        "number": 10280,
        "title": "Optimize ReduceSum, ReduceMean, ReduceMin, ReduceMax",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-01-13T18:01:40Z",
        "updated_at": "2023-01-13T11:04:10Z",
        "closed_at": "2022-02-18T11:51:02Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10280",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10280",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10280.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10280.patch",
            "merged_at": "2022-02-18T11:51:02Z"
        },
        "body": "**Description**:\r\n\r\nImproves ReduceSum, ReduceMax, ReduceMean, ReduceMin on CPU for cases RKR (the tensor is equivalent to a 3D tensor with one reduced axis, one kept axis, one reduced axis. It reduces the memory consumption) (30% faster).\r\n\r\n**Motivation and Context**\r\n\r\n- performance\r\n- Raised by issue #10099.\r\n\r\nSee the following script to measure the improvment:\r\n\r\n```\r\nimport time\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport onnx\r\nimport onnxruntime as ort\r\n\r\n\r\ndef create_onnx_model(node):\r\n    # Size is (batch_size / 2) GB\r\n    input_proto = onnx.helper.make_tensor_value_info('x', onnx.TensorProto.FLOAT, [None, *FEATURE_MAP_SHAPE])\r\n    output_proto = onnx.helper.make_tensor_value_info('y', onnx.TensorProto.FLOAT, [1, FEATURE_MAP_SHAPE[0], 1, 1])\r\n\r\n    node_def = onnx.helper.make_node(\r\n        node,\r\n        inputs=[input_proto.name],\r\n        outputs=[output_proto.name],\r\n        name='op',\r\n        axes=(0, 2, 3),\r\n    )\r\n\r\n    graph_def = onnx.helper.make_graph(\r\n        nodes=[node_def],\r\n        name='test-model',\r\n        inputs=[input_proto],\r\n        outputs=[output_proto],\r\n    )\r\n\r\n    model_def = onnx.helper.make_model(graph_def, producer_name='onnx-example')\r\n    model_def.ir_version = 4\r\n    model_def.opset_import[0].version = 11\r\n\r\n    onnx.checker.check_model(model_def, full_check=True)\r\n\r\n    onnx.save_model(model_def, 'test.onnx')\r\n\r\n    return ort.InferenceSession('test.onnx', providers=['CPUExecutionProvider'])\r\n\r\n\r\nbatch_size = 16\r\nFEATURE_MAP_SHAPE = (128, 512, 512)\r\nshape = (batch_size, *FEATURE_MAP_SHAPE)\r\n\r\nN = 5\r\n\r\nx = np.random.randn(*shape).astype(np.float32)\r\n\r\nresults = []\r\nnodes = ['ReduceSum', 'ReduceMean', 'ReduceMin', 'ReduceMax', 'ReduceSum']\r\nwith tqdm(total=N * len(nodes)) as pbar:\r\n    for node in nodes:\r\n        model = create_onnx_model(node)\r\n        durs = []\r\n        for i in range(N):\r\n            x *= -1\r\n            begin = time.perf_counter()\r\n            model.run(None, {'x': x})[0].shape\r\n            duration = time.perf_counter() - begin\r\n            durs.append(duration)\r\n            pbar.update(1)\r\n        durs.sort()\r\n        results.append((node, durs))\r\n\r\nfor node, durs in results:\r\n    print(node, sum(durs[1:-1]) / (len(durs) - 2), durs)\r\n\r\n\r\n\"\"\"\r\nPR:\r\n\r\nReduceSum 0.12530109999999914 [0.11439150000000353, 0.12402879999999783, 0.1247271000000012, 0.12714739999999836, 0.13132369999999582]\r\nReduceMean 0.12379500000000121 [0.12040319999999838, 0.12092700000000178, 0.12471620000000172, 0.12574180000000013, 0.13234720000000522]\r\nReduceMin 0.12942566666666502 [0.12426919999999342, 0.12519710000000117, 0.12768109999999666, 0.13539879999999727, 0.13887529999999515]\r\nReduceMax 0.1296077999999999 [0.1240763000000058, 0.128204199999999, 0.13001030000000213, 0.13060889999999858, 0.1819714000000019]\r\n\r\nNo PR:\r\n\r\nReduceSum 0.16718310000000022 [0.1642044000000027, 0.16425759999999912, 0.1684125000000023, 0.16887919999999923, 0.21092490000000197]\r\nReduceMean 0.17254450000000313 [0.16611610000000354, 0.16648840000000575, 0.1679203000000058, 0.18322479999999786, 0.23252000000000095]\r\nReduceMin 0.1797097666666687 [0.14939999999999998, 0.17422279999999546, 0.17787720000000462, 0.18702930000000606, 0.2097418000000033]\r\nReduceMax 0.17173149999999993 [0.1606559999999959, 0.16596030000000184, 0.17150569999999732, 0.17772850000000062, 0.18525440000000515]\r\n\r\n\"\"\"\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10280/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10281",
        "id": 1102188477,
        "node_id": "PR_kwDOCVq1mM4w9Ii9",
        "number": 10281,
        "title": "Track Session Creation Time",
        "user": {
            "login": "oliviajain",
            "id": 25233514,
            "node_id": "MDQ6VXNlcjI1MjMzNTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/25233514?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/oliviajain",
            "html_url": "https://github.com/oliviajain",
            "followers_url": "https://api.github.com/users/oliviajain/followers",
            "following_url": "https://api.github.com/users/oliviajain/following{/other_user}",
            "gists_url": "https://api.github.com/users/oliviajain/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/oliviajain/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/oliviajain/subscriptions",
            "organizations_url": "https://api.github.com/users/oliviajain/orgs",
            "repos_url": "https://api.github.com/users/oliviajain/repos",
            "events_url": "https://api.github.com/users/oliviajain/events{/privacy}",
            "received_events_url": "https://api.github.com/users/oliviajain/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T19:03:37Z",
        "updated_at": "2022-01-21T21:20:55Z",
        "closed_at": "2022-01-21T21:20:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10281",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10281",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10281.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10281.patch",
            "merged_at": "2022-01-21T21:20:54Z"
        },
        "body": "**Description**: Monitor session creation time.\r\n\r\n**Motivation and Context**\r\n- Be able to catch regressions in session creation time.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10281/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10282",
        "id": 1102193897,
        "node_id": "PR_kwDOCVq1mM4w9Jxh",
        "number": 10282,
        "title": "Add _force_exportable_set and pass debug_options",
        "user": {
            "login": "jingyanwangms",
            "id": 47403504,
            "node_id": "MDQ6VXNlcjQ3NDAzNTA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/47403504?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jingyanwangms",
            "html_url": "https://github.com/jingyanwangms",
            "followers_url": "https://api.github.com/users/jingyanwangms/followers",
            "following_url": "https://api.github.com/users/jingyanwangms/following{/other_user}",
            "gists_url": "https://api.github.com/users/jingyanwangms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jingyanwangms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jingyanwangms/subscriptions",
            "organizations_url": "https://api.github.com/users/jingyanwangms/orgs",
            "repos_url": "https://api.github.com/users/jingyanwangms/repos",
            "events_url": "https://api.github.com/users/jingyanwangms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jingyanwangms/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T19:07:15Z",
        "updated_at": "2022-01-19T18:26:30Z",
        "closed_at": "2022-01-19T18:26:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10282",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10282",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10282.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10282.patch",
            "merged_at": "2022-01-19T18:26:28Z"
        },
        "body": "**Description**: This PR fixes \r\n\r\n- key error thrown from `for args in module_arg_pool[module]:`, due to forward function of classes in _force_exportable_set are not always called\r\n- pass through debug_options\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10282/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10283",
        "id": 1102286508,
        "node_id": "I_kwDOCVq1mM5Bs46s",
        "number": 10283,
        "title": "add QLinearMatMul do not quantize per channel flag to quantize_static extra options",
        "user": {
            "login": "alnah005",
            "id": 29386674,
            "node_id": "MDQ6VXNlcjI5Mzg2Njc0",
            "avatar_url": "https://avatars.githubusercontent.com/u/29386674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/alnah005",
            "html_url": "https://github.com/alnah005",
            "followers_url": "https://api.github.com/users/alnah005/followers",
            "following_url": "https://api.github.com/users/alnah005/following{/other_user}",
            "gists_url": "https://api.github.com/users/alnah005/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/alnah005/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/alnah005/subscriptions",
            "organizations_url": "https://api.github.com/users/alnah005/orgs",
            "repos_url": "https://api.github.com/users/alnah005/repos",
            "events_url": "https://api.github.com/users/alnah005/events{/privacy}",
            "received_events_url": "https://api.github.com/users/alnah005/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-13T20:05:59Z",
        "updated_at": "2022-04-12T03:43:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Currently, quantizing a dense layer with dimensions B x D makes the weight get quantized D times as D is seen as the number of channels. Ideally, that should be excluded by listing which nodes should not be quantized per channel ([specifically here for MatMul](https://github.com/microsoft/onnxruntime/blob/4b205eb2b302d6f8ca0aa19951e05a1059137e26/onnxruntime/python/tools/quantization/operators/matmul.py#L21)), when the [global quantize per channel flag](https://github.com/microsoft/onnxruntime/blob/3d9d8e20ccb753995e7a29e35f40572f129d10d2/onnxruntime/python/tools/quantization/quantize.py#L141) is set to true.\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using): 1.10\r\n\r\n**Describe the solution you'd like**\r\nHave an extra option in quantize_static that excludes nodes that shouldn't be quantized per channel when the quantize per channel flag is set to true.\r\n\r\n**Describe alternatives you've considered**\r\nReplacing the hardcoded [op_level_per_channel](https://github.com/microsoft/onnxruntime/blob/3d9d8e20ccb753995e7a29e35f40572f129d10d2/onnxruntime/python/tools/quantization/operators/matmul.py#L70) True to False.\r\n\r\n**Additional context**\r\nDense layer features shouldn't be considered as channels as the computation for a dense layer is not independent across features.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10283/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10284",
        "id": 1102408249,
        "node_id": "PR_kwDOCVq1mM4w96En",
        "number": 10284,
        "title": "Reset MIN&MAX for float/double",
        "user": {
            "login": "RandySheriffH",
            "id": 48490400,
            "node_id": "MDQ6VXNlcjQ4NDkwNDAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/48490400?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RandySheriffH",
            "html_url": "https://github.com/RandySheriffH",
            "followers_url": "https://api.github.com/users/RandySheriffH/followers",
            "following_url": "https://api.github.com/users/RandySheriffH/following{/other_user}",
            "gists_url": "https://api.github.com/users/RandySheriffH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RandySheriffH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RandySheriffH/subscriptions",
            "organizations_url": "https://api.github.com/users/RandySheriffH/orgs",
            "repos_url": "https://api.github.com/users/RandySheriffH/repos",
            "events_url": "https://api.github.com/users/RandySheriffH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RandySheriffH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T21:30:04Z",
        "updated_at": "2022-01-14T21:57:31Z",
        "closed_at": "2022-01-14T21:57:30Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10284",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10284",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10284.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10284.patch",
            "merged_at": "2022-01-14T21:57:30Z"
        },
        "body": "Reset MIN&MAX value for float&double inputs on cuda topk op to fix parity issue.\r\nhttps://github.com/microsoft/onnxruntime/issues/9843",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10284/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10285",
        "id": 1102501986,
        "node_id": "PR_kwDOCVq1mM4w-PO5",
        "number": 10285,
        "title": "support type promotion in binary poerators in eager mode",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-13T22:35:00Z",
        "updated_at": "2022-01-20T18:06:11Z",
        "closed_at": "2022-01-20T18:06:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10285",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10285",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10285.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10285.patch",
            "merged_at": "2022-01-20T18:06:10Z"
        },
        "body": "**Description**: Reuse pytorch's type promotion strategy to handle kernel invoke with different types in eager mode\r\n\r\ncurrently we only enable it with a whitelist. will have another PR to parse the onnx type constrains to automatically resolve which arguments need type promotion.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10285/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10286",
        "id": 1102716239,
        "node_id": "I_kwDOCVq1mM5Buh1P",
        "number": 10286,
        "title": "ORTValue to Pytorch CUDA Tensor Interface ",
        "user": {
            "login": "ManuelAngel99",
            "id": 20950298,
            "node_id": "MDQ6VXNlcjIwOTUwMjk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/20950298?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ManuelAngel99",
            "html_url": "https://github.com/ManuelAngel99",
            "followers_url": "https://api.github.com/users/ManuelAngel99/followers",
            "following_url": "https://api.github.com/users/ManuelAngel99/following{/other_user}",
            "gists_url": "https://api.github.com/users/ManuelAngel99/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ManuelAngel99/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ManuelAngel99/subscriptions",
            "organizations_url": "https://api.github.com/users/ManuelAngel99/orgs",
            "repos_url": "https://api.github.com/users/ManuelAngel99/repos",
            "events_url": "https://api.github.com/users/ManuelAngel99/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ManuelAngel99/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-14T01:27:11Z",
        "updated_at": "2022-01-20T19:21:22Z",
        "closed_at": "2022-01-14T21:14:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm implementing a T5 model in ONNX Runtime with the intention of speeding up GPU inference. In order to avoid copying the decoder outputs back and forth from the GPU to the CPU I'm using ONNX Runtime io binding, this allows to easily use Pytorch tensors as inputs to the model using the data_ptr() method of the tensor. Since the dimmensions of the input are known before \r\nrunning the model there is no major issue supplying the input shape to the input binder.\r\n\r\nThe same procedure can be applied with the output bindings, however, the shape of the output needs to be precalculated and a torch tensor needs to be created in order to store the result. This can be rather cumbersome when dealing with a large number of outputs with different dimmensions (like the past key values of the T5 decoder). \r\n\r\nThis could be avoided if there was a simple method to create a Torch tensor in the gpu from an ORTValue located in the gpu without needing to transfer the data to the cpu, which causes a considerable latency increase.\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to create a Torch Tensor in the GPU directly from an ORT Value located in the gpu.\r\n\r\nFor example:\r\n\r\n```\r\n# Dummy ORT Value`\r\nortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(X, 'cuda', 0)`\r\ntorch_tensor = ortvalue.torch_tensor()\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10286/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10289",
        "id": 1102870501,
        "node_id": "PR_kwDOCVq1mM4w_jUv",
        "number": 10289,
        "title": "Symmetric QGEMM ",
        "user": {
            "login": "chenfucn",
            "id": 1316708,
            "node_id": "MDQ6VXNlcjEzMTY3MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1316708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chenfucn",
            "html_url": "https://github.com/chenfucn",
            "followers_url": "https://api.github.com/users/chenfucn/followers",
            "following_url": "https://api.github.com/users/chenfucn/following{/other_user}",
            "gists_url": "https://api.github.com/users/chenfucn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chenfucn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chenfucn/subscriptions",
            "organizations_url": "https://api.github.com/users/chenfucn/orgs",
            "repos_url": "https://api.github.com/users/chenfucn/repos",
            "events_url": "https://api.github.com/users/chenfucn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chenfucn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-14T03:32:41Z",
        "updated_at": "2022-01-24T22:59:34Z",
        "closed_at": "2022-01-24T18:49:04Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10289",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10289",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10289.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10289.patch",
            "merged_at": "2022-01-24T18:49:04Z"
        },
        "body": "**Description**: \r\n\r\nAdding code for symmetric quantized matrix multiplication.  Used in quantized convolution, achieving significant perf gain.\r\n\r\nTODO, use this in other operators\r\n\r\n\r\nDOT kernel perf test:\r\n\r\nPixel 5a:\r\n\r\nCartoongan | 513.539 ms | 471.786 ms\r\n-- | -- | --\r\nEfficient | 57.5169 ms | 56.4174 ms\r\nEdgetpu | 14.6673 ms | 13.5959 ms\r\n\r\n\r\n\r\nNEON kernel perf test\r\n\r\nPixel 3a\r\n\r\nCartoongan | 1423.53 ms | 1069.92 ms\r\n-- | -- | --\r\nEfficient | 114.086 ms | 107.968 ms\r\nEdgetpu | 39.2632 ms | 36.9839 ms\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10289/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10290",
        "id": 1103353857,
        "node_id": "I_kwDOCVq1mM5Bw9gB",
        "number": 10290,
        "title": "ONNX Runtime DLL load Error",
        "user": {
            "login": "rishabhmalhotra027",
            "id": 49022188,
            "node_id": "MDQ6VXNlcjQ5MDIyMTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49022188?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rishabhmalhotra027",
            "html_url": "https://github.com/rishabhmalhotra027",
            "followers_url": "https://api.github.com/users/rishabhmalhotra027/followers",
            "following_url": "https://api.github.com/users/rishabhmalhotra027/following{/other_user}",
            "gists_url": "https://api.github.com/users/rishabhmalhotra027/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rishabhmalhotra027/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rishabhmalhotra027/subscriptions",
            "organizations_url": "https://api.github.com/users/rishabhmalhotra027/orgs",
            "repos_url": "https://api.github.com/users/rishabhmalhotra027/repos",
            "events_url": "https://api.github.com/users/rishabhmalhotra027/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rishabhmalhotra027/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-14T09:38:26Z",
        "updated_at": "2022-08-12T08:23:05Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "While using onnxruntime reference in a net framework project, we are hitting the following exception in production \r\n\r\n`Unexpected error encountered by 'Alexandria' processor: System.TypeInitializationException: The type initializer for 'Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.PreProcessingHelperFactory' threw an exception. ---> System.TypeInitializationException: The type initializer for 'Microsoft.ML.OnnxRuntime.NativeMethods' threw an exception. ---> System.DllNotFoundException: Unable to load DLL 'onnxruntime': The specified module could not be found. (Exception from HRESULT: 0x8007007E) at Microsoft.ML.OnnxRuntime.NativeMethods.OrtGetApiBase() at Microsoft.ML.OnnxRuntime.NativeMethods..cctor() --- End of inner exception stack trace --- at Microsoft.ML.OnnxRuntime.SessionOptions..ctor() at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.PreProcessingHelperFactory..cctor() --- End of inner exception stack trace --- at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.PreProcessingHelperFactory.GetLanguageWordEmbedding(String language) at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.MultilingualPreProcessor.GetClassificationIndex(String sentence, String language, ILogger logger, IMetricsLogger metricsLogger) at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.SpanishSpecificTextProcessor.GetFilteredSentences(IList1 sentences) at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.DefinitionsExtractor.ExtractAndFilterSentencesMultilingual(ILogger logger, IMetricsLogger metricsLogger, String body, DefinitionSettings definitionSettings, Guid tenantId, Boolean isPreFilteringEnabled) at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.DefinitionsExtractor.<ExtractDefinitionsMultilingual>d__23.MoveNext() --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at Microsoft.Substrate.KnowledgeMining.DefinitionExtraction.DefinitionsExtractor.<ExtractDefinitions>d__21.MoveNext() --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at Microsoft.Griffin.SharePointHome.Notifier.KnowledgeGraph.Processors.Extractors.DefinitionsMultiTypeExtractor.<ExtractAsync>d__6.MoveNext() --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at Microsoft.Griffin.KnowledgeGraph.Processors.ProcessingSteps.DefinitionExtractionStep.<ExecuteAsync>d__6.MoveNext() --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at Microsoft.Griffin.KnowledgeGraph.Processors.MultiStepProcessor1.<ExecuteAsync>d__6.MoveNext()`\r\n\r\nWe cannot reproduce the same error in local machine, as the dll reference is present in the project, and we're able to see the dll in the target folder once we build the project.\r\n\r\nHere are the references in the dev csproj\r\n    `<Reference Include=\"Microsoft.ML.OnnxRuntime\">`\r\n      `<HintPath>$(PkgMicrosoft_ML_OnnxRuntime_Managed_1_4_0)\\lib\\netstandard1.1\\Microsoft.ML.OnnxRuntime.dll</HintPath>`\r\n    `</Reference>`\r\n    `<Reference Include=\"netstandard\" />`\r\n    `<Reference Include=\"System\" />`\r\n    `<Reference Include=\"System.Memory\">`\r\n      `<HintPath>$(PkgSystem_Memory)\\lib\\netstandard2.0\\System.Memory.dll</HintPath>`\r\n    `</Reference>`\r\n\r\n  `<ItemGroup>`\r\n    `<Content Include=\"$(PkgMicrosoft_ML_OnnxRuntime_1_4_0)\\runtimes\\win-x64\\native\\onnxruntime.dll\" Visible=\"false\">`\r\n      `<Link>onnxruntime.dll</Link>`\r\n      `<CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>`\r\n    `</Content>`\r\n    `<Content Include=\"$(PkgMicrosoft_ML_OnnxRuntime_1_4_0)\\runtimes\\win-x64\\native\\onnxruntime.lib\" Visible=\"false\">`\r\n      `<Link>onnxruntime.lib</Link>`\r\n      `<CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>`\r\n    `</Content>`\r\n  `</ItemGroup>`\r\n\r\nThe same references had to be mentioned in the test csproj, otherwise the unit tests were hitting an error - Unable to find an entry point named ‘OrtGetApiBase’ in DLL ‘onnxruntime’ in local, and the same exception as above in cloud build. Do we need to add something else in the csproj to make this work in prod? \r\n\r\n**System information**\r\n- OS Platform - Windows 10\r\n- ONNX Runtime installed from (source or binary): Griffin repository NuGet\r\n- ONNX Runtime version: (CPU ONNX) - 1.4.0\r\n- .NetFramework - 4.7.2\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10290/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10291",
        "id": 1103425236,
        "node_id": "I_kwDOCVq1mM5BxO7U",
        "number": 10291,
        "title": "Python's flatbuffers version API ",
        "user": {
            "login": "pkluska",
            "id": 11422674,
            "node_id": "MDQ6VXNlcjExNDIyNjc0",
            "avatar_url": "https://avatars.githubusercontent.com/u/11422674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pkluska",
            "html_url": "https://github.com/pkluska",
            "followers_url": "https://api.github.com/users/pkluska/followers",
            "following_url": "https://api.github.com/users/pkluska/following{/other_user}",
            "gists_url": "https://api.github.com/users/pkluska/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pkluska/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pkluska/subscriptions",
            "organizations_url": "https://api.github.com/users/pkluska/orgs",
            "repos_url": "https://api.github.com/users/pkluska/repos",
            "events_url": "https://api.github.com/users/pkluska/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pkluska/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "chilo-ms",
                "id": 54722500,
                "node_id": "MDQ6VXNlcjU0NzIyNTAw",
                "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/chilo-ms",
                "html_url": "https://github.com/chilo-ms",
                "followers_url": "https://api.github.com/users/chilo-ms/followers",
                "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
                "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
                "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
                "repos_url": "https://api.github.com/users/chilo-ms/repos",
                "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
                "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-14T10:25:04Z",
        "updated_at": "2022-04-16T07:55:25Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen trying to quantize the model targeting TRT EP GPU runtime the TypeError is thrown due to to flatbuffers API change between versions 1.12.0 and 2.0.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.3 LTS (In docker nvidia/pytorch:21.11-py3)\r\n- ONNX Runtime installed from (source or binary): binary (PyPi GPU)\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.12\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.5\r\n- GPU model and memory: V100 16GB\r\n\r\n**To Reproduce**\r\n1. Install ONNX Runtime with GPU from pypi: `pip install onnxruntime-gpu==1.10.0`\r\n2. Try to quantize model for TRT EP GPU e.g. https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/image_classification/trt/resnet50  \r\n3. Error is thrown due to TypeError in https://github.com/microsoft/onnxruntime/blob/v1.10.0/onnxruntime/python/tools/quantization/quant_utils.py#L378:\r\n```python\r\n        TrtTable.TrtTableStartDictVector(builder, len(key_value_list))\r\n        for key_value in key_value_list:\r\n            builder.PrependUOffsetTRelative(key_value)\r\n>       main_dict = builder.EndVector(len(key_value_list))\r\nE       TypeError: EndVector() takes 1 positional argument but 2 were given\r\n\r\n/opt/conda/lib/python3.8/site-packages/onnxruntime/quantization/quant_utils.py:378: TypeError\r\n```\r\n\r\n**Expected behavior**\r\nModel is quantized properly and error is not thrown.\r\n\r\n**Additional context**\r\nWhen installing ONNX Runtime the latest version of flatbuffers is installed i.e. 2.0 which has different method signature than in 1.12.0.\r\n1.12.0 -> https://github.com/google/flatbuffers/blob/v1.12.1/python/flatbuffers/builder.py#L379\r\n2.0.5 -> https://github.com/google/flatbuffers/blob/v2.0.5/python/flatbuffers/builder.py#L380 \r\n\r\nCurrent workaround is to manually downgrade the flatbuffers to 1.12.0. \r\n\r\nI can contribute PR to fix that, but I would like to know what is your opinion on how to approach this. Should it be to update the code to reflect the changes or pinpoint the flatbuffers version to 1.12.0?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10291/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10292",
        "id": 1103459560,
        "node_id": "I_kwDOCVq1mM5BxXTo",
        "number": 10292,
        "title": "Can't build docker file for arm32v7",
        "user": {
            "login": "darkcoder2000",
            "id": 10888825,
            "node_id": "MDQ6VXNlcjEwODg4ODI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10888825?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/darkcoder2000",
            "html_url": "https://github.com/darkcoder2000",
            "followers_url": "https://api.github.com/users/darkcoder2000/followers",
            "following_url": "https://api.github.com/users/darkcoder2000/following{/other_user}",
            "gists_url": "https://api.github.com/users/darkcoder2000/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/darkcoder2000/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/darkcoder2000/subscriptions",
            "organizations_url": "https://api.github.com/users/darkcoder2000/orgs",
            "repos_url": "https://api.github.com/users/darkcoder2000/repos",
            "events_url": "https://api.github.com/users/darkcoder2000/events{/privacy}",
            "received_events_url": "https://api.github.com/users/darkcoder2000/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-14T10:52:09Z",
        "updated_at": "2022-01-25T03:06:34Z",
        "closed_at": "2022-01-25T03:06:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nI need a onnxruntime build for c++ on arm32v7.\r\nI am follwing the build instructions from here https://onnxruntime.ai/docs/build/inferencing.html#arm\r\nand here https://github.com/microsoft/onnxruntime/blob/master/dockerfiles/README.md#arm-32v7\r\n\r\nI cloned the git repo  https://github.com/microsoft/onnxruntime.git  and executed \"git submodule update --init\".\r\nWhen I execute the \"docker build -t onnxruntime-source-arm32v7 -f Dockerfile.arm32v7 ..\" the docker build fails saying \r\n\r\n build [ERROR] - Failed to resolve executable path for 'cmake'.\r\n\r\n**Urgency**\r\nnone\r\n\r\n**System information**\r\n - Windows 10 Pro 19043.1415\r\n - Docker version 20.10.8, build 3967b7d\r\n - i7 8th gen / 32 GB Ram\r\n\r\n**To Reproduce**\r\nFollow the docker build instructions as stated in the description\r\n\r\n**Expected behavior**\r\nThe docker build should proceed without errors and create the libonnxruntime.so to be used on linux/arm32\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/10888825/149503347-4258a7ee-ba56-4f06-8fca-0efef4d8e0e0.png)\r\n\r\n\r\n**Additional context**\r\nWhen I do the same on Ubuntu 20.04 it is even worse since it can't execute \"RUN dnf .... command\" in script \"install_fedora_arm32.sh\"\r\nIt is saying \"standard_init_linux.go:228 exec user process caused: exec format error\"\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10292/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10293",
        "id": 1103475115,
        "node_id": "I_kwDOCVq1mM5BxbGr",
        "number": 10293,
        "title": "How to write CUDA custom op?",
        "user": {
            "login": "luchangli03",
            "id": 34341633,
            "node_id": "MDQ6VXNlcjM0MzQxNjMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/34341633?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/luchangli03",
            "html_url": "https://github.com/luchangli03",
            "followers_url": "https://api.github.com/users/luchangli03/followers",
            "following_url": "https://api.github.com/users/luchangli03/following{/other_user}",
            "gists_url": "https://api.github.com/users/luchangli03/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/luchangli03/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/luchangli03/subscriptions",
            "organizations_url": "https://api.github.com/users/luchangli03/orgs",
            "repos_url": "https://api.github.com/users/luchangli03/repos",
            "events_url": "https://api.github.com/users/luchangli03/events{/privacy}",
            "received_events_url": "https://api.github.com/users/luchangli03/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-14T11:04:50Z",
        "updated_at": "2022-01-17T06:11:27Z",
        "closed_at": "2022-01-17T06:11:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "In the custom op codes in the following pages, I did not find any hint about hot to set the custom op type to CPU or GPU, could someone give me some examples about how to write CUDA GPU custom op?\r\nhttps://faxu.github.io/onnxruntime/docs/reference/operators/add-custom-op.html\r\nhttps://github.com/microsoft/onnxruntime/blob/master/onnxruntime/test/testdata/custom_op_library/custom_op_library.cc\r\nhttps://github.com/microsoft/onnxruntime/blob/master/onnxruntime/test/python/onnxruntime_test_python.py\r\nThank you very much.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10293/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10294",
        "id": 1104280923,
        "node_id": "I_kwDOCVq1mM5B0f1b",
        "number": 10294,
        "title": "Symbolic shape infer issue: rank = 0 in handle_negative_axis",
        "user": {
            "login": "JunzheJosephZhu",
            "id": 24391451,
            "node_id": "MDQ6VXNlcjI0MzkxNDUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/24391451?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JunzheJosephZhu",
            "html_url": "https://github.com/JunzheJosephZhu",
            "followers_url": "https://api.github.com/users/JunzheJosephZhu/followers",
            "following_url": "https://api.github.com/users/JunzheJosephZhu/following{/other_user}",
            "gists_url": "https://api.github.com/users/JunzheJosephZhu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JunzheJosephZhu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JunzheJosephZhu/subscriptions",
            "organizations_url": "https://api.github.com/users/JunzheJosephZhu/orgs",
            "repos_url": "https://api.github.com/users/JunzheJosephZhu/repos",
            "events_url": "https://api.github.com/users/JunzheJosephZhu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JunzheJosephZhu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-01-15T02:07:23Z",
        "updated_at": "2022-03-10T00:59:28Z",
        "closed_at": "2022-03-10T00:59:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi!\r\nI exported a torchvision mask rcnn model to onnx, then tried to run it with tensorRT backend:\r\nsess = ort.InferenceSession(\"rcnn.onnx\", providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider'])\r\nHowever, it gave me an error saying I needed to use symbolic_shape_infer,\r\nwhen I did, line 71's assertion\r\n    assert axis < rank and axis >= -rank\r\nfailed. I checked and both axis and rank are 0.\r\nAny solution?\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10294/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10295",
        "id": 1104366224,
        "node_id": "I_kwDOCVq1mM5B00qQ",
        "number": 10295,
        "title": "error: ‘Ort::g_api’ should have been declared inside ‘Ort’ while compiling with g++",
        "user": {
            "login": "abilashravi-ta",
            "id": 53215532,
            "node_id": "MDQ6VXNlcjUzMjE1NTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/53215532?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abilashravi-ta",
            "html_url": "https://github.com/abilashravi-ta",
            "followers_url": "https://api.github.com/users/abilashravi-ta/followers",
            "following_url": "https://api.github.com/users/abilashravi-ta/following{/other_user}",
            "gists_url": "https://api.github.com/users/abilashravi-ta/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abilashravi-ta/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abilashravi-ta/subscriptions",
            "organizations_url": "https://api.github.com/users/abilashravi-ta/orgs",
            "repos_url": "https://api.github.com/users/abilashravi-ta/repos",
            "events_url": "https://api.github.com/users/abilashravi-ta/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abilashravi-ta/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-15T04:21:09Z",
        "updated_at": "2022-02-01T05:13:05Z",
        "closed_at": "2022-02-01T05:12:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Description**\r\nI built **onnxruntime** from source following [these](https://onnxruntime.ai/docs/build/inferencing.html#cpu) instructions.\r\nGetting `error: ‘Ort::g_api’ should have been declared inside ‘Ort’` when trying to _include_ **onnxruntime_cxx_api.h** in a simple `hello_world.cpp` code.\r\n\r\n**System information**\r\n- OS Platform and Distribution: **WSL 2.0** _Ubuntu 20.04.3 LTS on Windows 10 x86_64_\r\n- ONNX Runtime installed from (source or binary): source (using the link mentioned above)\r\n- G++ Compiler version: 9.3.0\r\n\r\n**To Reproduce**\r\nWhen I compile the following piece of code with `g++ -o run1 imp_onnx.cpp -I/home/abilashravi/trials/onnx_in_c/onnxruntime/include/onnxruntime/core/session`\r\n```\r\n// imp_onnx.cpp\r\n#include <iostream>\r\n#include <onnxruntime_cxx_api.h>\r\n\r\nint main()\r\n{\r\n\tstd::cout << \"Hello world.!\";\r\n\treturn 0;\r\n}\r\n```\r\nI get this\r\n![g++ er1](https://user-images.githubusercontent.com/53215532/149608263-b2b064ff-e5eb-485e-b69c-30644c2d3cfc.JPG)\r\n\r\n\r\nI tried to fix it based on discussions [here](https://github.com/microsoft/onnxruntime/issues/2081) by adding `const OrtApi* Ort::g_api = OrtGetApi(ORT_API_VERSION);` to the code. But when I compile the following\r\n```\r\n// imp_onnx.cpp\r\n#include <iostream>\r\n#include <onnxruntime_cxx_api.h>\r\n\r\nconst OrtApi* Ort::g_api = OrtGetApi(ORT_API_VERSION);\r\n\r\nint main()\r\n{\r\n\tstd::cout << \"Hello world.!\";\r\n\treturn 0;\r\n}\r\n```\r\nI'm getting this\r\n![g++ er2](https://user-images.githubusercontent.com/53215532/149608545-e3ce26f8-6ec6-456f-8ad3-3510c3d84303.JPG)\r\n\r\nAny suggestion would be helpful.!\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10295/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10296",
        "id": 1104831023,
        "node_id": "PR_kwDOCVq1mM4xGSQ1",
        "number": 10296,
        "title": "int8/uint8 support for Argmax for opset 1, 11, 12",
        "user": {
            "login": "yihonglyu",
            "id": 8860750,
            "node_id": "MDQ6VXNlcjg4NjA3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8860750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yihonglyu",
            "html_url": "https://github.com/yihonglyu",
            "followers_url": "https://api.github.com/users/yihonglyu/followers",
            "following_url": "https://api.github.com/users/yihonglyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/yihonglyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yihonglyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yihonglyu/subscriptions",
            "organizations_url": "https://api.github.com/users/yihonglyu/orgs",
            "repos_url": "https://api.github.com/users/yihonglyu/repos",
            "events_url": "https://api.github.com/users/yihonglyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yihonglyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-15T19:47:48Z",
        "updated_at": "2022-01-18T22:37:35Z",
        "closed_at": "2022-01-18T22:37:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10296",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10296",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10296.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10296.patch",
            "merged_at": "2022-01-18T22:37:34Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10296/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10297",
        "id": 1104861999,
        "node_id": "PR_kwDOCVq1mM4xGYVR",
        "number": 10297,
        "title": "Add TensorRT timing cache feature",
        "user": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-15T21:53:57Z",
        "updated_at": "2023-03-16T20:58:09Z",
        "closed_at": "2023-03-16T20:58:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10297",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10297",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10297.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10297.patch",
            "merged_at": null
        },
        "body": "TensorRT provides the timing cache feature to reduce the builder time by keeping the layer profiling information during the builder phase. This PR added timing cache feature into ORT-TRT.\r\n\r\nAlso, please notice that ORT won't use `OrtTensorRTProviderOptions` struct anymore for TRT EP when adding additional provider option. Instead, it uses the opaque struct `OrtTensorRTProviderOptionsV2` as internal struct for setting provider options that can be converted to a string.\r\nPlease see https://github.com/microsoft/onnxruntime/pull/7808 and https://github.com/microsoft/onnxruntime/pull/10188 for more details and context.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10297/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10298",
        "id": 1105075430,
        "node_id": "I_kwDOCVq1mM5B3hzm",
        "number": 10298,
        "title": "Cannot find OrtCUDAProviderOptionsV2 APIs in released onnxruntime_c_api.h",
        "user": {
            "login": "HaoboGu",
            "id": 8640918,
            "node_id": "MDQ6VXNlcjg2NDA5MTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8640918?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/HaoboGu",
            "html_url": "https://github.com/HaoboGu",
            "followers_url": "https://api.github.com/users/HaoboGu/followers",
            "following_url": "https://api.github.com/users/HaoboGu/following{/other_user}",
            "gists_url": "https://api.github.com/users/HaoboGu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/HaoboGu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/HaoboGu/subscriptions",
            "organizations_url": "https://api.github.com/users/HaoboGu/orgs",
            "repos_url": "https://api.github.com/users/HaoboGu/repos",
            "events_url": "https://api.github.com/users/HaoboGu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/HaoboGu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-16T15:02:51Z",
        "updated_at": "2022-01-19T03:02:44Z",
        "closed_at": "2022-01-19T03:02:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello,\r\n\r\nI'm using `onnxruntime-win-x64-gpu-1.10.0.zip` from release page and I found there is no OrtCUDAProviderOptionsV2 APIs in `include/onnxruntime_c_api.h`\r\n\r\nThis api can be found in onnxruntime's doc page: https://onnxruntime.ai/docs/api/c/group___global.html#ga6b319b3ba435fb46c3808d7957c4684f\r\n\r\nDo I miss something?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10298/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10299",
        "id": 1105085572,
        "node_id": "I_kwDOCVq1mM5B3kSE",
        "number": 10299,
        "title": "Bad results when using IOBinding with bind_input of non ortvalue type",
        "user": {
            "login": "jeshels",
            "id": 80462280,
            "node_id": "MDQ6VXNlcjgwNDYyMjgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/80462280?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeshels",
            "html_url": "https://github.com/jeshels",
            "followers_url": "https://api.github.com/users/jeshels/followers",
            "following_url": "https://api.github.com/users/jeshels/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeshels/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeshels/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeshels/subscriptions",
            "organizations_url": "https://api.github.com/users/jeshels/orgs",
            "repos_url": "https://api.github.com/users/jeshels/repos",
            "events_url": "https://api.github.com/users/jeshels/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeshels/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-16T15:42:34Z",
        "updated_at": "2022-01-24T13:51:55Z",
        "closed_at": "2022-01-20T15:34:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI tried to use a PyTorch Tensor allocated on GPU as an input for session run (avoiding copying it to CPU) using IOBinding. The program yields incorrect output values (correct shape and type, but values are off). The same thing happens when binding a NumPy array.\r\n\r\n**Urgency**\r\nNone.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): Tried both source and binary installations\r\n- ONNX Runtime version: 1.7.0 and 1.10.0\r\n- Python version: 3.9.9\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: CUDA version 10.1.105 / cuDNN version 8.0.5\r\n- GPU model and memory: Quadro RTX 4000\r\n\r\n**To Reproduce**\r\nHere is my failed attempt to run the session with GPU PyTorch tensor as input (the program yields incorrect output values).\r\n\r\n```python\r\narray = numpy.array(SOME_4D_NUMPY_ARRAY)\r\ngpu_tensor = torch.from_numpy(array).cuda()\r\n\r\nio_binding = sess.io_binding()\r\n\r\n# Binding PyTorch GPU Tensor directly\r\nio_binding.bind_input(\r\n    name=INPUT_NAME,\r\n    device_type='cuda',\r\n    device_id=0,\r\n    element_type=np.float32,\r\n    shape=tuple(gpu_tensor.shape),\r\n    buffer_ptr=gpu_tensor.data_ptr())\r\n\r\nfor output in OUTPUT_NAMES:\r\n    io_binding.bind_output(output)\r\n\r\nsess.run_with_iobinding(io_binding)\r\n\r\n# Outputs contain incorrect values\r\noutputs = io_binding.copy_outputs_to_cpu()\r\n```\r\n\r\nI checked the outputs generated when binding the NumPy array directly, which also yields incorrect values:\r\n\r\n```python\r\narray = numpy.array(SOME_4D_NUMPY_ARRAY)\r\n\r\nio_binding = sess.io_binding()\r\n\r\nio_binding.bind_input(\r\n    name=INPUT_NAME,\r\n    device_type='cpu',\r\n    device_id=0,\r\n    element_type=np.float32,\r\n    shape=tuple(array.shape),\r\n    buffer_ptr=array.ctypes.get_data())\r\n\r\nfor output in OUTPUT_NAMES:\r\n    io_binding.bind_output(output)\r\n\r\nsess.run_with_iobinding(io_binding)\r\n\r\noutputs = io_binding.copy_outputs_to_cpu()\r\n```\r\n\r\nHowever, by creating an OrtValue from the NumPy array I actually get correct outputs values:\r\n\r\n```python\r\narray = numpy.array(SOME_4D_NUMPY_ARRAY)\r\nortval = ort.OrtValue.ortvalue_from_numpy(self._cpu_arr)\r\n\r\nio_binding = sess.io_binding()\r\n\r\nio_binding.bind_input(\r\n    name=INPUT_NAME,\r\n    device_type='cpu',\r\n    device_id=0,\r\n    element_type=np.float32,\r\n    shape=tuple(ortval.shape()),\r\n    buffer_ptr=ortval.data_ptr())\r\n\r\nfor output in OUTPUT_NAMES:\r\n    io_binding.bind_output(output)\r\n\r\nsess.run_with_iobinding(io_binding)\r\n\r\noutputs = io_binding.copy_outputs_to_cpu()\r\n```\r\n\r\nAnother successful way to get correct outputs results was by using `bind_cpu_input()` instead of `bind_input()`:\r\n\r\n```python\r\narray = numpy.array(SOME_4D_NUMPY_ARRAY)\r\n\r\nio_binding = sess.io_binding()\r\n\r\nio_binding.bind_cpu_input(\r\n    name=INPUT_NAME\r\n    arr_on_cpu=array)\r\n\r\nfor output in OUTPUT_NAMES:\r\n    io_binding.bind_output(output)\r\n\r\nsess.run_with_iobinding(io_binding)\r\n\r\noutputs = io_binding.copy_outputs_to_cpu()\r\n```\r\n\r\n**Expected behavior**\r\nI expect all the above attempts to yield the same output values (floating point precision aside).\r\n\r\n**Additional context**\r\nI cannot provide the model.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10299/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10300",
        "id": 1105093325,
        "node_id": "I_kwDOCVq1mM5B3mLN",
        "number": 10300,
        "title": "Crash on IOBinding synchronize_inputs()",
        "user": {
            "login": "jeshels",
            "id": 80462280,
            "node_id": "MDQ6VXNlcjgwNDYyMjgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/80462280?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeshels",
            "html_url": "https://github.com/jeshels",
            "followers_url": "https://api.github.com/users/jeshels/followers",
            "following_url": "https://api.github.com/users/jeshels/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeshels/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeshels/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeshels/subscriptions",
            "organizations_url": "https://api.github.com/users/jeshels/orgs",
            "repos_url": "https://api.github.com/users/jeshels/repos",
            "events_url": "https://api.github.com/users/jeshels/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeshels/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-16T16:13:10Z",
        "updated_at": "2022-01-25T22:48:52Z",
        "closed_at": "2022-01-25T22:48:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nPython program crash with exit code 139 (SIGSEGV Segmentation fault (core dumped)) when invoking `IOBinding.synchronize_inputs()`.\r\n\r\n**Urgency**\r\nNone.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): source installation. Built with `--use_cuda --cudnn_home /usr --cuda_home /usr/local/cuda --build_wheel --enable_pybind --config RelWithDebInfo --build_shared_lib --parallel`\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.9\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: CUDA version 10.1.105 / cuDNN version 8.0.5\r\n- GPU model and memory: Quadro RTX 4000\r\n\r\n**To Reproduce**\r\nI can reproduce with this minimal example:\r\n\r\n```python\r\nimport onnxruntime as ort\r\n\r\nmodel = ort.InferenceSession(PATH, providers=['CUDAExecutionProvider'])\r\nio = model.io_binding()\r\nio.synchronize_inputs() # CRASH - exit code 139 - Segmentation fault\r\n```\r\n\r\nI get the same behavior when using `bind_input()` and `bind_output()` prior to invoking `synchronize_inputs()`.\r\n\r\n**Expected behavior**\r\nI expect the method to work without crashing the program, and to yield an informative error message in case of misuse.\r\n\r\n**Additional context**\r\nI cannot provide the model, but I can execute it successfully with `session.run()` and `IOBinding` (as far as I don't invoke `synchronize_inputs()`). I didn't check whether `synchronize_outputs()` cause a crash as well.\r\n\r\n**Update:** I am able to reproduce the segmentation fault with this [CenterFace](https://github.com/Star-Clouds/CenterFace) ONNX model (I downloaded [this](https://github.com/Star-Clouds/CenterFace/blob/master/models/onnx/centerface.onnx) file). Moreover, it seems to be related to the model, since there is not segmentation fault when using the minimal example code with [Tiny YOLOv2](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny-yolov2) ONNX model. I deliberately chose detection models since I am facing this with a detection model.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10300/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10301",
        "id": 1105405362,
        "node_id": "PR_kwDOCVq1mM4xIEUX",
        "number": 10301,
        "title": "add openvino build pipliene",
        "user": {
            "login": "leqiao-1",
            "id": 61653207,
            "node_id": "MDQ6VXNlcjYxNjUzMjA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/61653207?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/leqiao-1",
            "html_url": "https://github.com/leqiao-1",
            "followers_url": "https://api.github.com/users/leqiao-1/followers",
            "following_url": "https://api.github.com/users/leqiao-1/following{/other_user}",
            "gists_url": "https://api.github.com/users/leqiao-1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/leqiao-1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/leqiao-1/subscriptions",
            "organizations_url": "https://api.github.com/users/leqiao-1/orgs",
            "repos_url": "https://api.github.com/users/leqiao-1/repos",
            "events_url": "https://api.github.com/users/leqiao-1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/leqiao-1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2022-01-17T05:47:35Z",
        "updated_at": "2022-01-24T02:10:27Z",
        "closed_at": "2022-01-24T02:10:27Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10301",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10301",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10301.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10301.patch",
            "merged_at": null
        },
        "body": "**Description**: add openvino python package build pipeline for OLive \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10301/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10302",
        "id": 1105503523,
        "node_id": "I_kwDOCVq1mM5B5KUj",
        "number": 10302,
        "title": "React Native: Can't load a model: Can't create InferenceSession",
        "user": {
            "login": "Shahzaib-MST",
            "id": 72867170,
            "node_id": "MDQ6VXNlcjcyODY3MTcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/72867170?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Shahzaib-MST",
            "html_url": "https://github.com/Shahzaib-MST",
            "followers_url": "https://api.github.com/users/Shahzaib-MST/followers",
            "following_url": "https://api.github.com/users/Shahzaib-MST/following{/other_user}",
            "gists_url": "https://api.github.com/users/Shahzaib-MST/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Shahzaib-MST/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Shahzaib-MST/subscriptions",
            "organizations_url": "https://api.github.com/users/Shahzaib-MST/orgs",
            "repos_url": "https://api.github.com/users/Shahzaib-MST/repos",
            "events_url": "https://api.github.com/users/Shahzaib-MST/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Shahzaib-MST/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "hanbitmyths",
                "id": 35605090,
                "node_id": "MDQ6VXNlcjM1NjA1MDkw",
                "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hanbitmyths",
                "html_url": "https://github.com/hanbitmyths",
                "followers_url": "https://api.github.com/users/hanbitmyths/followers",
                "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
                "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
                "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
                "repos_url": "https://api.github.com/users/hanbitmyths/repos",
                "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-17T08:05:40Z",
        "updated_at": "2022-08-12T08:34:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I have converted the Keras model to onnx using onnxmltools on python. the summary of the model is as below:\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 32)                480       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 64)                2112      \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 128)               8320      \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 64)                8256      \r\n_________________________________________________________________\r\ndropout (Dropout)            (None, 64)                0         \r\n_________________________________________________________________\r\ndense_4 (Dense)              (None, 5)                 325       \r\n=================================================================\r\nTotal params: 19,493\r\nTrainable params: 19,493\r\nNon-trainable params: 0\r\n\r\nThe converted model is working fine when used on python. In order to use the onnx model in react native, I converted the onnx model to ort format using the script:\r\n**python -m onnxruntime.tools.convert_onnx_models_to_ort model.onnx**\r\n \r\nThe converted ORT model works perfectly fine on python but when I use this model in react native it throws exceptions while loading the model\r\nthe exceptions is:\r\n**[Error: Can't load a model: Can't create InferenceSession]**",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10302/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10303",
        "id": 1105503554,
        "node_id": "I_kwDOCVq1mM5B5KVC",
        "number": 10303,
        "title": "onnxruntime inference is around 5 times slower than pytorch when using GPU",
        "user": {
            "login": "nssrivathsa",
            "id": 97871027,
            "node_id": "U_kgDOBdVksw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97871027?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nssrivathsa",
            "html_url": "https://github.com/nssrivathsa",
            "followers_url": "https://api.github.com/users/nssrivathsa/followers",
            "following_url": "https://api.github.com/users/nssrivathsa/following{/other_user}",
            "gists_url": "https://api.github.com/users/nssrivathsa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nssrivathsa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nssrivathsa/subscriptions",
            "organizations_url": "https://api.github.com/users/nssrivathsa/orgs",
            "repos_url": "https://api.github.com/users/nssrivathsa/repos",
            "events_url": "https://api.github.com/users/nssrivathsa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nssrivathsa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 24,
        "created_at": "2022-01-17T08:05:42Z",
        "updated_at": "2023-02-23T06:14:25Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nInference time of onnxruntime is 5x times slower as compared to the pytorch model on GPU BUT 2.5x times faster on CPU\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- ONNX Runtime installed from (source or binary): Source \r\n- ONNX Runtime version: 1.11.0 (onnx version 1.10.1)\r\n- Python version: 3.8.12\r\n- CUDA/cuDNN version:  cuda version 11.5, cudnn version 8.2\r\n- GPU model and memory: Quadro M2000M, 4 GB\r\n\r\n**To Reproduce**\r\n```\r\nbatch_size = 1\r\ntotal_samples = 1000\r\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n    \r\ndef convert_to_onnx(resnet):\r\n   resnet.eval()\r\n   dummy_input = (torch.randn(batch_size, 3, 224, 224, device=device)).to(device=device)\r\n   input_names = [ 'input' ]\r\n   output_names = [ 'output' ]\r\n   torch.onnx.export(resnet, \r\n               dummy_input,\r\n               \"resnet18.onnx\",\r\n               verbose=True,\r\n               opset_version=13,\r\n               input_names=input_names,\r\n               output_names=output_names,\r\n               export_params=True,\r\n               do_constant_folding=True,\r\n               dynamic_axes={\r\n                  'input': {0: 'batch_size'},  # variable length axes\r\n                  'output': {0: 'batch_size'}}        \r\n               )\r\n                  \r\ndef infer_pytorch(resnet):\r\n   print('Pytorch Inference')\r\n   print('==========================')\r\n   print()\r\n\r\n   x = torch.randn((batch_size, 3, 224, 224))\r\n   x = x.to(device=device)\r\n\r\n   latency = []\r\n   for i in range(total_samples):\r\n      t0 = time.time()\r\n      resnet.eval()\r\n      with torch.no_grad():\r\n         out = resnet(x)\r\n      latency.append(time.time() - t0)\r\n\r\n   print('Number of runs:', len(latency))\r\n   print(\"Average PyTorch {} Inference time = {} ms\".format(device.type, format(sum(latency) * 1000 / len(latency), '.2f')))  \r\n\r\ndef to_numpy(tensor):\r\n   return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\r\n\r\ndef infer_onnxruntime():\r\n   print('Onnxruntime Inference')\r\n   print('==========================')\r\n   print()\r\n\r\n   onnx_model = onnx.load(\"resnet18.onnx\")\r\n   onnx.checker.check_model(onnx_model)\r\n\r\n   # Input\r\n   x = torch.randn((batch_size, 3, 224, 224))\r\n   x = x.to(device=device)\r\n   x = to_numpy(x)\r\n\r\n   so = onnxruntime.SessionOptions()\r\n   so.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\r\n   so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n   \r\n   exproviders = ['CUDAExecutionProvider', 'CPUExecutionProvider']\r\n\r\n   model_onnx_path = os.path.join(\".\", \"resnet18.onnx\")\r\n   ort_session = onnxruntime.InferenceSession(model_onnx_path, so, providers=exproviders)\r\n\r\n   options = ort_session.get_provider_options()\r\n   cuda_options = options['CUDAExecutionProvider']\r\n   cuda_options['cudnn_conv_use_max_workspace'] = '1'\r\n   ort_session.set_providers(['CUDAExecutionProvider'], [cuda_options])\r\n\r\n   #IOBinding\r\n   input_names = ort_session.get_inputs()[0].name\r\n   output_names = ort_session.get_outputs()[0].name\r\n   io_binding = ort_session.io_binding()\r\n\r\n   io_binding.bind_cpu_input(input_names, x)\r\n   io_binding.bind_output(output_names, device)\r\n   \r\n   #warm up run\r\n   ort_session.run_with_iobinding(io_binding)\r\n   ort_outs = io_binding.copy_outputs_to_cpu()\r\n\r\n   latency = []\r\n\r\n   for i in range(total_samples):\r\n      t0 = time.time()\r\n      ort_session.run_with_iobinding(io_binding)\r\n      latency.append(time.time() - t0)\r\n      ort_outs = io_binding.copy_outputs_to_cpu()\r\n   print('Number of runs:', len(latency))\r\n   print(\"Average onnxruntime {} Inference time = {} ms\".format(device.type, format(sum(latency) * 1000 / len(latency), '.2f')))   \r\n\r\nif __name__ == '__main__':\r\n   torch.cuda.empty_cache()\r\n   resnet = (models.resnet18(pretrained=True)).to(device=device)\r\n   convert_to_onnx(resnet)\r\n   infer_onnxruntime()\r\n   infer_pytorch(resnet)\r\n```\r\n\r\n**Current behavior**\r\n\r\nIf run on CPU, \r\n```\r\nAverage onnxruntime cpu Inference time = 18.48 ms\r\nAverage PyTorch cpu Inference time = 51.74 ms\r\n```\r\nbut, if run on GPU, I see\r\n```\r\nAverage onnxruntime cuda Inference time = 47.89 ms\r\nAverage PyTorch cuda Inference time = 8.94 ms\r\n```\r\n\r\nIf I change graph optimizations to onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL, I see some improvements in inference time on GPU, but its still slower than Pytorch.\r\n\r\nI had read about similar issues here and ensured that i do the io binding so that the inputs are on GPU.\r\nWhen converting the resnet to onnx, I see traces like\r\n`%193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cuda:0),` \r\nso, the nodes of the model are on GPU.\r\n\r\nFurther, during the processing for onnxruntime, I print device usage stats and I see this - \r\n```\r\nUsing device: cuda:0\r\nGPU Device name: Quadro M2000M\r\nMemory Usage:\r\nAllocated: 0.1 GB\r\nCached:    0.1 GB\r\n```\r\nSo, GPU device is being used.\r\nFurther, I have used the resnet18.onnx model from the ModelZoo to see if it is a converted mode issue, but i get the same results.\r\n\r\nSo, I cannot seem to figure this out any further and I am stuck here since quite a few days.\r\nCould somebody please point out to what could be the issue here?\r\n\r\nThanks\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10303/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10304",
        "id": 1105816753,
        "node_id": "I_kwDOCVq1mM5B6Wyx",
        "number": 10304,
        "title": "Optimize Albert HuggingFace model",
        "user": {
            "login": "danielbellhv",
            "id": 84714841,
            "node_id": "MDQ6VXNlcjg0NzE0ODQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/84714841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielbellhv",
            "html_url": "https://github.com/danielbellhv",
            "followers_url": "https://api.github.com/users/danielbellhv/followers",
            "following_url": "https://api.github.com/users/danielbellhv/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielbellhv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielbellhv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielbellhv/subscriptions",
            "organizations_url": "https://api.github.com/users/danielbellhv/orgs",
            "repos_url": "https://api.github.com/users/danielbellhv/repos",
            "events_url": "https://api.github.com/users/danielbellhv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielbellhv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-17T12:50:20Z",
        "updated_at": "2022-01-18T15:35:48Z",
        "closed_at": "2022-01-18T15:35:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Based on [SO post](https://stackoverflow.com/q/70740565/17840900).\r\n\r\nGoal: Amend this [Notebook][1] to work with **albert-base-v2** model\r\n\r\nKernel: `conda_pytorch_p36`.\r\n\r\n**Section 2.1** exports the finalised model. It too uses a BERT specific function. However, I cannot find an equivalent for Albert.\r\n\r\nI've successfully implemented alternatives for Albert up until this section.\r\n\r\nCode:\r\n```python\r\n# optimize transformer-based models with onnxruntime-tools\r\nfrom onnxruntime_tools import optimizer\r\nfrom onnxruntime_tools.transformers.onnx_model_bert import BertOptimizationOptions\r\n\r\n# disable embedding layer norm optimization for better model size reduction\r\nopt_options = BertOptimizationOptions('bert')\r\nopt_options.enable_embed_layer_norm = False\r\n...\r\n```\r\n\r\n**Do functions for Optimizing and Quantizing an Albert model exist?**\r\n\r\nUpdate: You can run Quantization in the notebook, without running Optimization. You just need to remove '.opt.' from code, that is an indicative of optimised filenames.\r\n\r\n  [1]: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10304/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10305",
        "id": 1106168046,
        "node_id": "I_kwDOCVq1mM5B7sju",
        "number": 10305,
        "title": "bug: ONNX Runtime error: node->GetOutputEdgesCount() == 0 was false. Can't remove node",
        "user": {
            "login": "mattans",
            "id": 13219238,
            "node_id": "MDQ6VXNlcjEzMjE5MjM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/13219238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mattans",
            "html_url": "https://github.com/mattans",
            "followers_url": "https://api.github.com/users/mattans/followers",
            "following_url": "https://api.github.com/users/mattans/following{/other_user}",
            "gists_url": "https://api.github.com/users/mattans/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mattans/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mattans/subscriptions",
            "organizations_url": "https://api.github.com/users/mattans/orgs",
            "repos_url": "https://api.github.com/users/mattans/repos",
            "events_url": "https://api.github.com/users/mattans/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mattans/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-17T18:48:04Z",
        "updated_at": "2022-01-19T21:46:36Z",
        "closed_at": "2022-01-19T21:46:36Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nI have a simple Keras RNN model, composed by embedding, LSTM, and linear layers. The model works well in Keras when dumped and loaded. I converted the loaded model to ONNX opset 15 using `tf2onnx.convert.from_keras`, but I get this error when I init the `InferenceSession` object:\r\n\r\n`onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: D:\\a\\_work\\1\\s\\onnxruntime\\core\\graph\\graph.cc:3275 onnxruntime::Graph::RemoveNode node->GetOutputEdgesCount() == 0 was false. Can't remove node sequential/lstm_7/transpose as it still has output edges.`\r\n\r\nThis is the relevant node in Netron: https://i.stack.imgur.com/cBKqy.png\r\n\r\nIndeed it has output edges...\r\n\r\nIs this some kind of optimization that I can turn off in with `disabled_optimizers=...`? (this argument is not documented unfortunately)\r\n\r\nThank you.\r\n\r\n\r\n**Urgency**\r\ntwo weeks project\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11\r\n- ONNX Runtime installed from (source or binary): from pip\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: no\r\n\r\n**To Reproduce**\r\nCannot attach ONNX file without hiding params",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10305/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10306",
        "id": 1106447424,
        "node_id": "I_kwDOCVq1mM5B8wxA",
        "number": 10306,
        "title": "量化错误，我查看了链接库确实没用找个方法",
        "user": {
            "login": "yanni1995",
            "id": 49504923,
            "node_id": "MDQ6VXNlcjQ5NTA0OTIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/49504923?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yanni1995",
            "html_url": "https://github.com/yanni1995",
            "followers_url": "https://api.github.com/users/yanni1995/followers",
            "following_url": "https://api.github.com/users/yanni1995/following{/other_user}",
            "gists_url": "https://api.github.com/users/yanni1995/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yanni1995/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yanni1995/subscriptions",
            "organizations_url": "https://api.github.com/users/yanni1995/orgs",
            "repos_url": "https://api.github.com/users/yanni1995/repos",
            "events_url": "https://api.github.com/users/yanni1995/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yanni1995/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-18T03:52:33Z",
        "updated_at": "2023-04-20T18:02:29Z",
        "closed_at": "2023-04-20T18:02:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Traceback (most recent call last):\r\n  File \"D:/pythonProject1/quanonnx.py\", line 12, in <module>\r\n    quantized_model = quantize_qat(model_fp32, model_quant, op_types_to_quantize=['Conv'])\r\n  File \"D:\\Python\\lib\\site-packages\\onnxruntime\\quantization\\quantize.py\", line 349, in quantize_qat\r\n    op_types_to_quantize)\r\n  File \"D:\\Python\\lib\\site-packages\\onnxruntime\\quantization\\onnx_quantizer.py\", line 33, in __init__\r\n    model = onnx.shape_inference.infer_shapes(model)\r\nAttributeError: module 'onnx' has no attribute 'shape_inference'",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10306/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10307",
        "id": 1106567442,
        "node_id": "PR_kwDOCVq1mM4xL3pT",
        "number": 10307,
        "title": "Improve NonZero on CUDA/ROCM",
        "user": {
            "login": "pengwa",
            "id": 10530022,
            "node_id": "MDQ6VXNlcjEwNTMwMDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10530022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pengwa",
            "html_url": "https://github.com/pengwa",
            "followers_url": "https://api.github.com/users/pengwa/followers",
            "following_url": "https://api.github.com/users/pengwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/pengwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pengwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pengwa/subscriptions",
            "organizations_url": "https://api.github.com/users/pengwa/orgs",
            "repos_url": "https://api.github.com/users/pengwa/repos",
            "events_url": "https://api.github.com/users/pengwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pengwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-18T07:34:38Z",
        "updated_at": "2022-03-24T23:35:46Z",
        "closed_at": "2022-03-24T23:35:46Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10307",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10307",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10307.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10307.patch",
            "merged_at": "2022-03-24T23:35:46Z"
        },
        "body": "**Description**: improve NonZero on CUDA/ROCM.\r\n\r\nWithout the change, ORT is a lot slower than PT. \r\n\r\n![image](https://user-images.githubusercontent.com/10530022/149904055-d7c22a8c-1ab7-4a5a-af77-39bfa211cfb9.png)\r\n\r\nWith the changes, we see 2% ~ 17% latency reduction compared with stock PT on different kind of data.  \r\n\r\n![image](https://user-images.githubusercontent.com/10530022/149901936-e125dcf9-6b42-49ca-b4b0-e371bf01386d.png)\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10307/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10308",
        "id": 1106642232,
        "node_id": "I_kwDOCVq1mM5B9gU4",
        "number": 10308,
        "title": "A problem was encountered exporting an ONNX model with accuracy of FLOAT16",
        "user": {
            "login": "SiChuanJay",
            "id": 52130681,
            "node_id": "MDQ6VXNlcjUyMTMwNjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/52130681?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SiChuanJay",
            "html_url": "https://github.com/SiChuanJay",
            "followers_url": "https://api.github.com/users/SiChuanJay/followers",
            "following_url": "https://api.github.com/users/SiChuanJay/following{/other_user}",
            "gists_url": "https://api.github.com/users/SiChuanJay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SiChuanJay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SiChuanJay/subscriptions",
            "organizations_url": "https://api.github.com/users/SiChuanJay/orgs",
            "repos_url": "https://api.github.com/users/SiChuanJay/repos",
            "events_url": "https://api.github.com/users/SiChuanJay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SiChuanJay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1220611565,
                "node_id": "MDU6TGFiZWwxMjIwNjExNTY1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/converter",
                "name": "converter",
                "color": "0E8A16",
                "default": false,
                "description": "related to ONNX converters"
            },
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "thiagocrepaldi",
            "id": 5469809,
            "node_id": "MDQ6VXNlcjU0Njk4MDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5469809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thiagocrepaldi",
            "html_url": "https://github.com/thiagocrepaldi",
            "followers_url": "https://api.github.com/users/thiagocrepaldi/followers",
            "following_url": "https://api.github.com/users/thiagocrepaldi/following{/other_user}",
            "gists_url": "https://api.github.com/users/thiagocrepaldi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thiagocrepaldi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thiagocrepaldi/subscriptions",
            "organizations_url": "https://api.github.com/users/thiagocrepaldi/orgs",
            "repos_url": "https://api.github.com/users/thiagocrepaldi/repos",
            "events_url": "https://api.github.com/users/thiagocrepaldi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thiagocrepaldi/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "thiagocrepaldi",
                "id": 5469809,
                "node_id": "MDQ6VXNlcjU0Njk4MDk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5469809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/thiagocrepaldi",
                "html_url": "https://github.com/thiagocrepaldi",
                "followers_url": "https://api.github.com/users/thiagocrepaldi/followers",
                "following_url": "https://api.github.com/users/thiagocrepaldi/following{/other_user}",
                "gists_url": "https://api.github.com/users/thiagocrepaldi/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/thiagocrepaldi/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/thiagocrepaldi/subscriptions",
                "organizations_url": "https://api.github.com/users/thiagocrepaldi/orgs",
                "repos_url": "https://api.github.com/users/thiagocrepaldi/repos",
                "events_url": "https://api.github.com/users/thiagocrepaldi/events{/privacy}",
                "received_events_url": "https://api.github.com/users/thiagocrepaldi/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 13,
        "created_at": "2022-01-18T09:02:29Z",
        "updated_at": "2022-11-16T15:33:17Z",
        "closed_at": "2022-11-16T15:33:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello, When I try to export the PyTorch model as an ONNX model with accuracy of FLOAT16, in the ONNX structure diagram, the input is float16, but the output is still float32, as shown below, and an error is reported at runtime.\r\n![149513940-4e1e8b7c-7d8a-4f9a-a6e1-86f6a645ceaa](https://user-images.githubusercontent.com/52130681/149904319-9b9112e4-7193-482f-a359-482ebe333867.jpg)\r\n\r\n```python\r\nimport argparse\r\nimport torch\r\n\r\nfrom model.model import MattingNetwork\r\n\r\n\r\nclass Exporter:\r\n    def __init__(self):\r\n        self.parse_args()\r\n        self.init_model()\r\n        self.export()\r\n        \r\n    def parse_args(self):\r\n        parser = argparse.ArgumentParser()\r\n        parser.add_argument('--model-variant', type=str, default='mobilenetv3', choices=['mobilenetv3', 'mobilenetv3_small', 'resnet18'])\r\n        parser.add_argument('--model-refiner', type=str, default='deep_guided_filter', choices=['deep_guided_filter', 'fast_guided_filter'])\r\n        parser.add_argument('--precision', type=str, default='float16', choices=['float16', 'float32'])\r\n        parser.add_argument('--opset', type=int, default=11)\r\n        parser.add_argument('--device', type=str, default='cuda:0')\r\n        parser.add_argument('--checkpoint', type=str, default='automatic.pth')\r\n        parser.add_argument('--output', type=str, default=r'C:\\Users\\HuangZhe\\Desktop\\automatic.onnx')\r\n        self.args = parser.parse_args()\r\n        \r\n    def init_model(self):\r\n        self.precision = torch.float32 if self.args.precision == 'float32' else torch.float16\r\n        self.model = MattingNetwork(self.args.model_variant, self.args.model_refiner).eval().to(self.args.device, self.precision)\r\n        if self.args.checkpoint is not None:\r\n            self.model.load_state_dict(torch.load(self.args.checkpoint, map_location=self.args.device), strict=False)\r\n        \r\n    def export(self):\r\n        rec = (torch.zeros([1, 1, 1, 1]).to(self.args.device, self.precision),) * 4\r\n        src = torch.randn(1, 3, 1080, 1920).to(self.args.device, self.precision)\r\n        downsample_ratio = torch.tensor([0.25]).to(self.args.device, dtype=self.precision)\r\n        \r\n        dynamic_spatial = {0: 'batch_size', 2: 'height', 3: 'width'}\r\n        dynamic_everything = {0: 'batch_size', 1: 'channels', 2: 'height', 3: 'width'}\r\n        \r\n        torch.onnx.export(\r\n            self.model,\r\n            (src, *rec, downsample_ratio),\r\n            self.args.output,\r\n            export_params=True,\r\n            opset_version=self.args.opset,\r\n            do_constant_folding=True,\r\n            input_names=['src', 'r1i', 'r2i', 'r3i', 'r4i', 'downsample_ratio'],\r\n            output_names=['fgr', 'pha', 'r1o', 'r2o', 'r3o', 'r4o'],\r\n            dynamic_axes={\r\n                'src': dynamic_spatial,\r\n                'fgr': dynamic_spatial,\r\n                'pha': dynamic_spatial,\r\n                'r1i': dynamic_everything,\r\n                'r2i': dynamic_everything,\r\n                'r3i': dynamic_everything,\r\n                'r4i': dynamic_everything,\r\n                'r1o': dynamic_spatial,\r\n                'r2o': dynamic_spatial,\r\n                'r3o': dynamic_spatial,\r\n                'r4o': dynamic_spatial,\r\n            })\r\n\r\nif __name__ == '__main__':\r\n    Exporter()\r\n```\r\n\r\nThanks for your help!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10308/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10309",
        "id": 1106681249,
        "node_id": "PR_kwDOCVq1mM4xMPQc",
        "number": 10309,
        "title": "winograd",
        "user": {
            "login": "wejoncy",
            "id": 9417365,
            "node_id": "MDQ6VXNlcjk0MTczNjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9417365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wejoncy",
            "html_url": "https://github.com/wejoncy",
            "followers_url": "https://api.github.com/users/wejoncy/followers",
            "following_url": "https://api.github.com/users/wejoncy/following{/other_user}",
            "gists_url": "https://api.github.com/users/wejoncy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wejoncy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wejoncy/subscriptions",
            "organizations_url": "https://api.github.com/users/wejoncy/orgs",
            "repos_url": "https://api.github.com/users/wejoncy/repos",
            "events_url": "https://api.github.com/users/wejoncy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wejoncy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-18T09:40:44Z",
        "updated_at": "2022-01-21T05:06:18Z",
        "closed_at": "2022-01-18T09:40:55Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10309",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10309",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10309.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10309.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10309/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10310",
        "id": 1106830115,
        "node_id": "I_kwDOCVq1mM5B-OMj",
        "number": 10310,
        "title": "ValueError: The state dictionary of the model you are training to load is corrupted. Are you sure it was properly saved?",
        "user": {
            "login": "danielbellhv",
            "id": 84714841,
            "node_id": "MDQ6VXNlcjg0NzE0ODQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/84714841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielbellhv",
            "html_url": "https://github.com/danielbellhv",
            "followers_url": "https://api.github.com/users/danielbellhv/followers",
            "following_url": "https://api.github.com/users/danielbellhv/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielbellhv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielbellhv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielbellhv/subscriptions",
            "organizations_url": "https://api.github.com/users/danielbellhv/orgs",
            "repos_url": "https://api.github.com/users/danielbellhv/repos",
            "events_url": "https://api.github.com/users/danielbellhv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielbellhv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-18T12:12:19Z",
        "updated_at": "2022-01-18T14:31:59Z",
        "closed_at": "2022-01-18T14:31:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Based on [SO post](https://stackoverflow.com/q/70754085/17840900).\r\n\r\nGoal: Amend this [Notebook][1] to work with **albert-base-v2** model\r\n\r\nKernel: `conda_pytorch_p36`.\r\n\r\n**Section 1.2** instantiates a model from files in `./MRPC/` dir.\r\n\r\nHowever, I *think* it is for a **BERT** model, not **Albert**. So, I downloaded an Albert `config.json` file from [here][2]. It is this chnage that causes the error.\r\n\r\n**What else do I need to do in order to instantiate an Albert model?**\r\n\r\n**Is there an a similar download folder for Albert-related files?**\r\n\r\n---\r\n\r\n`./MRPC/` dir:\r\n```\r\n!curl https://download.pytorch.org/tutorial/MRPC.zip --output MPRC.zip\r\n!unzip -n MPRC.zip\r\n```\r\n```python\r\nfrom os import listdir\r\nfrom os.path import isfile, join\r\n​\r\nmypath = './MRPC/'\r\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\r\nonlyfiles\r\n---\r\n\r\n['tokenizer_config.json',\r\n 'special_tokens_map.json',\r\n 'pytorch_model.bin',\r\n 'config.json',\r\n 'training_args.bin',\r\n 'added_tokens.json',\r\n 'vocab.txt']\r\n```\r\n\r\nConfigs:\r\n```python\r\n# The output directory for the fine-tuned model, $OUT_DIR.\r\nconfigs.output_dir = \"./MRPC/\"\r\n\r\n# The data directory for the MRPC task in the GLUE benchmark, $GLUE_DIR/$TASK_NAME.\r\nconfigs.data_dir = \"./glue_data/MRPC\"\r\n\r\n# The model name or path for the pre-trained model.\r\nconfigs.model_name_or_path = \"albert-base-v2\"\r\n# The maximum length of an input sequence\r\nconfigs.max_seq_length = 128\r\n\r\n# Prepare GLUE task.\r\nconfigs.task_name = \"MRPC\".lower()\r\nconfigs.processor = processors[configs.task_name]()\r\nconfigs.output_mode = output_modes[configs.task_name]\r\nconfigs.label_list = configs.processor.get_labels()\r\nconfigs.model_type = \"albert\".lower()\r\nconfigs.do_lower_case = True\r\n\r\n# Set the device, batch size, topology, and caching flags.\r\nconfigs.device = \"cpu\"\r\nconfigs.eval_batch_size = 1\r\nconfigs.n_gpu = 0\r\nconfigs.local_rank = -1\r\nconfigs.overwrite_cache = False\r\n```\r\n\r\nModel:\r\n```python\r\nmodel = AlbertForSequenceClassification.from_pretrained(configs.output_dir)  # !\r\nmodel.to(configs.device)\r\n```\r\n\r\nTraceback:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-36-0936fd8cbb17> in <module>\r\n      1 # load model\r\n----> 2 model = AlbertForSequenceClassification.from_pretrained(configs.output_dir)\r\n      3 model.to(configs.device)\r\n      4 \r\n      5 # quantize model\r\n\r\n~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/modeling_utils.py in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\n   1460                     pretrained_model_name_or_path,\r\n   1461                     ignore_mismatched_sizes=ignore_mismatched_sizes,\r\n-> 1462                     _fast_init=_fast_init,\r\n   1463                 )\r\n   1464 \r\n\r\n~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/modeling_utils.py in _load_state_dict_into_model(cls, model, state_dict, pretrained_model_name_or_path, ignore_mismatched_sizes, _fast_init)\r\n   1601             if any(key in expected_keys_not_prefixed for key in loaded_keys):\r\n   1602                 raise ValueError(\r\n-> 1603                     \"The state dictionary of the model you are training to load is corrupted. Are you sure it was \"\r\n   1604                     \"properly saved?\"\r\n   1605                 )\r\n\r\nValueError: The state dictionary of the model you are training to load is corrupted. Are you sure it was properly saved?\r\n```\r\n\r\n\r\n  [1]: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb\r\n  [2]: https://huggingface.co/albert-base-v2/tree/main",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10310/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10311",
        "id": 1107026138,
        "node_id": "I_kwDOCVq1mM5B--Da",
        "number": 10311,
        "title": "Bug: pthread sent an error! undefined:undefined: ortWasmThreaded is not defined",
        "user": {
            "login": "wanghsinche",
            "id": 14119632,
            "node_id": "MDQ6VXNlcjE0MTE5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/14119632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wanghsinche",
            "html_url": "https://github.com/wanghsinche",
            "followers_url": "https://api.github.com/users/wanghsinche/followers",
            "following_url": "https://api.github.com/users/wanghsinche/following{/other_user}",
            "gists_url": "https://api.github.com/users/wanghsinche/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wanghsinche/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wanghsinche/subscriptions",
            "organizations_url": "https://api.github.com/users/wanghsinche/orgs",
            "repos_url": "https://api.github.com/users/wanghsinche/repos",
            "events_url": "https://api.github.com/users/wanghsinche/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wanghsinche/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            },
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-18T15:13:10Z",
        "updated_at": "2023-03-20T13:48:26Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi team, I used the example in your repo. But the `onnxruntime-web` session threw some error after I fed a tensor to it, while I still got some output. The code was run on my WLS2 ubuntu 18.  \r\n```bash\r\n$ node test/index.js\r\ndata of result tensor 'c': 700,800,900,1580,1840,2100,2460,2880,3300\r\nworker.js onmessage() captured an uncaught exception: ReferenceError: ortWasmThreaded is not defined\r\npthread sent an error! undefined:undefined: ortWasmThreaded is not defined\r\n```\r\nI tried another model and got the same error as well. I am sure that the input tensor is converted in right shape because it works in `onnxruntime-node` .\r\n\r\n\r\n**Urgency**\r\n none.\r\n\r\n**System information**\r\n- Linux Ubuntu 18 at WSL2:\r\n- ONNX Runtime installed from (source or binary):     \"onnxruntime-web\": \"^1.10.0\"\r\n- ONNX Runtime version: 1.10.0\r\n- node version: v16.13.1\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: \r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n\r\nhttps://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/quick-start_onnxruntime-web-bundler \r\n\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10311/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10312",
        "id": 1107200346,
        "node_id": "PR_kwDOCVq1mM4xN8es",
        "number": 10312,
        "title": "[Website] Add new logos/quotes",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-18T17:54:10Z",
        "updated_at": "2022-01-19T22:05:09Z",
        "closed_at": "2022-01-19T18:06:58Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10312",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10312",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10312.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10312.patch",
            "merged_at": "2022-01-19T18:06:58Z"
        },
        "body": "Staged here for preview: https://faxu.github.io/onnxruntime/\r\n\r\n- add new quotes for Hypefactors and Writer\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10312/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10313",
        "id": 1107267324,
        "node_id": "PR_kwDOCVq1mM4xOKL3",
        "number": 10313,
        "title": "[js/common] upgrade marked@4.0.10 (Dependbot warning)",
        "user": {
            "login": "fs-eire",
            "id": 7679871,
            "node_id": "MDQ6VXNlcjc2Nzk4NzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7679871?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fs-eire",
            "html_url": "https://github.com/fs-eire",
            "followers_url": "https://api.github.com/users/fs-eire/followers",
            "following_url": "https://api.github.com/users/fs-eire/following{/other_user}",
            "gists_url": "https://api.github.com/users/fs-eire/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fs-eire/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fs-eire/subscriptions",
            "organizations_url": "https://api.github.com/users/fs-eire/orgs",
            "repos_url": "https://api.github.com/users/fs-eire/repos",
            "events_url": "https://api.github.com/users/fs-eire/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fs-eire/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-18T19:11:46Z",
        "updated_at": "2022-01-18T22:00:11Z",
        "closed_at": "2022-01-18T22:00:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10313",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10313",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10313.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10313.patch",
            "merged_at": "2022-01-18T22:00:10Z"
        },
        "body": "**Description**: This change upgrade NPM package **marked** to v4.0.10. https://github.com/advisories/GHSA-5v2h-r2cx-5xgj",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10313/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10314",
        "id": 1107440835,
        "node_id": "PR_kwDOCVq1mM4xOuab",
        "number": 10314,
        "title": "Fix TopK with NAN on Cuda",
        "user": {
            "login": "RandySheriffH",
            "id": 48490400,
            "node_id": "MDQ6VXNlcjQ4NDkwNDAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/48490400?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RandySheriffH",
            "html_url": "https://github.com/RandySheriffH",
            "followers_url": "https://api.github.com/users/RandySheriffH/followers",
            "following_url": "https://api.github.com/users/RandySheriffH/following{/other_user}",
            "gists_url": "https://api.github.com/users/RandySheriffH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RandySheriffH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RandySheriffH/subscriptions",
            "organizations_url": "https://api.github.com/users/RandySheriffH/orgs",
            "repos_url": "https://api.github.com/users/RandySheriffH/repos",
            "events_url": "https://api.github.com/users/RandySheriffH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RandySheriffH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-18T22:54:27Z",
        "updated_at": "2022-01-28T00:19:56Z",
        "closed_at": "2022-01-28T00:19:56Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10314",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10314",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10314.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10314.patch",
            "merged_at": "2022-01-28T00:19:56Z"
        },
        "body": "This PR is to address cases that there are NAN in input for TopK on Cuda.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10314/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10315",
        "id": 1107497666,
        "node_id": "PR_kwDOCVq1mM4xO6Eo",
        "number": 10315,
        "title": "[ortmodule] Ensure contiguous tensor into forward pass",
        "user": {
            "login": "jiafatom",
            "id": 30608893,
            "node_id": "MDQ6VXNlcjMwNjA4ODkz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30608893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jiafatom",
            "html_url": "https://github.com/jiafatom",
            "followers_url": "https://api.github.com/users/jiafatom/followers",
            "following_url": "https://api.github.com/users/jiafatom/following{/other_user}",
            "gists_url": "https://api.github.com/users/jiafatom/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jiafatom/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jiafatom/subscriptions",
            "organizations_url": "https://api.github.com/users/jiafatom/orgs",
            "repos_url": "https://api.github.com/users/jiafatom/repos",
            "events_url": "https://api.github.com/users/jiafatom/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jiafatom/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-19T00:24:16Z",
        "updated_at": "2022-01-19T06:06:38Z",
        "closed_at": "2022-01-19T06:06:37Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10315",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10315",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10315.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10315.patch",
            "merged_at": "2022-01-19T06:06:37Z"
        },
        "body": "**Description**: Ensure contiguous tensor input into `_utils._torch_tensor_to_dlpack(input)`.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n`_utils._torch_tensor_to_dlpack(input)` need contiguous tensor input. However, in hierarchical ortmodule, some pytorch submodules can have non-contiguous tensor output. So we need convert it to contiguous tensor into ort submodules. \r\nActually I find the backward pass already have this conversion. So add this to forward pass here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10315/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10316",
        "id": 1107533134,
        "node_id": "PR_kwDOCVq1mM4xPBHR",
        "number": 10316,
        "title": "Allow dynamic element type in PythonOp",
        "user": {
            "login": "wschin",
            "id": 3524474,
            "node_id": "MDQ6VXNlcjM1MjQ0NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3524474?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wschin",
            "html_url": "https://github.com/wschin",
            "followers_url": "https://api.github.com/users/wschin/followers",
            "following_url": "https://api.github.com/users/wschin/following{/other_user}",
            "gists_url": "https://api.github.com/users/wschin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wschin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wschin/subscriptions",
            "organizations_url": "https://api.github.com/users/wschin/orgs",
            "repos_url": "https://api.github.com/users/wschin/repos",
            "events_url": "https://api.github.com/users/wschin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wschin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "wschin",
            "id": 3524474,
            "node_id": "MDQ6VXNlcjM1MjQ0NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3524474?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wschin",
            "html_url": "https://github.com/wschin",
            "followers_url": "https://api.github.com/users/wschin/followers",
            "following_url": "https://api.github.com/users/wschin/following{/other_user}",
            "gists_url": "https://api.github.com/users/wschin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wschin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wschin/subscriptions",
            "organizations_url": "https://api.github.com/users/wschin/orgs",
            "repos_url": "https://api.github.com/users/wschin/repos",
            "events_url": "https://api.github.com/users/wschin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wschin/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "wschin",
                "id": 3524474,
                "node_id": "MDQ6VXNlcjM1MjQ0NzQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3524474?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wschin",
                "html_url": "https://github.com/wschin",
                "followers_url": "https://api.github.com/users/wschin/followers",
                "following_url": "https://api.github.com/users/wschin/following{/other_user}",
                "gists_url": "https://api.github.com/users/wschin/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wschin/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wschin/subscriptions",
                "organizations_url": "https://api.github.com/users/wschin/orgs",
                "repos_url": "https://api.github.com/users/wschin/repos",
                "events_url": "https://api.github.com/users/wschin/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wschin/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-19T01:23:22Z",
        "updated_at": "2022-07-12T00:31:59Z",
        "closed_at": "2022-06-23T21:02:40Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10316",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10316",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10316.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10316.patch",
            "merged_at": null
        },
        "body": "PythonOp records the input/output types used when running exporter and enforce them in subsequent calls. However, in mix-precision mode, a model exported with fp16 may receive fp32 input, so we need to relax this constraint. Otherwise, ORT will throw.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10316/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10317",
        "id": 1107541235,
        "node_id": "PR_kwDOCVq1mM4xPCq0",
        "number": 10317,
        "title": "[debug only] float16 for Div in cpu",
        "user": {
            "login": "jiafatom",
            "id": 30608893,
            "node_id": "MDQ6VXNlcjMwNjA4ODkz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30608893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jiafatom",
            "html_url": "https://github.com/jiafatom",
            "followers_url": "https://api.github.com/users/jiafatom/followers",
            "following_url": "https://api.github.com/users/jiafatom/following{/other_user}",
            "gists_url": "https://api.github.com/users/jiafatom/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jiafatom/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jiafatom/subscriptions",
            "organizations_url": "https://api.github.com/users/jiafatom/orgs",
            "repos_url": "https://api.github.com/users/jiafatom/repos",
            "events_url": "https://api.github.com/users/jiafatom/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jiafatom/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-19T01:37:39Z",
        "updated_at": "2022-08-10T00:46:28Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10317",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10317",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10317.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10317.patch",
            "merged_at": null
        },
        "body": "As title.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10317/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10318",
        "id": 1107556445,
        "node_id": "PR_kwDOCVq1mM4xPFtp",
        "number": 10318,
        "title": "[Java] Adding the graph description to the exposed model metadata",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-19T02:09:07Z",
        "updated_at": "2022-02-28T18:05:04Z",
        "closed_at": "2022-02-28T18:05:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10318",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10318",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10318.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10318.patch",
            "merged_at": "2022-02-28T18:05:03Z"
        },
        "body": "**Description**:\r\nAdds the graph description field to the metadata visible in Java, and ported across the metadata test from C# to Java. Also adds a missing copyright statement to the `OnnxModelMetadata` class.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve? Users might want this metadata and can't access it without opening the protobuf directly.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10318/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10319",
        "id": 1107797288,
        "node_id": "PR_kwDOCVq1mM4xP38Y",
        "number": 10319,
        "title": "Fix issue with implicit inputs not being added to consumer nodes map.",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-19T08:25:21Z",
        "updated_at": "2022-01-19T21:46:37Z",
        "closed_at": "2022-01-19T21:46:36Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10319",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10319",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10319.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10319.patch",
            "merged_at": "2022-01-19T21:46:36Z"
        },
        "body": "**Description**: \r\nAdd implicit inputs to consumer nodes map in Graph.\r\n\r\n**Motivation and Context**\r\nFix #10305 ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10319/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10320",
        "id": 1107830993,
        "node_id": "I_kwDOCVq1mM5CCCjR",
        "number": 10320,
        "title": "Finding symbolic names of the inputs shapes with C++ API",
        "user": {
            "login": "fkavache",
            "id": 29062515,
            "node_id": "MDQ6VXNlcjI5MDYyNTE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/29062515?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fkavache",
            "html_url": "https://github.com/fkavache",
            "followers_url": "https://api.github.com/users/fkavache/followers",
            "following_url": "https://api.github.com/users/fkavache/following{/other_user}",
            "gists_url": "https://api.github.com/users/fkavache/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fkavache/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fkavache/subscriptions",
            "organizations_url": "https://api.github.com/users/fkavache/orgs",
            "repos_url": "https://api.github.com/users/fkavache/repos",
            "events_url": "https://api.github.com/users/fkavache/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fkavache/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-01-19T09:02:50Z",
        "updated_at": "2023-03-27T16:41:42Z",
        "closed_at": "2022-02-02T13:11:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I wonder if there is any way to find symbolic names of the input shapes using C++ API.\r\nWith python you can:\r\n\r\n```\r\nsession = onnxruntime.InferenceSession(‘...’, providers=['...'])\r\n\r\nsession .get_inputs()\r\n\r\nname = session .get_inputs()[0].name     # name is 'depth:0'\r\nshape = session .get_inputs()[0].shape   # shape is ['unk__2149', 'unk__2150', 'unk__2151', 1]\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10320/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10321",
        "id": 1107856778,
        "node_id": "PR_kwDOCVq1mM4xQEO2",
        "number": 10321,
        "title": "splitstringusing",
        "user": {
            "login": "wejoncy",
            "id": 9417365,
            "node_id": "MDQ6VXNlcjk0MTczNjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9417365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wejoncy",
            "html_url": "https://github.com/wejoncy",
            "followers_url": "https://api.github.com/users/wejoncy/followers",
            "following_url": "https://api.github.com/users/wejoncy/following{/other_user}",
            "gists_url": "https://api.github.com/users/wejoncy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wejoncy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wejoncy/subscriptions",
            "organizations_url": "https://api.github.com/users/wejoncy/orgs",
            "repos_url": "https://api.github.com/users/wejoncy/repos",
            "events_url": "https://api.github.com/users/wejoncy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wejoncy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-19T09:28:24Z",
        "updated_at": "2022-01-21T05:06:18Z",
        "closed_at": "2022-01-19T09:28:31Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10321",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10321",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10321.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10321.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10321/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10322",
        "id": 1107954874,
        "node_id": "I_kwDOCVq1mM5CCgy6",
        "number": 10322,
        "title": "Quantized int8 onnx GPT2 model returns different tokens whether using past_key_values or not for the same sentence",
        "user": {
            "login": "smolskayanastassia",
            "id": 73059925,
            "node_id": "MDQ6VXNlcjczMDU5OTI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/73059925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smolskayanastassia",
            "html_url": "https://github.com/smolskayanastassia",
            "followers_url": "https://api.github.com/users/smolskayanastassia/followers",
            "following_url": "https://api.github.com/users/smolskayanastassia/following{/other_user}",
            "gists_url": "https://api.github.com/users/smolskayanastassia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smolskayanastassia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smolskayanastassia/subscriptions",
            "organizations_url": "https://api.github.com/users/smolskayanastassia/orgs",
            "repos_url": "https://api.github.com/users/smolskayanastassia/repos",
            "events_url": "https://api.github.com/users/smolskayanastassia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smolskayanastassia/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-01-19T10:58:05Z",
        "updated_at": "2022-11-18T06:18:40Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Describe the issue:\r\nI converted DistilGPT2 pretrained model to float32 onnx. Then I quantized onnx model to int8 using this [notebook](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/notebooks/Inference_GPT2_with_OnnxRuntime_on_CPU.ipynb).\r\nI decided to check past_key_values in int8 onnx model.\r\n\r\nLet's take the sentence \"Hi How are\" and pass it into the model. The result (first 10 tokens) will be [' you', ' we', ' I', ' the', ' your', ' these', ' You', ' they', ' there', ' We']\r\n\r\nIf we pass \"Hi\" into the model and save past_key_values for it, then we pass \"How are\" and past_key_values  for \"Hi\" to the model we will get  [' you', ' we', ' the', ' I', ' your', ' there', ' they', ' You', ' these', ' all']\r\n\r\nThe result is different only for quantized int8 distilgpt2, but for distilgpt2 float32 the result is the same.\r\nMaybe someone knows why the result for quantized int8 distilgpt2 different whether I use past_key_values or not?\r\n\r\nCode: \r\n\r\n```\r\nimport torch\r\nimport onnxruntime\r\nimport numpy as np\r\nfrom transformers import GPT2Tokenizer\r\nfrom torch.nn import functional as F\r\n\r\nsession = onnxruntime.InferenceSession(\"distilgpt2_int8_v2.onnx\")\r\ntokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\r\ntokenizer.pad_token = tokenizer.eos_token\r\n\r\n# Parameters for DistilGPT2\r\nnum_attention_heads = 12\r\nhidden_size = 768\r\nnum_layer = 6\r\ndevice = \"cpu\"\r\n\r\ndef get_tokens(text, top_k=10):\r\n    encodings_dict = tokenizer.batch_encode_plus([text], padding=True)\r\n    input_ids = torch.tensor(encodings_dict[\"input_ids\"], dtype=torch.int64)\r\n    attention_mask = torch.tensor(encodings_dict[\"attention_mask\"], dtype=torch.float32)\r\n\r\n    position_ids = attention_mask.long().cumsum(-1) - 1\r\n\r\n    position_ids.masked_fill_(position_ids < 0, 0)\r\n\r\n    past_shape = [\r\n        2,\r\n        input_ids.size(0),\r\n        num_attention_heads,\r\n        0,\r\n        hidden_size // num_attention_heads,\r\n    ]\r\n    past = [torch.empty(past_shape).to(device)] * num_layer\r\n    \r\n    model_inputs = {\r\n    \"input_ids\": input_ids.cpu().numpy(),\r\n    \"attention_mask\": attention_mask.cpu().numpy(),\r\n    \"position_ids\": position_ids.cpu().numpy(),\r\n    }\r\n\r\n    for i, past_i in enumerate(past):\r\n        model_inputs[f\"past_{i}\"] = past_i.cpu().numpy()\r\n\r\n    ort_outputs = session.run(None, model_inputs)\r\n\r\n    next_token_logits = torch.Tensor(ort_outputs[0][:, -1, :])\r\n    top_n_logits, top_n_tokens = torch.topk(next_token_logits, top_k, dim=1)\r\n    top_n_probs = F.softmax(top_n_logits, dim=-1)\r\n    words = [\r\n        tokenizer.decode(x, skip_special_tokens=True)\r\n        for x in top_n_tokens[0]\r\n    ]\r\n    new_past = np.array(ort_outputs[1:])\r\n    return words, new_past\r\n\r\n\r\n# Results for \"Hi How are\" without using past_key_values \r\n# [' you',  ' we', ' I', ' the', ' your', ' these', ' You', ' they', ' there', ' We'],\r\nwords, _ = get_tokens(\"Hi How are\", top_k=10)\r\nprint(words)\r\n\r\n# Results \"How are\" with past_key_values for \"Hi\"\r\n#[' you', ' we', ' the', ' I', ' your', ' there', ' they', ' You', ' these', ' all']\r\n_, past = get_tokens(\"Hi\", top_k=10)\r\n\r\ntext = \"Hi How are\"\r\nencodings_dict = tokenizer.batch_encode_plus([text])\r\n\r\ninput_ids = torch.tensor(encodings_dict[\"input_ids\"], dtype=torch.int64)\r\nprev_seq_length = past[0].shape[3]\r\ninput_ids = input_ids[:, prev_seq_length:]\r\ncurr_seq_length = prev_seq_length + input_ids.shape[1]\r\nattention_mask = torch.ones([1, curr_seq_length], dtype=torch.float32)\r\n\r\nposition_ids = attention_mask.long().cumsum(-1) - 1\r\n\r\nposition_ids = position_ids[:, prev_seq_length:]\r\n\r\npast = torch.from_numpy(past)\r\nmodel_inputs = {\r\n\"input_ids\": input_ids.cpu().numpy(),\r\n\"attention_mask\": attention_mask.cpu().numpy(),\r\n\"position_ids\": position_ids.cpu().numpy(),\r\n}\r\n\r\nfor i, past_i in enumerate(past):\r\n    model_inputs[f\"past_{i}\"] = past_i.cpu().numpy()\r\n    \r\nort_outputs = session.run(None, model_inputs)\r\n\r\nnext_token_logits = torch.Tensor(ort_outputs[0][:, -1, :])\r\ntop_n_logits, top_n_tokens = torch.topk(next_token_logits, 10, dim=1)\r\ntop_n_probs = F.softmax(top_n_logits, dim=-1)\r\nwords = [\r\n    tokenizer.decode(x, skip_special_tokens=True)\r\n    for x in top_n_tokens[0]\r\n]\r\nprint(words)\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10322/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10323",
        "id": 1108347806,
        "node_id": "I_kwDOCVq1mM5CEAue",
        "number": 10323,
        "title": "[Microsoft.ML.OnnxRuntime.GPU] onnxruntime::CudaCall CUDNN failure 4",
        "user": {
            "login": "Ignasinou",
            "id": 19283475,
            "node_id": "MDQ6VXNlcjE5MjgzNDc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/19283475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ignasinou",
            "html_url": "https://github.com/Ignasinou",
            "followers_url": "https://api.github.com/users/Ignasinou/followers",
            "following_url": "https://api.github.com/users/Ignasinou/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ignasinou/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ignasinou/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ignasinou/subscriptions",
            "organizations_url": "https://api.github.com/users/Ignasinou/orgs",
            "repos_url": "https://api.github.com/users/Ignasinou/repos",
            "events_url": "https://api.github.com/users/Ignasinou/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ignasinou/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-19T17:06:03Z",
        "updated_at": "2022-02-08T08:01:58Z",
        "closed_at": "2022-02-08T08:01:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nTrying to do inference on GPU on a model exported from pytorch that takes two inputs, one is (1,5,224,224) size and the other one (1,8000).\r\n\r\nThe following snippet shows the loading of dummy input data and the inferencing process. I have also attached the outputs when running the project.\r\n\r\n**System information**\r\n- Windows 10 Pro\r\n- ONNX Runtime installed from NuGet.\r\n- ONNX Runtime version: Microsoft.ML.OnnxRuntime.Gpu 1.10.0\r\n- Python version: 3.9.5 / 3.7.9\r\n- Visual Studio version (if applicable): Microsoft Visual Studio Community 2019 - Version 16.11.6\r\n- CUDA/cuDNN version: 11.1 / 8.0.5\r\n- GPU model and memory: RTX 2060\r\n\r\n**To Reproduce**\r\n\r\n``` c++\r\n#include <iostream>\r\n#include \"onnxruntime_cxx_api.h\"\r\n#include <chrono>\r\n\r\n#define USE_CUDA // Chnage USE_CPU to USE_CUDA\r\n\r\n\r\nint main()\r\n{\r\n\tauto providers = Ort::GetAvailableProviders();\r\n\tfor (auto provider : providers)\r\n\t\tstd::cout << provider << std::endl;\r\n\r\n\tOrt::Env env = Ort::Env{ ORT_LOGGING_LEVEL_VERBOSE, \"Default\" };\r\n\tOrt::SessionOptions session_options;\r\n\r\n#ifdef USE_CUDA\r\n\tOrt::ThrowOnError(OrtSessionOptionsAppendExecutionProvider_CUDA(session_options, 0));\r\n#endif  // CUDA GPU Enabled\r\n\r\nOrt::Session session(env, L\"cuda_noOptimized.onnx\", session_options);\r\nstd::cout << \"Model Loaded Successfully!\\n\";\r\n\r\nOrt::AllocatorWithDefaultOptions allocator;\r\n\r\nOrt::MemoryInfo info(\"Cuda\", OrtDeviceAllocator, 0, OrtMemTypeDefault);\r\n\r\n// print number of model input nodes\r\nsize_t num_input_nodes = session.GetInputCount();\r\nstd::vector<const char*> input_node_names(num_input_nodes);\r\nstd::vector<int64_t> input_node_dims;  // simplify... this model has only 1 input node {1, 3, 224, 224}.\r\n                                       // Otherwise need vector<vector<>>\r\n\r\nsize_t num_output_nodes = session.GetOutputCount();\r\nstd::vector<char*> outputNames;\r\nfor (size_t i = 0; i < num_output_nodes; ++i)\r\n{\r\n    char* name = session.GetOutputName(i, allocator);\r\n    std::cout << \"output: \" << name << std::endl;\r\n    outputNames.push_back(name);\r\n}\r\n\r\n\r\nprintf(\"Number of inputs = %zu\\n\", num_input_nodes);\r\n\r\n// iterate over all input nodes\r\nfor (int i = 0; i < num_input_nodes; i++) {\r\n    // print input node names\r\n    char* input_name = session.GetInputName(i, allocator);\r\n    printf(\"Input %d : name=%s\\n\", i, input_name);\r\n    input_node_names[i] = input_name;\r\n\r\n    // print input node types\r\n    Ort::TypeInfo type_info = session.GetInputTypeInfo(i);\r\n    auto tensor_info = type_info.GetTensorTypeAndShapeInfo();\r\n\r\n    ONNXTensorElementDataType type = tensor_info.GetElementType();\r\n    printf(\"Input %d : type=%d\\n\", i, type);\r\n\r\n    // print input shapes/dims\r\n    input_node_dims = tensor_info.GetShape();\r\n    printf(\"Input %d : num_dims=%zu\\n\", i, input_node_dims.size());\r\n    for (int j = 0; j < input_node_dims.size(); j++)\r\n        printf(\"Input %d : dim %d=%jd\\n\", i, j, input_node_dims[j]);\r\n}\r\n\r\nstd::vector<float> inputValuesVideo({ 1,5,224,224 });\r\nstd::vector<float> inputValuesAudio({ 1,8000 });\r\n\r\nauto video_tensor_size = 1 * 5 * 244 * 244;\r\nstd::vector<float> input_tensor_video_values(video_tensor_size);\r\nfor (size_t i = 0; i < video_tensor_size; ++i)\r\n{\r\n    input_tensor_video_values[i] = 1;\r\n}\r\n\r\nauto audio_tensor_size = 1 * 8000;\r\nstd::vector<float> input_tensor_audio_values(audio_tensor_size);\r\nfor (size_t i = 0; i < audio_tensor_size; ++i)\r\n{\r\n    input_tensor_audio_values[i] = 1;\r\n}\r\n\r\nOrt::Value input_tensor_video = Ort::Value::CreateTensor<float>(info, input_tensor_video_values.data(), video_tensor_size, session.GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape().data(), session.GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape().size());\r\nOrt::Value input_tensor_audio = Ort::Value::CreateTensor<float>(info, input_tensor_audio_values.data(), audio_tensor_size, session.GetInputTypeInfo(1).GetTensorTypeAndShapeInfo().GetShape().data(), session.GetInputTypeInfo(1).GetTensorTypeAndShapeInfo().GetShape().size());\r\n\r\n//// Create Inputs\r\nstd::vector<Ort::Value> ort_inputs;\r\n\r\nconst char* const output_names[] = { \"output\" };\r\nconst char* input_names[] = { \"input1\", \"input2\"};\r\nort_inputs.push_back(std::move(input_tensor_video));\r\nort_inputs.push_back(std::move(input_tensor_audio));\r\n\r\n\r\n// Measure latency\r\nint numTests{ 100 };\r\nstd::chrono::steady_clock::time_point begin =\r\nstd::chrono::steady_clock::now();\r\nfor (int i = 0; i < numTests; i++)\r\n{\r\n    auto ort_outputs = session.Run(Ort::RunOptions{}, input_names, ort_inputs.data(), ort_inputs.size(), output_names, 1);\r\n}\r\nstd::chrono::steady_clock::time_point end =\r\nstd::chrono::steady_clock::now();\r\nstd::cout << \"Minimum Inference Latency: \"\r\n<< std::chrono::duration_cast<std::chrono::milliseconds>(end -\r\n    begin)\r\n    .count() /\r\n    static_cast<float>(numTests)\r\n    << \" ms\" << std::endl;\r\n\r\n\r\n\r\n//\tsystem(\"PAUSE\");\r\n}\r\n```\r\n**OUTPUT**\r\n\r\n```\r\nModel Loaded Successfully!\r\noutput: output\r\noutput: 450\r\noutput: 372\r\noutput: 373\r\noutput: 456\r\nNumber of inputs = 2\r\nInput 0 : name=input1\r\nInput 0 : type=1\r\nInput 0 : num_dims=4\r\nInput 0 : dim 0=1\r\nInput 0 : dim 1=5\r\nInput 0 : dim 2=224\r\nInput 0 : dim 3=224\r\nInput 1 : name=input2\r\nInput 1 : type=1\r\nInput 1 : num_dims=2\r\nInput 1 : dim 0=1\r\nInput 1 : dim 1=8000\r\n2022-01-19 18:03:00.0142985 [I:onnxruntime:, sequential_executor.cc:155 onnxruntime::SequentialExecutor::Execute] Begin execution\r\n2022-01-19 18:03:00.0353534 [I:onnxruntime:Default, bfc_arena.cc:256 onnxruntime::BFCArena::Reserve] Reserving memory in BFCArena for Cuda size: 33554432\r\n2022-01-19 18:03:00.5930322 [E:onnxruntime:Default, cuda_call.cc:118 onnxruntime::CudaCall] CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; GPU=0 ; hostname=DESKTOP-57FVN2Q ; expr=cudnnFindConvolutionForwardAlgorithmEx( s_.handle, s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), max_ws_size);\r\n2022-01-19 18:03:00.5931983 [E:onnxruntime:, sequential_executor.cc:346 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Conv node. Name:'Conv_88' Status Message: CUDNN error executing cudnnFindConvolutionForwardAlgorithmEx( s_.handle, s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), max_ws_size)\r\n2022-01-19 18:03:00.5941795 [E:onnxruntime:Default, cuda_call.cc:118 onnxruntime::CudaCall] CUDA failure 700: an illegal memory access was encountered ; GPU=0 ; hostname=DESKTOP-57FVN2Q ; expr=cudaEventRecord(current_deferred_release_event, static_cast<cudaStream_t>(GetComputeStream()));\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10323/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10324",
        "id": 1108467192,
        "node_id": "I_kwDOCVq1mM5CEd34",
        "number": 10324,
        "title": "rationalize documentation on ORT-Windows integration",
        "user": {
            "login": "garymm",
            "id": 421339,
            "node_id": "MDQ6VXNlcjQyMTMzOQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/421339?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/garymm",
            "html_url": "https://github.com/garymm",
            "followers_url": "https://api.github.com/users/garymm/followers",
            "following_url": "https://api.github.com/users/garymm/following{/other_user}",
            "gists_url": "https://api.github.com/users/garymm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/garymm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/garymm/subscriptions",
            "organizations_url": "https://api.github.com/users/garymm/orgs",
            "repos_url": "https://api.github.com/users/garymm/repos",
            "events_url": "https://api.github.com/users/garymm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/garymm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-19T19:17:47Z",
        "updated_at": "2022-07-22T18:59:50Z",
        "closed_at": "2022-07-22T18:59:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "Currently there's some documentation of how ORT is integrated into Windows on the [DirectML EP page](https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider.html) and some on the [High Level Design page](https://onnxruntime.ai/docs/reference/high-level-design.html).\r\n\r\nThere are a lot of details on the High Level Design page that don't really seem like they're about the high level design (e.g. distribution choices table).\r\n\r\nIt seems to me that it might be best to move the content from High Level Design to a dedicated page about how to use ONNX Runtime on Windows (possibly taking some content from the DirectML EP page).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10324/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10325",
        "id": 1108518521,
        "node_id": "PR_kwDOCVq1mM4xSPsi",
        "number": 10325,
        "title": "Add test quantization of ArgMax for TensorRT",
        "user": {
            "login": "yihonglyu",
            "id": 8860750,
            "node_id": "MDQ6VXNlcjg4NjA3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8860750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yihonglyu",
            "html_url": "https://github.com/yihonglyu",
            "followers_url": "https://api.github.com/users/yihonglyu/followers",
            "following_url": "https://api.github.com/users/yihonglyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/yihonglyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yihonglyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yihonglyu/subscriptions",
            "organizations_url": "https://api.github.com/users/yihonglyu/orgs",
            "repos_url": "https://api.github.com/users/yihonglyu/repos",
            "events_url": "https://api.github.com/users/yihonglyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yihonglyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-19T20:19:52Z",
        "updated_at": "2022-02-01T00:22:17Z",
        "closed_at": "2022-02-01T00:22:17Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10325",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10325",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10325.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10325.patch",
            "merged_at": "2022-02-01T00:22:17Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10325/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10326",
        "id": 1108596031,
        "node_id": "PR_kwDOCVq1mM4xSgG3",
        "number": 10326,
        "title": "Remove unused pipeline orttraining-linux-gpu-perf-test-ci-pipeline.yml and unused send_perf_metrics tool",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-19T21:51:21Z",
        "updated_at": "2022-01-21T22:31:35Z",
        "closed_at": "2022-01-21T22:31:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10326",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10326",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10326.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10326.patch",
            "merged_at": "2022-01-21T22:31:34Z"
        },
        "body": "**Description**\r\nRemove unused pipeline orttraining-linux-gpu-perf-test-ci-pipeline.yml and unused send_perf_metrics tool.\r\n\r\n**Motivation and Context**\r\nThere is a component governance alert about one of the dependencies of the send_perf_metrics tool.\r\nRemoving it and the dependent pipeline as they are not being used.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10326/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327",
        "id": 1108641603,
        "node_id": "I_kwDOCVq1mM5CFIdD",
        "number": 10327,
        "title": "what is the right way to convert `ortValue`  to `torch.tensor` for GPU?",
        "user": {
            "login": "Ki6an",
            "id": 63173962,
            "node_id": "MDQ6VXNlcjYzMTczOTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/63173962?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ki6an",
            "html_url": "https://github.com/Ki6an",
            "followers_url": "https://api.github.com/users/Ki6an/followers",
            "following_url": "https://api.github.com/users/Ki6an/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ki6an/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ki6an/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ki6an/subscriptions",
            "organizations_url": "https://api.github.com/users/Ki6an/orgs",
            "repos_url": "https://api.github.com/users/Ki6an/repos",
            "events_url": "https://api.github.com/users/Ki6an/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ki6an/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 19,
        "created_at": "2022-01-19T22:57:29Z",
        "updated_at": "2022-10-24T18:08:46Z",
        "closed_at": "2022-10-24T18:08:45Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi, I'm working on making [fastT5](https://github.com/Ki6an/fastT5) support GPU, the library implements huggingface's `generate()` method to produce the output tokens. so most of this pipeline is in PyTorch (you can look into [this file](https://github.com/Ki6an/fastT5/blob/master/fastT5/onnx_models.py) to know how it's done for CPU).  I'm using `io-binding` to avoid copying data btw CPU and GPU for running the model on onnxruntime with CUDA EP.  \r\n\r\nThe inputs to ort are provided as torch tensors so binding them is fast and easy as `io_binding.bind_input()`  takes `tensor.data_ptr()` as input and also the input shapes are known. \r\n\r\nfor outputs, I used `io_binding.bind_output()` and provided only the `name` and `device` since we don't know the output shape or data_ptr. we can pre-create tensors (by precalculating the tensor shape ) to store output but it can become cumbersome as t5 creates large numbers of outputs with different shapes.\r\n\r\nso I chose `io_binding.get_outputs()` to get the outputs, now, the outputs are provided as `outvalues`, in order to convert them to tensor we have to first convert them to numpy,  using `torch.from_numpy(ort_output.numpy()).to(device)`. this conversion process is affecting the inference speed significantly as there are lots of outputs to work with and also in a loop.\r\n\r\n```js\r\ntt to ort.run:1730.759693000664 ms, tt ortValue to torch tensor:2520.3441690007367 ms, total time:4882.381090000081 ms   \r\n```\r\nas you can see the conversion process is taking a lot of time, is there a better and more efficient way to convert outvalues to torch tensor?\r\nmaybe not using numpy as an intermediate step?\r\n\r\nany help would be appreciated \r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10330",
        "id": 1108803542,
        "node_id": "I_kwDOCVq1mM5CFv_W",
        "number": 10330,
        "title": "Onnxruntime multithread options [C++ CPU]",
        "user": {
            "login": "zhuxiaoxuhit",
            "id": 32813150,
            "node_id": "MDQ6VXNlcjMyODEzMTUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/32813150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhuxiaoxuhit",
            "html_url": "https://github.com/zhuxiaoxuhit",
            "followers_url": "https://api.github.com/users/zhuxiaoxuhit/followers",
            "following_url": "https://api.github.com/users/zhuxiaoxuhit/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhuxiaoxuhit/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhuxiaoxuhit/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhuxiaoxuhit/subscriptions",
            "organizations_url": "https://api.github.com/users/zhuxiaoxuhit/orgs",
            "repos_url": "https://api.github.com/users/zhuxiaoxuhit/repos",
            "events_url": "https://api.github.com/users/zhuxiaoxuhit/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhuxiaoxuhit/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-01-20T03:24:15Z",
        "updated_at": "2023-04-14T15:30:48Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI disabled openmp when build onnxruntime, and try to use session_options to set number of threads.\r\nI think it should be like that:\r\n```\r\nnum_threads = InterOpNumThreads *  IntraOpNumThreads\r\n```\r\nbut I got results like this:\r\n```\r\nnum_threads = InterOpNumThreads +  IntraOpNumThreads  - 2\r\n```\r\n\r\nInterOpNumThreads | IntraOpNumThreads | MultiThreadUsedCount\r\n-- | -- | --\r\n1 | 1 | 0\r\n1 | 2 | 1\r\n2 | 1 | 1\r\n2 | 2 | 2\r\n2 | 3 | 3\r\n3 | 3 | 4\r\n5 | 5 | 8\r\n\r\n\r\nI want to konw reason and **how to set InterOpNumThreads and IntraOpNumThreads to accelerate onnxuntime inference.**\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS\r\n- ONNX Runtime installed from (source or binary): master\r\n- GCC/Compiler version (if compiling from source): gcc (GCC) 5.4.0\r\n\r\n**To Reproduce**\r\nI disabled openmp when build onnxruntime, and try to use session_options to set number of threads.\r\n``` // If use openmp, please disable num of threads setting.\r\n    session_options_.SetExecutionMode(ORT_PARALLEL);\r\n    session_options_.SetInterOpNumThreads(1);\r\n    session_options_.SetIntraOpNumThreads(1);\r\n```\r\n\r\n**Screenshots**\r\nInterOpNumThreads=1, IntraOpNumThreads=1, Got MultiThreadUsedCount=0\r\n<img width=\"209\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266194-d0f18bc7-c456-4966-8787-0c0e9f8ea608.png\">\r\nInterOpNumThreads=1, IntraOpNumThreads=2, Got MultiThreadUsedCount=1\r\n<img width=\"200\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266351-4ebbc719-6952-401c-8d72-f07a51c04e82.png\">\r\nInterOpNumThreads=2, IntraOpNumThreads=1, Got MultiThreadUsedCount=1\r\n<img width=\"206\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266367-67dadc9b-bd85-49b0-873c-e42ecffc157f.png\">\r\nInterOpNumThreads=2, IntraOpNumThreads=2, Got MultiThreadUsedCount=2\r\n<img width=\"202\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266383-a7c9804c-6c96-4ab1-9da9-3a657f950d90.png\">\r\nInterOpNumThreads=2, IntraOpNumThreads=3, Got MultiThreadUsedCount=3\r\n<img width=\"206\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266394-e08cf6d7-1f98-4980-b49f-b972f090fe12.png\">\r\nInterOpNumThreads=3, IntraOpNumThreads=3, Got MultiThreadUsedCount=4\r\n<img width=\"208\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266403-c5388214-fadd-44ca-9dd2-a355a07ea3eb.png\">\r\nInterOpNumThreads=5, IntraOpNumThreads=5, Got MultiThreadUsedCount=8\r\n<img width=\"206\" alt=\"Image\" src=\"https://user-images.githubusercontent.com/32813150/150266411-6fe9c094-df75-4626-bdf8-9fea7922c666.png\">\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10330/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10331",
        "id": 1108871355,
        "node_id": "PR_kwDOCVq1mM4xTZCU",
        "number": 10331,
        "title": "Fix CUDA10.2 Build Break for BFloat16 Change",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-20T05:14:05Z",
        "updated_at": "2022-01-20T10:17:29Z",
        "closed_at": "2022-01-20T10:17:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10331",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10331",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10331.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10331.patch",
            "merged_at": "2022-01-20T10:17:28Z"
        },
        "body": "cuBlas supports BFloat16 since CUDA11, so we need to return no_supported status when CUDA verison is smaller than 11.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10331/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10334",
        "id": 1108914495,
        "node_id": "PR_kwDOCVq1mM4xThwF",
        "number": 10334,
        "title": "fix bugs in cpuid_info",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-20T06:30:03Z",
        "updated_at": "2022-01-21T00:30:19Z",
        "closed_at": "2022-01-21T00:30:19Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10334",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10334",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10334.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10334.patch",
            "merged_at": "2022-01-21T00:30:19Z"
        },
        "body": "**Description**: Describe your changes.\r\nFix following bugs in cpuid_info component:\r\n1. CPUIDINFO_ARCH_X86 and CPUIDINFO_ARCH_ARM should be defined in header file instead of .cc file. This causes very tricky issue. Both macros are used to determine if pytorch_cpuinfo_init_ is a member of CPUIDInfo in the cpuid_info.h.\r\n    pytorch_cpuinfo_init_ is a member of CPUIDInfo in cpuid_info.cc file on x86 and arm because those 2 macros are defined in cpuid_info.cc. \r\n    cpuid_info.h is also referred in platform.cc file.  pytorch_cpuinfo_init_ is determined not a member of CPUIDInfo in platform.cc file because those 2 macros are not defined there. It results that symbol has_arm_neon_dot_ uses the value of pytorch_cpuinfo_init_ in platform.cc. \r\n\r\n2. DefaultLogger is not initialized at the time of construction of CPUIDInfo.\r\n\r\n3. Unused CPUIDInfo instance_. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10334/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10335",
        "id": 1108986627,
        "node_id": "PR_kwDOCVq1mM4xTwgJ",
        "number": 10335,
        "title": "[FIX] Add condition in amd ci pipeline yaml to stop test in time",
        "user": {
            "login": "PeixuanZuo",
            "id": 94887879,
            "node_id": "U_kgDOBaffxw",
            "avatar_url": "https://avatars.githubusercontent.com/u/94887879?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PeixuanZuo",
            "html_url": "https://github.com/PeixuanZuo",
            "followers_url": "https://api.github.com/users/PeixuanZuo/followers",
            "following_url": "https://api.github.com/users/PeixuanZuo/following{/other_user}",
            "gists_url": "https://api.github.com/users/PeixuanZuo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PeixuanZuo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PeixuanZuo/subscriptions",
            "organizations_url": "https://api.github.com/users/PeixuanZuo/orgs",
            "repos_url": "https://api.github.com/users/PeixuanZuo/repos",
            "events_url": "https://api.github.com/users/PeixuanZuo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PeixuanZuo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-20T08:09:29Z",
        "updated_at": "2022-01-24T07:34:50Z",
        "closed_at": "2022-01-24T07:34:50Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10335",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10335",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10335.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10335.patch",
            "merged_at": "2022-01-24T07:34:49Z"
        },
        "body": "**Description**:  Change the process to stop ci pipeline in time when the onnxruntime build failed.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nThe process of amd ci pipeline is build onnxruntime firstly, and then do all the test. When the onnxruntime build fails, all subsequent tests fail. This brings confusion to the amd ci pipeline analysis, some pr ci failed caused by onnxruntime build failure but the number of test failure is also counted. Change the process to stop ci pipeline in time, and avoid producing failed tasks caused by onnxruntime failure.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10335/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10336",
        "id": 1108989214,
        "node_id": "I_kwDOCVq1mM5CGdUe",
        "number": 10336,
        "title": "Failed to load Library - OnnxRuntime Yolov5 GPU Support C#",
        "user": {
            "login": "MagnusGabell",
            "id": 8070347,
            "node_id": "MDQ6VXNlcjgwNzAzNDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8070347?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MagnusGabell",
            "html_url": "https://github.com/MagnusGabell",
            "followers_url": "https://api.github.com/users/MagnusGabell/followers",
            "following_url": "https://api.github.com/users/MagnusGabell/following{/other_user}",
            "gists_url": "https://api.github.com/users/MagnusGabell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MagnusGabell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MagnusGabell/subscriptions",
            "organizations_url": "https://api.github.com/users/MagnusGabell/orgs",
            "repos_url": "https://api.github.com/users/MagnusGabell/repos",
            "events_url": "https://api.github.com/users/MagnusGabell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MagnusGabell/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 34,
        "created_at": "2022-01-20T08:12:10Z",
        "updated_at": "2022-01-31T11:36:54Z",
        "closed_at": "2022-01-25T16:20:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have made a program .net6 Console app in VS 2022 C# that can use the Yolo5 model as onnx format for CPU. When changing the library to GPU I get\r\n\r\nMicrosoft.ML.OnnxRuntime.OnnxRuntimeException\r\nHResult=0x80131500\r\nMessage=[ErrorCode:Fail] OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library\r\nSource=Microsoft.ML.OnnxRuntime\r\nStackTrace:\r\nat Microsoft.ML.OnnxRuntime.NativeApiStatus.VerifySuccess(IntPtr nativeStatus)\r\nat Microsoft.ML.OnnxRuntime.SessionOptions.AppendExecutionProvider_CUDA(Int32 deviceId)\r\nat Microsoft.ML.OnnxRuntime.SessionOptions.MakeSessionOptionWithCudaProvider(Int32 deviceId)\r\nat Yolov5Net.App.Program.Main(String[] args) in C:\\Development\\YoloV5\\yolov5-net\\src\\Yolov5Net.App\\Program.cs:line 23\r\n\r\nHow can I get the program to utilize the GPU instead of CPU?\r\nI have installed : cuda and cuDNN according to instructions.\r\nTested latest and version 10.1.\r\nGraphic card is Quadro M1200.\r\n\r\nSystem information\r\n\r\nOS: Windows 10\r\nModel: Yolo5l\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n\r\nTo Reproduce\r\nWrite a code for CPU then change to GPU by adding a\r\nvar opts = new SessionOptions(); opts.LogSeverityLevel = OrtLoggingLevel.ORT_LOGGING_LEVEL_VERBOSE; var so = SessionOptions.MakeSessionOptionWithCudaProvider(1);\r\nIt crash on MakeSessionOptionWithCudaProvider(1). I dont want to use 0 cause its built in GFX.\r\n![image](https://user-images.githubusercontent.com/8070347/150298829-60978e75-5df5-4f86-95ee-a90887ce61ce.png)\r\n\r\nAdditional context\r\nPlease help. I dont know how to get this final step to work. The libraries are all copied in to bin. They exists everywhere.\r\nIs this related to the Windows 10 pipeline issue for onnx?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10336/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10337",
        "id": 1109020652,
        "node_id": "PR_kwDOCVq1mM4xT3mD",
        "number": 10337,
        "title": "add optimization and bug fix for attention fusion",
        "user": {
            "login": "flygragon",
            "id": 16490990,
            "node_id": "MDQ6VXNlcjE2NDkwOTkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/16490990?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/flygragon",
            "html_url": "https://github.com/flygragon",
            "followers_url": "https://api.github.com/users/flygragon/followers",
            "following_url": "https://api.github.com/users/flygragon/following{/other_user}",
            "gists_url": "https://api.github.com/users/flygragon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/flygragon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/flygragon/subscriptions",
            "organizations_url": "https://api.github.com/users/flygragon/orgs",
            "repos_url": "https://api.github.com/users/flygragon/repos",
            "events_url": "https://api.github.com/users/flygragon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/flygragon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-01-20T08:46:20Z",
        "updated_at": "2022-08-10T00:46:28Z",
        "closed_at": null,
        "author_association": "FIRST_TIMER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10337",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10337",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10337.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10337.patch",
            "merged_at": null
        },
        "body": "**Description**: \r\nThis pull request is mainly aimed to optimize the attention fusion transformer and improve inference efficiency for BERT and DistilBERT. It optimized the reshape shape limits,  added support for empty input mask of DistilBert model type, deal with fused reshape and where, eliminate fused reshape node to remove.\r\n\r\n**Motivation and Context**\r\n- Optimize and fix the problem that the attention module of normal BERT model cannot be fused due to the serious limits of shape check for reshape nodes.\r\n- Fix the problem that the attention module of DistilBert model cannot be fused due to that the input mask of the where node is empty and fused to the where node, and add multi paths for input mask.\r\n- Fix empty concat nodes to remove when reshape is fused\r\n- Fix empty mask nodes to remove when where is fused\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10337/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10339",
        "id": 1109199622,
        "node_id": "I_kwDOCVq1mM5CHQsG",
        "number": 10339,
        "title": "Attention module not fused for custom GPT2 model",
        "user": {
            "login": "dave-rtzr",
            "id": 70870584,
            "node_id": "MDQ6VXNlcjcwODcwNTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/70870584?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dave-rtzr",
            "html_url": "https://github.com/dave-rtzr",
            "followers_url": "https://api.github.com/users/dave-rtzr/followers",
            "following_url": "https://api.github.com/users/dave-rtzr/following{/other_user}",
            "gists_url": "https://api.github.com/users/dave-rtzr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dave-rtzr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dave-rtzr/subscriptions",
            "organizations_url": "https://api.github.com/users/dave-rtzr/orgs",
            "repos_url": "https://api.github.com/users/dave-rtzr/repos",
            "events_url": "https://api.github.com/users/dave-rtzr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dave-rtzr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-20T11:42:36Z",
        "updated_at": "2022-02-05T19:29:16Z",
        "closed_at": "2022-02-05T19:29:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\n\r\nThis issue is not about bug.\r\n\r\nI would like to fuse the graph of my model, so that I can get a speed up as illustrated [here](https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/transformers#model-optimizer)\r\nOne thing that differs from the example is that I am not using GPT2LMHeadModel, which I confirmed that the fusion works as expected,\r\nbut I am trying to fuse a custom GPT2 Model as follows\r\nThis model is used for estimating the likelihood of a sentence.\r\n\r\n```python\r\nclass MyGPT2Model(GPT2LMHeadModel):\r\n  def __init__(self, config):\r\n    super().__init__(config)\r\n    self.pad_token_id = 3 # for example\r\n    \r\n  def forward(self, input_ids):\r\n    attention_mask = torch.ones_like(input_ids)\r\n    attention_mask[ input_ids == self.pad_token_id ] = 0\r\n    logits = super().forward(input_ids=input_ids, attention_mask=attention_mask, use_cache=False, return_dict=False)[0] #logits\r\n    logits = logits[ : , :-1 , : ]\r\n    labels = input_ids[ : , 1: ]\r\n\r\n    return MyGPT2Model.postprocess(logits, labels, self.pad_token_id)\r\n    \r\n  @staticmethod  \r\n  def postprocess(logits, labels, pad_token_id: int):\r\n    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\r\n    out = log_probs.gather(dim=2, index=labels.unsqueeze(2)).squeeze(2)\r\n    out[ labels == pad_token_id ] = 0\r\n    return out.sum(dim=1)\r\n```\r\n\r\nI designed my model as above since gpt2_helper.py had a similar model, which I assumed the optimization would succeed.\r\nI exported above model as follows.\r\n\r\n```python\r\nmodel = MyGPT2Model.from_pretrained(\"gpt2\").to(\"cuda:0\")\r\nmodel.eval()\r\nbsz, seq_len = 256, 64\r\nx = torch.randint(0, 1000, (bsz, seq_len), dtype=torch.long, device=\"cuda:0\") # 1000 is less than the vocab size\r\n\r\nwith torch.inference_mode():\r\n  torch.onnx.export(\r\n                model,\r\n                args=(x,),\r\n                f=\"/workspace/model.onnx\",\r\n                input_names=[\"input__0\"],\r\n                output_names=[\"output__0\"],\r\n                opset_version=11,\r\n                dynamic_axes={\r\n                    \"input__0\": {0: \"batch_size\", 1: \"seq_len\"},\r\n                    \"output__0\": {0: \"batch_size\"},\r\n                },\r\n                do_constant_folding=True,\r\n            )\r\n```\r\n\r\nafter exporting model to onnx using torch.onnx.export with opset 11, and try to optimize the model using the following command,\r\n\r\n```python\r\nroot@ef62a7f0723c:/workspace# python -m onnxruntime.transformers.optimizer --input ./model.onnx --output ./out.onnx --model_type gpt2 --num_heads 12 --hidden_size 768 --input_int32 --float16 --use_gpu --opt_level 0\r\n```\r\nI constantly get the following error\r\n\r\n```bash\r\nremove_useless_cast_nodes: Removed 15 Cast nodes with output type same as input\r\n               apply: Fused LayerNormalization count: 25\r\n               apply: Fused FastGelu count: 12\r\nremove_useless_reshape_nodes: Remove reshape node Reshape_17 since its input shape is same as output: ['batch_size', 'seq_len']\r\nremove_useless_reshape_nodes: Remove reshape node Reshape_26 since its input shape is same as output: [1, 'seq_len']\r\nremove_useless_reshape_nodes: Remove reshape node Reshape_29 since its input shape is same as output: ['batch_size', 'seq_len']\r\nremove_useless_reshape_nodes: Remove reshape node Reshape_2365 since its input shape is same as output: ['batch_size', 'seq_len', 768]\r\n         prune_graph: Graph pruned: 0 inputs, 0 outputs and 742 nodes are removed\r\n         postprocess: postprocess: remove Reshape count:72\r\n               apply: Fused FastGelu(add bias) count: 12\r\n            optimize: opset verion: 11\r\nchange_graph_inputs_to_int32: Graph inputs are changed to int32. Added 1 Cast nodes, and removed 0 Cast nodes.\r\n  save_model_to_file: Sort graphs in topological order\r\n  save_model_to_file: Model saved to ./out.onnx\r\nget_fused_operator_statistics: Optimized operators:{'EmbedLayerNormalization': 0, 'Attention': 0, 'Gelu': 0, 'FastGelu': 12, 'BiasGelu': 0, 'LayerNormalization': 25, 'SkipLayerNormalization': 0}\r\n  is_fully_optimized: Attention not fused\r\n                main: The model has been optimized.\r\n```\r\n\r\nI am working on nvcr.io/nvidia/pytorch:21.12-py3, with onnxruntime-gpu==1.10.0, transformers==4.13.0 manually installed.\r\n\r\nIt seems like the problem is not caused by the postprocessing function, since just returning the logits also yields the same error.\r\nI would appreciate any ideas on this problem",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10339/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10340",
        "id": 1109230230,
        "node_id": "I_kwDOCVq1mM5CHYKW",
        "number": 10340,
        "title": "Converting PyTorch to ONNX model increases file size for ALBert",
        "user": {
            "login": "danielbellhv",
            "id": 84714841,
            "node_id": "MDQ6VXNlcjg0NzE0ODQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/84714841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielbellhv",
            "html_url": "https://github.com/danielbellhv",
            "followers_url": "https://api.github.com/users/danielbellhv/followers",
            "following_url": "https://api.github.com/users/danielbellhv/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielbellhv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielbellhv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielbellhv/subscriptions",
            "organizations_url": "https://api.github.com/users/danielbellhv/orgs",
            "repos_url": "https://api.github.com/users/danielbellhv/repos",
            "events_url": "https://api.github.com/users/danielbellhv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielbellhv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-20T12:15:38Z",
        "updated_at": "2022-01-21T12:30:45Z",
        "closed_at": "2022-01-21T09:39:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Performance** Issue.\r\n\r\nBased on [SO post](https://stackoverflow.com/q/70786010/17840900).\r\n\r\nGoal: Use this [Notebook][1] to perform quantisation on **albert-base-v2** model.\r\n\r\nKernel: `conda_pytorch_p36`.\r\n\r\n---\r\n\r\nOutputs in **Sections 1.2 & 2.2** show that:\r\n- converting vanilla **BERT** from **PyTorch to ONNX** stays the **same size**, `417.6 MB`.\r\n- **Quantization models are smaller** than vanilla BERT, PyTorch `173.0 MB` and ONNX `104.8 MB`.\r\n\r\nHowever, when running ALBert:\r\n- PyTorch and ONNX model **sizes are different**.\r\n- Quantized model sizes are **bigger** than vanilla.\r\n\r\nI *think* this is the reason for **poorer model performance of both Quantization** methods of ALBert, compared to vanilla ALBert.\r\n\r\nPyTorch:\r\n```\r\nSize (MB): 44.58906650543213\r\nSize (MB): 22.373255729675293\r\n```\r\n\r\nONNX:\r\n```\r\nONNX full precision model size (MB): 341.64233207702637\r\nONNX quantized model size (MB): 85.53886985778809\r\n```\r\n\r\n---\r\n\r\n**Why might exporting **ALBert** from PyTorch to ONNX increase model size, but not for BERT?**\r\n\r\nPlease let me know if there's anything else I can add to post.\r\n\r\n  [1]: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10340/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10341",
        "id": 1109288364,
        "node_id": "PR_kwDOCVq1mM4xUvO9",
        "number": 10341,
        "title": "[TVM EP] support of TVM Virtual Machine",
        "user": {
            "login": "vvchernov",
            "id": 28704584,
            "node_id": "MDQ6VXNlcjI4NzA0NTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/28704584?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vvchernov",
            "html_url": "https://github.com/vvchernov",
            "followers_url": "https://api.github.com/users/vvchernov/followers",
            "following_url": "https://api.github.com/users/vvchernov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vvchernov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vvchernov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vvchernov/subscriptions",
            "organizations_url": "https://api.github.com/users/vvchernov/orgs",
            "repos_url": "https://api.github.com/users/vvchernov/repos",
            "events_url": "https://api.github.com/users/vvchernov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vvchernov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 17,
        "created_at": "2022-01-20T13:14:28Z",
        "updated_at": "2022-03-05T11:22:52Z",
        "closed_at": "2022-03-02T10:02:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10341",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10341",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10341.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10341.patch",
            "merged_at": "2022-03-02T10:02:33Z"
        },
        "body": "Support TVM Virtual Machine on TVM EP side\r\n\r\nWaiting for merging of [TVM PR](https://github.com/apache/tvm/pull/9980) (done) and [ORT PR#10260](https://github.com/microsoft/onnxruntime/pull/10260) (done) and [ORT PR#10505](https://github.com/microsoft/onnxruntime/pull/10505) (done) before check this PR\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341/reactions",
            "total_count": 4,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 2,
            "confused": 0,
            "heart": 2,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10341/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10342",
        "id": 1109309874,
        "node_id": "I_kwDOCVq1mM5CHrmy",
        "number": 10342,
        "title": "onnx.load() | DecodeError: Error parsing message",
        "user": {
            "login": "danielbellhv",
            "id": 84714841,
            "node_id": "MDQ6VXNlcjg0NzE0ODQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/84714841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielbellhv",
            "html_url": "https://github.com/danielbellhv",
            "followers_url": "https://api.github.com/users/danielbellhv/followers",
            "following_url": "https://api.github.com/users/danielbellhv/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielbellhv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielbellhv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielbellhv/subscriptions",
            "organizations_url": "https://api.github.com/users/danielbellhv/orgs",
            "repos_url": "https://api.github.com/users/danielbellhv/repos",
            "events_url": "https://api.github.com/users/danielbellhv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielbellhv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 16,
        "created_at": "2022-01-20T13:34:35Z",
        "updated_at": "2022-01-26T09:14:04Z",
        "closed_at": "2022-01-25T16:45:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Bug** issue.\r\n\r\nGoal: re-develop this [BERT Notebook][1] to use [textattack/albert-base-v2-MRPC][2].\r\n\r\nKernel: `conda_pytorch_p36`. Deleted all output files and did Restart & Run All.\r\n\r\nI can successfully create and save an ONNX model from HuggingFace Transformers model in run time memory. Error occurs when `onnx.load()`, from storage into memory.\r\n\r\n**Are my ONNX files corrupted?**\r\n\r\n#### `albert.onnx` and `alber.opt.onnx` [here][2].\r\n---\r\n\r\nSection 2.1 - export in-memory PyTorch model as ONNX model:\r\n```python\r\nimport onnxruntime\r\n\r\ndef export_onnx_model(args, model, tokenizer, onnx_model_path):\r\n    with torch.no_grad():\r\n        inputs = {'input_ids':      torch.ones(1,128, dtype=torch.int64),\r\n                    'attention_mask': torch.ones(1,128, dtype=torch.int64),\r\n                    'token_type_ids': torch.ones(1,128, dtype=torch.int64)}\r\n        outputs = model(**inputs)\r\n\r\n        symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\r\n        torch.onnx.export(model,                                            # model being run\r\n                    (inputs['input_ids'],                             # model input (or a tuple for multiple inputs)\r\n                    inputs['attention_mask'], \r\n                    inputs['token_type_ids']),                                         # model input (or a tuple for multiple inputs)\r\n                    onnx_model_path,                                # where to save the model (can be a file or file-like object)\r\n                    opset_version=11,                                 # the ONNX version to export the model to\r\n                    do_constant_folding=True,                         # whether to execute constant folding for optimization\r\n                    input_names=['input_ids',                         # the model's input names\r\n                                'input_mask', \r\n                                'segment_ids'],\r\n                    output_names=['output'],                    # the model's output names\r\n                    dynamic_axes={'input_ids': symbolic_names,        # variable length axes\r\n                                'input_mask' : symbolic_names,\r\n                                'segment_ids' : symbolic_names})\r\n        logger.info(\"ONNX Model exported to {0}\".format(onnx_model_path))\r\n\r\nexport_onnx_model(configs, model, tokenizer, \"albert.onnx\")\r\n```\r\n\r\nThen optimisation:\r\n```\r\npip install torch_optimizer\r\n```\r\n```python\r\nimport torch_optimizer as optim\r\n\r\noptimizer = optim.DiffGrad(model.parameters(), lr=0.001)\r\noptimizer.step()\r\n\r\ntorch.save(optimizer.state_dict(), 'albert.opt.onnx')\r\n```\r\n\r\nSection 2.2 Quantize ONNX model:\r\n```python\r\nfrom onnxruntime.quantization import quantize_dynamic, QuantType\r\nimport onnx\r\n\r\ndef quantize_onnx_model(onnx_model_path, quantized_model_path):    \r\n    onnx_opt_model = onnx.load(onnx_model_path)  # DecodeError\r\n    quantize_dynamic(onnx_model_path,\r\n                     quantized_model_path,\r\n                     weight_type=QuantType.QInt8)\r\n\r\n    logger.info(f\"quantized model saved to:{quantized_model_path}\")\r\n\r\nquantize_onnx_model('albert.opt.onnx', 'albert.opt.quant.onnx')\r\n\r\nprint('ONNX full precision model size (MB):', os.path.getsize(\"albert.opt.onnx\")/(1024*1024))\r\nprint('ONNX quantized model size (MB):', os.path.getsize(\"albert.opt.quant.onnx\")/(1024*1024))\r\n```\r\n\r\nTraceback:\r\n```\r\n---------------------------------------------------------------------------\r\nDecodeError                               Traceback (most recent call last)\r\n<ipython-input-16-2d2d32b0a667> in <module>\r\n     10     logger.info(f\"quantized model saved to:{quantized_model_path}\")\r\n     11 \r\n---> 12 quantize_onnx_model('albert.opt.onnx', 'albert.opt.quant.onnx')\r\n     13 \r\n     14 print('ONNX full precision model size (MB):', os.path.getsize(\"albert.opt.onnx\")/(1024*1024))\r\n\r\n<ipython-input-16-2d2d32b0a667> in quantize_onnx_model(onnx_model_path, quantized_model_path)\r\n      3 \r\n      4 def quantize_onnx_model(onnx_model_path, quantized_model_path):\r\n----> 5     onnx_opt_model = onnx.load(onnx_model_path)\r\n      6     quantize_dynamic(onnx_model_path,\r\n      7                      quantized_model_path,\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/onnx/__init__.py in load_model(f, format, load_external_data)\r\n    119     '''\r\n    120     s = _load_bytes(f)\r\n--> 121     model = load_model_from_string(s, format=format)\r\n    122 \r\n    123     if load_external_data:\r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/onnx/__init__.py in load_model_from_string(s, format)\r\n    156     Loaded in-memory ModelProto\r\n    157     '''\r\n--> 158     return _deserialize(s, ModelProto())\r\n    159 \r\n    160 \r\n\r\n~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/onnx/__init__.py in _deserialize(s, proto)\r\n     97                          '\\ntype is {}'.format(type(proto)))\r\n     98 \r\n---> 99     decoded = cast(Optional[int], proto.ParseFromString(s))\r\n    100     if decoded is not None and decoded != len(s):\r\n    101         raise google.protobuf.message.DecodeError(\r\n\r\nDecodeError: Error parsing message\r\n```\r\n\r\nOutput Files:\r\n```\r\nalbert.onnx  # original save\r\nalbert.opt.onnx  # optimised version save\r\n```\r\n\r\nPlease let me know if there's anything else I can add to post.\r\n\r\n[1]: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb\r\n  [2]: https://huggingface.co/textattack/albert-base-v2-MRPC",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10342/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10343",
        "id": 1109329800,
        "node_id": "I_kwDOCVq1mM5CHweI",
        "number": 10343,
        "title": "`Non-zero status code returned while running MatMul node` once too many requests",
        "user": {
            "login": "JulesBelveze",
            "id": 32683010,
            "node_id": "MDQ6VXNlcjMyNjgzMDEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/32683010?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JulesBelveze",
            "html_url": "https://github.com/JulesBelveze",
            "followers_url": "https://api.github.com/users/JulesBelveze/followers",
            "following_url": "https://api.github.com/users/JulesBelveze/following{/other_user}",
            "gists_url": "https://api.github.com/users/JulesBelveze/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JulesBelveze/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JulesBelveze/subscriptions",
            "organizations_url": "https://api.github.com/users/JulesBelveze/orgs",
            "repos_url": "https://api.github.com/users/JulesBelveze/repos",
            "events_url": "https://api.github.com/users/JulesBelveze/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JulesBelveze/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-20T13:53:53Z",
        "updated_at": "2022-04-16T07:55:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHey all,\r\nI am running some inferences with FastAPI & ONNX-runtime on GPU and I am currently trying to benchmark for autoscaling. For this reason the payload I'm sending is always the same.\r\nEverything seems to work fine but once I make too many simultaneous requests I'm getting the following issue:\r\n```\r\nE:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running MatMul node. Name:'MatMul_33' Status Message: CUBLAS error executing cublasGemmHelper( Base::CublasHandle(), transB, transA, static_cast<int>(helper.N()), static_cast<int>(helper.M()), static_cast<int>(helper.K()), &alpha, reinterpret_cast<const CudaT*>(right_X->template Data<T>()), ldb, reinterpret_cast<const CudaT*>(left_X->template Data<T>()), lda, &zero, reinterpret_cast<CudaT*>(Y->template MutableData<T>()), ldc, device_prop)\r\n```\r\n\r\nI ain't really clear to me, but I suspect this is an OOM issue, right?\r\nThe main problem is that once the above error is hit then it is no longer possible to make a call to the API without getting this error, as if the entire `InferenceSession` was down.\r\n\r\nI know that's a quite vague description but that's all I have, feel free if you need any further info. I can provide checkpoints and payload if needed.\r\n\r\n\r\n**Urgency**\r\nThis is quite blocking as the entire `InferenceSession` seems to be down and needs to be restarted.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux #1 SMP x86_64 Intel(R) Xeon(R) CPU @ 2.00GHz GenuineIntel GNU/Linux`\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: onnxruntime-gpu==1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version: 11.0\r\n- GPU model and memory: Tesla P4\r\n\r\n**Expected behavior**\r\nI would expect the session to be still running.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10343/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10344",
        "id": 1109522481,
        "node_id": "I_kwDOCVq1mM5CIfgx",
        "number": 10344,
        "title": "quantize/__init__.py, line 97 | SyntaxError: Missing parentheses in call to 'print'. Did you mean print(\"Available input ports:\")?",
        "user": {
            "login": "danielbellhv",
            "id": 84714841,
            "node_id": "MDQ6VXNlcjg0NzE0ODQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/84714841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielbellhv",
            "html_url": "https://github.com/danielbellhv",
            "followers_url": "https://api.github.com/users/danielbellhv/followers",
            "following_url": "https://api.github.com/users/danielbellhv/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielbellhv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielbellhv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielbellhv/subscriptions",
            "organizations_url": "https://api.github.com/users/danielbellhv/orgs",
            "repos_url": "https://api.github.com/users/danielbellhv/repos",
            "events_url": "https://api.github.com/users/danielbellhv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielbellhv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-01-20T16:36:21Z",
        "updated_at": "2022-01-21T09:53:05Z",
        "closed_at": "2022-01-20T17:13:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Quantization bug occurs when running both code snippets in [ONNXRuntime README](https://github.com/microsoft/onnxruntime/blob/fe0b2b2abd494b7ff14c00c0f2c51e0ccf2a3094/onnxruntime/python/tools/quantization/README.md).\r\n\r\n[Example - Quantize an ONNX Model](https://github.com/microsoft/onnxruntime/blob/fe0b2b2abd494b7ff14c00c0f2c51e0ccf2a3094/onnxruntime/python/tools/quantization/README.md#example---quantize-an-onnx-model):\r\n```python\r\nimport onnx\r\nfrom quantize import quantize, QuantizationMode\r\n\r\n# Load the onnx model\r\nmodel = onnx.load('path/to/the/model.onnx')\r\n# Quantize\r\nquantized_model = quantize(model, quantization_mode=QuantizationMode.IntegerOps)\r\n# Save the quantized model\r\nonnx.save(quantized_model, 'path/to/the/quantized_model.onnx')\r\n```\r\n\r\n[End-to-end example](https://github.com/microsoft/onnxruntime/blob/fe0b2b2abd494b7ff14c00c0f2c51e0ccf2a3094/onnxruntime/python/tools/quantization/README.md#end-to-end-example):\r\n```python\r\nimport onnx\r\nfrom quantize import quantize, QuantizationMode\r\nmodel = onnx.load('albert.opt.onnx')\r\nquantized_model = quantize(model, quantization_mode=QuantizationMode.IntegerOps, force_fusions=True)\r\nonnx.save(quantized_model, 'albert.opt.quant.onnx')\r\n```\r\n\r\nBoth get the same Traceback:\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\n  File \"<ipython-input-36-95f122b772e5>\", line 2, in <module>\r\n    from quantize import quantize, QuantizationMode\r\n\r\n  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/quantize/__init__.py\", line 97\r\n    print \"Available input ports:\"\r\n                                 ^\r\nSyntaxError: Missing parentheses in call to 'print'. Did you mean print(\"Available input ports:\")?\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10344/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10345",
        "id": 1109837354,
        "node_id": "PR_kwDOCVq1mM4xWhb3",
        "number": 10345,
        "title": "avoid using term whitelist",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-20T22:44:54Z",
        "updated_at": "2022-01-21T21:30:54Z",
        "closed_at": "2022-01-21T21:30:53Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10345",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10345",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10345.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10345.patch",
            "merged_at": "2022-01-21T21:30:53Z"
        },
        "body": "**Description**: avoid using term whitelist",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10345/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10346",
        "id": 1109870815,
        "node_id": "PR_kwDOCVq1mM4xWoZ0",
        "number": 10346,
        "title": "[eager mode]: add configuration for ort virtual device count",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-20T23:41:02Z",
        "updated_at": "2022-01-26T00:15:56Z",
        "closed_at": "2022-01-26T00:15:55Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10346",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10346",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10346.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10346.patch",
            "merged_at": "2022-01-26T00:15:55Z"
        },
        "body": "**Description**: add an environment var for the virtual device count.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10346/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10347",
        "id": 1109873302,
        "node_id": "PR_kwDOCVq1mM4xWo6m",
        "number": 10347,
        "title": " [QDQ] Hookup NNAPI GetCapability/Compile with shared QDQ selectors",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-20T23:46:30Z",
        "updated_at": "2022-01-26T01:13:48Z",
        "closed_at": "2022-01-26T01:13:47Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10347",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10347",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10347.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10347.patch",
            "merged_at": "2022-01-26T01:13:47Z"
        },
        "body": "**Description**: [QDQ] Hookup NNAPI GetCapability/Compile with shared QDQ selectors\r\n\r\n**Motivation and Context**\r\n- To avoid excessively large PR, the NNAPI QDQ integration is splitted into the following small tasks\r\n- [x] 1. Add shared NodeUnit class (#10052[merged])\r\n- [x] 2. Move NNAPI EP to use NodeUnitIODef for non-QDQ ops (#10237[merged])\r\n- [x] 3. Add shared QDQ selectors (#10178[merged])\r\n- [x] 4. Hookup NNAPI GetCapability/Compile with shared QDQ selectors (this PR)\r\n- [ ] 5. Enable QDQ for ops with QLinear version (QLinear[Conv/Matmul/Pool/...])\r\n- [ ] 6. Enable QDQ for ops without QLinear Version\r\n\r\n- Added share functions to get all the NodeUnits(QDQ and single node) in the graph\r\n- NNAPI GetCapability/Compile runs on a list of mixed SingleNode/QDQGroup NodeUnit\r\n- Disabled the support for all QDQ NodeUnit for now (can be individually enabled for each op, in task 5 and 6)\r\n- Modified the build settings for Extended Minimal build\r\n- Added a simple UT\r\n- Some minor update",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10347/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10348",
        "id": 1109966511,
        "node_id": "PR_kwDOCVq1mM4xW9Fn",
        "number": 10348,
        "title": "Add \"available since\" message for C API additions since v1.10.0.",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-01-21T02:00:10Z",
        "updated_at": "2022-01-25T18:15:35Z",
        "closed_at": "2022-01-25T18:15:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10348",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10348",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10348.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10348.patch",
            "merged_at": "2022-01-25T18:15:34Z"
        },
        "body": "**Description**\r\nAdd \"available since\" message for C API additions since v1.10.0.\r\n\r\n**Motivation and Context**\r\nThe C API docs may be updated with new APIs before they are available in a release. Adding a \"new in version x\" message indicates when they can be used.\r\n\r\n#10298",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10348/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10349",
        "id": 1109989683,
        "node_id": "PR_kwDOCVq1mM4xXBuk",
        "number": 10349,
        "title": "Enable transpose optimizer in minimal extended build",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-01-21T02:45:17Z",
        "updated_at": "2022-01-31T17:41:05Z",
        "closed_at": "2022-01-31T17:41:04Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10349",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10349",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10349.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10349.patch",
            "merged_at": "2022-01-31T17:41:04Z"
        },
        "body": "**Description**\r\nEnable transpose optimizer and infrastructure it depends on in a minimal extended build.\r\n\r\n**Motivation and Context**\r\nEnable the transpose optimizer to run as part of runtime optimization of ORT format models.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10349/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10350",
        "id": 1110003023,
        "node_id": "PR_kwDOCVq1mM4xXEaz",
        "number": 10350,
        "title": "Update Training Op Kernel Hashes",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-21T03:12:02Z",
        "updated_at": "2022-02-07T02:10:08Z",
        "closed_at": "2022-02-07T02:09:46Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10350",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10350",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10350.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10350.patch",
            "merged_at": null
        },
        "body": "Update the training Op kernel hashes so it won't report any warning during UT running.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10350/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10351",
        "id": 1110059415,
        "node_id": "PR_kwDOCVq1mM4xXPni",
        "number": 10351,
        "title": "additional options of NNAPI for ORT_PERF_TOOL",
        "user": {
            "login": "wejoncy",
            "id": 9417365,
            "node_id": "MDQ6VXNlcjk0MTczNjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9417365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wejoncy",
            "html_url": "https://github.com/wejoncy",
            "followers_url": "https://api.github.com/users/wejoncy/followers",
            "following_url": "https://api.github.com/users/wejoncy/following{/other_user}",
            "gists_url": "https://api.github.com/users/wejoncy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wejoncy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wejoncy/subscriptions",
            "organizations_url": "https://api.github.com/users/wejoncy/orgs",
            "repos_url": "https://api.github.com/users/wejoncy/repos",
            "events_url": "https://api.github.com/users/wejoncy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wejoncy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2022-01-21T05:02:01Z",
        "updated_at": "2022-02-07T06:13:43Z",
        "closed_at": "2022-01-24T18:17:57Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10351",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10351",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10351.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10351.patch",
            "merged_at": "2022-01-24T18:17:57Z"
        },
        "body": "**Description**: Describe your changes.\r\nTo control the sub-options for NNAPI in the ort perf-test-tool. It's impossible to pass any values to NNAPI like 'disable_cpu' via perf-test-tool command args. This PR is to support it via a addition keyword `-i`;\r\n\r\n**Usage**\r\nif you want to pass any options listed here [configuration options](https://onnxruntime.ai/docs/execution-providers/NNAPI-ExecutionProvider.html#configuration-options) to have a specific performance benchmarking.\r\n```\r\n./onnxruntime_perf_test -i NNAPI_FLAG_CPU_DISABLED|true -e nnapi xx.onnx\r\n```\r\nMeanwhile, if you want to pass multiple options\r\n```\r\n./onnxruntime_perf_test -i NNAPI_FLAG_CPU_DISABLED|true  NNAPI_FLAG_USE_FP16|true   NNAPI_FLAG_USE_NCHW|true -e nnapi xx.onnx\r\n```\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n   this change supplies a ability of pass options to NNAPI EP for perf-test-tool\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10351/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10352",
        "id": 1110131355,
        "node_id": "I_kwDOCVq1mM5CK0Kb",
        "number": 10352,
        "title": "Issues when trying to use Onnxruntime and Tensorrt execution provider in a java application",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-01-21T07:09:00Z",
        "updated_at": "2022-03-16T16:26:04Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWe have a seq2seq model which was exported to two onnx files (encoder/decoder), and use it via the onnx runtime inference session. It runs fine on the GPU with cuda provider, but when I try to switch to tensorrt execution provider I met several issues.\r\nOur goal is to switch to TensorRT execution provider 8.2 for better inference time, but below look like the TensorRT issues. Can you please help? \r\nOur model export can be found [here](https://github.com/brevity2021/pegasus_xsm_onnx/blob/main/export_xsum_onnx.py) and I try to describe the onnx session settings below. Code is a bit difficult to attach, but basically what it does is to create encoding/decoding session from two onnx files, then do inference by session.run.\r\n\r\nThe errors are as follows:\r\n1. When I use the onnxruntime 1.10 jar + tensorrt 8.2  (using nvidia container nvcr.io/nvidia/tensorrt:21.12-py3), with java 14:\r\nit throws the following error and quit, in the middle of the decoding process (the first few runs of decoding_session.run() is fine, but it throws this error after decoding a few tokens):\r\n**Unexpected Internal Error: [virtualMemoryBuffer.cpp::~StdVirtualMemoryBufferImpl::121] Error Code 1: Cuda Runtime (driver shutting down)\r\nUnexpected Internal Error: [virtualMemoryBuffer.cpp::~StdVirtualMemoryBufferImpl::121] Error Code 1: Cuda Runtime (driver shutting down)**\r\n\r\nSwitching to cuda runs fine in this case. There are no difference in the code executed, the only difference is that under TensorRT setting, we use \r\n```\r\nOrtSession.SessionOptions.addTensorrt(0);\r\nOrtSession.SessionOptions.addCuda(0);\r\n```\r\nwhile under Cuda setting we only use `OrtSession.SessionOptions.addCuda(0)`;\r\n\r\n2. I tried to build a Onnxruntime jar using the latest master, using \r\n`./build.sh --cudnn_home /usr/lib/x86_64-linux-gnu --cuda_home /usr/local/cuda --use_tensorrt --tensorrt_home /opt/tensorrt --build_java` in the tensorrt:21.12-py3 container, but using this jar has errors both under cuda/tensorrt.\r\n\r\nUnder the cuda setting, at the end of the program, the log shows:\r\n**pure virtual method called\r\nterminate called without an active exception\r\nAborted (core dumped)**\r\n\r\nUnder the tensorrt setting, the program quits at the beginning of the decoding run. It shows the following error:\r\n**2022-01-21 06:21:44.557369308 [E:onnxruntime:ort-java, tensorrt_execution_provider.h:57 log] [2022-01-21 06:21:44   **ERROR] 4: [graphShapeAnalyzer.cpp::processCheck::581] Error Code 4: Internal Error (IAssertionLayer (Unnamed Layer* 9) [Assertion]: condition[0] is false: 0. For input: 'input_ids' all named dimensions that share the same name must be equal. Note: Named dimensions were present on the following axes: 1 (name: 'sequence'), 1 (name: 'sequence'))****\r\n\r\n==========================================================================\r\n **A fatal error has been detected by the Java Runtime Environment:\r\n\r\n  SIGSEGV (0xb) at pc=0x00007f722416bad6, pid=49, tid=57\r\n\r\n\r\n JRE version: OpenJDK Runtime Environment (14.0.2+12) (build 14.0.2+12-46)\r\n Java VM: OpenJDK 64-Bit Server VM (14.0.2+12-46, mixed mode, tiered, g1 gc, linux-amd64)\r\n Problematic frame:\r\n C  [libonnxruntime_providers_tensorrt.so+0x22ad6]  nvinfer1::ICudaEngine::serialize() const+0x14**\r\n\r\n==========================================================================\r\n\r\nWonder if this has anything to do with multi-threading as we use this in our session options (see below).\r\n\r\nThanks a lot.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Inside container tensorrt:21.12-py3\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10 (GPU)\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: V100\r\n\r\n**Additional context**\r\nOur onnx session options are set as follows:\r\n```\r\nOrtSession.SessionOptions opts;\r\nopts.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT);\r\nopts.setMemoryPatternOptimization(true)\r\nif (useTensorRT) {\r\n          opts.addTensorrt(0);\r\n}\r\nopts.addCUDA(0);\r\nopts.setExecutionMode(OrtSession.SessionOptions.ExecutionMode.PARALLEL);\r\nopts.setInterOpNumThreads(8);\r\nopts.setIntraOpNumThreads(8);\r\n\r\nOrtEnvironment env;\r\nOrtSession session = env.createSession(model_path, opts);\r\n```\r\n\r\nWhen using the TensorRT execution provider, I also set the following environment variables:\r\n```\r\nORT_TENSORRT_MAX_WORKSPACE_SIZE=22147483648\r\nORT_TENSORRT_CACHE_PATH=folder\r\nORT_TENSORRT_ENGINE_CACHE_ENABLE=1\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10352/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10353",
        "id": 1110836455,
        "node_id": "PR_kwDOCVq1mM4xZyMs",
        "number": 10353,
        "title": "Pin version of post to dashboard scripts' dependencies and update them to work with recent version.",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-01-21T19:44:44Z",
        "updated_at": "2022-01-22T03:35:59Z",
        "closed_at": "2022-01-22T03:35:59Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10353",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10353",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10353.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10353.patch",
            "merged_at": "2022-01-22T03:35:58Z"
        },
        "body": "**Description**\r\nPin version of post to dashboard scripts' dependencies and update them to work with recent version.\r\n\r\n**Motivation and Context**\r\nFix build break and reduce likelihood of future breaks due to new versions.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10353/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10354",
        "id": 1111004537,
        "node_id": "PR_kwDOCVq1mM4xaXB6",
        "number": 10354,
        "title": "Bump log4js from 6.3.0 to 6.4.0 in /js/web",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-01-21T22:33:37Z",
        "updated_at": "2022-01-27T04:51:51Z",
        "closed_at": "2022-01-27T04:51:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10354",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10354",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10354.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10354.patch",
            "merged_at": "2022-01-27T04:51:50Z"
        },
        "body": "Bumps [log4js](https://github.com/log4js-node/log4js-node) from 6.3.0 to 6.4.0.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/log4js-node/log4js-node/blob/master/CHANGELOG.md\">log4js's changelog</a>.</em></p>\n<blockquote>\n<h2>6.4.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1141\">security: default file permission to be 0o600 instead of 0o644</a> - thanks <a href=\"https://www.huntr.dev/users/ranjit-git\">ranjit-git</a> and <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1148\">chore(docs): updated fileSync.md and misc comments</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1062\">feat: Added warnings when log() is used with invalid levels before fallbacking to INFO</a> - thanks <a href=\"https://github.com/abernh\"><code>@​abernh</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1103\">feat: exposed Recording</a> - thanks <a href=\"https://github.com/polo-language\"><code>@​polo-language</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1113\">bug: Fixed file descriptor leak if repeated configure()</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1110\">bug: Fixed MaxListenersExceededWarning from NodeJS</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1142\">test: added assertion for increase of SIGHUP listeners on log4js.configure()</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1028\">bug: Fixed missing TCP appender with Webpack and Typescript</a> - thanks <a href=\"https://github.com/techmunk\"><code>@​techmunk</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1097\">bug: Fixed dateFile appender exiting NodeJS on error</a> - thanks <a href=\"https://github.com/4eb0da\"><code>@​4eb0da</code></a>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1144\">refactor: using writer.writable instead of alive for checking</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1089\">bug: Fixed TCP appender exiting NodeJS on error</a> - thanks <a href=\"https://github.com/jhonatanTeixeira\"><code>@​jhonatanTeixeira</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/529\">bug: Fixed Multiprocess appender exiting NodeJS on error</a> - thanks <a href=\"https://github.com/harlentan\"><code>@​harlentan</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1127\">test: update fakeFS.read as graceful-fs uses it</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1128\">test: update fakeFS.realpath as fs-extra uses it</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li>test: added tap.tearDown() to clean up test files\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1143\">#1143</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1022\">#1022</a> - thanks <a href=\"https://github.com/abetomo\"><code>@​abetomo</code></a></li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1079\"><code>type: improved @​types for AppenderModule</code></a> - thanks <a href=\"https://github.com/nicobao\"><code>@​nicobao</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1116\">type: Updated fileSync appender types</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1031\">type: Removed erroneous type in file appender</a> - thanks <a href=\"https://github.com/vdmtrv\"><code>@​vdmtrv</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1115\">type: Updated Logger.log type</a> - thanks <a href=\"https://github.com/ZLundqvist\"><code>@​ZLundqvist</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1117\">type: Updated Logger._log type</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1118\">type: Updated Logger.level type</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1072\">type: Updated Levels.getLevel type</a> - thanks <a href=\"https://github.com/saulzhong\"><code>@​saulzhong</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1147\">chore(deps): bump streamroller from 3.0.1 to 3.0.2</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1146\">chore(deps): bump date-format from 4.0.2 to 4.0.3</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1145\">chore(deps-dev): bump eslint from from 8.6.0 to 8.7.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1140\">chore(deps-dev): bump nyc from 14.1.1 to 15.1.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1138\">chore(deps-dev): bump eslint from 5.16.0 to 8.6.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1137\">chore(deps): bump flatted from 2.0.2 to 3.2.4</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1136\">chore(deps-dev): bump fs-extra from 8.1.0 to 10.0.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1135\">chore(deps): bump streamroller from 2.2.4 to 3.0.1</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1151\">feat: allows for zero backups</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1149\">api: migrated from daysToKeep to numBackups due to streamroller@^3.0.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/streamroller/pull/65\">bug: compressed file ignores dateFile appender &quot;mode&quot;</a> - thanks <a href=\"https://github.com/rnd-debug\"><code>@​rnd-debug</code></a></li>\n<li>issue: addresses additional separator in filename (<a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1039\">#1039</a>) - details: <a href=\"https://github.com/log4js-node/streamroller/blob/master/CHANGELOG.md\">streamroller@3.0.0 changelog</a></li>\n<li>issue: addresses daysToKeep naming confusion (<a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1035\">#1035</a>, <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1080\">#1080</a>)  - details: <a href=\"https://github.com/log4js-node/streamroller/blob/master/CHANGELOG.md\">streamroller@3.0.0 changelog</a></li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1134\">chore(deps): bump date-format from 3.0.0 to 4.0.2</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1130\">chore(deps): Updated dependencies</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a>\n<ul>\n<li>eslint-config-prettier from 6.15.0 to 8.3.0</li>\n<li>eslint-plugin-prettier from 3.4.1 to 4.0.0</li>\n<li>husky from 3.1.0 to 7.0.4</li>\n<li>prettier from 1.19.0 to 2.5.1</li>\n<li>typescript from 3.9.10 to 4.5.4</li>\n</ul>\n</li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1129\">chore(deps-dev): bump eslint-config-prettier from 6.15.0 to 8.3.0</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/pull/1121\">chore(deps): Updated dependencies</a> - thanks <a href=\"https://github.com/peteriman\"><code>@​peteriman</code></a>\n<ul>\n<li>codecov from 3.6.1 to 3.8.3</li>\n<li>eslint-config-prettier from 6.5.0 to 6.15.0</li>\n</ul>\n</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/9fdbed5ad45d1b09b35c1ef5355ba726b60cb702\"><code>9fdbed5</code></a> 6.4.0</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/788c7a83bbb6f9b20a9f17bd7c3013b78b72f4d3\"><code>788c7a8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1150\">#1150</a> from log4js-node/update-changelog</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/7fdb141135e930960d44597d969a1aff14627346\"><code>7fdb141</code></a> chore: updated changelog for 6.4.0</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/e6bd888c2d4ee2c0ba257349ce78112fc4a591be\"><code>e6bd888</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1151\">#1151</a> from log4js-node/feat-zero-backup</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/ac599e42c6762cd0cc6ee3a34873c6f839dd196f\"><code>ac599e4</code></a> allow for zero backup - in sync with <a href=\"https://github.com/log4js-node/streamrol\">https://github.com/log4js-node/streamrol</a>...</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/53248cd564f63ee2d5634761ed5078d8882d6df4\"><code>53248cd</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1149\">#1149</a> from log4js-node/migrate-daysToKeep-to-numBackups</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/436d9b49515601640be4866caa26d202684e5f26\"><code>436d9b4</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1148\">#1148</a> from log4js-node/update-docs</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/d6b017e72041913a18fefa0194459cebd63ba440\"><code>d6b017e</code></a> chore(docs): updated fileSync.md and misc comments</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/d4617a730da73136be2e887e6a5ec28aacabd899\"><code>d4617a7</code></a> chore(deps): migrated from daysToKeep to numBackups due to streamroller@^3.0.0</li>\n<li><a href=\"https://github.com/log4js-node/log4js-node/commit/0ad013382345029d312d30f4d5783c1dd2c16182\"><code>0ad0133</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/log4js-node/log4js-node/issues/1147\">#1147</a> from log4js-node/update-deps</li>\n<li>Additional commits viewable in <a href=\"https://github.com/log4js-node/log4js-node/compare/v6.3.0...v6.4.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=log4js&package-manager=npm_and_yarn&previous-version=6.3.0&new-version=6.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10354/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]