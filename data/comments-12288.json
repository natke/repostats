[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1192976872",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1192976872",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1192976872,
        "node_id": "IC_kwDOCVq1mM5HG2Ho",
        "user": {
            "login": "zhanghuanrong",
            "id": 5163183,
            "node_id": "MDQ6VXNlcjUxNjMxODM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5163183?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhanghuanrong",
            "html_url": "https://github.com/zhanghuanrong",
            "followers_url": "https://api.github.com/users/zhanghuanrong/followers",
            "following_url": "https://api.github.com/users/zhanghuanrong/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhanghuanrong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhanghuanrong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhanghuanrong/subscriptions",
            "organizations_url": "https://api.github.com/users/zhanghuanrong/orgs",
            "repos_url": "https://api.github.com/users/zhanghuanrong/repos",
            "events_url": "https://api.github.com/users/zhanghuanrong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhanghuanrong/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-22T22:21:45Z",
        "updated_at": "2022-07-22T22:21:45Z",
        "author_association": "MEMBER",
        "body": "Thanks for reporting. Yet we need more information to start investigating.\r\nCould you please give more details ?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1192976872/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1192977456",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1192977456",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1192977456,
        "node_id": "IC_kwDOCVq1mM5HG2Qw",
        "user": {
            "login": "dboshardy",
            "id": 2131537,
            "node_id": "MDQ6VXNlcjIxMzE1Mzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2131537?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dboshardy",
            "html_url": "https://github.com/dboshardy",
            "followers_url": "https://api.github.com/users/dboshardy/followers",
            "following_url": "https://api.github.com/users/dboshardy/following{/other_user}",
            "gists_url": "https://api.github.com/users/dboshardy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dboshardy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dboshardy/subscriptions",
            "organizations_url": "https://api.github.com/users/dboshardy/orgs",
            "repos_url": "https://api.github.com/users/dboshardy/repos",
            "events_url": "https://api.github.com/users/dboshardy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dboshardy/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-22T22:23:08Z",
        "updated_at": "2022-07-22T22:23:08Z",
        "author_association": "NONE",
        "body": "> Thanks for reporting. Yet we need more information to start investigating. Could you please give more details ?\r\n\r\nI'm happy to help, but you'll have to be more specific.  What details would you need?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1192977456/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1195102153",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1195102153",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1195102153,
        "node_id": "IC_kwDOCVq1mM5HO8_J",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-26T07:19:09Z",
        "updated_at": "2023-04-11T00:32:18Z",
        "author_association": "MEMBER",
        "body": "InferenceSession supports concurrent Run calls as the operator kernels used to execute the model are stateless. There's no internal waiting for existing requests to complete before starting the next one.\r\n\r\nFWIW the execution should be deterministic. Are you able to capture the input used in a failed request to see if it fails every time?\r\n\r\nAccording to the error it's coming from an InstanceNormalization node and not a Conv node. There's not much use of SafeInt in the InstanceNormalization kernel. Only places I could see were around checking the total size of the input tensor. Without seeing the model it's hard to say what else could be off.\r\n\r\nAny chance the InstanceNormalization node is early in the model and is consuming a model input that is perhaps being overwritten outside of ORT? We treat model inputs as constant and do NOT copy them. Due to that, if you modify the buffer externally whilst the request is running you could affect nodes that consume model inputs.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1195102153/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1205775412",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1205775412",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1205775412,
        "node_id": "IC_kwDOCVq1mM5H3qw0",
        "user": {
            "login": "dboshardy",
            "id": 2131537,
            "node_id": "MDQ6VXNlcjIxMzE1Mzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2131537?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dboshardy",
            "html_url": "https://github.com/dboshardy",
            "followers_url": "https://api.github.com/users/dboshardy/followers",
            "following_url": "https://api.github.com/users/dboshardy/following{/other_user}",
            "gists_url": "https://api.github.com/users/dboshardy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dboshardy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dboshardy/subscriptions",
            "organizations_url": "https://api.github.com/users/dboshardy/orgs",
            "repos_url": "https://api.github.com/users/dboshardy/repos",
            "events_url": "https://api.github.com/users/dboshardy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dboshardy/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-04T21:14:36Z",
        "updated_at": "2022-08-04T21:16:19Z",
        "author_association": "NONE",
        "body": "@scottmckay Apologies for the late reply.  Yes, I have capture inputs that error and there is no determinism when it comes to these errors.  The same image put through the same model will error under heavy load but under little load, no error.  \r\n\r\nI've also noticed the behavior where, once the model errors in this manner, reloading the model by deleting the inference session (`del` in python in this instance) and creating a new one all subsequent requests, at least that I can tell, seem to error in the same manner.\r\n\r\nThe error happens in different nodes each time it initially pops up. It typically occurs in one of the many Conv nodes. This instance was a bit unusual.\r\n\r\nIt's definitely possible this is a weird interaction under heavy load with the inference session and how uvicorn or FastAPI are handling the concurrency in the docker container.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1205775412/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1408135649",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1408135649",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1408135649,
        "node_id": "IC_kwDOCVq1mM5T7nHh",
        "user": {
            "login": "junrong1",
            "id": 47480627,
            "node_id": "MDQ6VXNlcjQ3NDgwNjI3",
            "avatar_url": "https://avatars.githubusercontent.com/u/47480627?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/junrong1",
            "html_url": "https://github.com/junrong1",
            "followers_url": "https://api.github.com/users/junrong1/followers",
            "following_url": "https://api.github.com/users/junrong1/following{/other_user}",
            "gists_url": "https://api.github.com/users/junrong1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/junrong1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/junrong1/subscriptions",
            "organizations_url": "https://api.github.com/users/junrong1/orgs",
            "repos_url": "https://api.github.com/users/junrong1/repos",
            "events_url": "https://api.github.com/users/junrong1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/junrong1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-30T07:51:29Z",
        "updated_at": "2023-01-30T07:51:29Z",
        "author_association": "NONE",
        "body": "I have the similar problem\r\nSystem Information\r\n\r\n- Python 3.8\r\n- ONNX Runtime version: 1.12.0\r\n`\r\n\r\n| See the caveats in the documentation: https://pandas.pydata.org/pandas-\r\n\r\n\r\n\r\n|   File \"/usr/local/lib/python3.8/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 373, in \r\n\r\n|   File \"/usr/local/lib/python3.8/dist-packages/uvicorn/middleware/proxy_headers.py\", line 75, in \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n|   File \"/usr/local/lib/python3.8/dist-\r\n\r\n| onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running FusedMatMul node. Name:'/bert/encoder/layer.0/attention/self/MatMul_FusedMatMulAndScale' Status Message: /onnxruntime_src/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow    \r\n`",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1408135649/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1445429685",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1445429685",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1445429685,
        "node_id": "IC_kwDOCVq1mM5WJ4G1",
        "user": {
            "login": "LemurPwned",
            "id": 8441184,
            "node_id": "MDQ6VXNlcjg0NDExODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8441184?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LemurPwned",
            "html_url": "https://github.com/LemurPwned",
            "followers_url": "https://api.github.com/users/LemurPwned/followers",
            "following_url": "https://api.github.com/users/LemurPwned/following{/other_user}",
            "gists_url": "https://api.github.com/users/LemurPwned/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LemurPwned/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LemurPwned/subscriptions",
            "organizations_url": "https://api.github.com/users/LemurPwned/orgs",
            "repos_url": "https://api.github.com/users/LemurPwned/repos",
            "events_url": "https://api.github.com/users/LemurPwned/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LemurPwned/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-02-26T18:32:22Z",
        "updated_at": "2023-02-26T18:32:22Z",
        "author_association": "NONE",
        "body": "I'm facing a similar issue when when multiple (2 is usually enough to reproduce) processes of onnxruntime run on the same Docker container.  \r\nCuriously this does not happen with all the models, only some -- is there some way to debug this reliably? Could it be connected to the way the model is converted to onnx or how it is being optimised?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1445429685/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1479539740",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1479539740",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1479539740,
        "node_id": "IC_kwDOCVq1mM5YL_wc",
        "user": {
            "login": "LeviViana",
            "id": 17881241,
            "node_id": "MDQ6VXNlcjE3ODgxMjQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17881241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LeviViana",
            "html_url": "https://github.com/LeviViana",
            "followers_url": "https://api.github.com/users/LeviViana/followers",
            "following_url": "https://api.github.com/users/LeviViana/following{/other_user}",
            "gists_url": "https://api.github.com/users/LeviViana/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LeviViana/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LeviViana/subscriptions",
            "organizations_url": "https://api.github.com/users/LeviViana/orgs",
            "repos_url": "https://api.github.com/users/LeviViana/repos",
            "events_url": "https://api.github.com/users/LeviViana/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LeviViana/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-22T13:07:28Z",
        "updated_at": "2023-03-22T13:07:28Z",
        "author_association": "NONE",
        "body": "I faced a very similar issue, in my case, this happened only when the GPU memory was full.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1479539740/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500871574",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1500871574",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1500871574,
        "node_id": "IC_kwDOCVq1mM5ZdXuW",
        "user": {
            "login": "zeruniverse",
            "id": 4648756,
            "node_id": "MDQ6VXNlcjQ2NDg3NTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4648756?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeruniverse",
            "html_url": "https://github.com/zeruniverse",
            "followers_url": "https://api.github.com/users/zeruniverse/followers",
            "following_url": "https://api.github.com/users/zeruniverse/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeruniverse/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeruniverse/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeruniverse/subscriptions",
            "organizations_url": "https://api.github.com/users/zeruniverse/orgs",
            "repos_url": "https://api.github.com/users/zeruniverse/repos",
            "events_url": "https://api.github.com/users/zeruniverse/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeruniverse/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-08T11:28:21Z",
        "updated_at": "2023-04-08T11:28:21Z",
        "author_association": "NONE",
        "body": "> I'm facing a similar issue when when multiple (2 is usually enough to reproduce) processes of onnxruntime run on the same Docker container. Curiously this does not happen with all the models, only some -- is there some way to debug this reliably? Could it be connected to the way the model is converted to onnx or how it is being optimised?\r\n\r\n@zhanghuanrong Faced same issue on v1.14.1 (upgraded from v1.10.0) with ~30 models loaded (some constantly loads and unloads to/from GPU, other models persists on GPU)\r\n\r\n```\r\nonnx runtime error 6: Non-zero status code returned while running Conv node. Name:'/model.8/cv1/conv/Conv' Status Message: /workspace/onnxruntime/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow\r\n```\r\n\r\nThis error occurs on a model I don't unload from GPU. And when it happens, inferencing on this specific model will ALWAYS fail afterwards but other models are not affected. However, if I restart everything, this model just works fine (and most time, it works well). It's not easy to reproduce this bug but I saw several other people facing same issues above. Might be due to some rare race condition?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500871574/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1501544615",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1501544615",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1501544615,
        "node_id": "IC_kwDOCVq1mM5Zf8Cn",
        "user": {
            "login": "zeruniverse",
            "id": 4648756,
            "node_id": "MDQ6VXNlcjQ2NDg3NTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4648756?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeruniverse",
            "html_url": "https://github.com/zeruniverse",
            "followers_url": "https://api.github.com/users/zeruniverse/followers",
            "following_url": "https://api.github.com/users/zeruniverse/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeruniverse/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeruniverse/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeruniverse/subscriptions",
            "organizations_url": "https://api.github.com/users/zeruniverse/orgs",
            "repos_url": "https://api.github.com/users/zeruniverse/repos",
            "events_url": "https://api.github.com/users/zeruniverse/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeruniverse/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-10T08:21:20Z",
        "updated_at": "2023-04-10T08:21:20Z",
        "author_association": "NONE",
        "body": "> > I'm facing a similar issue when when multiple (2 is usually enough to reproduce) processes of onnxruntime run on the same Docker container. Curiously this does not happen with all the models, only some -- is there some way to debug this reliably? Could it be connected to the way the model is converted to onnx or how it is being optimised?\r\n> \r\n> @zhanghuanrong Faced same issue on v1.14.1 (upgraded from v1.10.0) with ~30 models loaded (some constantly loads and unloads to/from GPU, other models persists on GPU)\r\n> \r\n> ```\r\n> onnx runtime error 6: Non-zero status code returned while running Conv node. Name:'/model.8/cv1/conv/Conv' Status Message: /workspace/onnxruntime/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow\r\n> ```\r\n> \r\n> This error occurs on a model I don't unload from GPU. And when it happens, inferencing on this specific model will ALWAYS fail afterwards but other models are not affected. However, if I restart everything, this model just works fine (and most time, it works well). It's not easy to reproduce this bug but I saw several other people facing same issues above. Might be due to some rare race condition?\r\n\r\n+cc @skottmckay",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1501544615/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1568144992",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1568144992",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1568144992,
        "node_id": "IC_kwDOCVq1mM5dd_5g",
        "user": {
            "login": "haikuoxin",
            "id": 28586862,
            "node_id": "MDQ6VXNlcjI4NTg2ODYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/28586862?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/haikuoxin",
            "html_url": "https://github.com/haikuoxin",
            "followers_url": "https://api.github.com/users/haikuoxin/followers",
            "following_url": "https://api.github.com/users/haikuoxin/following{/other_user}",
            "gists_url": "https://api.github.com/users/haikuoxin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/haikuoxin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/haikuoxin/subscriptions",
            "organizations_url": "https://api.github.com/users/haikuoxin/orgs",
            "repos_url": "https://api.github.com/users/haikuoxin/repos",
            "events_url": "https://api.github.com/users/haikuoxin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/haikuoxin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-30T09:56:59Z",
        "updated_at": "2023-05-30T09:56:59Z",
        "author_association": "NONE",
        "body": "> I faced a very similar issue, in my case, this happened only when the GPU memory was full.\r\n\r\nIt may be related to the GPU memory. I am using the stack of \r\nUbuntu 20.04 \r\ngunicorn\r\nFastAPI\r\nonnxruntime-gpu \r\n\r\n8 workers within a container to deploy a model inference service. When workers=8 occupy the GPU memory to its full capacity, the same error occurs. when using workers=7 and leaving some redundant GPU memory, the issue disappears.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1568144992/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1569767971",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1569767971",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1569767971,
        "node_id": "IC_kwDOCVq1mM5dkMIj",
        "user": {
            "login": "junrong1",
            "id": 47480627,
            "node_id": "MDQ6VXNlcjQ3NDgwNjI3",
            "avatar_url": "https://avatars.githubusercontent.com/u/47480627?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/junrong1",
            "html_url": "https://github.com/junrong1",
            "followers_url": "https://api.github.com/users/junrong1/followers",
            "following_url": "https://api.github.com/users/junrong1/following{/other_user}",
            "gists_url": "https://api.github.com/users/junrong1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/junrong1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/junrong1/subscriptions",
            "organizations_url": "https://api.github.com/users/junrong1/orgs",
            "repos_url": "https://api.github.com/users/junrong1/repos",
            "events_url": "https://api.github.com/users/junrong1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/junrong1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-31T08:49:20Z",
        "updated_at": "2023-05-31T08:49:20Z",
        "author_association": "NONE",
        "body": "> \r\n\r\nI finally realized this problem related to the work load.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1569767971/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1625514582",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1625514582",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1625514582,
        "node_id": "IC_kwDOCVq1mM5g42JW",
        "user": {
            "login": "MarouaneMja",
            "id": 59453891,
            "node_id": "MDQ6VXNlcjU5NDUzODkx",
            "avatar_url": "https://avatars.githubusercontent.com/u/59453891?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MarouaneMja",
            "html_url": "https://github.com/MarouaneMja",
            "followers_url": "https://api.github.com/users/MarouaneMja/followers",
            "following_url": "https://api.github.com/users/MarouaneMja/following{/other_user}",
            "gists_url": "https://api.github.com/users/MarouaneMja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MarouaneMja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MarouaneMja/subscriptions",
            "organizations_url": "https://api.github.com/users/MarouaneMja/orgs",
            "repos_url": "https://api.github.com/users/MarouaneMja/repos",
            "events_url": "https://api.github.com/users/MarouaneMja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MarouaneMja/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-07T14:39:35Z",
        "updated_at": "2023-07-07T14:39:35Z",
        "author_association": "NONE",
        "body": "Hello everyone, has someone find a solution to this problem? Any updates , please! I am facing the same problem. I am using the stack: \r\n- Ubuntu 20.04\r\n- triton inference server 23.04",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1625514582/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1626492252",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1626492252",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1626492252,
        "node_id": "IC_kwDOCVq1mM5g8k1c",
        "user": {
            "login": "zeruniverse",
            "id": 4648756,
            "node_id": "MDQ6VXNlcjQ2NDg3NTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4648756?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeruniverse",
            "html_url": "https://github.com/zeruniverse",
            "followers_url": "https://api.github.com/users/zeruniverse/followers",
            "following_url": "https://api.github.com/users/zeruniverse/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeruniverse/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeruniverse/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeruniverse/subscriptions",
            "organizations_url": "https://api.github.com/users/zeruniverse/orgs",
            "repos_url": "https://api.github.com/users/zeruniverse/repos",
            "events_url": "https://api.github.com/users/zeruniverse/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeruniverse/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-08T02:21:43Z",
        "updated_at": "2023-07-08T02:21:43Z",
        "author_association": "NONE",
        "body": "> Hello everyone, has someone find a solution to this problem? Any updates , please! I am facing the same problem. I am using the stack:\r\n> \r\n> * Ubuntu 20.04\r\n> * triton inference server 23.04\r\n\r\n23.06 is still failing. \r\n\r\n```\r\n\"[StatusCode.INTERNAL] onnx runtime error 6: Non-zero status code returned while running Conv node. Name:'/model.8/cv1/conv/Conv' Status Message: /workspace/onnxruntime/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1626492252/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1630988194",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1630988194",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1630988194,
        "node_id": "IC_kwDOCVq1mM5hNuei",
        "user": {
            "login": "MarouaneMja",
            "id": 59453891,
            "node_id": "MDQ6VXNlcjU5NDUzODkx",
            "avatar_url": "https://avatars.githubusercontent.com/u/59453891?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MarouaneMja",
            "html_url": "https://github.com/MarouaneMja",
            "followers_url": "https://api.github.com/users/MarouaneMja/followers",
            "following_url": "https://api.github.com/users/MarouaneMja/following{/other_user}",
            "gists_url": "https://api.github.com/users/MarouaneMja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MarouaneMja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MarouaneMja/subscriptions",
            "organizations_url": "https://api.github.com/users/MarouaneMja/orgs",
            "repos_url": "https://api.github.com/users/MarouaneMja/repos",
            "events_url": "https://api.github.com/users/MarouaneMja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MarouaneMja/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-11T14:57:51Z",
        "updated_at": "2023-07-11T14:57:51Z",
        "author_association": "NONE",
        "body": "> > Hello everyone, has someone find a solution to this problem? Any updates , please! I am facing the same problem. I am using the stack:\r\n> > \r\n> > * Ubuntu 20.04\r\n> > * triton inference server 23.04\r\n> \r\n> 23.06 is still failing.\r\n> \r\n> ```\r\n> \"[StatusCode.INTERNAL] onnx runtime error 6: Non-zero status code returned while running Conv node. Name:'/model.8/cv1/conv/Conv' Status Message: /workspace/onnxruntime/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow\r\n> ```\r\n\r\nThank you for your response, I will follow the issue you have mentioned  ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1630988194/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1630998393",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12288#issuecomment-1630998393",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12288",
        "id": 1630998393,
        "node_id": "IC_kwDOCVq1mM5hNw95",
        "user": {
            "login": "MarouaneMja",
            "id": 59453891,
            "node_id": "MDQ6VXNlcjU5NDUzODkx",
            "avatar_url": "https://avatars.githubusercontent.com/u/59453891?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MarouaneMja",
            "html_url": "https://github.com/MarouaneMja",
            "followers_url": "https://api.github.com/users/MarouaneMja/followers",
            "following_url": "https://api.github.com/users/MarouaneMja/following{/other_user}",
            "gists_url": "https://api.github.com/users/MarouaneMja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MarouaneMja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MarouaneMja/subscriptions",
            "organizations_url": "https://api.github.com/users/MarouaneMja/orgs",
            "repos_url": "https://api.github.com/users/MarouaneMja/repos",
            "events_url": "https://api.github.com/users/MarouaneMja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MarouaneMja/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-11T15:03:40Z",
        "updated_at": "2023-07-11T15:03:40Z",
        "author_association": "NONE",
        "body": "> > Hello everyone, has someone find a solution to this problem? Any updates , please! I am facing the same problem. I am using the stack:\r\n> > \r\n> > * Ubuntu 20.04\r\n> > * triton inference server 23.04\r\n> \r\n> 23.06 is still failing.\r\n> \r\n> ```\r\n> \"[StatusCode.INTERNAL] onnx runtime error 6: Non-zero status code returned while running Conv node. Name:'/model.8/cv1/conv/Conv' Status Message: /workspace/onnxruntime/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow() Integer overflow\r\n> ```\r\n\r\nWhat is tricky about this bug, is that the model works fine on some images , however it fails on others.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1630998393/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]