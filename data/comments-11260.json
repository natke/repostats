[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1103159220",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11260#issuecomment-1103159220",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11260",
        "id": 1103159220,
        "node_id": "IC_kwDOCVq1mM5BwN-0",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-19T20:55:56Z",
        "updated_at": "2022-04-19T20:55:56Z",
        "author_association": "MEMBER",
        "body": "Comparing with QLinearOps, QDQ format is much more flexible and helps the ONNX quantization ecosystem. Here are some benefits examples:\r\n- different EPs/accelerators supports different set of quantized operators. As long as they support QuantizeLinear and DeQuantizeLinear, they can run the model successfully. \r\n- ONNX exporter (like pytorch to onnx) and converter (like tf2onnx) can convert/export quantized models from original framework to quantized ONNX model with QDQ format. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1103159220/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]