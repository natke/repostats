[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10032",
        "id": 1079306556,
        "node_id": "PR_kwDOCVq1mM4vzM_0",
        "number": 10032,
        "title": "Remove OpenMP code",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-14T04:44:07Z",
        "updated_at": "2021-12-15T08:58:43Z",
        "closed_at": "2021-12-15T08:58:43Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10032",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10032",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10032.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10032.patch",
            "merged_at": "2021-12-15T08:58:43Z"
        },
        "body": "**Description**: \r\n\r\nRemove OpenMP code\r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10032/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10033",
        "id": 1079312701,
        "node_id": "PR_kwDOCVq1mM4vzOPy",
        "number": 10033,
        "title": "Fix some static analysis warnings in the core framework",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-14T04:58:28Z",
        "updated_at": "2021-12-14T22:41:43Z",
        "closed_at": "2021-12-14T22:41:43Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10033",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10033",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10033.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10033.patch",
            "merged_at": "2021-12-14T22:41:43Z"
        },
        "body": "**Description**: \r\nFix some static analysis warnings in the core framework\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10033/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10034",
        "id": 1079314692,
        "node_id": "PR_kwDOCVq1mM4vzOpf",
        "number": 10034,
        "title": "Fix some warnings in mlas",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-14T05:02:30Z",
        "updated_at": "2021-12-14T22:41:12Z",
        "closed_at": "2021-12-14T22:41:12Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10034",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10034",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10034.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10034.patch",
            "merged_at": "2021-12-14T22:41:11Z"
        },
        "body": "**Description**: \r\n\r\n1. C26451. Arithmetic overflow: Using operator 'operator' on a size-a byte value and then casting the result to a size-b byte value. Cast the value to the wider type before calling operator 'operator' to avoid overflow. Ignore some occurrences.\r\n2. Use constexpr to replace const.\r\n3. Use \"[[fallthrough]]\" when we fall through from one label to another. \r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10034/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10035",
        "id": 1079370287,
        "node_id": "PR_kwDOCVq1mM4vzaNX",
        "number": 10035,
        "title": "Yield op supports bf16",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-14T06:38:58Z",
        "updated_at": "2021-12-14T21:12:37Z",
        "closed_at": "2021-12-14T21:12:37Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10035",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10035",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10035.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10035.patch",
            "merged_at": "2021-12-14T21:12:37Z"
        },
        "body": "\r\n**Description**: Describe your changes.\r\n\r\nAdd `bfloat16_t` to the list of supported types in the yield op's schema.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve? Required for using `ORTModule` with `bfloat16_t` parameters.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10035/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10036",
        "id": 1079550428,
        "node_id": "I_kwDOCVq1mM5AWKHc",
        "number": 10036,
        "title": "how to create float tensor with missing value using java runtime",
        "user": {
            "login": "reneix",
            "id": 4262204,
            "node_id": "MDQ6VXNlcjQyNjIyMDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4262204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/reneix",
            "html_url": "https://github.com/reneix",
            "followers_url": "https://api.github.com/users/reneix/followers",
            "following_url": "https://api.github.com/users/reneix/following{/other_user}",
            "gists_url": "https://api.github.com/users/reneix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/reneix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/reneix/subscriptions",
            "organizations_url": "https://api.github.com/users/reneix/orgs",
            "repos_url": "https://api.github.com/users/reneix/repos",
            "events_url": "https://api.github.com/users/reneix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/reneix/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1805781160,
                "node_id": "MDU6TGFiZWwxODA1NzgxMTYw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Java",
                "name": "api:Java",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to the Java API"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-14T10:02:48Z",
        "updated_at": "2022-04-17T09:54:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm using lightgbm classifier exported onnx model  pred in java runtime.\r\nmy onnx model included missing value imputer , but I have no idea how to create a tensor with missing values.\r\n\r\nwhen using Float[][]  createTensor throw exception as below, however, float[][] works.\r\nmy question is when using float[][], I can't set missing values as null or something else....\r\n\r\nplease help.\r\n\r\nexception :\r\nai.onnxruntime.OrtException: Cannot create an OnnxTensor from a base type of class java.lang.Float\r\n\tat ai.onnxruntime.TensorInfo.constructFromJavaArray(TensorInfo.java:232)\r\n\tat ai.onnxruntime.OnnxTensor.createTensor(OnnxTensor.java:337)\r\n\tat ai.onnxruntime.OnnxTensor.createTensor(OnnxTensor.java:321)\r\n\r\ncode snap as below:\r\n            for (Map.Entry<String, Float[]> kv : floatFeature.entrySet()) {\r\n                String feaName = kv.getKey();\r\n                Float[] feaValues = kv.getValue();\r\n                Float[][] feaValues2d = new Float[feaValues.length][1];\r\n                for (int i = 0; i < feaValues.length; i++) {\r\n//                    feaValues2d[i] = ArrayUtils.toPrimitive(new Float[] {feaValues[i]});\r\n                    feaValues2d[i] = new Float[] {feaValues[i]};\r\n                }\r\n                OnnxTensor test = OnnxTensor.createTensor(env, feaValues2d);\r\n                newTensor.put(feaName, test);\r\n            }\r\n\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n-         <dependency>\r\n            <groupId>com.microsoft.onnxruntime</groupId>\r\n            <artifactId>onnxruntime</artifactId>\r\n            <version>1.9.0</version>\r\n        </dependency>\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10036/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10037",
        "id": 1079921083,
        "node_id": "I_kwDOCVq1mM5AXkm7",
        "number": 10037,
        "title": "how to build an unit8 model!",
        "user": {
            "login": "Chenhait",
            "id": 68895932,
            "node_id": "MDQ6VXNlcjY4ODk1OTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/68895932?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Chenhait",
            "html_url": "https://github.com/Chenhait",
            "followers_url": "https://api.github.com/users/Chenhait/followers",
            "following_url": "https://api.github.com/users/Chenhait/following{/other_user}",
            "gists_url": "https://api.github.com/users/Chenhait/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Chenhait/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Chenhait/subscriptions",
            "organizations_url": "https://api.github.com/users/Chenhait/orgs",
            "repos_url": "https://api.github.com/users/Chenhait/repos",
            "events_url": "https://api.github.com/users/Chenhait/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Chenhait/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-14T15:48:58Z",
        "updated_at": "2021-12-16T01:59:42Z",
        "closed_at": "2021-12-16T01:59:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "hi, I convert a onnx model, and use triton server to infer.\r\nhowever, the data and the model not in the same computer.\r\nthe input and output of ONNX model are fp32, it is too big to transmit.\r\nso, I want to change the input and output to  int8.\r\nis it possible?\r\nthank you very much if any advance!!\r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10037/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10038",
        "id": 1080090486,
        "node_id": "I_kwDOCVq1mM5AYN92",
        "number": 10038,
        "title": "Importing onnxruntime on AWS Lambdas with ARM64 processor causes crash",
        "user": {
            "login": "glefundes",
            "id": 11791798,
            "node_id": "MDQ6VXNlcjExNzkxNzk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11791798?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/glefundes",
            "html_url": "https://github.com/glefundes",
            "followers_url": "https://api.github.com/users/glefundes/followers",
            "following_url": "https://api.github.com/users/glefundes/following{/other_user}",
            "gists_url": "https://api.github.com/users/glefundes/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/glefundes/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/glefundes/subscriptions",
            "organizations_url": "https://api.github.com/users/glefundes/orgs",
            "repos_url": "https://api.github.com/users/glefundes/repos",
            "events_url": "https://api.github.com/users/glefundes/events{/privacy}",
            "received_events_url": "https://api.github.com/users/glefundes/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 26,
        "created_at": "2021-12-14T18:37:19Z",
        "updated_at": "2023-06-26T13:04:13Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI'm currently migrating a service deployed as a serverless function on AWS Lambda to the new ARM64 Graviton2 processor. Importing onnxruntime throws a cpuinfo error and crashes the code with the following messages:\r\n\r\n```\r\nError in cpuinfo: failed to parse the list of possible processors in /sys/devices/system/cpu/possible\r\n--\r\nError in cpuinfo: failed to parse the list of present processors in /sys/devices/system/cpu/present\r\nError in cpuinfo: failed to parse both lists of possible and present processors\r\nterminate called after throwing an instance of 'onnxruntime::OnnxRuntimeException'\r\nwhat():  /onnxruntime_src/onnxruntime/core/common/cpuid_info.cc:62 onnxruntime::CPUIDInfo::CPUIDInfo() Failed to initialize CPU info.\r\n\r\n```\r\nThe files _/sys/devices/system/cpu/possible_ and _/sys/devices/system/cpu/present_ don't exist and apparently this causes the crash. Is this expected behaviour? I'm not sure how to proceed. Is onnxruntime currently not supported by Graviton2 processors? The contents of /proc/cpuinfo are as follows:\r\n\r\n```\r\n\r\nprocessor\t: 0\r\n--\r\nBogoMIPS\t: 243.75\r\nFeatures\t: fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp ssbs\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x3\r\nCPU part\t: 0xd0c\r\nCPU revision\t: 1\r\nprocessor\t: 1\r\nBogoMIPS\t: 243.75\r\nFeatures\t: fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp ssbs\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x3\r\nCPU part\t: 0xd0c\r\nCPU revision\t: 1\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (AWS Lambda python runtime)\r\n- ONNX Runtime installed from (source or binary): binary (with pip)\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.5",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10038/timeline",
        "performed_via_github_app": null,
        "state_reason": "reopened"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10039",
        "id": 1080143272,
        "node_id": "I_kwDOCVq1mM5AYa2o",
        "number": 10039,
        "title": "ONNX runtime mysterious crash",
        "user": {
            "login": "niyazidageek",
            "id": 82367001,
            "node_id": "MDQ6VXNlcjgyMzY3MDAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/82367001?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/niyazidageek",
            "html_url": "https://github.com/niyazidageek",
            "followers_url": "https://api.github.com/users/niyazidageek/followers",
            "following_url": "https://api.github.com/users/niyazidageek/following{/other_user}",
            "gists_url": "https://api.github.com/users/niyazidageek/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/niyazidageek/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/niyazidageek/subscriptions",
            "organizations_url": "https://api.github.com/users/niyazidageek/orgs",
            "repos_url": "https://api.github.com/users/niyazidageek/repos",
            "events_url": "https://api.github.com/users/niyazidageek/events{/privacy}",
            "received_events_url": "https://api.github.com/users/niyazidageek/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-14T19:38:56Z",
        "updated_at": "2021-12-20T10:45:30Z",
        "closed_at": "2021-12-20T10:45:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Problem**\r\nMy code is unable to create an inference session. The program doesn't even throw an exception. Process is being automatically killed and that is it. I don't know what to do.\r\n\r\n**System information**\r\n- OS MacOS  (Big Sur):\r\n- ONNX Runtime installed from : Nuget.org\r\n- ONNX Runtime version: 1.10\r\n- Visual Studio 2019 (for Mac OS, version: 8.10.14)\r\n- CPU: M1 Silicon, 8gb RAM\r\n\r\n**ONNX Model**\r\n- [yolov5n.onnx.zip](https://github.com/microsoft/onnxruntime/files/7714246/yolov5n.onnx.zip)\r\n\r\n**Screenshots**\r\n- As you can see, code doesn't throw any exceptions and process is being killed at that line.\r\n<img width=\"842\" alt=\"Screen Shot 2021-12-14 at 23 25 32\" src=\"https://user-images.githubusercontent.com/82367001/146067063-99d1bfcf-f62f-4f18-a6d3-430e94c0a21c.png\">\r\n\r\n\r\n- Here is the window that i get after the process is killed\r\n<img width=\"1440\" alt=\"Screen Shot 2021-12-14 at 23 25 52\" src=\"https://user-images.githubusercontent.com/82367001/146067237-dd0778ec-0c0f-4586-bd87-0ac0b45a3df9.png\">\r\n\r\n\r\n**Additional message**\r\nI really don't know what to do. Please, help me. I haven't been able to handle this problem for more than 1 week. Additionally, the same piece of code works perfectly on Windows. Don't know what is wrong with **onnx** on Mac OS",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10039/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10040",
        "id": 1080433547,
        "node_id": "PR_kwDOCVq1mM4v2-oG",
        "number": 10040,
        "title": "Enable argument files in build.py.",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-15T00:36:22Z",
        "updated_at": "2021-12-15T16:22:16Z",
        "closed_at": "2021-12-15T16:22:15Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10040",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10040",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10040.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10040.patch",
            "merged_at": "2021-12-15T16:22:15Z"
        },
        "body": "**Description**\r\nPython's argparse.ArgumentParser supports passing files containing arguments.\r\nhttps://docs.python.org/3/library/argparse.html#fromfile-prefix-chars\r\n\r\nThis change enables argument files for build.py as there are potentially many arguments and it can be easier to keep common ones in a file.\r\n\r\nFor example:\r\n```\r\n$ cat cuda_opts.txt\r\n--build_dir /path/to/build/dir\r\n--use_cuda --cuda_version 11.4\r\n--cuda_home /path/to/cuda/home\r\n--cudnn_home /path/to/cudnn/home\r\n\r\n$ python tools/ci_build/build.py @cuda_opts.txt --update\r\n```\r\n\r\n**Motivation and Context**\r\nMake it easier to manage build.py arguments.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10040/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10041",
        "id": 1080451345,
        "node_id": "PR_kwDOCVq1mM4v3CYY",
        "number": 10041,
        "title": "Conv node bug, cached state was incoherent",
        "user": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T01:10:41Z",
        "updated_at": "2022-03-01T09:31:59Z",
        "closed_at": "2022-03-01T09:31:58Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10041",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10041",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10041.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10041.patch",
            "merged_at": "2022-03-01T09:31:58Z"
        },
        "body": "**Description**: When a zero sized shape passes through the Conv node we early exit during the computation, unfortunately this skips the setting of one of our cached state values. If we move the setting before the early exit, the cached state stays coherent.\r\n\r\nFixes: https://github.com/microsoft/onnxruntime/issues/10020\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10042",
        "id": 1080501366,
        "node_id": "PR_kwDOCVq1mM4v3MmS",
        "number": 10042,
        "title": "A small fix to allocators",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-15T02:48:24Z",
        "updated_at": "2021-12-15T05:21:09Z",
        "closed_at": "2021-12-15T05:21:08Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10042",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10042",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10042.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10042.patch",
            "merged_at": "2021-12-15T05:21:08Z"
        },
        "body": "**Description**: \r\n\r\nCalcMemSizeForArray is a static function, it should be access from the class name, not pointers.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\nFix a VC++ warning:\r\n\r\nwarning C6031: return value ignored: called-function could return unexpected value\r\n\r\n\r\n\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10043",
        "id": 1080559175,
        "node_id": "I_kwDOCVq1mM5AaAZH",
        "number": 10043,
        "title": "How to config the developing ide?",
        "user": {
            "login": "ZinuoCai",
            "id": 42794964,
            "node_id": "MDQ6VXNlcjQyNzk0OTY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/42794964?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ZinuoCai",
            "html_url": "https://github.com/ZinuoCai",
            "followers_url": "https://api.github.com/users/ZinuoCai/followers",
            "following_url": "https://api.github.com/users/ZinuoCai/following{/other_user}",
            "gists_url": "https://api.github.com/users/ZinuoCai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ZinuoCai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ZinuoCai/subscriptions",
            "organizations_url": "https://api.github.com/users/ZinuoCai/orgs",
            "repos_url": "https://api.github.com/users/ZinuoCai/repos",
            "events_url": "https://api.github.com/users/ZinuoCai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ZinuoCai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T04:42:21Z",
        "updated_at": "2021-12-15T05:25:04Z",
        "closed_at": "2021-12-15T05:19:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I am new to onnxruntime, and I wonder how to config the ide to code. Both vscode and clion are all right.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10044",
        "id": 1080635000,
        "node_id": "I_kwDOCVq1mM5AaS54",
        "number": 10044,
        "title": "Segmentation fault : onnxruntime infer all outputs include all nodes with python API",
        "user": {
            "login": "wangxudong-cq",
            "id": 76459010,
            "node_id": "MDQ6VXNlcjc2NDU5MDEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/76459010?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangxudong-cq",
            "html_url": "https://github.com/wangxudong-cq",
            "followers_url": "https://api.github.com/users/wangxudong-cq/followers",
            "following_url": "https://api.github.com/users/wangxudong-cq/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangxudong-cq/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangxudong-cq/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangxudong-cq/subscriptions",
            "organizations_url": "https://api.github.com/users/wangxudong-cq/orgs",
            "repos_url": "https://api.github.com/users/wangxudong-cq/repos",
            "events_url": "https://api.github.com/users/wangxudong-cq/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangxudong-cq/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2021-12-15T06:45:08Z",
        "updated_at": "2022-08-12T08:36:23Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nSegmentation fault (core dumped)\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04.5 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: Version: 1.6.0\r\n- Python version: Python 3.8.10\r\n\r\n**To Reproduce**\r\nmodel:https://github.com/onnx/models/blob/master/vision/classification/inception_and_googlenet/inception_v1/model/inception-v1-9.onnx\r\n\r\n#test.py\r\n```\r\n  import onnx\r\n  import onnx.numpy_helper\r\n  import onnxruntime as ort\r\n  from collections import OrderedDict\r\n  \r\n  \r\n  def readArrayFromPB(file):\r\n      tensor = onnx.TensorProto()\r\n      with open(file, \"rb\") as f:\r\n          tensor.ParseFromString(f.read())\r\n      array = onnx.numpy_helper.to_array(tensor)\r\n      return array\r\n  \r\n  def writeArrayToPB(file, array):\r\n      tensor = onnx.numpy_helper.from_array(array)\r\n      with open(file, \"wb\") as f:\r\n          f.write(tensor.SerializeToString())\r\n  \r\n  if __name__==\"__main__\":\r\n      model = onnx.load_model(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_nodes/inception-v1-9/inception-v1-9.onnx\")\r\n  \r\n      OutputNameLists = []\r\n      for i in range(len(model.graph.node)):\r\n          OutputNameLists.extend(model.graph.node[i].output)    \r\n  \r\n      OutputNameList = []\r\n      for i in range(len(model.graph.output)):\r\n          OutputNameList.append(model.graph.output[i].name)\r\n  \r\n      all_outs = list(set(OutputNameLists) - set(OutputNameList))\r\n      all_outs = [onnx.ValueInfoProto(name=x) for x in all_outs]\r\n      print(\"all_outs:{0}\".format(all_outs))\r\n  \r\n      model.graph.output.extend(all_outs)\r\n  \r\n      ort_session = ort.InferenceSession(model.SerializeToString())\r\n  \r\n      ort_ins = {}\r\n      ort_ins.update({\"data_0\":readArrayFromPB(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_nodes/inception-v1-9/test_data_set_0/input_0.pb\")})\r\n      \r\n      # ort_outnames = [\"prob_1\"]\r\n      ort_outnames = [x.name for x in ort_session.get_outputs()]\r\n      print(\"ort_outnames:{0}\".format(ort_outnames))\r\n      \r\n      ort_array = ort_session.run(ort_outnames, ort_ins)\r\n  \r\n      ort_outs = OrderedDict(zip(ort_outnames, ort_array))\r\n      ort_outshapes = {}\r\n      for k,v in ort_outs.items():\r\n          writeArrayToPB(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_outs/inception-v1-9/prob_1.pb\",v)\r\n          ort_outshapes.update({k:v.shape})\r\n      print(ort_outshapes)\r\n```\r\n\r\n**Expected behavior**\r\nonnxruntime infer success\r\n\r\n**Screenshots**\r\n(ubuntu) wang@VM-1-159-ubuntu:~/wangxudong/RPP_iTest/netmodel$ python3 test.py\r\nall_outs:[name: \"loss3_classifier_1\"\r\n, name: \"conv1_7x7_s2_1\"\r\n, name: \"inception_4b_5x5_reduce_2\"\r\n, name: \"inception_4b_5x5_1\"\r\n, name: \"inception_4c_1x1_2\"\r\n, name: \"inception_4c_3x3_reduce_2\"\r\n, name: \"pool3_3x3_s2_1\"\r\n, name: \"inception_5b_pool_proj_2\"\r\n, name: \"inception_5a_5x5_2\"\r\n, name: \"inception_4c_5x5_2\"\r\n, name: \"inception_3a_pool_1\"\r\n, name: \"pool1_norm1_1\"\r\n, name: \"inception_4c_3x3_1\"\r\n, name: \"inception_3a_3x3_reduce_2\"\r\n, name: \"inception_4d_pool_proj_2\"\r\n, name: \"inception_4e_pool_1\"\r\n, name: \"_pool5/7x7_s1_mask_1\"\r\n, name: \"inception_4b_3x3_reduce_2\"\r\n, name: \"pool5_7x7_s1_1\"\r\n, name: \"inception_4a_5x5_1\"\r\n, name: \"inception_3a_5x5_1\"\r\n, name: \"inception_4d_5x5_reduce_1\"\r\n, name: \"inception_5b_5x5_2\"\r\n, name: \"inception_4d_5x5_reduce_2\"\r\n, name: \"inception_3b_5x5_reduce_2\"\r\n, name: \"inception_4b_1x1_2\"\r\n, name: \"inception_4a_1x1_1\"\r\n, name: \"inception_4b_3x3_1\"\r\n, name: \"inception_3a_1x1_1\"\r\n, name: \"inception_4d_3x3_1\"\r\n, name: \"pool1_3x3_s2_1\"\r\n, name: \"inception_5b_output_1\"\r\n, name: \"inception_5a_5x5_reduce_2\"\r\n, name: \"inception_4d_1x1_1\"\r\n, name: \"inception_4e_5x5_1\"\r\n, name: \"conv2_3x3_1\"\r\n, name: \"inception_4e_1x1_2\"\r\n, name: \"inception_4d_3x3_reduce_1\"\r\n, name: \"inception_3b_5x5_2\"\r\n, name: \"inception_4d_3x3_reduce_2\"\r\n, name: \"inception_4c_pool_1\"\r\n, name: \"inception_5b_1x1_1\"\r\n, name: \"inception_5a_3x3_reduce_2\"\r\n, name: \"inception_5a_output_1\"\r\n, name: \"inception_4a_3x3_2\"\r\n, name: \"inception_5a_pool_proj_1\"\r\n, name: \"inception_3a_5x5_reduce_2\"\r\n, name: \"inception_3a_pool_proj_1\"\r\n, name: \"inception_5a_pool_1\"\r\n, name: \"inception_4e_pool_proj_1\"\r\n, name: \"conv2_3x3_reduce_1\"\r\n, name: \"inception_4c_pool_proj_1\"\r\n, name: \"inception_4d_3x3_2\"\r\n, name: \"inception_3b_3x3_reduce_2\"\r\n, name: \"inception_4a_5x5_reduce_1\"\r\n, name: \"inception_4a_3x3_1\"\r\n, name: \"inception_4c_output_1\"\r\n, name: \"pool2_3x3_s2_1\"\r\n, name: \"inception_4e_3x3_1\"\r\n, name: \"inception_4e_pool_proj_2\"\r\n, name: \"conv2_3x3_2\"\r\n, name: \"inception_3b_pool_1\"\r\n, name: \"conv2_norm2_1\"\r\n, name: \"inception_5b_3x3_reduce_2\"\r\n, name: \"inception_4a_3x3_reduce_1\"\r\n, name: \"inception_5a_pool_proj_2\"\r\n, name: \"conv1_7x7_s2_2\"\r\n, name: \"inception_3a_pool_proj_2\"\r\n, name: \"inception_3a_3x3_1\"\r\n, name: \"inception_5b_5x5_reduce_2\"\r\n, name: \"inception_4b_5x5_2\"\r\n, name: \"inception_4e_5x5_reduce_1\"\r\n, name: \"inception_4b_pool_proj_1\"\r\n, name: \"inception_4c_3x3_reduce_1\"\r\n, name: \"inception_5a_5x5_1\"\r\n, name: \"inception_4a_pool_proj_1\"\r\n, name: \"inception_4a_5x5_reduce_2\"\r\n, name: \"inception_4a_1x1_2\"\r\n, name: \"inception_5a_3x3_reduce_1\"\r\n, name: \"inception_5b_1x1_2\"\r\n, name: \"inception_4c_5x5_reduce_2\"\r\n, name: \"inception_4c_3x3_2\"\r\n, name: \"inception_4e_3x3_reduce_2\"\r\n, name: \"inception_5b_pool_proj_1\"\r\n, name: \"inception_3a_5x5_reduce_1\"\r\n, name: \"inception_3a_5x5_2\"\r\n, name: \"inception_3b_pool_proj_1\"\r\n, name: \"inception_3b_pool_proj_2\"\r\n, name: \"OC2_DUMMY_0\"\r\n, name: \"inception_4e_output_1\"\r\n, name: \"inception_4b_pool_proj_2\"\r\n, name: \"inception_3b_output_1\"\r\n, name: \"inception_4b_3x3_2\"\r\n, name: \"inception_4a_3x3_reduce_2\"\r\n, name: \"inception_4a_5x5_2\"\r\n, name: \"inception_4e_1x1_1\"\r\n, name: \"inception_3b_5x5_reduce_1\"\r\n, name: \"inception_4e_5x5_reduce_2\"\r\n, name: \"inception_3b_5x5_1\"\r\n, name: \"inception_5b_pool_1\"\r\n, name: \"inception_3a_3x3_2\"\r\n, name: \"inception_3a_3x3_reduce_1\"\r\n, name: \"inception_5b_5x5_reduce_1\"\r\n, name: \"inception_4d_5x5_1\"\r\n, name: \"inception_5b_3x3_1\"\r\n, name: \"inception_4d_pool_proj_1\"\r\n, name: \"inception_4b_1x1_1\"\r\n, name: \"inception_3a_output_1\"\r\n, name: \"inception_4b_3x3_reduce_1\"\r\n, name: \"inception_3b_3x3_2\"\r\n, name: \"inception_5a_1x1_1\"\r\n, name: \"inception_4d_1x1_2\"\r\n, name: \"inception_3b_1x1_2\"\r\n, name: \"inception_4c_5x5_1\"\r\n, name: \"inception_5b_3x3_reduce_1\"\r\n, name: \"inception_3b_3x3_reduce_1\"\r\n, name: \"inception_4b_output_1\"\r\n, name: \"inception_5a_3x3_2\"\r\n, name: \"inception_4d_pool_1\"\r\n, name: \"inception_4d_output_1\"\r\n, name: \"inception_4e_3x3_reduce_1\"\r\n, name: \"OC2_DUMMY_2\"\r\n, name: \"inception_4a_pool_1\"\r\n, name: \"inception_4c_5x5_reduce_1\"\r\n, name: \"inception_4a_output_1\"\r\n, name: \"inception_4c_1x1_1\"\r\n, name: \"pool4_3x3_s2_1\"\r\n, name: \"inception_3a_1x1_2\"\r\n, name: \"inception_4b_5x5_reduce_1\"\r\n, name: \"inception_4d_5x5_2\"\r\n, name: \"inception_4a_pool_proj_2\"\r\n, name: \"conv2_3x3_reduce_2\"\r\n, name: \"inception_5a_1x1_2\"\r\n, name: \"inception_5b_3x3_2\"\r\n, name: \"inception_3b_1x1_1\"\r\n, name: \"inception_5a_5x5_reduce_1\"\r\n, name: \"pool5_7x7_s1_2\"\r\n, name: \"inception_5a_3x3_1\"\r\n, name: \"inception_4e_5x5_2\"\r\n, name: \"inception_3b_3x3_1\"\r\n, name: \"inception_5b_5x5_1\"\r\n, name: \"inception_4c_pool_proj_2\"\r\n, name: \"inception_4b_pool_1\"\r\n, name: \"inception_4e_3x3_2\"\r\n]\r\nort_outnames:['prob_1', 'loss3_classifier_1', 'conv1_7x7_s2_1', 'inception_4b_5x5_reduce_2', 'inception_4b_5x5_1', 'inception_4c_1x1_2', 'inception_4c_3x3_reduce_2', 'pool3_3x3_s2_1', 'inception_5b_pool_proj_2', 'inception_5a_5x5_2', 'inception_4c_5x5_2', 'inception_3a_pool_1', 'pool1_norm1_1', 'inception_4c_3x3_1', 'inception_3a_3x3_reduce_2', 'inception_4d_pool_proj_2', 'inception_4e_pool_1', '_pool5/7x7_s1_mask_1', 'inception_4b_3x3_reduce_2', 'pool5_7x7_s1_1', 'inception_4a_5x5_1', 'inception_3a_5x5_1', 'inception_4d_5x5_reduce_1', 'inception_5b_5x5_2', 'inception_4d_5x5_reduce_2', 'inception_3b_5x5_reduce_2', 'inception_4b_1x1_2', 'inception_4a_1x1_1', 'inception_4b_3x3_1', 'inception_3a_1x1_1', 'inception_4d_3x3_1', 'pool1_3x3_s2_1', 'inception_5b_output_1', 'inception_5a_5x5_reduce_2', 'inception_4d_1x1_1', 'inception_4e_5x5_1', 'conv2_3x3_1', 'inception_4e_1x1_2', 'inception_4d_3x3_reduce_1', 'inception_3b_5x5_2', 'inception_4d_3x3_reduce_2', 'inception_4c_pool_1', 'inception_5b_1x1_1', 'inception_5a_3x3_reduce_2', 'inception_5a_output_1', 'inception_4a_3x3_2', 'inception_5a_pool_proj_1', 'inception_3a_5x5_reduce_2', 'inception_3a_pool_proj_1', 'inception_5a_pool_1', 'inception_4e_pool_proj_1', 'conv2_3x3_reduce_1', 'inception_4c_pool_proj_1', 'inception_4d_3x3_2', 'inception_3b_3x3_reduce_2', 'inception_4a_5x5_reduce_1', 'inception_4a_3x3_1', 'inception_4c_output_1', 'pool2_3x3_s2_1', 'inception_4e_3x3_1', 'inception_4e_pool_proj_2', 'conv2_3x3_2', 'inception_3b_pool_1', 'conv2_norm2_1', 'inception_5b_3x3_reduce_2', 'inception_4a_3x3_reduce_1', 'inception_5a_pool_proj_2', 'conv1_7x7_s2_2', 'inception_3a_pool_proj_2', 'inception_3a_3x3_1', 'inception_5b_5x5_reduce_2', 'inception_4b_5x5_2', 'inception_4e_5x5_reduce_1', 'inception_4b_pool_proj_1', 'inception_4c_3x3_reduce_1', 'inception_5a_5x5_1', 'inception_4a_pool_proj_1', 'inception_4a_5x5_reduce_2', 'inception_4a_1x1_2', 'inception_5a_3x3_reduce_1', 'inception_5b_1x1_2', 'inception_4c_5x5_reduce_2', 'inception_4c_3x3_2', 'inception_4e_3x3_reduce_2', 'inception_5b_pool_proj_1', 'inception_3a_5x5_reduce_1', 'inception_3a_5x5_2', 'inception_3b_pool_proj_1', 'inception_3b_pool_proj_2', 'OC2_DUMMY_0', 'inception_4e_output_1', 'inception_4b_pool_proj_2', 'inception_3b_output_1', 'inception_4b_3x3_2', 'inception_4a_3x3_reduce_2', 'inception_4a_5x5_2', 'inception_4e_1x1_1', 'inception_3b_5x5_reduce_1', 'inception_4e_5x5_reduce_2', 'inception_3b_5x5_1', 'inception_5b_pool_1', 'inception_3a_3x3_2', 'inception_3a_3x3_reduce_1', 'inception_5b_5x5_reduce_1', 'inception_4d_5x5_1', 'inception_5b_3x3_1', 'inception_4d_pool_proj_1', 'inception_4b_1x1_1', 'inception_3a_output_1', 'inception_4b_3x3_reduce_1', 'inception_3b_3x3_2', 'inception_5a_1x1_1', 'inception_4d_1x1_2', 'inception_3b_1x1_2', 'inception_4c_5x5_1', 'inception_5b_3x3_reduce_1', 'inception_3b_3x3_reduce_1', 'inception_4b_output_1', 'inception_5a_3x3_2', 'inception_4d_pool_1', 'inception_4d_output_1', 'inception_4e_3x3_reduce_1', 'OC2_DUMMY_2', 'inception_4a_pool_1', 'inception_4c_5x5_reduce_1', 'inception_4a_output_1', 'inception_4c_1x1_1', 'pool4_3x3_s2_1', 'inception_3a_1x1_2', 'inception_4b_5x5_reduce_1', 'inception_4d_5x5_2', 'inception_4a_pool_proj_2', 'conv2_3x3_reduce_2', 'inception_5a_1x1_2', 'inception_5b_3x3_2', 'inception_3b_1x1_1', 'inception_5a_5x5_reduce_1', 'pool5_7x7_s1_2', 'inception_5a_3x3_1', 'inception_4e_5x5_2', 'inception_3b_3x3_1', 'inception_5b_5x5_1', 'inception_4c_pool_proj_2', 'inception_4b_pool_1', 'inception_4e_3x3_2']\r\nSegmentation fault (core dumped)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10045",
        "id": 1080687549,
        "node_id": "I_kwDOCVq1mM5Aafu9",
        "number": 10045,
        "title": "I can not run the tensorrt example \"quantized BERT model example\"",
        "user": {
            "login": "fangd123",
            "id": 3364985,
            "node_id": "MDQ6VXNlcjMzNjQ5ODU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3364985?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fangd123",
            "html_url": "https://github.com/fangd123",
            "followers_url": "https://api.github.com/users/fangd123/followers",
            "following_url": "https://api.github.com/users/fangd123/following{/other_user}",
            "gists_url": "https://api.github.com/users/fangd123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fangd123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fangd123/subscriptions",
            "organizations_url": "https://api.github.com/users/fangd123/orgs",
            "repos_url": "https://api.github.com/users/fangd123/repos",
            "events_url": "https://api.github.com/users/fangd123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fangd123/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-15T07:44:38Z",
        "updated_at": "2022-04-17T09:54:15Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I ran the exmaple file [quantized BERT model example](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/nlp/bert/trt) \r\n\r\nIt said error\r\n\r\n```bash\r\n [E:onnxruntime:Default, tensorrt_execution_provider.h:51 log] [2021-12-15 07:23:33   ERROR] 1: [codeGenerator.cpp::compileGraph::476] Error Code 1: Myelin (Quantize op 1886_QuantizeLinear_quantize_scale_node{ForeignNode[1798...Add_1257]} has mis-matched Scale shape and dimension at axis)\r\n[1]    2881918 segmentation fault (core dumped)  python e2e_tensorrt_bert_example.py\r\n```\r\n\r\nI used the model from the huggingface transformers which named \"bert-base-uncased\" and converted it into onnx file\r\n\r\n**System information**\r\n- OS Platform and Distribution Linux Ubuntu 20.04:\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.4.2\r\n- GPU model and memory: RTX3090\r\n- Tensorrt: 8.0.3.4",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10046",
        "id": 1080714617,
        "node_id": "I_kwDOCVq1mM5AamV5",
        "number": 10046,
        "title": "[BUG] Registered type of RoiAlign  does not work ",
        "user": {
            "login": "zhibai-269",
            "id": 56142653,
            "node_id": "MDQ6VXNlcjU2MTQyNjUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/56142653?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhibai-269",
            "html_url": "https://github.com/zhibai-269",
            "followers_url": "https://api.github.com/users/zhibai-269/followers",
            "following_url": "https://api.github.com/users/zhibai-269/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhibai-269/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhibai-269/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhibai-269/subscriptions",
            "organizations_url": "https://api.github.com/users/zhibai-269/orgs",
            "repos_url": "https://api.github.com/users/zhibai-269/repos",
            "events_url": "https://api.github.com/users/zhibai-269/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhibai-269/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 11,
        "created_at": "2021-12-15T08:15:10Z",
        "updated_at": "2022-04-16T05:55:24Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI register three type(MLFloat16、float、double ) for Roialign to compute for onnx model.When I put  MLFloat16 in the front in .cc file,I can run float16 models successfully, but float 、double  with errors.But When I put float in the front ,I can run float models successfully, others with errors.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos 7.2 \r\n- ONNX Runtime installed from (source or binary):source\r\n- ONNX Runtime version: 1.7\r\n- Python version: 3.7.3\r\n- GCC/Compiler version (if compiling from source):gcc 5.4\r\n- CUDA/cuDNN version: CUDA 11.1、CUDA 10.1etc.\r\n- GPU model and memory: NVIDIA GeForce 3090、T4 etc.\r\n\r\n\r\n**To Reproduce**\r\nHere are the models.\r\n[roi_align.zip](https://github.com/microsoft/onnxruntime/files/7717431/roi_align.zip)\r\n\r\n\r\n\r\n\r\n**Screenshots**\r\n***As you can see ,I registered three Type in cuda_execution_provider.cc***\r\n![TH~6BNVZKLIB9 H@938870T](https://user-images.githubusercontent.com/56142653/146135303-5713a871-dab8-4991-84b4-829798d3daec.png)\r\nThen I run a test.py ,with a float16 ONNX model,and   got a right answer .However,when I run a same test.py with a float32 ONNX model(any other files hasn't been changed), I got the error blow.\r\n\r\n![F$_ 9)$~`C7GQAX3%MT7 JA](https://user-images.githubusercontent.com/56142653/146136514-b72939c0-6ff6-488a-8471-edf77378479c.jpg)\r\n\r\n***After that I moved the float Type in front of MLFloat16 in cuda_execution_provider.cc.***\r\n![G8 E1SYZ(1 5K%Q(QQ{I8M](https://user-images.githubusercontent.com/56142653/146136829-68d81fe4-d984-4c94-b0b8-3cb73a7ac998.png)\r\n***This time I can run the test.py with float32 model succesffly.When we run this test script with float16 model ,the same error occurs.***\r\n![UPO6THQ7SO~`@~4FSTSI1H](https://user-images.githubusercontent.com/56142653/146138247-ba7e264a-dbd9-4378-800b-a5fb6ae88c11.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n**Additional context**\r\nI tried test.py  whith duoble type models ,and got error all times.NEED HELP !@snnn !\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10047",
        "id": 1081163603,
        "node_id": "I_kwDOCVq1mM5AcT9T",
        "number": 10047,
        "title": "CUDA Cross-attention kernel",
        "user": {
            "login": "romain-keramitas-prl",
            "id": 91061498,
            "node_id": "MDQ6VXNlcjkxMDYxNDk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/91061498?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/romain-keramitas-prl",
            "html_url": "https://github.com/romain-keramitas-prl",
            "followers_url": "https://api.github.com/users/romain-keramitas-prl/followers",
            "following_url": "https://api.github.com/users/romain-keramitas-prl/following{/other_user}",
            "gists_url": "https://api.github.com/users/romain-keramitas-prl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/romain-keramitas-prl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/romain-keramitas-prl/subscriptions",
            "organizations_url": "https://api.github.com/users/romain-keramitas-prl/orgs",
            "repos_url": "https://api.github.com/users/romain-keramitas-prl/repos",
            "events_url": "https://api.github.com/users/romain-keramitas-prl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/romain-keramitas-prl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-15T15:17:08Z",
        "updated_at": "2022-08-12T08:37:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm able to use the `onnxruntime.transformers` codebase to optimize Tranformer-based model using self-attention, however it's not possible to use the self-attention kernel for cross-attention.\r\n\r\n**System information**\r\n\r\n- ONNX Runtime version (you are using): 1.10.0\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would like to know if the implementation of a CUDA kernel for cross-attention is something you've considered adding to ONNXRuntime - or simply a modification of the current self-attention kernel to take in one input for queries and one input for keys and values.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFor generative models I think the self-attention kernel can be used after a first pass, as we can simply reuse past keys and values. However that is not the case more generally, when you only perform one inference on a given pair of input.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10048",
        "id": 1081325117,
        "node_id": "I_kwDOCVq1mM5Ac7Y9",
        "number": 10048,
        "title": "System.MissingMethodException: Method not found: System.Memory'1<!0> Microsoft.ML.OnnxRuntime.Tensors.DenseTensor'1.get_Buffer() on iOS",
        "user": {
            "login": "juwens",
            "id": 11560817,
            "node_id": "MDQ6VXNlcjExNTYwODE3",
            "avatar_url": "https://avatars.githubusercontent.com/u/11560817?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juwens",
            "html_url": "https://github.com/juwens",
            "followers_url": "https://api.github.com/users/juwens/followers",
            "following_url": "https://api.github.com/users/juwens/following{/other_user}",
            "gists_url": "https://api.github.com/users/juwens/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juwens/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juwens/subscriptions",
            "organizations_url": "https://api.github.com/users/juwens/orgs",
            "repos_url": "https://api.github.com/users/juwens/repos",
            "events_url": "https://api.github.com/users/juwens/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juwens/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2385898474,
                "node_id": "MDU6TGFiZWwyMzg1ODk4NDc0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:mobile",
                "name": "platform:mobile",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime mobile; typically submitted using template"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 11,
        "created_at": "2021-12-15T17:57:20Z",
        "updated_at": "2022-08-12T08:27:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nRuntime exception when predicting data with our onnx model on iOS.\r\nWorks fine on android.\r\n\r\n```\r\nSystem.MissingMethodException: Method not found: System.Memory`1<!0> Microsoft.ML.OnnxRuntime.Tensors.DenseTensor`1.get_Buffer()\r\n\r\n  at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase+<>c__DisplayClass8_0`1[TRow,TDst].<CreateDirectVBufferSetter>b__0 (TRow row) [0x0001d] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase[TRow].FillValues (TRow row) [0x0000f] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.Data.TypedCursorable`1+RowImplementation[TRow].FillValues (TRow row) [0x00000] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngineBase`2[TSrc,TDst].FillValues (TDst prediction) [0x00000] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngine`2[TSrc,TDst].Predict (TSrc example, TDst& prediction) [0x0002a] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngineBase`2[TSrc,TDst].Predict (TSrc example) [0x00006] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at OnnxLib.OnnxAlgorithm.Predict (System.String onnxPath, System.Single[] inputData) [0x0005e] in /Users/jjaehrig/repo/foobar_ml/src/OnnxLib/OnnxAlgorithm.cs:26\r\n  at XamarinApp.MainPage.OnAppearing () [0x00015] in /Users/jjaehrig/repo/foobar_ml/src/XamarinApp/XamarinApp/MainPage.xaml.cs:23\r\n  at Xamarin.Forms.Page.SendAppearing () [0x00045] in D:\\a\\1\\s\\Xamarin.Forms.Core\\Page.cs:452\r\n  at Xamarin.Forms.Platform.iOS.PageRenderer.ViewDidAppear (System.Boolean animated) [0x0004d] in D:\\a\\1\\s\\Xamarin.Forms.Platform.iOS\\Renderers\\PageRenderer.cs:215\r\n  at at (wrapper managed-to-native) UIKit.UIApplication.UIApplicationMain(int,string[],intptr,intptr)\r\n  at UIKit.UIApplication.Main (System.String[] args, System.Type principalClass, System.Type delegateClass) [0x00047] in /Users/builder/azdo/_work/1/s/xamarin-macios/src/UIKit/UIApplication.cs:79\r\n  at XamarinApp.iOS.Application.Main (System.String[] args) [0x00001] in /Users/jjaehrig/repo/foobar_ml/src/XamarinApp/XamarinApp.iOS/Main.cs:17\r\n```\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS 15\r\n- ONNX Runtime installed from (source or binary): 1.10\r\n- ONNX Runtime version: 1.10\r\n- Python version: n/a\r\n- Visual Studio version (if applicable): VS Mac 8.10.15\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**To Reproduce**\r\n- create a bare minimal engine, run it -> crash\r\n- i can't provide our onnx because of intellectual property, but i can try to create a similar one.\r\n- but essentially its this:\r\n```\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.Diagnostics;\r\nusing System.Numerics;\r\n\r\nnamespace FooLib\r\n{\r\n    public static class FooAlgorithm\r\n    {\r\n        public static Vector3 Predict(string onnxPath, float[] inputData)\r\n        {\r\n            if (inputData.Length != FooInput.InputLength) throw new ArgumentException($\"array must be of length {FooInput.InputLength}\");\r\n\r\n            var mlContext = new MLContext();\r\n\r\n            var onnxPredictionPipeline = GetPredictionPipeline(mlContext, onnxPath);\r\n            var onnxPredictionEngine = mlContext.Model.CreatePredictionEngine<FooInput, FooOutput>(onnxPredictionPipeline);\r\n\r\n\r\n            var input = new FooInput()\r\n            {\r\n                sequenceinput = inputData,\r\n            };\r\n\r\n            var prediction = onnxPredictionEngine.Predict(input);\r\n\r\n            var sm = prediction.softmax;\r\n            Debug.WriteLine($\"Prediction: {sm[0]}; {sm[1]}; {sm[2]}\");\r\n            return new Vector3(sm[0], sm[1], sm[2]);\r\n        }\r\n\r\n        private static ITransformer GetPredictionPipeline(MLContext mlContext, string onnxPath)\r\n        {\r\n            var inputColumns = new string[]\r\n            {\r\n                \"sequenceinput\"\r\n            };\r\n\r\n            var outputColumns = new string[] { \"softmax\" };\r\n\r\n            var onnxPredictionPipeline =\r\n                mlContext\r\n                    .Transforms\r\n                    .ApplyOnnxModel(\r\n                        outputColumnNames: outputColumns,\r\n                        inputColumnNames: inputColumns,\r\n                        onnxPath);\r\n\r\n            var emptyDv = mlContext.Data.LoadFromEnumerable(new FooInput[] { });\r\n\r\n            return onnxPredictionPipeline.Fit(emptyDv);\r\n        }\r\n    }\r\n\r\n    class FooInput\r\n    {\r\n        public const int InputLength = 72;\r\n\r\n        private float[] _sequenceinput;\r\n\r\n        public FooInput()\r\n        {\r\n            sequenceinput = new float[InputLength];\r\n        }\r\n\r\n        [ColumnName(\"sequenceinput\"), VectorType(InputLength)]\r\n        public float[] sequenceinput\r\n        {\r\n            get => _sequenceinput;\r\n            set\r\n            {\r\n                if (value.Length != InputLength) throw new ArgumentException($\"array must be of length {InputLength}\");\r\n                _sequenceinput = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    class FooOutput\r\n    {\r\n        [ColumnName(\"softmax\"), VectorType(3)]\r\n        public float[] softmax { get; set; }\r\n    }\r\n}\r\n```\r\n**Expected behavior**\r\nno MissingMethodException \r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nTried to apply https://devblogs.microsoft.com/xamarin/machine-learning-in-xamarin-forms-with-onnx-runtime/ to our onnx scenario",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10049",
        "id": 1081390344,
        "node_id": "PR_kwDOCVq1mM4v6H5-",
        "number": 10049,
        "title": "Disable ROCm C++ BERT batch and performance tests",
        "user": {
            "login": "suffiank",
            "id": 4366369,
            "node_id": "MDQ6VXNlcjQzNjYzNjk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4366369?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suffiank",
            "html_url": "https://github.com/suffiank",
            "followers_url": "https://api.github.com/users/suffiank/followers",
            "following_url": "https://api.github.com/users/suffiank/following{/other_user}",
            "gists_url": "https://api.github.com/users/suffiank/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suffiank/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suffiank/subscriptions",
            "organizations_url": "https://api.github.com/users/suffiank/orgs",
            "repos_url": "https://api.github.com/users/suffiank/repos",
            "events_url": "https://api.github.com/users/suffiank/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suffiank/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T19:01:28Z",
        "updated_at": "2022-10-17T14:44:19Z",
        "closed_at": "2021-12-16T23:24:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10049",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10049",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10049.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10049.patch",
            "merged_at": null
        },
        "body": "Making CI pipeline flaky. Disable for now.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10050",
        "id": 1081514003,
        "node_id": "PR_kwDOCVq1mM4v6fDM",
        "number": 10050,
        "title": "fix aten view op",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-15T21:06:36Z",
        "updated_at": "2022-01-04T16:29:31Z",
        "closed_at": "2022-01-04T16:29:30Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10050",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10050",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10050.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10050.patch",
            "merged_at": "2022-01-04T16:29:30Z"
        },
        "body": "**Description**: The view operator in eager mode doesn't use the aten infer size correctly. actually we don't need to invoke that.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10051",
        "id": 1081540447,
        "node_id": "PR_kwDOCVq1mM4v6kqK",
        "number": 10051,
        "title": "Optimization Convolution op when using dnnl ep",
        "user": {
            "login": "georgen117",
            "id": 16688936,
            "node_id": "MDQ6VXNlcjE2Njg4OTM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16688936?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/georgen117",
            "html_url": "https://github.com/georgen117",
            "followers_url": "https://api.github.com/users/georgen117/followers",
            "following_url": "https://api.github.com/users/georgen117/following{/other_user}",
            "gists_url": "https://api.github.com/users/georgen117/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/georgen117/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/georgen117/subscriptions",
            "organizations_url": "https://api.github.com/users/georgen117/orgs",
            "repos_url": "https://api.github.com/users/georgen117/repos",
            "events_url": "https://api.github.com/users/georgen117/events{/privacy}",
            "received_events_url": "https://api.github.com/users/georgen117/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-12-15T21:42:50Z",
        "updated_at": "2021-12-16T04:28:35Z",
        "closed_at": "2021-12-16T04:28:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10051",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10051",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10051.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10051.patch",
            "merged_at": "2021-12-16T04:28:34Z"
        },
        "body": "**Description**: \r\nIf Group attr = 1 allow the OneDNN library to optimize the memory\r\nlayout for the device the Convolution operator is being run on.\r\n\r\nWithout this optimization, the default NCHW memory layout is used\r\non CPUs, the NCHW memory layout can result in a significant performance\r\ndecrease.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nUsing the default NCHW memory layout on CPU resulted in poor performance when running convolution models on CPU.\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10052",
        "id": 1081570197,
        "node_id": "PR_kwDOCVq1mM4v6q_D",
        "number": 10052,
        "title": "[QDQ] Add shared NodeUnit class",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T22:23:59Z",
        "updated_at": "2022-01-06T01:32:12Z",
        "closed_at": "2021-12-17T01:37:52Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10052",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10052",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10052.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10052.patch",
            "merged_at": "2021-12-17T01:37:52Z"
        },
        "body": "**Description**: Add NodeUnit class\r\n\r\n**Motivation and Context**\r\n- To avoid excessively large PR, the NNAPI QDQ integration is splitted into the following small tasks\r\n- [x] 1. Add shared NodeUnit class (this PR)\r\n- [ ] 2. Move NNAPI EP to use NodeUnit IODef for non-QDQ ops\r\n- [ ] 3. Add shared QDQ selectors\r\n- [ ] 4. Hookup NNAPI GetCapability/Compile with shared QDQ selectors\r\n- [ ] 5. Enable QDQ for ops with QLinear version (QLinear[Conv/Matmul/Pool/...])\r\n- [ ] 6. Enable QDQ for ops without QLinear Version\r\n\r\n- This is step 1 of the tasks, we add the shared NodeUnit and move NNAPI builder interface to take NodeUnit, the NNAPI builders still work as before, we have not yet converted the quantized input of some QLinear ops to quant_params, which will be covered in step 2 (there are some code (later removed from `onnxruntime/core/providers/shared/node_unit/node_unit.cc`) in this [commit](https://github.com/microsoft/onnxruntime/pull/10052/commits/ceb60bf8c762206deaf72d4602a5016580f213b6) of the PR)\r\n- The shared NodeUnit class will be shared between a single Node or a QDQ group, which will both be treated as a unit with necessary functions, the main difference between a Node interface and a NodeUnit interface is the IODef which embed the input with its quantization params (scale and ZP), which defines a consistent way to retrieve quantization information for input and output\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10055",
        "id": 1081613145,
        "node_id": "PR_kwDOCVq1mM4v60JS",
        "number": 10055,
        "title": "Abjindal/clean eager backend",
        "user": {
            "login": "ajindal1",
            "id": 32752809,
            "node_id": "MDQ6VXNlcjMyNzUyODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/32752809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajindal1",
            "html_url": "https://github.com/ajindal1",
            "followers_url": "https://api.github.com/users/ajindal1/followers",
            "following_url": "https://api.github.com/users/ajindal1/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajindal1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajindal1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajindal1/subscriptions",
            "organizations_url": "https://api.github.com/users/ajindal1/orgs",
            "repos_url": "https://api.github.com/users/ajindal1/repos",
            "events_url": "https://api.github.com/users/ajindal1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajindal1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T23:36:32Z",
        "updated_at": "2022-01-19T22:20:10Z",
        "closed_at": "2022-01-19T22:20:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10055",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10055",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10055.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10055.patch",
            "merged_at": "2022-01-19T22:20:10Z"
        },
        "body": "**Description**: Describe your changes.\r\nReleasing the backends manager for eager mode when python interpreter exit.\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10056",
        "id": 1081660365,
        "node_id": "PR_kwDOCVq1mM4v6-Kr",
        "number": 10056,
        "title": "Reduce ops for DNNL ep",
        "user": {
            "login": "georgen117",
            "id": 16688936,
            "node_id": "MDQ6VXNlcjE2Njg4OTM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16688936?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/georgen117",
            "html_url": "https://github.com/georgen117",
            "followers_url": "https://api.github.com/users/georgen117/followers",
            "following_url": "https://api.github.com/users/georgen117/following{/other_user}",
            "gists_url": "https://api.github.com/users/georgen117/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/georgen117/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/georgen117/subscriptions",
            "organizations_url": "https://api.github.com/users/georgen117/orgs",
            "repos_url": "https://api.github.com/users/georgen117/repos",
            "events_url": "https://api.github.com/users/georgen117/events{/privacy}",
            "received_events_url": "https://api.github.com/users/georgen117/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-12-16T01:03:07Z",
        "updated_at": "2021-12-16T15:31:17Z",
        "closed_at": "2021-12-16T15:31:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10056",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10056",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10056.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10056.patch",
            "merged_at": "2021-12-16T15:31:17Z"
        },
        "body": "**Description**: Describe your changes.\r\nThis adds all of the ONNX specified Reduce ops to the DNNL execution provider\r\nThe ops added are  ReduceL1, ReduceL2, ReduceLogSum, ReduceLogSumExp, ReduceMax, ReduceMin, ReduceProd, ReduceSum, ReduceSumSquare.\r\n\r\nThis is a modification of the already existing ReduceMean code.\r\n\r\nThe code can now handle the keepdims attribute. Previous code  would only accept ReduceMean if the keepdims == 1.\r\n\r\nCommit also contains a documentation fix for the recently commtied DNNL QAttention op. The in code documentaiton, some how had a bunch of new lines added that made reading more difficult.  The extra newlines were cleaned up.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nThis change expands the model coverage of the DNNL execution provider. By adding all the Reduction Operators.\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10057",
        "id": 1081743889,
        "node_id": "PR_kwDOCVq1mM4v7PKY",
        "number": 10057,
        "title": "Revert a bad change in bfc_arena.cc",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T03:59:35Z",
        "updated_at": "2021-12-16T07:38:47Z",
        "closed_at": "2021-12-16T07:38:46Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10057",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10057",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10057.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10057.patch",
            "merged_at": "2021-12-16T07:38:46Z"
        },
        "body": "**Description**: \r\n\r\nRevert a bad change in bfc_arena.cc which was introduced in #10033 by me. It is causing failures in AMD GPU pipeline.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10058",
        "id": 1082101141,
        "node_id": "I_kwDOCVq1mM5Af42V",
        "number": 10058,
        "title": "Unexpected numerical differences between batch and single row predictions",
        "user": {
            "login": "cbourjau",
            "id": 3288058,
            "node_id": "MDQ6VXNlcjMyODgwNTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3288058?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbourjau",
            "html_url": "https://github.com/cbourjau",
            "followers_url": "https://api.github.com/users/cbourjau/followers",
            "following_url": "https://api.github.com/users/cbourjau/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbourjau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbourjau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbourjau/subscriptions",
            "organizations_url": "https://api.github.com/users/cbourjau/orgs",
            "repos_url": "https://api.github.com/users/cbourjau/repos",
            "events_url": "https://api.github.com/users/cbourjau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbourjau/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-12-16T11:49:49Z",
        "updated_at": "2022-09-07T02:14:15Z",
        "closed_at": "2022-09-07T02:14:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n`onnxruntime` version `1.10.0` (Python bindings) produces slightly different results in batch mode with four or more rows than when performing single-row predictions for float32 input of the `Log` node. ~Other node types such as `Exp` do not exhibit this behavior.~ Turns out at least `Exp` is also affected. I updated the test case below. \r\n\r\n**Urgency**\r\nOur production use case requires reproducible predictions regardless if they were submitted as a single row (or batch of less then 4 rows) or within a larger batch. We are currently forced to fall back to single-row predictions which naturally causes a large performance hit.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux  5.4.0-1060-aws #63~18.04.1-Ubuntu SMP x86_64 x86_64 x86_64 GNU/Linux`\r\n- ONNX Runtime installed from (source or binary): binary from [conda-forge](https://github.com/conda-forge/onnxruntime-feedstock)\r\n- ONNX Runtime version: `1.10.0`\r\n- Python version: `3.9.7`\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**To Reproduce**\r\nThe following test case reproduces the issue reliably in the above described environment:\r\n```python\r\nfrom onnx import helper, checker, TensorProto, version\r\nimport onnxruntime as rt\r\nimport numpy as np\r\n\r\n\r\ndef test_minimal_log():\r\n    assert rt.__version__ == \"1.10.0\"\r\n    assert version.version == \"1.10.2\"  # ONNX version\r\n    node = helper.make_node(\"Log\", inputs=[\"input\"], outputs=[\"output\"])\r\n    inputs = [helper.make_tensor_value_info(\"input\", TensorProto.FLOAT, [None])]\r\n    outputs = [helper.make_tensor_value_info(\"output\", TensorProto.FLOAT, [None])]\r\n    g = helper.make_graph([node], \"log_batch_issue\", inputs, outputs)\r\n    model = helper.make_model(g)\r\n    checker.check_model(model, full_check=True)\r\n    sess = rt.InferenceSession(model.SerializeToString())\r\n    # Issue only occurs for certain values. For example, `42.42` works\r\n    # as expected.\r\n    input_vals = np.array([1.06023156] * 4, dtype=\"float32\")\r\n    first_row_batch = sess.run([\"output\"], {\"input\": input_vals})[0][0]\r\n    first_row_single = sess.run([\"output\"], {\"input\": input_vals[:1]})[0][0]\r\n    assert first_row_batch == first_row_single\r\n    \r\ndef test_minimal_exp():\r\n    assert rt.__version__ == \"1.10.0\"\r\n    assert version.version == \"1.10.2\"\r\n    node = helper.make_node(\"Exp\", inputs=[\"input\"], outputs=[\"output\"])\r\n    inputs = [helper.make_tensor_value_info(\"input\", TensorProto.DOUBLE, [None])]\r\n    outputs = [helper.make_tensor_value_info(\"output\", TensorProto.DOUBLE, [None])]\r\n    g = helper.make_graph([node], \"log_batch_issue\", inputs, outputs)\r\n    model = helper.make_model(g)\r\n    checker.check_model(model, full_check=True)\r\n    sess = rt.InferenceSession(model.SerializeToString())\r\n    # Issue only occurs for certain values. For example, `42.42` works\r\n    # as expected.\r\n    input_vals = np.array([-0.26606467366] * 4, dtype=\"float64\")  # For Exp\r\n    first_row_batch = sess.run([\"output\"], {\"input\": input_vals})[0][0]\r\n    first_row_single = sess.run([\"output\"], {\"input\": input_vals[:1]})[0][0]\r\n    assert first_row_batch == first_row_single\r\n```\r\n\r\n**Expected behavior**\r\nI expect the results of each row to be independent of the batch size in which they were submitted. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10059",
        "id": 1082287984,
        "node_id": "PR_kwDOCVq1mM4v9BvD",
        "number": 10059,
        "title": "[DOC] add STVM EP docs",
        "user": {
            "login": "vvchernov",
            "id": 28704584,
            "node_id": "MDQ6VXNlcjI4NzA0NTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/28704584?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vvchernov",
            "html_url": "https://github.com/vvchernov",
            "followers_url": "https://api.github.com/users/vvchernov/followers",
            "following_url": "https://api.github.com/users/vvchernov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vvchernov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vvchernov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vvchernov/subscriptions",
            "organizations_url": "https://api.github.com/users/vvchernov/orgs",
            "repos_url": "https://api.github.com/users/vvchernov/repos",
            "events_url": "https://api.github.com/users/vvchernov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vvchernov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T14:52:17Z",
        "updated_at": "2021-12-16T22:59:44Z",
        "closed_at": "2021-12-16T22:59:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10059",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10059",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10059.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10059.patch",
            "merged_at": "2021-12-16T22:59:44Z"
        },
        "body": "Add docs for new execution provider: Standalone TVM (STVM) EP\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10060",
        "id": 1082607404,
        "node_id": "PR_kwDOCVq1mM4v-GKA",
        "number": 10060,
        "title": "Convert com.microsoft::ATen into org.pytorch.aten::ATen onnx op",
        "user": {
            "login": "thiagocrepaldi",
            "id": 5469809,
            "node_id": "MDQ6VXNlcjU0Njk4MDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5469809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thiagocrepaldi",
            "html_url": "https://github.com/thiagocrepaldi",
            "followers_url": "https://api.github.com/users/thiagocrepaldi/followers",
            "following_url": "https://api.github.com/users/thiagocrepaldi/following{/other_user}",
            "gists_url": "https://api.github.com/users/thiagocrepaldi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thiagocrepaldi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thiagocrepaldi/subscriptions",
            "organizations_url": "https://api.github.com/users/thiagocrepaldi/orgs",
            "repos_url": "https://api.github.com/users/thiagocrepaldi/repos",
            "events_url": "https://api.github.com/users/thiagocrepaldi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thiagocrepaldi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 13,
        "created_at": "2021-12-16T20:16:13Z",
        "updated_at": "2022-03-10T18:18:23Z",
        "closed_at": "2022-02-28T19:14:46Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10060",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10060",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10060.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10060.patch",
            "merged_at": "2022-02-28T19:14:46Z"
        },
        "body": "Pytorch ONNX exporter now emits org.pytorch.aten::ATen nodes with operator_name and overload_name attribute\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10061",
        "id": 1082645715,
        "node_id": "PR_kwDOCVq1mM4v-OPo",
        "number": 10061,
        "title": "Add citation file",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T21:11:17Z",
        "updated_at": "2021-12-17T03:56:23Z",
        "closed_at": "2021-12-17T03:56:22Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10061",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10061",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10061.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10061.patch",
            "merged_at": "2021-12-17T03:56:22Z"
        },
        "body": "Add citation file to repo\r\n\r\nRef: https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10062",
        "id": 1082734320,
        "node_id": "PR_kwDOCVq1mM4v-g_B",
        "number": 10062,
        "title": "adding definition of concat operator for mapping it to onnx",
        "user": {
            "login": "ajindal1",
            "id": 32752809,
            "node_id": "MDQ6VXNlcjMyNzUyODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/32752809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajindal1",
            "html_url": "https://github.com/ajindal1",
            "followers_url": "https://api.github.com/users/ajindal1/followers",
            "following_url": "https://api.github.com/users/ajindal1/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajindal1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajindal1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajindal1/subscriptions",
            "organizations_url": "https://api.github.com/users/ajindal1/orgs",
            "repos_url": "https://api.github.com/users/ajindal1/repos",
            "events_url": "https://api.github.com/users/ajindal1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajindal1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T23:38:22Z",
        "updated_at": "2022-01-06T22:56:37Z",
        "closed_at": "2022-01-06T22:56:36Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10062",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10062",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10062.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10062.patch",
            "merged_at": "2022-01-06T22:56:36Z"
        },
        "body": "**Description**: Describe your changes.\r\nImplementing concat operator mapping to onnx, and defined required create ort value funciton. Unable to use the opgen script output because the TensorList is passed, which does have device and other options as generated by the opgen script.\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10063",
        "id": 1082742406,
        "node_id": "I_kwDOCVq1mM5AiVaG",
        "number": 10063,
        "title": "Linking custom library to onnxruntime fails on Linux",
        "user": {
            "login": "bkaruman",
            "id": 65257187,
            "node_id": "MDQ6VXNlcjY1MjU3MTg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/65257187?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bkaruman",
            "html_url": "https://github.com/bkaruman",
            "followers_url": "https://api.github.com/users/bkaruman/followers",
            "following_url": "https://api.github.com/users/bkaruman/following{/other_user}",
            "gists_url": "https://api.github.com/users/bkaruman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bkaruman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bkaruman/subscriptions",
            "organizations_url": "https://api.github.com/users/bkaruman/orgs",
            "repos_url": "https://api.github.com/users/bkaruman/repos",
            "events_url": "https://api.github.com/users/bkaruman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bkaruman/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-16T23:57:51Z",
        "updated_at": "2022-04-17T09:54:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHello, I am trying to link a .so file  to onnxruntime for profiling experiments on Linux and observed that build fails. Not sure if I am doing it right.\r\n\r\n**Urgency**\r\nThis is blocking our efforts to run profiling experiments on ONNX RT.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version:v1.10.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\nI have modified the CMakeLists.txt to include paths \r\nif (NOT WIN32)\r\n  set(MYAPP_INCLUDE_DIR \"/home/path/to/app/include\")\r\n  set(MYAPP_LIB \"/home/path/to/app/lib64/runtime\")\r\n  include_directories(${MYAPP_INCLUDE_DIR})\r\n  list(APPEND onnxruntime_EXTERNAL_LIBRARIES ${MYAPP_LIB}/myapp.so)\r\nendif() \r\n\r\n\r\nCan someone share guidelines on modifying cmake to link custom libraries?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10064",
        "id": 1082743107,
        "node_id": "PR_kwDOCVq1mM4v-iz-",
        "number": 10064,
        "title": "Add STVM to website installation matrix",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-16T23:59:39Z",
        "updated_at": "2021-12-17T00:35:08Z",
        "closed_at": "2021-12-17T00:35:08Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10064",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10064",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10064.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10064.patch",
            "merged_at": "2021-12-17T00:35:08Z"
        },
        "body": "Staged here: https://natke.github.io/onnxruntime/\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10067",
        "id": 1082854420,
        "node_id": "PR_kwDOCVq1mM4v-5fW",
        "number": 10067,
        "title": "add int8_t for Resize",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T03:44:15Z",
        "updated_at": "2021-12-17T23:36:10Z",
        "closed_at": "2021-12-17T23:36:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10067",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10067",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10067.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10067.patch",
            "merged_at": "2021-12-17T23:36:09Z"
        },
        "body": "As we support quantization for format s8s8, we need Resize to support int8_t.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10068",
        "id": 1082932882,
        "node_id": "I_kwDOCVq1mM5AjD6S",
        "number": 10068,
        "title": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ArgMax_1094:ArgMax(11)",
        "user": {
            "login": "dengfenglai321",
            "id": 50360389,
            "node_id": "MDQ6VXNlcjUwMzYwMzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/50360389?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dengfenglai321",
            "html_url": "https://github.com/dengfenglai321",
            "followers_url": "https://api.github.com/users/dengfenglai321/followers",
            "following_url": "https://api.github.com/users/dengfenglai321/following{/other_user}",
            "gists_url": "https://api.github.com/users/dengfenglai321/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dengfenglai321/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dengfenglai321/subscriptions",
            "organizations_url": "https://api.github.com/users/dengfenglai321/orgs",
            "repos_url": "https://api.github.com/users/dengfenglai321/repos",
            "events_url": "https://api.github.com/users/dengfenglai321/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dengfenglai321/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-17T06:32:05Z",
        "updated_at": "2021-12-23T09:15:18Z",
        "closed_at": "2021-12-23T09:15:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\nhi i run\r\n`onnx_session1 = onnxruntime.InferenceSession(\"./pretrained/textmodel.onnx\")`\r\nand generate error as below:\r\n\r\n**File \"D:\\anaconda3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 312, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ArgMax_1094:ArgMax(11)**\r\n\r\nONNX - 1.7.0\r\nonnxruntime - 1.7.0\r\n\r\n\r\ncould you help me to solve this problem?\r\n\r\nand the onnx model i transfered here\r\n\r\n\r\n![企业微信截图_16397227177148](https://user-images.githubusercontent.com/50360389/146499754-a24ac96f-cd16-41ce-9006-5cf1030adc37.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10069",
        "id": 1082937340,
        "node_id": "I_kwDOCVq1mM5AjE_8",
        "number": 10069,
        "title": "GRU runtime error. ",
        "user": {
            "login": "bigbigzxl",
            "id": 25808190,
            "node_id": "MDQ6VXNlcjI1ODA4MTkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/25808190?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bigbigzxl",
            "html_url": "https://github.com/bigbigzxl",
            "followers_url": "https://api.github.com/users/bigbigzxl/followers",
            "following_url": "https://api.github.com/users/bigbigzxl/following{/other_user}",
            "gists_url": "https://api.github.com/users/bigbigzxl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bigbigzxl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bigbigzxl/subscriptions",
            "organizations_url": "https://api.github.com/users/bigbigzxl/orgs",
            "repos_url": "https://api.github.com/users/bigbigzxl/repos",
            "events_url": "https://api.github.com/users/bigbigzxl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bigbigzxl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-17T06:41:02Z",
        "updated_at": "2022-04-17T09:54:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nin GRU case，with the same parameters and inputs, the output of ONNX is inconstant with Tensorflow.\r\n\r\n**Urgency**\r\n none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04) ：  (Red Hat 4.8.5-16)] on linux\r\n- ONNX Runtime installed from (source or binary):  binary\r\n- ONNX Runtime version: onnx.__version__='1.6.0'\r\n- Python version: python3.65\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): GCC 4.8.5 20150623\r\n- CUDA/cuDNN version:  \r\n                                        torch.__version__： - 1.7.1+cu101\r\n                                        torch.version.cuda：10.2\r\n                                        torch.backends.cudnn.version()：7603\r\n\r\n- GPU model and memory: Tesla V100， 64GB\r\n\r\n**To Reproduce**\r\njust single gru case.\r\n\r\n**Expected behavior**\r\nthe output of onnx is equal with the output of tensorflow.\r\n\r\n**Screenshots**\r\n\r\n![image](https://user-images.githubusercontent.com/25808190/146499217-25902f3e-0d69-47e1-8e92-1e2fa92334bd.png)\r\n\r\n\r\n![tf output](https://user-images.githubusercontent.com/25808190/146498805-faf47d8d-e211-4645-bc7d-c6e5778d40ae.png)\r\n\r\n![onnx runtime output](https://user-images.githubusercontent.com/25808190/146498784-7cdb6e53-3293-4b20-aa79-8c984baa61de.png)\r\n**Additional context**\r\nGRU params:\r\nBatch = 3\r\ntime step: T = 28\r\noutput size: H = 5\r\ninput size: X = 10\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10070",
        "id": 1083039474,
        "node_id": "I_kwDOCVq1mM5Ajd7y",
        "number": 10070,
        "title": "How to use ep TensorrtExecutionProvider_fp16",
        "user": {
            "login": "QuantumLiu",
            "id": 21980268,
            "node_id": "MDQ6VXNlcjIxOTgwMjY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21980268?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/QuantumLiu",
            "html_url": "https://github.com/QuantumLiu",
            "followers_url": "https://api.github.com/users/QuantumLiu/followers",
            "following_url": "https://api.github.com/users/QuantumLiu/following{/other_user}",
            "gists_url": "https://api.github.com/users/QuantumLiu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/QuantumLiu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/QuantumLiu/subscriptions",
            "organizations_url": "https://api.github.com/users/QuantumLiu/orgs",
            "repos_url": "https://api.github.com/users/QuantumLiu/repos",
            "events_url": "https://api.github.com/users/QuantumLiu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/QuantumLiu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T09:10:56Z",
        "updated_at": "2021-12-18T04:24:28Z",
        "closed_at": "2021-12-18T04:24:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI' m using `TensorrtExecutionProvider `which build by command:\r\n`./build.sh --cudnn_home \"/usr/local/cuda\" --cuda_home \"/usr/local/cuda\" --use_tensorrt --tensorrt_home \"/home/tianqing/Downloads/TensorRT-7.2.3.4\" --skip_submodule_sync --build_wheel --parallel --skip_tests --use_openvino --config Release`\r\nIt use `TensorrtExecutionProvider ` perfectly, but I can't using TensorrtExecutionProvider_fp16.  \r\nI tried to build and run with \r\n`export ORT_TENSORRT_FP16_ENABLE=1\r\n`\r\nhttps://github.com/microsoft/onnxruntime/issues/2967\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n```\r\n# packages in environment at /home/tianqing/anaconda3/envs/infer:\r\n#\r\n# Name                    Version                   Build  Channel\r\nonnx                      1.10.1                   pypi_0    pypi\r\nonnx-simplifier           0.3.6                    pypi_0    pypi\r\nonnx2keras                0.0.24                   pypi_0    pypi\r\nonnxconverter-common      1.8.1                    pypi_0    pypi\r\nonnxmltools               1.10.0                   pypi_0    pypi\r\nonnxoptimizer             0.2.6                    pypi_0    pypi\r\nonnxruntime-gpu-tensorrt  1.8.1                    pypi_0    pypi\r\nskl2onnx                  1.10.0                   pypi_0    pypi\r\n```\r\n**Describe the solution you'd like**\r\nAn option to build TensorrtExecutionProvider_fp16 ep.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\n`session.get_providers()\r\n`\r\ngot:\r\n`['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'OpenVINOExecutionProvider', 'CPUExecutionProvider']`",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10071",
        "id": 1083099446,
        "node_id": "I_kwDOCVq1mM5Ajsk2",
        "number": 10071,
        "title": "how to forward with a batch images, oncetime?",
        "user": {
            "login": "xinsuinizhuan",
            "id": 40679769,
            "node_id": "MDQ6VXNlcjQwNjc5NzY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/40679769?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinsuinizhuan",
            "html_url": "https://github.com/xinsuinizhuan",
            "followers_url": "https://api.github.com/users/xinsuinizhuan/followers",
            "following_url": "https://api.github.com/users/xinsuinizhuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinsuinizhuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinsuinizhuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinsuinizhuan/subscriptions",
            "organizations_url": "https://api.github.com/users/xinsuinizhuan/orgs",
            "repos_url": "https://api.github.com/users/xinsuinizhuan/repos",
            "events_url": "https://api.github.com/users/xinsuinizhuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinsuinizhuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T10:15:33Z",
        "updated_at": "2021-12-19T02:55:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I want to foward with multi images once time with yolov5, to to do?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10074",
        "id": 1083254139,
        "node_id": "I_kwDOCVq1mM5AkSV7",
        "number": 10074,
        "title": "when my models input size is 3808, then i forward with yolov5, the memry is break.",
        "user": {
            "login": "xinsuinizhuan",
            "id": 40679769,
            "node_id": "MDQ6VXNlcjQwNjc5NzY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/40679769?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinsuinizhuan",
            "html_url": "https://github.com/xinsuinizhuan",
            "followers_url": "https://api.github.com/users/xinsuinizhuan/followers",
            "following_url": "https://api.github.com/users/xinsuinizhuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinsuinizhuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinsuinizhuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinsuinizhuan/subscriptions",
            "organizations_url": "https://api.github.com/users/xinsuinizhuan/orgs",
            "repos_url": "https://api.github.com/users/xinsuinizhuan/repos",
            "events_url": "https://api.github.com/users/xinsuinizhuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinsuinizhuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            },
            {
                "id": 2233102485,
                "node_id": "MDU6TGFiZWwyMjMzMTAyNDg1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:windows",
                "name": "platform:windows",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to the Windows platform"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T13:20:04Z",
        "updated_at": "2021-12-19T02:58:47Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\n**System information**\r\n- OS Platform and Distribution: win10\r\n- ONNX Runtime installed from (source or binary):binary\r\n- ONNX Runtime version:1.10\r\n- Python version:\r\n- Visual Studio version (if applicable):vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 2060\r\n- GPU model and memory:\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C9670 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeException，位于内存位置 0x000000B2687C95C0 处。\r\n0x00007FFBEB5F4F69 处(位于 ewb_single.exe 中)引发的异常: Microsoft C++ 异常: onnxruntime::OnnxRuntimeExceptio\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10075",
        "id": 1083342392,
        "node_id": "I_kwDOCVq1mM5Akn44",
        "number": 10075,
        "title": "Model local functions not recognized by onnxruntime",
        "user": {
            "login": "jantonguirao",
            "id": 3891217,
            "node_id": "MDQ6VXNlcjM4OTEyMTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3891217?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jantonguirao",
            "html_url": "https://github.com/jantonguirao",
            "followers_url": "https://api.github.com/users/jantonguirao/followers",
            "following_url": "https://api.github.com/users/jantonguirao/following{/other_user}",
            "gists_url": "https://api.github.com/users/jantonguirao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jantonguirao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jantonguirao/subscriptions",
            "organizations_url": "https://api.github.com/users/jantonguirao/orgs",
            "repos_url": "https://api.github.com/users/jantonguirao/repos",
            "events_url": "https://api.github.com/users/jantonguirao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jantonguirao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T14:59:49Z",
        "updated_at": "2022-01-11T16:18:16Z",
        "closed_at": "2022-01-11T16:18:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nModel local functions seem to be not recognized by onnxruntime. Attempting to use a model that uses a model local function (copy-pasted from ONNX's function_verify_test.cc) results in an error: `foo is not a registered function/op`\r\n\r\n**Urgency**\r\nThis slows down the progress of the experiments regarding the ONNX preprocessing working group.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.3 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**To Reproduce**\r\n```\r\nimport onnx\r\nimport onnxruntime\r\nimport numpy as np\r\nfrom onnx import parser\r\nm = parser.parse_model(\r\n'''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 13, \"custom_domain\" : 1],\r\n  producer_name: \"FunctionProtoTest\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"A test model for model local functions.\"\r\n>\r\nagraph (float[N] x) => (float[N] w)\r\n{\r\n    y = custom_domain.foo(x)\r\n    w = Identity(y)\r\n}\r\n\r\n<\r\n  domain: \"custom_domain\",\r\n  opset_import: [ \"\" : 13],\r\n  doc_string: \"Test function proto\"\r\n>\r\nfoo (x) => (y) {\r\n      Q_Min = Constant <value = float[1] {0.0}> ()\r\n      Q_Max = Constant <value = float[1] {255.0}> ()\r\n      X_Min = ReduceMin <keepdims = 0> (x)\r\n      X_Max = ReduceMax <keepdims = 0> (x)\r\n      X_Range = Sub (X_Max, X_Min)\r\n      Scale = Div (X_Range, Q_Max)\r\n      ZeroPoint_FP = Sub (Q_Min, Scale)\r\n      Zeropoint = Cast <to = 2> (ZeroPoint_FP)\r\n      y = QuantizeLinear (x, Scale, Zeropoint)\r\n}\r\n'''\r\n)\r\n\r\nonnx.save(m, \"test.onnx\")\r\nsession = onnxruntime.InferenceSession(\"test.onnx\", None)\r\nresult = session.run([], {'x' : np.array([1, 2, 3])})\r\n```\r\nresults in \r\n```\r\nFail: [ONNXRuntimeError] : 1 : FAIL : Load model from test.onnx failed:Fatal error: foo is not a registered function/op\r\n```\r\n\r\n**Expected behavior**\r\nsession.run executes, including the local function.\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nN/A",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10076",
        "id": 1083440205,
        "node_id": "PR_kwDOCVq1mM4wA1Nu",
        "number": 10076,
        "title": "Fix Microsoft.AI.MachineLearning NuGet App failure with multiple binaries copied to same destination",
        "user": {
            "login": "smk2007",
            "id": 6754002,
            "node_id": "MDQ6VXNlcjY3NTQwMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6754002?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smk2007",
            "html_url": "https://github.com/smk2007",
            "followers_url": "https://api.github.com/users/smk2007/followers",
            "following_url": "https://api.github.com/users/smk2007/following{/other_user}",
            "gists_url": "https://api.github.com/users/smk2007/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smk2007/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smk2007/subscriptions",
            "organizations_url": "https://api.github.com/users/smk2007/orgs",
            "repos_url": "https://api.github.com/users/smk2007/repos",
            "events_url": "https://api.github.com/users/smk2007/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smk2007/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T16:48:10Z",
        "updated_at": "2021-12-21T20:34:04Z",
        "closed_at": "2021-12-21T20:34:04Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10076",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10076",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10076.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10076.patch",
            "merged_at": "2021-12-21T20:34:04Z"
        },
        "body": "Fix Microsoft.AI.MachineLearning NuGet App failure with multiple binaries copied to same destination\r\n\r\nIssue: This was regressed in 1.10 by changes that were beginning to remove references to the UWP built versions of the binaries. These are no longer needed. However, in this state the .NuGet package began to reference both the native and UWP versions concurrently. This is because the NuGet package will forcibly copy anything in the lib/uap10.0 folder in the UWP context, causing multiple binaries to be copied into the destination.\r\n\r\nFix: Completely remove the UWP built binaries from the package and add a build test to make sure that this does not happen again.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10077",
        "id": 1083484538,
        "node_id": "PR_kwDOCVq1mM4wA-dt",
        "number": 10077,
        "title": "add qdq support for LeakyRelu",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T17:47:47Z",
        "updated_at": "2022-01-03T22:48:50Z",
        "closed_at": "2022-01-03T22:48:50Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10077",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10077",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10077.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10077.patch",
            "merged_at": "2022-01-03T22:48:50Z"
        },
        "body": "1. add qdq fusion for LeakyRelu.\r\n2. support both int8 and uint8 for UnaryOperator.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10078",
        "id": 1083628706,
        "node_id": "PR_kwDOCVq1mM4wBdGn",
        "number": 10078,
        "title": "Check kMSDomain already exists before registering it",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T21:31:19Z",
        "updated_at": "2021-12-18T01:55:16Z",
        "closed_at": "2021-12-18T01:55:16Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10078",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10078",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10078.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10078.patch",
            "merged_at": "2021-12-18T01:55:16Z"
        },
        "body": "**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\n External execution providers may register custom ops into the `kMSDomain`, which may cause a redundant registration of `kMSDomain` during `Environment::Initialize` or `RegisterOrtOpSchemas` and thereby an [assertion failure](https://github.com/onnx/onnx/blob/c9f53d00932ab60e381a71789a85db0463a8d9e0/onnx/defs/schema.h#L982). \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10079",
        "id": 1083698366,
        "node_id": "I_kwDOCVq1mM5Al-y-",
        "number": 10079,
        "title": "[fp16] InstanceNorm generate totally wrong result on fp16",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-18T00:21:25Z",
        "updated_at": "2022-01-03T18:55:19Z",
        "closed_at": "2022-01-03T18:55:19Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi, I found InstanceNorm generates totally wrong result on fp16, while both fp32 model and partial fp16 model (i.e., InstanceNorm is fp32) generate correct result. See below: \r\n\r\n  | Fp32 model | Partial fp16 model | Full fp16 model\r\n-- | -- | -- | --\r\nResult | [[ 6.0549564 -3.183563  -2.8680713]    [   6.1917925 -3.354034  -2.8344436]    [   6.169338  -3.3007898 -2.8652153]    [   6.1567574 -3.3921351 -2.7612722]    [   6.079842  -3.1844094 -2.8921494]    [   6.04279   -3.3625133 -2.6769447]] | [[ 6.0546875 -3.1835938 -2.8671875]    [   6.1914062 -3.3535156 -2.8339844]    [   6.1679688 -3.3007812 -2.8632812]    [   6.15625   -3.390625  -2.7617188]    [   6.078125  -3.1835938 -2.890625 ]    [   6.0429688 -3.3613281 -2.6757812]] | **[[   3.953125  -1.5253906 -2.4238281]    [ 3.953125    -1.5253906 -2.4238281]    [ 3.953125    -1.5253906 -2.4238281]    [ 3.953125    -1.5253906 -2.4238281]    [ 3.953125    -1.5253906 -2.4238281]    [ 3.953125    -1.5253906 -2.4238281]]**\r\n\r\nCould you help check if there anything wrong for InstanceNorm on fp16? \r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.6\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 11.5, CuDNN 8.3.1\r\n- GPU model and memory: V100, 16GB\r\n\r\n**To Reproduce**\r\n- Test code: \r\n```python\r\nimport numpy as np\r\nimport onnxruntime as ort\r\n\r\nsess_options = ort.SessionOptions()\r\nsess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nsess_options.enable_mem_pattern=False\r\n\r\n#Full fp16 model\r\nsess = ort.InferenceSession(\"graph_opset12_optimized_fp16_keep_io_True_unblockInstanceNormalization.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\n#Partial fp16 model (every other ops are fp16 except InstanceNormalization)\r\n#sess = ort.InferenceSession(\"graph_opset12_optimized_fp16_keep_io_True.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\n#Full fp32 model\r\n#sess = ort.InferenceSession(\"graph_opset12_optimized.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\ninput_name = sess.get_inputs()[0].name\r\nlabel_name = sess.get_outputs()[0].name\r\n\r\n#warm-up run\r\nnp.random.seed(123)\r\nbatch_size=6\r\ninput = np.random.rand(batch_size, 3, 480, 480)*256\r\ninput = np.floor(input).astype(np.float32)\r\npred = sess.run([label_name], {input_name: input})[0]\r\nprint(pred)\r\n```\r\n\r\n- Test models:\r\n  Full fp16 model: https://drive.google.com/file/d/1lvoLHigqiWaB3eFPoStQ22L5Avh316h8/view?usp=sharing\r\n  Partial fp16 model: https://drive.google.com/file/d/1Z2lrFbQ61mqZOapz4GQUUINn4aFCgvRH/view?usp=sharing\r\n  Full fp32 model: https://drive.google.com/file/d/1LIFFxD8O39VITABQuH0H0Zx4kT3Wk-xd/view?usp=sharing\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10080",
        "id": 1083723150,
        "node_id": "PR_kwDOCVq1mM4wBwbP",
        "number": 10080,
        "title": "Coding style fix.",
        "user": {
            "login": "satyajandhyala",
            "id": 26722914,
            "node_id": "MDQ6VXNlcjI2NzIyOTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26722914?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/satyajandhyala",
            "html_url": "https://github.com/satyajandhyala",
            "followers_url": "https://api.github.com/users/satyajandhyala/followers",
            "following_url": "https://api.github.com/users/satyajandhyala/following{/other_user}",
            "gists_url": "https://api.github.com/users/satyajandhyala/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/satyajandhyala/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/satyajandhyala/subscriptions",
            "organizations_url": "https://api.github.com/users/satyajandhyala/orgs",
            "repos_url": "https://api.github.com/users/satyajandhyala/repos",
            "events_url": "https://api.github.com/users/satyajandhyala/events{/privacy}",
            "received_events_url": "https://api.github.com/users/satyajandhyala/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-18T02:13:57Z",
        "updated_at": "2021-12-18T20:05:49Z",
        "closed_at": "2021-12-18T20:05:49Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10080",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10080",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10080.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10080.patch",
            "merged_at": "2021-12-18T20:05:49Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10081",
        "id": 1083857872,
        "node_id": "I_kwDOCVq1mM5AmlvQ",
        "number": 10081,
        "title": "Do threading settings have any effect on GPU EPs",
        "user": {
            "login": "admayber",
            "id": 44822281,
            "node_id": "MDQ6VXNlcjQ0ODIyMjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/44822281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/admayber",
            "html_url": "https://github.com/admayber",
            "followers_url": "https://api.github.com/users/admayber/followers",
            "following_url": "https://api.github.com/users/admayber/following{/other_user}",
            "gists_url": "https://api.github.com/users/admayber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/admayber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/admayber/subscriptions",
            "organizations_url": "https://api.github.com/users/admayber/orgs",
            "repos_url": "https://api.github.com/users/admayber/repos",
            "events_url": "https://api.github.com/users/admayber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/admayber/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-18T15:43:25Z",
        "updated_at": "2022-04-17T09:54:10Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "I'm having trouble understanding the relationship between the ORT top-level thread settings - IntraOpNumThreads, InterOpNumThreads, ExecutionMode - and the GPU EPs (cuda and trt).\r\n\r\nI would normally assume those settings have no impact if running on GPU. However, they aren't attached as options on the CPU execution provider, they're top-level settings in the SessionOptions class in the cpp api, which implies to me that they're relevant regardless of EP (e.g., maybe they still have impact on the runtime orchestration when running cuda / trt). Is that true at all, or is it safe to ignore them if running in GPU?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10082",
        "id": 1084302042,
        "node_id": "I_kwDOCVq1mM5AoSLa",
        "number": 10082,
        "title": "how to use dynamic_quant to quantize an onnx model with custom op",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-20T03:01:53Z",
        "updated_at": "2021-12-21T01:57:26Z",
        "closed_at": "2021-12-21T01:57:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\nHi, I have a custom op, and i have register the op in onnxruntime.\r\nnow, I can use the api `opts.register_custom_ops_library(_lib_path(\"my_custom_op.so\"))` to load the .so file, and do inference on the model with this custom op.\r\nbut, when I try to quant the model with this custom op, I git an error:\r\n`onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from dfsmn_online.onnx failed:Fatal error: fsmn_forward is not a registered function/op`\r\nI am confused that how to add the build .so file to onnxruntime.quantization and quant the model\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n- 1.10.0\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\nquant the model with custom op \r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10083",
        "id": 1084317840,
        "node_id": "I_kwDOCVq1mM5AoWCQ",
        "number": 10083,
        "title": "MaxPool shape inference is NOT matched with ONNX OP SPEC ",
        "user": {
            "login": "RunnerZhong",
            "id": 30307463,
            "node_id": "MDQ6VXNlcjMwMzA3NDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30307463?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RunnerZhong",
            "html_url": "https://github.com/RunnerZhong",
            "followers_url": "https://api.github.com/users/RunnerZhong/followers",
            "following_url": "https://api.github.com/users/RunnerZhong/following{/other_user}",
            "gists_url": "https://api.github.com/users/RunnerZhong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RunnerZhong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RunnerZhong/subscriptions",
            "organizations_url": "https://api.github.com/users/RunnerZhong/orgs",
            "repos_url": "https://api.github.com/users/RunnerZhong/repos",
            "events_url": "https://api.github.com/users/RunnerZhong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RunnerZhong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "snnn",
                "id": 856316,
                "node_id": "MDQ6VXNlcjg1NjMxNg==",
                "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/snnn",
                "html_url": "https://github.com/snnn",
                "followers_url": "https://api.github.com/users/snnn/followers",
                "following_url": "https://api.github.com/users/snnn/following{/other_user}",
                "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
                "organizations_url": "https://api.github.com/users/snnn/orgs",
                "repos_url": "https://api.github.com/users/snnn/repos",
                "events_url": "https://api.github.com/users/snnn/events{/privacy}",
                "received_events_url": "https://api.github.com/users/snnn/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-20T03:27:45Z",
        "updated_at": "2022-08-12T08:36:23Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nFrom ONNX OP spec，if I used auto_pad = Valid, the output shape is inferred as below:\r\n`VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\r\nSAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\r\n`\r\nAbove inference is not effected whether ceil_mode if set.\r\nBut from ONNXRUNTIME, I found the inference is different if ceil_mode is set or not.\r\n\r\n`int64_t ComputeOutputSize(int64_t in_size,\r\n                            int64_t stride,\r\n                            int64_t kernel,\r\n                            int64_t pad_needed,\r\n                            int64_t dilation) const {\r\n    if (ceil_mode == 0) {\r\n      return static_cast<int64_t>(static_cast<float>(in_size + pad_needed - dilation * (kernel - 1) - 1) / stride + 1);\r\n    }\r\n    return static_cast<int64_t>(\r\n        std::ceil(static_cast<float>(in_size + pad_needed - dilation * (kernel - 1) - 1) / stride + 1));\r\n  }`\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nClear And Matched behavior between ONNX op SPEC and ONNX Run Time\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10084",
        "id": 1084434667,
        "node_id": "PR_kwDOCVq1mM4wD78r",
        "number": 10084,
        "title": "aten add_ op supports bf16",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T07:05:44Z",
        "updated_at": "2022-01-05T17:33:29Z",
        "closed_at": "2022-01-05T17:33:29Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10084",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10084",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10084.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10084.patch",
            "merged_at": "2022-01-05T17:33:29Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\nUpdates the `aten::add_.Tensor` op to support `BFloat16` tensors.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\nThis is required to run bf16 models on the ORT eager device.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10085",
        "id": 1084490640,
        "node_id": "PR_kwDOCVq1mM4wEHhN",
        "number": 10085,
        "title": "CUDA BFloat16 Refactor",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T08:19:02Z",
        "updated_at": "2022-01-14T11:38:57Z",
        "closed_at": "2022-01-14T11:38:57Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10085",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10085",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10085.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10085.patch",
            "merged_at": "2022-01-14T11:38:57Z"
        },
        "body": "Previous code casted BFloat16 to CUDA's nv_bfloat16 type for calculation, which required A100 to run because nv_bfloat16's calculation can run on A100 only. PyTorch uses its own type c10::BFloat16 for calculation. This PR is to refactor our code to follow the same idea to use our own onnxruntime::BFloat16 for calculation. The general implemtation is to cast BFloat16 to float for calculation, and use nv_bfloat16 on A100 using macro __CUDA_ARCH__ >= 800.\r\n\r\nWith this implementation, we can support BFloat16 on most of the Nvidia devices besides A100.\r\n\r\nTested the code using ORTModule in two ways (need latest nightly PyTorch and ONNX for some BFloat16 support):\r\n- Add cast to torch.bfloat16 in the Module, this can run on both V100 and A100, and can get same calculation results\r\n- Use torch.autocast. PyTorch supports BFloat16 autocast on A100 only. I tested both PyTorch and ORT using torch.autocast on A100 to run the BERT model from transformers. We can get the same result (ignoring the margin of error), and ORT's perf is better than PyTorch (same as autocast of Float16).\r\n\r\nNote that PyTorch also uses its own type c10::Float16 type for float16 calculation in CUDA, but ORT casts to CUDA's half type. This is OK as half is supported by most of the Nvidia devices. This PR doesn't torch any logic related to the float16 case.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10086",
        "id": 1084567022,
        "node_id": "I_kwDOCVq1mM5ApS3u",
        "number": 10086,
        "title": "Same Pad_Head value in ORT for SAME_UPPER/SAME_LOWER if get negative odd pad value",
        "user": {
            "login": "RunnerZhong",
            "id": 30307463,
            "node_id": "MDQ6VXNlcjMwMzA3NDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30307463?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RunnerZhong",
            "html_url": "https://github.com/RunnerZhong",
            "followers_url": "https://api.github.com/users/RunnerZhong/followers",
            "following_url": "https://api.github.com/users/RunnerZhong/following{/other_user}",
            "gists_url": "https://api.github.com/users/RunnerZhong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RunnerZhong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RunnerZhong/subscriptions",
            "organizations_url": "https://api.github.com/users/RunnerZhong/orgs",
            "repos_url": "https://api.github.com/users/RunnerZhong/repos",
            "events_url": "https://api.github.com/users/RunnerZhong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RunnerZhong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-20T09:37:59Z",
        "updated_at": "2023-05-23T02:17:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nImplementation code in ORT is as below:\r\n![image](https://user-images.githubusercontent.com/30307463/146745972-dcaac56f-e653-4015-bd21-623ee6acf8d0.png)\r\n\r\nFor below case, Input_shape = [1,3,500, 224], kernel=[5, 6], stride=[10,2], auto_pad = same_upper/lower\r\nAccording to ONNX op SPEC,\r\n\r\n> SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\r\n\r\n> pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\r\n\r\nwe got pad_h_value = -5.\r\n\r\nSo, \r\n*pad_head = (pad_needed + 1) / 2;    # pad_head = -2\r\n  \r\n*pad_head = pad_needed / 2;   # pad_head = -2 too\r\n\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10087",
        "id": 1084864463,
        "node_id": "I_kwDOCVq1mM5AqbfP",
        "number": 10087,
        "title": "DecoderAttention kernel Shape Inference bug on dynamic axes",
        "user": {
            "login": "romain-keramitas-prl",
            "id": 91061498,
            "node_id": "MDQ6VXNlcjkxMDYxNDk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/91061498?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/romain-keramitas-prl",
            "html_url": "https://github.com/romain-keramitas-prl",
            "followers_url": "https://api.github.com/users/romain-keramitas-prl/followers",
            "following_url": "https://api.github.com/users/romain-keramitas-prl/following{/other_user}",
            "gists_url": "https://api.github.com/users/romain-keramitas-prl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/romain-keramitas-prl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/romain-keramitas-prl/subscriptions",
            "organizations_url": "https://api.github.com/users/romain-keramitas-prl/orgs",
            "repos_url": "https://api.github.com/users/romain-keramitas-prl/repos",
            "events_url": "https://api.github.com/users/romain-keramitas-prl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/romain-keramitas-prl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "wangyems",
                "id": 52801275,
                "node_id": "MDQ6VXNlcjUyODAxMjc1",
                "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wangyems",
                "html_url": "https://github.com/wangyems",
                "followers_url": "https://api.github.com/users/wangyems/followers",
                "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
                "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
                "organizations_url": "https://api.github.com/users/wangyems/orgs",
                "repos_url": "https://api.github.com/users/wangyems/repos",
                "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wangyems/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-20T14:37:01Z",
        "updated_at": "2021-12-21T23:10:09Z",
        "closed_at": "2021-12-21T23:10:09Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen specifying the past key and value in a `DecoderAttention` node, the shape inference fails if the batch size and sequence length are dynamic.\r\n\r\n\r\n**Urgency**\r\nDue to this bug the kernel is basically unusable, since you either must fix the batch size and sequence length, or not use the last key / value feature - which is the main feature of the kernel.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): binary (wheel)\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.9.9\r\n- Visual Studio version (if applicable): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: GeForce RTX 2060, 6GB\r\n\r\n**To Reproduce**\r\nI've created this GIST to exhibit the error\r\n-  [link](https://gist.github.com/rom1K/b9a1dbb313ce8cb1d53a188b170ed0cc)\r\n\r\n**Expected behavior**\r\nI expected dynamic shapes to be usable with the kernel, as is the case with the regular self-attention kernel.\r\n\r\n\r\n**Additional context**\r\nThe line raising the error is [here](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/graph/contrib_ops/contrib_defs.cc#L557). As we can see from this [line](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/graph/contrib_ops/contrib_defs.cc#L518) a bit above, which does the shape inference check for the older attention kernel, the check is done only on non-dynamic axis (number of heads and head size). \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/reactions",
            "total_count": 5,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10088",
        "id": 1085237751,
        "node_id": "PR_kwDOCVq1mM4wGjYM",
        "number": 10088,
        "title": "Generate native resources for all supported MacOS versions, not just 10.14",
        "user": {
            "login": "baronfel",
            "id": 573979,
            "node_id": "MDQ6VXNlcjU3Mzk3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/573979?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baronfel",
            "html_url": "https://github.com/baronfel",
            "followers_url": "https://api.github.com/users/baronfel/followers",
            "following_url": "https://api.github.com/users/baronfel/following{/other_user}",
            "gists_url": "https://api.github.com/users/baronfel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baronfel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baronfel/subscriptions",
            "organizations_url": "https://api.github.com/users/baronfel/orgs",
            "repos_url": "https://api.github.com/users/baronfel/repos",
            "events_url": "https://api.github.com/users/baronfel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baronfel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-20T21:58:24Z",
        "updated_at": "2022-01-07T22:00:08Z",
        "closed_at": "2022-01-07T21:42:49Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10088",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10088",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10088.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10088.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\n\r\nThis changes the generated path for MacOS assets in the nuget package from `runtimes/osx.10.14-<arch>` to `/runtimes/osx-<arch>`, which allows users on more versions of MacOS to use the library. This brings the library back to parity with the layout of 1.8.1. This should fix #9707.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n  - this change is required because the current package layout doesn't support as many MacOS versions as it used to. I'm unsure if this is by design or by accident. Without this change, MacOS consumers on versions other than 10.14 experience runtime errors instead of compile-time errors.\r\n- If it fixes an open issue, please link to the issue here.\r\n  - the fixed issue would be #9707.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/reactions",
            "total_count": 2,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10089",
        "id": 1085260324,
        "node_id": "I_kwDOCVq1mM5Ar8Ik",
        "number": 10089,
        "title": "Python bindings give RuntimeError on multi input models",
        "user": {
            "login": "thomasahle",
            "id": 946355,
            "node_id": "MDQ6VXNlcjk0NjM1NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/946355?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thomasahle",
            "html_url": "https://github.com/thomasahle",
            "followers_url": "https://api.github.com/users/thomasahle/followers",
            "following_url": "https://api.github.com/users/thomasahle/following{/other_user}",
            "gists_url": "https://api.github.com/users/thomasahle/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thomasahle/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thomasahle/subscriptions",
            "organizations_url": "https://api.github.com/users/thomasahle/orgs",
            "repos_url": "https://api.github.com/users/thomasahle/repos",
            "events_url": "https://api.github.com/users/thomasahle/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thomasahle/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-20T22:31:14Z",
        "updated_at": "2022-08-12T08:24:02Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nMy model takes two inputs\r\n\r\n    >>> print([o.name for o in ort_sess.get_inputs()])\r\n    ['priv', 'pub']\r\n\r\nWhen I run the model\r\n\r\n    >>> ort_sess.run(['value'], {'priv': priv, 'pub': pub})\r\n\r\nI get the stacktrace\r\n\r\n    File \"/Users/.../homebrew/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 192, in run\r\n        return self._sess.run(output_names, input_feed, run_options)\r\n    RuntimeError: Input must be a list of dictionaries or a single numpy array for input 'priv'.\r\n\r\nIt seems that the python bindings for onnxruntime doesn't support multi-input models?\r\n\r\nI also use the javascript bindings which work fine like this:\r\n\r\n       ... = await session.run({ priv: priv, pub: state });\r\n\r\n**Urgency**\r\nThis is completely blocking me from using my model in python.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Monterey 12.0.1\r\n- ONNX Runtime installed from (source or binary): homebrew\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.9",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10090",
        "id": 1085299965,
        "node_id": "PR_kwDOCVq1mM4wGwgg",
        "number": 10090,
        "title": "Fix DecoderAttention's shape inference when input cache has dynamic shape",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T23:48:19Z",
        "updated_at": "2021-12-21T05:19:30Z",
        "closed_at": "2021-12-21T05:19:29Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10090",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10090",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10090.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10090.patch",
            "merged_at": "2021-12-21T05:19:29Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\nhttps://github.com/microsoft/onnxruntime/issues/10087 \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10091",
        "id": 1085327713,
        "node_id": "PR_kwDOCVq1mM4wG2T1",
        "number": 10091,
        "title": "[website] Update customer quote section",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T00:48:58Z",
        "updated_at": "2022-01-03T21:42:47Z",
        "closed_at": "2022-01-03T21:42:43Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10091",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10091",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10091.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10091.patch",
            "merged_at": "2022-01-03T21:42:43Z"
        },
        "body": "Staged here for preview: https://faxu.github.io/onnxruntime/\r\n\r\nChanges:\r\n- update logo assets for sizing/spacing\r\n- update main page logo section to just icons\r\n- new page for quotes",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10092",
        "id": 1085333319,
        "node_id": "PR_kwDOCVq1mM4wG3dC",
        "number": 10092,
        "title": "Add build output directory to gitignore",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T01:02:34Z",
        "updated_at": "2021-12-30T19:27:35Z",
        "closed_at": "2021-12-30T19:27:35Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10092",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10092",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10092.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10092.patch",
            "merged_at": "2021-12-30T19:27:35Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10093",
        "id": 1085379904,
        "node_id": "PR_kwDOCVq1mM4wHAwb",
        "number": 10093,
        "title": "Update C/C++ API docs automation to create a PR (instead of push to publish branch)",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T02:48:16Z",
        "updated_at": "2022-01-08T00:16:47Z",
        "closed_at": "2022-01-08T00:16:47Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10093",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10093",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10093.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10093.patch",
            "merged_at": "2022-01-08T00:16:47Z"
        },
        "body": "See staged PR here: https://github.com/natke/onnxruntime/pull/15\r\n\r\nThis action creates a (or adds to an existing) PR to update the C/C++ API docs to the latest master. \r\n\r\nThe original action failed because it is trying to commit to a protected branch (https://github.com/microsoft/onnxruntime/actions/runs/1565902647)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10094",
        "id": 1085385095,
        "node_id": "I_kwDOCVq1mM5AsamH",
        "number": 10094,
        "title": "error: ‘nodiscard’ : onnxruntime DNNL/1DNN",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1630303001,
                "node_id": "MDU6TGFiZWwxNjMwMzAzMDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:oneDNN",
                "name": "ep:oneDNN",
                "color": "0052CC",
                "default": false,
                "description": "questions/issues related to DNNL EP"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T03:01:10Z",
        "updated_at": "2022-01-03T04:27:01Z",
        "closed_at": "2022-01-03T04:27:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhile trying to build onnxruntime for oneDNN for source using the command `./build.sh --enable_training --use_dnnl` , it throws the error.\r\n\r\n**System information**\r\n- OS Platform and Distribution : CentOS 7\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: N/A\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):N/A\r\n- GCC/Compiler version (if compiling from source): 9.2.0\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: No GPU\r\n\r\n**To Reproduce**\r\n- Clone the repo https://github.com/microsoft/onnxruntime\r\n- Run `./build.sh --enable_training --use_dnnl`\r\n\r\n\r\n**Console output**\r\n```\r\n > $ which gcc\r\n~/GCC-9.2.0/bin/gcc\r\n > $ which g++\r\n~/GCC-9.2.0/bin/g++\r\n > $ g++ --version\r\ng++ (GCC) 9.2.0\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n > $ ./build.sh --enable_training --use_dnnl\r\n2021-12-20 18:52:55,408 tools_python_utils [INFO] - flatbuffers module is not installed. parse_config will not be available\r\n2021-12-20 18:52:55,409 build [DEBUG] - Command line arguments:\r\n  --build_dir /home/nimmaturi.venkatadat/onnxruntime/build/Linux --enable_training --use_dnnl\r\n2021-12-20 18:52:55,416 build [DEBUG] - Defaulting to running update, build [and test for native builds].\r\n2021-12-20 18:52:55,416 build [INFO] - Build started\r\n2021-12-20 18:52:55,416 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  git submodule sync --recursive\r\nSynchronizing submodule url for 'cmake/external/SafeInt/safeint'\r\nSynchronizing submodule url for 'cmake/external/coremltools'\r\nSynchronizing submodule url for 'cmake/external/cub'\r\nSynchronizing submodule url for 'cmake/external/cxxopts'\r\nSynchronizing submodule url for 'cmake/external/date'\r\nSynchronizing submodule url for 'cmake/external/dlpack'\r\nSynchronizing submodule url for 'cmake/external/eigen'\r\nSynchronizing submodule url for 'cmake/external/emsdk'\r\nSynchronizing submodule url for 'cmake/external/flatbuffers'\r\nSynchronizing submodule url for 'cmake/external/googlebenchmark'\r\nSynchronizing submodule url for 'cmake/external/googletest'\r\nSynchronizing submodule url for 'cmake/external/json'\r\nSynchronizing submodule url for 'cmake/external/libprotobuf-mutator'\r\nSynchronizing submodule url for 'cmake/external/mimalloc'\r\nSynchronizing submodule url for 'cmake/external/mp11'\r\nSynchronizing submodule url for 'cmake/external/nsync'\r\nSynchronizing submodule url for 'cmake/external/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnxruntime-extensions'\r\nSynchronizing submodule url for 'cmake/external/protobuf'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/googletest'\r\nSynchronizing submodule url for 'cmake/external/pytorch_cpuinfo'\r\nSynchronizing submodule url for 'cmake/external/re2'\r\nSynchronizing submodule url for 'cmake/external/tensorboard'\r\nSynchronizing submodule url for 'cmake/external/tvm'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/HalideIR'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dlpack'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dmlc-core'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/rang'\r\nSynchronizing submodule url for 'cmake/external/tvm_update'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/cutlass'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/dlpack'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/dmlc-core'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/libbacktrace'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/rang'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/vta-hw'\r\nSynchronizing submodule url for 'cmake/external/wil'\r\nSynchronizing submodule url for 'server/external/spdlog'\r\n2021-12-20 18:52:57,413 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:52:57,414 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  git submodule update --init --recursive\r\n2021-12-20 18:53:00,243 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:53:00,243 build [INFO] - Generating CMake build tree\r\n2021-12-20 18:53:00,244 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug'\r\n  /usr/local/bin/cmake /home/nimmaturi.venkatadat/onnxruntime/cmake -Donnxruntime_RUN_ONNX_TESTS=OFF -Donnxruntime_BUILD_WINML_TESTS=ON -Donnxruntime_GENERATE_TEST_REPORTS=ON -DPython_EXECUTABLE=/home/nimmaturi.venkatadat/anaconda3/bin/python3 -DPYTHON_EXECUTABLE=/home/nimmaturi.venkatadat/anaconda3/bin/python3 -Donnxruntime_ROCM_VERSION= -Donnxruntime_USE_MIMALLOC=OFF -Donnxruntime_ENABLE_PYTHON=OFF -Donnxruntime_BUILD_CSHARP=OFF -Donnxruntime_BUILD_JAVA=OFF -Donnxruntime_BUILD_NODEJS=OFF -Donnxruntime_BUILD_OBJC=OFF -Donnxruntime_BUILD_SHARED_LIB=OFF -Donnxruntime_BUILD_APPLE_FRAMEWORK=OFF -Donnxruntime_USE_DNNL=ON -Donnxruntime_DNNL_GPU_RUNTIME= -Donnxruntime_DNNL_OPENCL_ROOT= -Donnxruntime_USE_NNAPI_BUILTIN=OFF -Donnxruntime_USE_RKNPU=OFF -Donnxruntime_USE_OPENMP=OFF -Donnxruntime_USE_TVM=OFF -Donnxruntime_USE_LLVM=OFF -Donnxruntime_ENABLE_MICROSOFT_INTERNAL=OFF -Donnxruntime_USE_VITISAI=OFF -Donnxruntime_USE_NUPHAR=OFF -Donnxruntime_USE_TENSORRT=OFF -Donnxruntime_TENSORRT_HOME= -Donnxruntime_USE_STVM=OFF -Donnxruntime_STVM_HOME=/home/nimmaturi.venkatadat/onnxruntime/cmake/external/tvm_update -Donnxruntime_USE_MIGRAPHX=OFF -Donnxruntime_MIGRAPHX_HOME= -Donnxruntime_CROSS_COMPILING=OFF -Donnxruntime_DISABLE_CONTRIB_OPS=OFF -Donnxruntime_DISABLE_ML_OPS=OFF -Donnxruntime_DISABLE_RTTI=OFF -Donnxruntime_DISABLE_EXCEPTIONS=OFF -Donnxruntime_MINIMAL_BUILD=OFF -Donnxruntime_EXTENDED_MINIMAL_BUILD=OFF -Donnxruntime_MINIMAL_BUILD_CUSTOM_OPS=OFF -Donnxruntime_REDUCED_OPS_BUILD=OFF -Donnxruntime_REDUCED_OP_TYPE_SUPPORT=OFF -Donnxruntime_ENABLE_LANGUAGE_INTEROP_OPS=OFF -Donnxruntime_USE_DML=OFF -Donnxruntime_USE_WINML=OFF -Donnxruntime_BUILD_MS_EXPERIMENTAL_OPS=OFF -Donnxruntime_USE_TELEMETRY=OFF -Donnxruntime_ENABLE_LTO=OFF -Donnxruntime_ENABLE_TRANSFORMERS_TOOL_TEST=OFF -Donnxruntime_USE_ACL=OFF -Donnxruntime_USE_ACL_1902=OFF -Donnxruntime_USE_ACL_1905=OFF -Donnxruntime_USE_ACL_1908=OFF -Donnxruntime_USE_ACL_2002=OFF -Donnxruntime_USE_ARMNN=OFF -Donnxruntime_ARMNN_RELU_USE_CPU=ON -Donnxruntime_ARMNN_BN_USE_CPU=ON -Donnxruntime_ENABLE_NVTX_PROFILE=OFF -Donnxruntime_ENABLE_TRAINING=ON -Donnxruntime_ENABLE_TRAINING_OPS=OFF -Donnxruntime_ENABLE_TRAINING_TORCH_INTEROP=OFF -Donnxruntime_ENABLE_CPU_FP16_OPS=ON -Donnxruntime_USE_NCCL=ON -Donnxruntime_BUILD_BENCHMARKS=OFF -Donnxruntime_USE_ROCM=OFF -Donnxruntime_ROCM_HOME= -DOnnxruntime_GCOV_COVERAGE=OFF -Donnxruntime_USE_MPI=ON -Donnxruntime_ENABLE_MEMORY_PROFILE=OFF -Donnxruntime_ENABLE_CUDA_LINE_NUMBER_INFO=OFF -Donnxruntime_BUILD_WEBASSEMBLY=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_SIMD=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_EXCEPTION_CATCHING=ON -Donnxruntime_ENABLE_WEBASSEMBLY_EXCEPTION_THROWING=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_THREADS=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_DEBUG_INFO=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_PROFILING=OFF -Donnxruntime_WEBASSEMBLY_MALLOC=dlmalloc -Donnxruntime_ENABLE_EAGER_MODE=OFF -Donnxruntime_ENABLE_EXTERNAL_CUSTOM_OP_SCHEMAS=OFF -Donnxruntime_NVCC_THREADS=1 -Donnxruntime_ENABLE_CUDA_PROFILING=OFF -Donnxruntime_DEV_MODE=ON -Donnxruntime_PYBIND_EXPORT_OPSCHEMA=OFF -Donnxruntime_ENABLE_MEMLEAK_CHECKER=ON -DCMAKE_BUILD_TYPE=Debug\r\nBuilding ONNX Runtime for x86_64\r\nUse gtest from submodule\r\n-- Found Python: /home/nimmaturi.venkatadat/anaconda3/bin/python3 (found version \"3.9.7\") found components: Interpreter\r\nUse protobuf from submodule\r\n--\r\n-- 3.16.0.0\r\n-- Using the single-header code from /home/nimmaturi.venkatadat/onnxruntime/cmake/external/json/single_include/\r\nNVCC_ERROR =\r\nNVCC_OUT = No such file or directory\r\n-- Found PythonInterp: /home/nimmaturi.venkatadat/anaconda3/bin/python3 (found version \"3.9.7\")\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\n--\r\n-- ******** Summary ********\r\n--   CMake version             : 3.22.1\r\n--   CMake command             : /usr/local/bin/cmake\r\n--   System                    : Linux\r\n--   C++ compiler              : /usr/bin/c++\r\n--   C++ compiler version      : 4.8.5\r\n--   CXX flags                 :  -ffunction-sections -fdata-sections -DCPUINFO_SUPPORTED -Wnon-virtual-dtor\r\n--   Build type                : Debug\r\n--   Compile definitions       : EIGEN_MPL2_ONLY;ENABLE_CPU_FP16_TRAINING_OPS;PLATFORM_POSIX;__STDC_FORMAT_MACROS\r\n--   CMAKE_PREFIX_PATH         :\r\n--   CMAKE_INSTALL_PREFIX      : /usr/local\r\n--   CMAKE_MODULE_PATH         : /home/nimmaturi.venkatadat/onnxruntime/cmake/external\r\n--\r\n--   ONNX version              : 1.10.1\r\n--   ONNX NAMESPACE            : onnx\r\n--   ONNX_USE_LITE_PROTO       : ON\r\n--   USE_PROTOBUF_SHARED_LIBS  : OFF\r\n--   Protobuf_USE_STATIC_LIBS  : ON\r\n--   ONNX_DISABLE_EXCEPTIONS   : OFF\r\n--   ONNX_WERROR               : OFF\r\n--   ONNX_BUILD_TESTS          : OFF\r\n--   ONNX_BUILD_BENCHMARKS     : OFF\r\n--   ONNXIFI_DUMMY_BACKEND     : OFF\r\n--   ONNXIFI_ENABLE_EXT        : OFF\r\n--\r\n--   Protobuf compiler         :\r\n--   Protobuf includes         :\r\n--   Protobuf libraries        :\r\n--   BUILD_ONNX_PYTHON         : OFF\r\n-- Found MPI_C: /home/nimmaturi.venkatadat/anaconda3/lib/libmpi.so (found version \"3.1\")\r\n-- Could NOT find MPI_CXX (missing: MPI_CXX_WORKS)\r\n-- Could NOT find MPI (missing: MPI_CXX_FOUND) (found version \"3.1\")\r\nCMake Warning at CMakeLists.txt:1723 (message):\r\n  MPI is not found.  Please define onnxruntime_MPI_HOME to specify the path\r\n  of MPI.  Otherwise, NCCL will be disabled.\r\n\r\n\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug\r\n2021-12-20 18:53:02,321 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:53:02,322 build [INFO] - Building targets for Debug configuration\r\n2021-12-20 18:53:02,322 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  /usr/local/bin/cmake --build /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug --config Debug\r\n[  0%] Performing update step for 'project_dnnl'\r\n[  0%] No patch step for 'project_dnnl'\r\n[  0%] Performing configure step for 'project_dnnl'\r\n-- DNNL_LIBRARY_NAME: dnnl\r\n-- Could NOT find Doxyrest (missing: DOXYREST_EXECUTABLE)\r\n-- Enabled workload: TRAINING\r\n-- Enabled primitives: ALL\r\n-- Primitive cache is enabled\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/src/project_dnnl-build\r\n[  1%] Performing build step for 'project_dnnl'\r\nConsolidate compiler generated dependencies of target dnnl_cpu_x64\r\n[ 59%] Built target dnnl_cpu_x64\r\nConsolidate compiler generated dependencies of target dnnl_common\r\n[ 72%] Built target dnnl_common\r\nConsolidate compiler generated dependencies of target dnnl_cpu\r\n[ 98%] Built target dnnl_cpu\r\n[100%] Built target dnnl\r\n[100%] Built target compat_libs\r\n[100%] Built target compat_libs.2\r\n[100%] Built target compat_libs.2.4\r\n[  1%] Performing install step for 'project_dnnl'\r\n[ 59%] Built target dnnl_cpu_x64\r\n[ 72%] Built target dnnl_common\r\n[ 98%] Built target dnnl_cpu\r\n[100%] Built target dnnl\r\n[100%] Built target compat_libs\r\n[100%] Built target compat_libs.2\r\n[100%] Built target compat_libs.2.4\r\nInstall the project...\r\n-- Install configuration: \"Debug\"\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_dnnl_programming_flow.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_programming_model.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_dnnl_object_snapshot.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/conf.py\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_padded_blk.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_singlescalar.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_training_inference_scope.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_img2.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_bf16_diagram.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/strides.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_depthwise_fusion.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_blk.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_diagram.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/unrolled_stack_rnn.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_multiscalar.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_overview_flow.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_img1.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_inference_scope.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/html\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so.2.4\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so.2\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_ocl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_ocl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool_iface.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_dnnl_mangling.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool_iface.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-config.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-config-version.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-targets.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-targets-debug.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so.2\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so.2.4\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/LICENSE\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/THIRD-PARTY-PROGRAMS\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/README\r\n[  1%] Completed 'project_dnnl'\r\n[  1%] Built target project_dnnl\r\nConsolidate compiler generated dependencies of target flatbuffers\r\n[  1%] Built target flatbuffers\r\nConsolidate compiler generated dependencies of target clog\r\n[  1%] Built target clog\r\nConsolidate compiler generated dependencies of target cpuinfo\r\n[  2%] Built target cpuinfo\r\nConsolidate compiler generated dependencies of target libprotobuf\r\n[  8%] Built target libprotobuf\r\nConsolidate compiler generated dependencies of target libprotoc\r\n[ 14%] Built target libprotoc\r\nConsolidate compiler generated dependencies of target protoc\r\n[ 14%] Built target protoc\r\n[ 14%] Running gen_proto.py on onnx/onnx.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_pb.py\r\n[ 14%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\n[ 14%] Built target gen_onnx_proto\r\n[ 14%] Running gen_proto.py on onnx/onnx-data.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx-data.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_data_pb.py\r\n[ 14%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\n[ 14%] Built target gen_onnx_data_proto\r\nConsolidate compiler generated dependencies of target libprotobuf-lite\r\n[ 16%] Built target libprotobuf-lite\r\n[ 16%] Running gen_proto.py on onnx/onnx-operators.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx-operators.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_operators_pb.py\r\n[ 16%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\n[ 16%] Built target gen_onnx_operators_proto\r\nConsolidate compiler generated dependencies of target onnx_proto\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-ml.pb.cc.o\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-operators-ml.pb.cc.o\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-data.pb.cc.o\r\n[ 16%] Linking CXX static library libonnx_proto.a\r\n[ 16%] Built target onnx_proto\r\n[ 16%] Building CXX object CMakeFiles/onnxruntime_common.dir/home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc.o\r\nIn file included from /home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/common.h:37:0,\r\n                 from /home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.h:6,\r\n                 from /home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc:22:\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h: In function ‘constexpr const char* onnxruntime::common::StatusCodeToString(onnxruntime::common::StatusCode)’:\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h:79:1: error: body of constexpr function ‘constexpr const char* onnxruntime::common::StatusCodeToString(onnxruntime::common::StatusCode)’ not a return-statement\r\n }\r\n ^\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h: At global scope:\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h:114:21: error: ‘nodiscard’ attribute directive ignored [-Werror=attributes]\r\n class [[nodiscard]] Status {\r\n                     ^\r\ncc1plus: all warnings being treated as errors\r\ngmake[2]: *** [CMakeFiles/onnxruntime_common.dir/home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc.o] Error 1\r\ngmake[1]: *** [CMakeFiles/onnxruntime_common.dir/all] Error 2\r\ngmake: *** [all] Error 2\r\nTraceback (most recent call last):\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 2391, in <module>\r\n    sys.exit(main())\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 2309, in main\r\n    build_targets(args, cmake_path, build_dir, configs, num_parallel_jobs, args.target)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 1192, in build_targets\r\n    run_subprocess(cmd_args, env=env)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 653, in run_subprocess\r\n    return run(*args, cwd=cwd, capture_stdout=capture_stdout, shell=shell, env=my_env)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/python/util/run.py\", line 42, in run\r\n    completed_process = subprocess.run(\r\n  File \"/home/nimmaturi.venkatadat/anaconda3/lib/python3.9/subprocess.py\", line 528, in run\r\n    raise CalledProcessError(retcode, process.args,\r\nsubprocess.CalledProcessError: Command '['/usr/local/bin/cmake', '--build', '/home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug', '--config', 'Debug']' returned non-zero exit status 2.\r\n\r\n> $\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10095",
        "id": 1085558755,
        "node_id": "I_kwDOCVq1mM5AtE_j",
        "number": 10095,
        "title": "Memory leak",
        "user": {
            "login": "se7enXF",
            "id": 33513042,
            "node_id": "MDQ6VXNlcjMzNTEzMDQy",
            "avatar_url": "https://avatars.githubusercontent.com/u/33513042?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/se7enXF",
            "html_url": "https://github.com/se7enXF",
            "followers_url": "https://api.github.com/users/se7enXF/followers",
            "following_url": "https://api.github.com/users/se7enXF/following{/other_user}",
            "gists_url": "https://api.github.com/users/se7enXF/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/se7enXF/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/se7enXF/subscriptions",
            "organizations_url": "https://api.github.com/users/se7enXF/orgs",
            "repos_url": "https://api.github.com/users/se7enXF/repos",
            "events_url": "https://api.github.com/users/se7enXF/events{/privacy}",
            "received_events_url": "https://api.github.com/users/se7enXF/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T08:19:39Z",
        "updated_at": "2021-12-24T06:29:15Z",
        "closed_at": "2021-12-24T06:29:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\nLoop to run session.run cause memory leak  \r\n```python\r\ninput_info = self.preprocess(img_rgb)\r\noutput_res = self.session.run([self.output_name], input_info)[0]\r\n# output_res = np.array([[2, 0.98, 0, 0, 400, 400]])\r\nouts = self.parse_det_results(output_res, threshold, max_det_results)\r\n```\r\ncode likes upper, commont 'np.array' line, run 'session.run' will get memory leak. uncomment 'np.array' line and comment\r\n'self.session.run' line  will process normal.  'self.session' is init at script start by 'onnxruntime.InferenceSession'. \r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary):pip install \r\n- ONNX Runtime version: gpu-1.10.0\r\n- Python version:python3.8\r\n- CUDA/cuDNN version:cuda11/cudnn8.0\r\n- GPU model and memory:Tesla T4 6G\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10096",
        "id": 1085638486,
        "node_id": "I_kwDOCVq1mM5AtYdW",
        "number": 10096,
        "title": "segmentation fault when get subgraph in tensorrt provider",
        "user": {
            "login": "RELOAD22",
            "id": 37140865,
            "node_id": "MDQ6VXNlcjM3MTQwODY1",
            "avatar_url": "https://avatars.githubusercontent.com/u/37140865?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RELOAD22",
            "html_url": "https://github.com/RELOAD22",
            "followers_url": "https://api.github.com/users/RELOAD22/followers",
            "following_url": "https://api.github.com/users/RELOAD22/following{/other_user}",
            "gists_url": "https://api.github.com/users/RELOAD22/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RELOAD22/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RELOAD22/subscriptions",
            "organizations_url": "https://api.github.com/users/RELOAD22/orgs",
            "repos_url": "https://api.github.com/users/RELOAD22/repos",
            "events_url": "https://api.github.com/users/RELOAD22/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RELOAD22/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T09:49:55Z",
        "updated_at": "2022-04-17T08:54:35Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nsegmentation fault when get subgraph in tensorrt provider. \r\nThis error occurs when i process a onnx model with multiple graphs. This model has a node called 'IF_312' which connects the other two graphs. \r\nNode 'IF_312': input(name: 436 type: boolean[1]), output(name: 437 type: float32[64,64])\r\nNode 'Add_299': output(name: 420 type: float32[1,64,64])\r\nThe following part of the code will have a bug when processing node 'Add_299':\r\nhttps://github.com/microsoft/onnxruntime/blob/7a1bdc2052bca1b4073229fee71123976731b866/onnxruntime/core/providers/tensorrt/tensorrt_execution_provider.cc#L748-L751\r\nAdd_299's output(420) is the input of the node in the subgraph connected by IF_312.    [torch-jit-export1 is then/else branch of Node 'IF_312'. torch-jit-export1 has Node 'Squeeze_313', which has input(name: 420).]\r\nWhen processing Node Add_299, one of it->GetNode() is IF_312.  it->GetDstArgIndex() is out of range, because Node 'IF_312' has no corresponding InputDefs. However, it->GetNode().ImplicitInputDefs() has the input def of 420.\r\n\r\nI use the following code to replace L751, and then this function can work(no error)\r\n`int inputdef_size = (int)((it->GetNode()).InputDefs().size());`\r\n`const auto& output = (it->GetDstArgIndex() < inputdef_size)?((it->GetNode()).InputDefs()[it->GetDstArgIndex()]) : (it->GetNode().ImplicitInputDefs()[it->GetDstArgIndex() - inputdef_size]);`\r\nhttps://github.com/microsoft/onnxruntime/blob/7a1bdc2052bca1b4073229fee71123976731b866/onnxruntime/core/providers/tensorrt/tensorrt_execution_provider.cc#L751\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n[model.onnx.zip](https://github.com/microsoft/onnxruntime/files/7751296/model.onnx.zip)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10097",
        "id": 1085768792,
        "node_id": "I_kwDOCVq1mM5At4RY",
        "number": 10097,
        "title": "Why it is not possible to `pickle` an `InferenceSession` object?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-21T12:12:46Z",
        "updated_at": "2022-08-24T15:43:23Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Why it is not possible to `pickle` an `InferenceSession` object?\r\nAs I understand, this is because it's a CPP binding. Why it is a challenge? What will make it possible?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10098",
        "id": 1085930215,
        "node_id": "I_kwDOCVq1mM5Aufrn",
        "number": 10098,
        "title": "Problem loading Scikit-Learn Pipeline With DictVectorizer",
        "user": {
            "login": "dafajon",
            "id": 25409216,
            "node_id": "MDQ6VXNlcjI1NDA5MjE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/25409216?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dafajon",
            "html_url": "https://github.com/dafajon",
            "followers_url": "https://api.github.com/users/dafajon/followers",
            "following_url": "https://api.github.com/users/dafajon/following{/other_user}",
            "gists_url": "https://api.github.com/users/dafajon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dafajon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dafajon/subscriptions",
            "organizations_url": "https://api.github.com/users/dafajon/orgs",
            "repos_url": "https://api.github.com/users/dafajon/repos",
            "events_url": "https://api.github.com/users/dafajon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dafajon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1220611565,
                "node_id": "MDU6TGFiZWwxMjIwNjExNTY1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/converter",
                "name": "converter",
                "color": "0E8A16",
                "default": false,
                "description": "related to ONNX converters"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "xadupre",
                "id": 22452781,
                "node_id": "MDQ6VXNlcjIyNDUyNzgx",
                "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xadupre",
                "html_url": "https://github.com/xadupre",
                "followers_url": "https://api.github.com/users/xadupre/followers",
                "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
                "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
                "organizations_url": "https://api.github.com/users/xadupre/orgs",
                "repos_url": "https://api.github.com/users/xadupre/repos",
                "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xadupre/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 10,
        "created_at": "2021-12-21T15:07:13Z",
        "updated_at": "2022-01-19T19:21:58Z",
        "closed_at": "2022-01-19T19:21:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have a pipeline serialized via `skl2onnx` converter.\r\n```python\r\npipeline = Pipeline([('feat', DictVectorizer(sparse=False)), ('dt', RandomForestClassifier())])\r\n```\r\n\r\nWhich ingests span based features to work as a sentence boundary detection model as follows:\r\n```python\r\n [{'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, {'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, {'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, ... ,{'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}]\r\n```\r\n\r\nKeys are of type `string` and values are `bool`.\r\n\r\nThe model is serialized with `skl2onnx` as follows.\r\n\r\n```python\r\ninitial_type = [('boolean_input', DictionaryType(StringTensorType([1]), BooleanTensorType([1])))]\r\nonx = convert_sklearn(pipeline, initial_types=initial_type)\r\n```\r\n\r\nUpon loading, I have the following error:\r\n\r\n```bash\r\nInvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from /Users/dorukhanafacan/sadedegel/sadedegel/ml/model/sbd.onnx failed:This is an invalid model. Type Error: Type 'map(string,tensor(bool))' of input parameter (boolean_input) of operator (DictVectorizer) in node (DictVectorizer) is invalid.\r\n```\r\n\r\nI tried again also with `StringType` for key but had the same issue. Loading models with `DictionaryType` initilalized with other key, value types returned different issues since they are not compatible with the input type the model is trained on. However `InvalidGraph` is not encountered with them.\r\n\r\n**Urgency**\r\nDelaying the next release of our [library](https://github.com/GlobalMaksimum/sadedegel)\r\n\r\n**System information**\r\n- OS Platform and Distribution: MacOS 10.14.2\r\n- ONNX Runtime installed from (source or binary): PyPI 1.10.0\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.12\r\n- Visual Studio version (if applicable): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10099",
        "id": 1086021536,
        "node_id": "I_kwDOCVq1mM5Au1-g",
        "number": 10099,
        "title": "ReduceMean consumes an unreasonable amount of VRAM",
        "user": {
            "login": "ponbaton",
            "id": 17086180,
            "node_id": "MDQ6VXNlcjE3MDg2MTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/17086180?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ponbaton",
            "html_url": "https://github.com/ponbaton",
            "followers_url": "https://api.github.com/users/ponbaton/followers",
            "following_url": "https://api.github.com/users/ponbaton/following{/other_user}",
            "gists_url": "https://api.github.com/users/ponbaton/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ponbaton/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ponbaton/subscriptions",
            "organizations_url": "https://api.github.com/users/ponbaton/orgs",
            "repos_url": "https://api.github.com/users/ponbaton/repos",
            "events_url": "https://api.github.com/users/ponbaton/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ponbaton/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T16:44:00Z",
        "updated_at": "2022-04-17T08:54:36Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nReduceMean allocates 4x the amount of memory of the input size.\r\n\r\nExample: (4, 128, 1024, 1024) float32 tensor with reduction along axes 0, 2, 3 should require memory for 128 floats.\r\n\r\nInstead it tries to allocate 8GB of space (which is 4x the input size) and fails with the following error:\r\n\r\n```\r\n[E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running ReduceMean node. Name:'op' Status Message: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:331 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool) Failed to allocate memory for requested buffer of size 8589934592\r\n```\r\n\r\n**Urgency**\r\n\r\nUrgent. This breaks testing several models with the required batch size.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.7\r\n- Visual Studio version (if applicable): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: GTX 1080Ti, 11GB\r\n\r\n**To Reproduce**\r\n\r\nRun the following code\r\n\r\n```python\r\nimport numpy as np\r\nimport onnx\r\nimport onnxruntime as ort\r\n\r\n\r\nFEATURE_MAP_SHAPE = (128, 1024, 1024)\r\n\r\n\r\ndef create_onnx_model():\r\n    # Size is (batch_size / 2) GB\r\n    input_proto = onnx.helper.make_tensor_value_info('x', onnx.TensorProto.FLOAT, [None, *FEATURE_MAP_SHAPE])\r\n    output_proto = onnx.helper.make_tensor_value_info('y', onnx.TensorProto.FLOAT, [1, FEATURE_MAP_SHAPE[0], 1, 1])\r\n\r\n    node_def = onnx.helper.make_node(\r\n        'ReduceMean',\r\n        inputs=[input_proto.name],\r\n        outputs=[output_proto.name],\r\n        name='op',\r\n        axes=(0, 2, 3),\r\n    )\r\n\r\n    graph_def = onnx.helper.make_graph(\r\n        nodes=[node_def],\r\n        name='test-model',\r\n        inputs=[input_proto],\r\n        outputs=[output_proto],\r\n    )\r\n\r\n    model_def = onnx.helper.make_model(graph_def, producer_name='onnx-example')\r\n    model_def.ir_version = 4\r\n    model_def.opset_import[0].version = 11\r\n\r\n    onnx.checker.check_model(model_def, full_check=True)\r\n\r\n    onnx.save_model(model_def, 'test.onnx')\r\n\r\n    return ort.InferenceSession('test.onnx', providers=['CUDAExecutionProvider'])\r\n\r\n\r\nmodel = create_onnx_model()\r\nbatch_size = 4\r\nx = np.zeros((batch_size, *FEATURE_MAP_SHAPE), np.float32)\r\nmodel.run(None, {'x': x})[0].shape\r\n```\r\n\r\nSee the attached Jupyter notebook for a complete runnable example: [reducemean_demo.zip](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)\r\n\r\n**Expected behavior**\r\n\r\nIn the attached example `batch_size` close to 20 should be possible, as in PyTorch (see [the same notebook](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)).\r\n\r\nI. e. ReduceMean should only require the same amount of memory as its output for operation.\r\n\r\n**Screenshots**\r\nNone\r\n\r\n**Additional context**\r\nA runnable example: [reducemean_demo.zip](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10100",
        "id": 1086025334,
        "node_id": "I_kwDOCVq1mM5Au252",
        "number": 10100,
        "title": "Can't Use INT8 Input Data on Quantized Model",
        "user": {
            "login": "Hamptonjc",
            "id": 41594631,
            "node_id": "MDQ6VXNlcjQxNTk0NjMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/41594631?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Hamptonjc",
            "html_url": "https://github.com/Hamptonjc",
            "followers_url": "https://api.github.com/users/Hamptonjc/followers",
            "following_url": "https://api.github.com/users/Hamptonjc/following{/other_user}",
            "gists_url": "https://api.github.com/users/Hamptonjc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Hamptonjc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Hamptonjc/subscriptions",
            "organizations_url": "https://api.github.com/users/Hamptonjc/orgs",
            "repos_url": "https://api.github.com/users/Hamptonjc/repos",
            "events_url": "https://api.github.com/users/Hamptonjc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Hamptonjc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-21T16:48:26Z",
        "updated_at": "2021-12-28T22:22:23Z",
        "closed_at": "2021-12-28T22:22:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I am currently trying to export a LSTM from PyTorch and quantize it. However I would like for it to accept INT8 data instead of FP32. When trying to use static quantization with an INT8 calibration data, I get the error: \"InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(int8)) , expected: (tensor(float))\". \r\n\r\nBelow is my process:\r\n\r\n```python\r\n# Imports\r\nimport torch\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nfrom onnxruntime.quantization import quantize_static, CalibrationDataReader\r\n\r\n# Create Torch module\r\nclass MyLSTM(torch.nn.Module):\r\n\r\n  def __init__(self):\r\n    super().__init__()\r\n    self.model = torch.nn.LSTM(input_size=512, hidden_size=128, batch_first=True)\r\n\r\n  def forward(self, input, hx, cx):\r\n    return self.model(input, (hx, cx))\r\n\r\n# Instantiate\r\nm = MyLSTM()\r\n\r\n# Create samples/names for exporter\r\ninput_sample = torch.randn((1,1,512))\r\nhidden_sample = torch.randn((1,1,128))\r\ncs_sample = torch.randn((1,1,128))\r\ninput_names = [\"input\", \"hidden_0\", \"cell_st_0\"]\r\noutput_names = [\"output\", \"hidden_1\", \"cell_st_1\"]\r\n\r\n# Export to ONNX\r\ntorch.onnx.export(m, (input_sample, hidden_sample, cs_sample),\r\n                  \"./LSTM.float.onnx\", input_names=input_names, \r\n                  output_names=output_names)\r\n\r\n\r\n# fake data for onnx quantizer to calibrate on\r\nclass PsuedoData(CalibrationDataReader):\r\n\r\n    def __init__(self, size):\r\n        super().__init__()\r\n        self.size = size\r\n        self.it = 0\r\n\r\n        \r\n    def get_next(self):\r\n        self.it += 1\r\n        if self.it == self.size:\r\n            return None\r\n        else:          \r\n            return {'input':np.random.random((1,1,512)).astype(np.int8),\r\n                    'hidden_0':np.random.random((1,1,128)).astype(np.int8),\r\n                    'cell_st_0':np.random.random((1,1,128)).astype(np.int8)\r\n                   }\r\n\r\n# Instantiate\r\ncali_data = PsuedoData(size=1000)\r\n\r\n# Quantize\r\nquantize_static(\"./LSTM.float.onnx\", \"/LSTM.quant.onnx\", cali_data)\r\n```\r\n\r\nI have also used float32 data in the calibration dataset. The model successfully quantizes. However I still get the error when I try to use INT8 data on the quantized model. Any suggestions?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10101",
        "id": 1086062317,
        "node_id": "I_kwDOCVq1mM5Au_7t",
        "number": 10101,
        "title": "RandomNormal with integer output seems ill-specified",
        "user": {
            "login": "ArchRobison",
            "id": 2983330,
            "node_id": "MDQ6VXNlcjI5ODMzMzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2983330?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ArchRobison",
            "html_url": "https://github.com/ArchRobison",
            "followers_url": "https://api.github.com/users/ArchRobison/followers",
            "following_url": "https://api.github.com/users/ArchRobison/following{/other_user}",
            "gists_url": "https://api.github.com/users/ArchRobison/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ArchRobison/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ArchRobison/subscriptions",
            "organizations_url": "https://api.github.com/users/ArchRobison/orgs",
            "repos_url": "https://api.github.com/users/ArchRobison/repos",
            "events_url": "https://api.github.com/users/ArchRobison/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ArchRobison/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T17:32:33Z",
        "updated_at": "2021-12-22T01:08:38Z",
        "closed_at": "2021-12-22T01:08:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "The specification https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormal seems to allow `RandomNormal` to have integer output. It's not clear to me if the implementation is correct, or even how to write a correct implementation.\r\n\r\nFor example, suppose the output has type `int32`, the mean is 1, and the scale is 1.0.  Simply generating a set of floating-point values with that mean and scale, and then converting to `int32` biases the mean towards zero and shrinks standard deviation. The net effect is a mean of about 0.66 and standard deviation of 0.83.  I have not yet run this example with the ONNX runtime, but looking over the code I didn't see compensation for these effects.\r\n\r\nWhat does the ONNX runtime do, and what _should_ it do for int32 output?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10102",
        "id": 1086071822,
        "node_id": "PR_kwDOCVq1mM4wJTn4",
        "number": 10102,
        "title": "[ROCm] update hipify-perl location",
        "user": {
            "login": "jeffdaily",
            "id": 904248,
            "node_id": "MDQ6VXNlcjkwNDI0OA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/904248?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeffdaily",
            "html_url": "https://github.com/jeffdaily",
            "followers_url": "https://api.github.com/users/jeffdaily/followers",
            "following_url": "https://api.github.com/users/jeffdaily/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeffdaily/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeffdaily/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeffdaily/subscriptions",
            "organizations_url": "https://api.github.com/users/jeffdaily/orgs",
            "repos_url": "https://api.github.com/users/jeffdaily/repos",
            "events_url": "https://api.github.com/users/jeffdaily/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeffdaily/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 33,
        "created_at": "2021-12-21T17:45:29Z",
        "updated_at": "2022-01-07T01:21:03Z",
        "closed_at": "2022-01-07T01:21:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10102",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10102",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10102.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10102.patch",
            "merged_at": "2022-01-07T01:21:03Z"
        },
        "body": "Depending on the ROCm version installed, hipify-perl might not always\r\nlive in the hard-coded path of /opt/rocm/bin. Use python 3.3's\r\nshutil.which to locate the script.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10103",
        "id": 1086226314,
        "node_id": "I_kwDOCVq1mM5Avn-K",
        "number": 10103,
        "title": "ORT gpu io binding output buffers corrupted over multiple inferences with resizing",
        "user": {
            "login": "viboga",
            "id": 44417868,
            "node_id": "MDQ6VXNlcjQ0NDE3ODY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/44417868?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viboga",
            "html_url": "https://github.com/viboga",
            "followers_url": "https://api.github.com/users/viboga/followers",
            "following_url": "https://api.github.com/users/viboga/following{/other_user}",
            "gists_url": "https://api.github.com/users/viboga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viboga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viboga/subscriptions",
            "organizations_url": "https://api.github.com/users/viboga/orgs",
            "repos_url": "https://api.github.com/users/viboga/repos",
            "events_url": "https://api.github.com/users/viboga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viboga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T20:59:44Z",
        "updated_at": "2021-12-21T23:07:20Z",
        "closed_at": "2021-12-21T21:01:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nOnnx inference on GPU provides performance boost with io binding. The buffers for outputs of a model are pre-allocated. They can be used over multiple iterations. However, repeated usage with varying shapes leads to corruption of the order or corruption of memory itself. The buffers are created on GPU with torch.zeros().\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2016 DataCenter\r\n- ONNX Runtime installed from (source or binary): source \r\n- ONNX Runtime version: 1.10 (latest as of 12/15/2021)\r\n- Python version: python 8\r\n- Visual Studio version (if applicable): VS 2019\r\n- GCC/Compiler version (if compiling from source): build from source, VS compiler\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: V100, 32GB\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior:\r\nIn order to fetch multiple outputs from multiple inferences, have a pre-allocated buffer of larger size than any of the intended outputs. \r\n1. For each iteration\r\nFetch the outputs from buffer using reshape logic as follows:\r\nbuffer.view(-1)[:target_size].view(target_shape)\r\n2. Change output sizes from iteration to iteration and the expected output is different from the run without io binding.\r\n3. It happens after first resize/reuse on my setup.\r\n\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation\r\nIssue was first seen/reproduced on modified GPT2 with BxSx50297 logits size.\r\n\r\n**Expected behavior**\r\nThe outputs are same with and without io binding.\r\n\r\n**Additional context**:\r\nI am describing the exact steps I used for a modified GPT2:\r\nlogits size of Batch_size x Sequence_length x 50297 (vocab) for input size of Batch_size x Sequence_length. There are other inputs attention_mask(bxs) (lower triangle of 1's)\r\nposition_ids(bxs) (ascending index from 0 - [0,1,2,..s-1]\r\nand past_state(2xbx32xsx128) - first iteration NA, from second iterations outputs from previous run.\r\n\r\n1. Allocate buffer for logits with size 4 (batch_size) x 1024 (sequence_length) x 50297.\r\n2. For the first iteration let b = 4 and s = 10 (4 batches are replicas of just one). After inference fetch the logits using\r\ntarget_size = [4,10,50297]\r\nresult = logits_buffer.view(-1)[:np.prod(target_size)].view(target_size)\r\n\r\n3. For the second iteration let the batch_size be 4, sequence_length be 1. Same as step 2, its a replica\r\nFetch the logits using \r\ntarget_size = [4, 1, 50297]\r\nresult = logits_buffer.view(-1)[:np.prod(target_size)].view(target_size)\r\n\r\nExpected output is all four batches are similar in second iteration: [0,1,50297] == [1,1,50297] == [2,1,50297] == [3,1,50297]\r\nbut this is not the case.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10104",
        "id": 1086287203,
        "node_id": "I_kwDOCVq1mM5Av21j",
        "number": 10104,
        "title": "Thread affinity mask does not seem to have any effect, leading to inconsistent performance",
        "user": {
            "login": "chausner",
            "id": 15180557,
            "node_id": "MDQ6VXNlcjE1MTgwNTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/15180557?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner",
            "html_url": "https://github.com/chausner",
            "followers_url": "https://api.github.com/users/chausner/followers",
            "following_url": "https://api.github.com/users/chausner/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner/orgs",
            "repos_url": "https://api.github.com/users/chausner/repos",
            "events_url": "https://api.github.com/users/chausner/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-21T22:44:24Z",
        "updated_at": "2021-12-23T23:56:34Z",
        "closed_at": "2021-12-23T23:56:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI am seeing inconsistent performance when benchmarking a CNN model. I have been able to trace the variation in performance to different assignment of threads to processor cores by the OS scheduler. Even though onnxruntime [should automatically set](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/session/inference_session.cc#L292) the processor affinity mask to restrict threads to the first half of logical cores, it apparently does not have an effect. If I do the same via `numactl`, I do see consistent performance but not when onnxruntime sets the affinity mask. I have checked with a debugger that onnxruntime is indeed setting the affinity mask for all 4 thread pool threads by setting a breakpoint on `pthread_setaffinity_np`.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): Official Python pip package\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- CPU: Intel® Core™ i7-7700HQ (4 physical cores, 8 logical cores)\r\n\r\n**To Reproduce**\r\nRun the following benchmark multiple times:\r\n```python\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nimport time\r\nsession = ort.InferenceSession('model.onnx')\r\ninput = np.array(shape=(1, 60000), dtype=np.float32)\r\nfor i in range(100):\r\n    start = time.time()\r\n    outputs = session.run(['output'], {'input': input})\r\n    print(f'Iteration: {it}, Elapsed: {time.time() - start}')\r\n```\r\nIt will show different elapsed times between runs, e.g. sometimes\r\n```\r\nIteration: 0, Elapsed: 0.223\r\nIteration: 1, Elapsed: 0.231\r\nIteration: 2, Elapsed: 0.230\r\n...\r\nIteration: 99: Elapsed: 0.219\r\n```\r\nand sometimes:\r\n```\r\nIteration: 0, Elapsed: 0.147\r\nIteration: 1, Elapsed: 0.145\r\nIteration: 2, Elapsed: 0.152\r\n...\r\nIteration: 99: Elapsed: 0.148\r\n```\r\n\r\nIf running long enough and initial thread assignment is suboptimal, it appears the OS scheduler after some time reassigns affinity to the faster configuration automatically which can be seen as e.g.:\r\n```\r\nIteration: 1, Elapsed: 0.226\r\n...\r\nIteration: 73, Elapsed: 0.224\r\nIteration: 74, Elapsed: 0.178\r\nIteration: 75, Elapsed: 0.152\r\nIteration: 76, Elapsed: 0.151\r\n...\r\nIteration: 99: Elapsed: 0.149\r\n```\r\n\r\nThe performance is consistently good (around 0.15s) when running\r\n```\r\nnumactl --physcpubind=0,1,2,3 python3 test.py\r\n```\r\nand consistently bad (around 0.23s) when running\r\n```\r\nnumactl --physcpubind=0,2,4,6 python3 test.py\r\n```\r\n\r\nIt appears as if the Ubuntu scheduler does not honor what applications set via `pthread_setaffinity_np` but it does honor the affinity set by `numactl`.\r\n\r\n**Expected behavior**\r\nWhen running the benchmark without `numactl`, I would expect the results to always match the fast case because onnxruntime should itself set the thread affinity mask appropriately to 0,1,2,3 (half of logical cores).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10105",
        "id": 1086288345,
        "node_id": "PR_kwDOCVq1mM4wKCLj",
        "number": 10105,
        "title": "Remove duplicated constant initializer copies for TensorRT nodes",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T22:46:47Z",
        "updated_at": "2021-12-22T20:19:57Z",
        "closed_at": "2021-12-22T20:19:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10105",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10105",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10105.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10105.patch",
            "merged_at": "2021-12-22T20:19:57Z"
        },
        "body": "When a subgraph is assigned to TensorRT EP, both ORT and TRT maintain a copy of the subgraph's constant initializers. This PR removes the ORT copy to save memory.\r\n1. add constant_initializers field in MetaDef in order to differentiate constant initializers and overridable initializers in the (sub)graph input.\r\n2. remove constant initializers from MetaDef input for TRT nodes, so that ORT can clean the constant initializers memory after partitioning.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10106",
        "id": 1086300199,
        "node_id": "PR_kwDOCVq1mM4wKErB",
        "number": 10106,
        "title": "Add support for FusedAdam to be mathematically equivalent to pytorch/AdamW",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T23:12:10Z",
        "updated_at": "2022-01-21T21:38:00Z",
        "closed_at": "2022-01-21T21:37:59Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10106",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10106",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10106.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10106.patch",
            "merged_at": "2022-01-21T21:37:59Z"
        },
        "body": "ORT's `FusedAdam` is currently mathematically equivalent to `transformers/AdamW`. Users wanting to work with `pytorch/AdamW` mathematical implementation would see convergence disparity because of the subtle differences.\r\n\r\nThis pull request introduces a way for users to select the implementation they want so that they can get the performance gains, as well as aligned convergence.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10108",
        "id": 1086383471,
        "node_id": "I_kwDOCVq1mM5AwOVv",
        "number": 10108,
        "title": "How to create writable build-in buffers during inference?",
        "user": {
            "login": "lawlict",
            "id": 35951198,
            "node_id": "MDQ6VXNlcjM1OTUxMTk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/35951198?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lawlict",
            "html_url": "https://github.com/lawlict",
            "followers_url": "https://api.github.com/users/lawlict/followers",
            "following_url": "https://api.github.com/users/lawlict/following{/other_user}",
            "gists_url": "https://api.github.com/users/lawlict/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lawlict/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lawlict/subscriptions",
            "organizations_url": "https://api.github.com/users/lawlict/orgs",
            "repos_url": "https://api.github.com/users/lawlict/repos",
            "events_url": "https://api.github.com/users/lawlict/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lawlict/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-22T02:18:54Z",
        "updated_at": "2022-01-27T23:37:18Z",
        "closed_at": "2022-01-27T23:37:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi, I try to create a first-in-first-out queue as a pytorch model, export it to onnx and infer with onnxruntime. The queue, with a limited size, updates every time when a new input comes, and returns the updated queue. Codes are very simple:\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass WavBuffer(nn.Module):\r\n    def __init__(self, size=10):\r\n        super().__init__()\r\n        self.size = size\r\n        wavbuf = torch.zeros(size)\r\n        self.register_buffer('wavbuf', wavbuf)\r\n\r\n    def forward(self, x):\r\n        self.wavbuf = torch.cat([self.wavbuf, x])[-self.size:]\r\n        return self.wavbuf\r\n\r\nmodel = WavBuffer(10)\r\nx = torch.ones(5)\r\nfor i in range(2):\r\n    wavbuf = model(x)\r\n    print(wavbuf)\r\n```\r\nAs expected, the outputs are:\r\n```\r\ntensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\r\ntensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\r\n```\r\nThen I export the model to onnx format and infer with onnxruntime:\r\n```\r\ntorch.onnx.export(\r\n    model, torch.zeros(5), 'model.onnx', verbose=False, input_names=['wav'],\r\n    output_names=['wavbuf'], opset_version=11\r\n)\r\n\r\nimport numpy as np\r\nimport onnxruntime\r\n\r\nmodel = onnxruntime.InferenceSession('model.onnx')\r\nx = np.ones(5, dtype=np.float32)\r\ninputs = {model.get_inputs()[0].name: x}\r\nfor i in range(2):\r\n    outputs = model.run(None, inputs)\r\n    wavbuf = outputs[0]\r\n    print(wavbuf)\r\n```\r\nHowever, now the outputs are:\r\n```\r\n[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\r\n[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\r\n```\r\nI guess that weights in onnx models are not changeable, but is there any solution to create writable build-in buffers during model design and change the buffers in onnx inference? An available example is LSTM, where the hidden states update for each time step. However, it is too difficult for me to its implementation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10109",
        "id": 1086421043,
        "node_id": "PR_kwDOCVq1mM4wKdu7",
        "number": 10109,
        "title": "ConcatGrad for OpSet13",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-22T03:47:51Z",
        "updated_at": "2021-12-24T02:02:53Z",
        "closed_at": "2021-12-24T02:02:53Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10109",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10109",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10109.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10109.patch",
            "merged_at": "2021-12-24T02:02:53Z"
        },
        "body": "Concat's grad uses Split Op, Split Op moves \"split\" from attribute to input since OpSet13. This PR is to support both cases for building gradient of Concat/ConcatTraning.\r\n\r\nThis is required to run ULR model when ORTModule uses OpSet14 by default.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10110",
        "id": 1086458077,
        "node_id": "I_kwDOCVq1mM5Awgjd",
        "number": 10110,
        "title": "Using tensorrt execution provider is significantly slower than cuda execution provider",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-22T05:13:54Z",
        "updated_at": "2021-12-22T19:42:56Z",
        "closed_at": "2021-12-22T19:42:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI was using both TensorrtExecutionProvider and the CudaExecutionProvider in Python to test the inference speed of the same model, however the TensorrtExecutionProvider is siginifantly slower.  I was using Tensorrt container 21.10 and ONNX Runtime version 1.10, on a V100 GPU. Using CUDA provider, the inference only takes 26ms, but using Tensorrt provider the inference takes > 3,000 ms with cache enabled. Can anyone help take a look at what's wrong with my setup?\r\n\r\nI turn on the verbose logging of the inference session and it shows \"\r\n [V:onnxruntime:, inference_session.cc:153 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n [V:onnxruntime:, inference_session.cc:155 VerifyEachNodeIsAssignedToAnEp] All nodes have been placed on [TensorrtExecutionProvider].\" Not sure if this is expected. I posted more detailed verbose logging in the additional context, and the profiling (screenshot below) doesn't show any single operations, just a whole \"TensorrtExecutionProvider_TRTKernel_graph_torch-jit-export\".\r\n\r\n**System information**\r\n(Using Tensorrt container 21.10)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  Cuda 11.4/CuDNN8.2.2\r\n- GPU model and memory: V100, 16G\r\n\r\n**To Reproduce**\r\nMy code was below. The ONNX model is an encoder model of a seq2seq model exported by torch.onnx.export. When we switch to cuda setting we only change providers to `EP_list_cuda` when creating the session.\r\n```\r\nEP_list_tensorrt = [('TensorrtExecutionProvider', {'trt_max_workspace_size':22147483648, 'trt_fp16_enable':True,'trt_engine_cache_enable':True,'trt_engine_cache_path':'./trt_cache'}), ('CUDAExecutionProvider', {'device_id':0})]\r\n\r\nEP_list_cuda = ['CUDAExecutionProvider']\r\n\r\nsess_options = ort.SessionOptions()\r\nsess_options.intra_op_num_threads = 4\r\nsess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nsess_options.log_severity_level = 0\r\nsess_options.log_verbosity_level = 1\r\nsess_options.enable_profiling = True\r\n\r\nencoder_session = ort.InferenceSession(args.onnx_model_path, sess_options, providers=EP_list_tensorrt)\r\n\r\nstart = time.perf_counter()\r\n\r\nencoder_result = encoder_session.run(None,{\"input_ids\":test_input[\"input_ids\"].cpu().numpy()})\r\n\r\nend = time.perf_counter()\r\n\r\nprint(f'Encoder takes time: {(end-start)*1000} ms')\r\n\r\nencoder_prof_file = encoder_session.end_profiling()\r\n```\r\n\r\n**Expected behavior**\r\nUsing TensorRTProvider shouldn't be this slow.\r\n\r\n**Screenshots**\r\nThe profiling file screenshot: https://paste.pics/FF0HX\r\n\r\n**Additional context**\r\nVerbose logging:\r\n2021-12-22 05:06:19.413336217 [I:onnxruntime:, inference_session.cc:273 operator()] Flush-to-zero and denormal-as-zero are off\r\n2021-12-22 05:06:19.413367427 [I:onnxruntime:, inference_session.cc:280 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n2021-12-22 05:06:22.279321986 [I:onnxruntime:, inference_session.cc:1228 Initialize] Initializing session.\r\n2021-12-22 05:06:22.279363097 [I:onnxruntime:, inference_session.cc:1265 Initialize] Adding default CPU execution provider.\r\n2021-12-22 05:06:22.279400158 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:Cuda id:0 OrtMemType:0 OrtAllocatorType:1 Device:[DeviceType:1 MemoryType:0 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.279424173 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:CudaPinned id:0 OrtMemType:-1 OrtAllocatorType:1 Device:[DeviceType:0 MemoryType:1 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.279448197 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:CUDA_CPU id:0 OrtMemType:-2 OrtAllocatorType:1 Device:[DeviceType:0 MemoryType:0 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.297476062 [I:onnxruntime:, graph.cc:3529 CleanUnusedInitializersAndNodeArgs] Removing initializer '274'. It is no longer used by any node.\r\n2021-12-22 05:06:22.312514583 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:22.320686565 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:25.039880040 [W:onnxruntime:Default, tensorrt_execution_provider.h:53 log] [2021-12-22 05:06:25 WARNING] /onnxruntime_src/cmake/external/onnx-tensorrt/onnx2trt_utils.cpp:362: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n2021-12-22 05:06:31.481898183 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:31.482785481 [V:onnxruntime:, inference_session.cc:153 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n2021-12-22 05:06:31.482809857 [V:onnxruntime:, inference_session.cc:155 VerifyEachNodeIsAssignedToAnEp] All nodes have been placed on [TensorrtExecutionProvider].\r\n2021-12-22 05:06:31.484109031 [V:onnxruntime:, session_state.cc:67 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n2021-12-22 05:06:31.484509663 [V:onnxruntime:, session_state.cc:113 CreateGraphInfo] Done saving OrtValue mappings.\r\n2021-12-22 05:06:31.485508500 [I:onnxruntime:, session_state_utils.cc:140 SaveInitializedTensors] Saving initialized tensors.\r\n2021-12-22 05:06:32.105186738 [I:onnxruntime:, session_state_utils.cc:266 SaveInitializedTensors] Done saving initialized tensors\r\n2021-12-22 05:06:32.106737739 [I:onnxruntime:, inference_session.cc:1437 Initialize] Session successfully initialized.\r\n2021-12-22 05:06:33.212640872 [I:onnxruntime:, sequential_executor.cc:155 Execute] Begin execution\r\nEncoder takes time: 3581.6109420266002 ms\r\n2021-12-22 05:06:35.879273667 [I:onnxruntime:, profiler.cc:115 EndProfiling] Writing profiler data to file onnxruntime_profile__2021-12-22_05-06-19.json\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10111",
        "id": 1086519060,
        "node_id": "I_kwDOCVq1mM5AwvcU",
        "number": 10111,
        "title": "is batch inference supported in dynamic quantization?",
        "user": {
            "login": "rohanshingade",
            "id": 18469762,
            "node_id": "MDQ6VXNlcjE4NDY5NzYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/18469762?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rohanshingade",
            "html_url": "https://github.com/rohanshingade",
            "followers_url": "https://api.github.com/users/rohanshingade/followers",
            "following_url": "https://api.github.com/users/rohanshingade/following{/other_user}",
            "gists_url": "https://api.github.com/users/rohanshingade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rohanshingade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rohanshingade/subscriptions",
            "organizations_url": "https://api.github.com/users/rohanshingade/orgs",
            "repos_url": "https://api.github.com/users/rohanshingade/repos",
            "events_url": "https://api.github.com/users/rohanshingade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rohanshingade/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-22T07:07:14Z",
        "updated_at": "2022-01-03T17:42:35Z",
        "closed_at": "2022-01-03T17:42:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI used dynamic quantization to quanitze the model. However running with different batch size, give inconsistent model prediction.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04.5 LTS\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.\r\n- Python version: 1.8.0\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Expected behavior**\r\nModel prediction should not change as batch size changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10112",
        "id": 1086658671,
        "node_id": "I_kwDOCVq1mM5AxRhv",
        "number": 10112,
        "title": "What's the fastest way to view my implemented changes?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-22T10:05:05Z",
        "updated_at": "2021-12-28T13:49:01Z",
        "closed_at": "2021-12-23T20:57:51Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm implementing some modifications to the python module, which includes modifying `CPP`, `header`, and `python` files.\r\n\r\nCurrently, when I modify files, I run `.\\build.bat --build_wheel --parallel` to generate a `wheel` file to install.\r\nThis process is pretty slow.\r\n\r\nIs there any other way, so that I'll be able to work fast on it? :)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10113",
        "id": 1086721155,
        "node_id": "I_kwDOCVq1mM5AxgyD",
        "number": 10113,
        "title": "onnxruntime latest version segment fault",
        "user": {
            "login": "henrywu2019",
            "id": 47995124,
            "node_id": "MDQ6VXNlcjQ3OTk1MTI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/47995124?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/henrywu2019",
            "html_url": "https://github.com/henrywu2019",
            "followers_url": "https://api.github.com/users/henrywu2019/followers",
            "following_url": "https://api.github.com/users/henrywu2019/following{/other_user}",
            "gists_url": "https://api.github.com/users/henrywu2019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/henrywu2019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/henrywu2019/subscriptions",
            "organizations_url": "https://api.github.com/users/henrywu2019/orgs",
            "repos_url": "https://api.github.com/users/henrywu2019/repos",
            "events_url": "https://api.github.com/users/henrywu2019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/henrywu2019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 13,
        "created_at": "2021-12-22T11:18:38Z",
        "updated_at": "2022-04-22T06:32:45Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nin docker, when cpu-sets are specified, onnxruntime will get segment fault.\r\n\r\n**Urgency**\r\naffect production\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- ONNX Runtime installed from (source or binary): pypi\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: CPU intel/AMD\r\n\r\n** Error **\r\n\r\n```\r\nRuntimeError: /onnxruntime_src/onnxruntime/core/platform/posix/env.cc:183 \r\nonnxruntime::{anonymous}::PosixThread::PosixThread(const char*, int, \r\nunsigned int (*)(int, Eigen::ThreadPoolInterface*), Eigen::ThreadPoolInterface*,\r\nconst onnxruntime::ThreadOptions&) pthread_setaffinity_np failed, error code: 0 error msg:\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10114",
        "id": 1087179944,
        "node_id": "PR_kwDOCVq1mM4wM-CR",
        "number": 10114,
        "title": "Builds onnxruntime + eager mode with the same value for _GLIBCXX_USE_CXX11_ABI as pytorch ",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-22T20:48:20Z",
        "updated_at": "2023-01-13T11:04:08Z",
        "closed_at": "2022-01-25T10:25:31Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10114",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10114",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10114.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10114.patch",
            "merged_at": "2022-01-25T10:25:31Z"
        },
        "body": "**Description**:\r\n\r\nEager mode does not work on Linux because _GLIBCXX_USE_CXX11_ABI=1 by default and pytorch build is released with _GLIBCXX_USE_CXX11_ABI=0.\r\n\r\n**Motivation and Context**\r\n\r\npytorch does not have to be recompiled before compiling onnxruntime.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10115",
        "id": 1087286962,
        "node_id": "PR_kwDOCVq1mM4wNUCi",
        "number": 10115,
        "title": "Fix the default provider related issue",
        "user": {
            "login": "feihugis",
            "id": 5057740,
            "node_id": "MDQ6VXNlcjUwNTc3NDA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5057740?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/feihugis",
            "html_url": "https://github.com/feihugis",
            "followers_url": "https://api.github.com/users/feihugis/followers",
            "following_url": "https://api.github.com/users/feihugis/following{/other_user}",
            "gists_url": "https://api.github.com/users/feihugis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/feihugis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/feihugis/subscriptions",
            "organizations_url": "https://api.github.com/users/feihugis/orgs",
            "repos_url": "https://api.github.com/users/feihugis/repos",
            "events_url": "https://api.github.com/users/feihugis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/feihugis/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "RyanUnderhill",
                "id": 38674843,
                "node_id": "MDQ6VXNlcjM4Njc0ODQz",
                "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/RyanUnderhill",
                "html_url": "https://github.com/RyanUnderhill",
                "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
                "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
                "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
                "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
                "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
                "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
                "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-23T00:58:20Z",
        "updated_at": "2023-03-01T21:25:21Z",
        "closed_at": "2023-03-01T21:25:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10115",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10115",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10115.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10115.patch",
            "merged_at": null
        },
        "body": "**Description**: If setting `providers` be be `None` for InferenceSession, will get the below message. This PR will make the behavior work as the doc `if not provided, then all available providers are used with the default precedence.`.\r\n\r\n```\r\nEP Error using None\r\nFalling back to ['CPUExecutionProvider'] and retrying.\r\n```\r\n\r\nAlso a related issue in the optimizer.py is fixed.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10116",
        "id": 1087321712,
        "node_id": "PR_kwDOCVq1mM4wNa8E",
        "number": 10116,
        "title": "Automate Python API docs generation ",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-23T02:34:34Z",
        "updated_at": "2022-01-04T02:22:23Z",
        "closed_at": "2022-01-04T02:22:23Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10116",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10116",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10116.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10116.patch",
            "merged_at": "2022-01-04T02:22:22Z"
        },
        "body": "PR created by this workflow staged here: https://github.com/natke/onnxruntime/pull/17 \r\n\r\nStaged here: https://natke.github.io/onnxruntime/docs/api/python/api_summary.html",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10117",
        "id": 1087340869,
        "node_id": "I_kwDOCVq1mM5Az4FF",
        "number": 10117,
        "title": "AssignNodesToEpsFromHashesImpl Failed to find kernel def hash (14280390279553192696) in kernel registries for Einsum(12) node with name 'Einsum_382'.",
        "user": {
            "login": "piekey1994",
            "id": 9911201,
            "node_id": "MDQ6VXNlcjk5MTEyMDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9911201?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/piekey1994",
            "html_url": "https://github.com/piekey1994",
            "followers_url": "https://api.github.com/users/piekey1994/followers",
            "following_url": "https://api.github.com/users/piekey1994/following{/other_user}",
            "gists_url": "https://api.github.com/users/piekey1994/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/piekey1994/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/piekey1994/subscriptions",
            "organizations_url": "https://api.github.com/users/piekey1994/orgs",
            "repos_url": "https://api.github.com/users/piekey1994/repos",
            "events_url": "https://api.github.com/users/piekey1994/events{/privacy}",
            "received_events_url": "https://api.github.com/users/piekey1994/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 2385898474,
                "node_id": "MDU6TGFiZWwyMzg1ODk4NDc0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:mobile",
                "name": "platform:mobile",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime mobile; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-23T03:24:26Z",
        "updated_at": "2022-08-11T22:03:28Z",
        "closed_at": "2022-08-11T22:03:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI exported the onnx file with pytorch 1.10 on PC. Then I convert the file to ORT format through onnxruntime 1.10. This is the config file:\r\nai.onnx;1;LayerNormalization\r\nai.onnx;9;ConstantOfShape,Where\r\nai.onnx;12;Einsum\r\nai.onnx;13;ArgMax,Cast,Concat,Gather,Log,LogSoftmax,Pad,Shape,Slice,Softmax,Transpose,Unsqueeze\r\nai.onnx;14;Add,Div,Mul,Relu,Reshape,Trilu\r\ncom.microsoft;1;DynamicQuantizeMatMul\r\n\r\nOn x86pc, I can load ort file and run it normally with the x86java version of onnxruntime.\r\n\r\nBut error encountered when loading ort model in Android.\r\nai.onnxruntime.OrtException: Error code - ORT_FAIL - message: inference_session.cc:1194 AssignNodesToEpsFromHashesImpl Failed to find kernel def hash (14280390279553192696) in kernel registries for Einsum(12) node with name 'Einsum_382'.\r\n\r\n\r\n**System information**\r\nOS Platform and Distribution: windows 64bit\r\nandroid studio version : android studio 4.1.1\r\nused android device : emulator(android api level 28 x86)\r\nONNX Runtime version: 'com.microsoft.onnxruntime:onnxruntime-mobile:1.10.0'\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10118",
        "id": 1087492548,
        "node_id": "PR_kwDOCVq1mM4wN-X9",
        "number": 10118,
        "title": "update",
        "user": {
            "login": "xusworld",
            "id": 13519244,
            "node_id": "MDQ6VXNlcjEzNTE5MjQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13519244?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xusworld",
            "html_url": "https://github.com/xusworld",
            "followers_url": "https://api.github.com/users/xusworld/followers",
            "following_url": "https://api.github.com/users/xusworld/following{/other_user}",
            "gists_url": "https://api.github.com/users/xusworld/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xusworld/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xusworld/subscriptions",
            "organizations_url": "https://api.github.com/users/xusworld/orgs",
            "repos_url": "https://api.github.com/users/xusworld/repos",
            "events_url": "https://api.github.com/users/xusworld/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xusworld/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-23T08:32:24Z",
        "updated_at": "2021-12-23T08:32:35Z",
        "closed_at": "2021-12-23T08:32:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10118",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10118",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10118.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10118.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10119",
        "id": 1087659809,
        "node_id": "I_kwDOCVq1mM5A1F8h",
        "number": 10119,
        "title": "onnxruntime_test_all fails at Gemm, Conv, Pool and Concat tests",
        "user": {
            "login": "ghost",
            "id": 10137,
            "node_id": "MDQ6VXNlcjEwMTM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ghost",
            "html_url": "https://github.com/ghost",
            "followers_url": "https://api.github.com/users/ghost/followers",
            "following_url": "https://api.github.com/users/ghost/following{/other_user}",
            "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
            "organizations_url": "https://api.github.com/users/ghost/orgs",
            "repos_url": "https://api.github.com/users/ghost/repos",
            "events_url": "https://api.github.com/users/ghost/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ghost/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 2682135653,
                "node_id": "MDU6TGFiZWwyNjgyMTM1NjUz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:ArmNN",
                "name": "ep:ArmNN",
                "color": "0052CC",
                "default": false,
                "description": "issues related to Arm NN execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-23T12:10:25Z",
        "updated_at": "2022-04-17T08:54:33Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Building successfully onnxruntime to use armnn as a provider onnxruntime_test_all fails. Using the library into my own app it crashes when doing a Conv operation.\r\n\r\nTo reproduce the error just build onnxruntime with the following options and run onnxruntime_test_all\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux xilinx-k26-starterkit-2021_1 5.10.0-xilinx-v2021.1 SMP Tue Aug 24 05:53:21 UTC 2021 aarch64 aarch64 aarch64 GNU/Linux (petalinux)\r\n- ONNX Runtime version: 1.11.0\r\n- Python version: N/A, using C/C++ api\r\n- GCC/Compiler version (if compiling from source): 10.2.0\r\n- ARM version: arm64v8-a\r\n\r\n**To Reproduce**\r\n\r\nBuild:\r\n\r\nComputeLibrary:\r\nscons Werror=1 debug=0 neon=1 opencl=0 embed_kernels=0 os=linux arch=arm64-v8a build=native extra_cxx_flags=-fPIC benchmark_tests=1 validation_tests=1\r\n\r\narmnn:\r\ncmake \\\r\n-DARMCOMPUTE_ROOT=/home/manu/ComputeLibrary \\\r\n-DARMCOMPUTE_BUILD_DIR=/home/manu/ComputeLibrary/build \\\r\n-DARMCOMPUTENEON=1 \\\r\n..\r\n\r\nmake -j4\r\n\r\nonnxruntime:\r\n\r\n./build.sh \\\r\n--config Release \\\r\n--update \\\r\n--build \\\r\n--parallel \\\r\n--build_shared_lib \\\r\n--use_armnn \\\r\n--armnn_home /home/manu/armnn \\\r\n--armnn_libs /home/manu/armnn/build \\\r\n--acl_home /home/manu/ComputeLibrary \\\r\n--acl_libs /home/manu/ComputeLibrary/build \\\r\n1>build.log 2>&1\r\n\r\nrun onnxruntime_test_all\r\n\r\n**Expected behavior**\r\nonnxruntime_test_all output:\r\n[  FAILED  ] 38 tests, listed below:\r\n[  FAILED  ] GemmOpTest.GemmNoTrans_float\r\n[  FAILED  ] GemmOpTest.GemmBroadcast\r\n[  FAILED  ] GemmOpTest.GemmTransB\r\n[  FAILED  ] GemmOpTest.GemmTransB_1\r\n[  FAILED  ] GemmOpTest.GemmNaN\r\n[  FAILED  ] GemmOpTest.GemmScalarBroadcast\r\n[  FAILED  ] GemmOpTest.Gemm2DBroadcast_1\r\n[  FAILED  ] GemmOpTest.Gemm2DBroadcast_2\r\n[  FAILED  ] GemmOpTest.GemmFalseBroadcast\r\n[  FAILED  ] GemmOpTest.GemmEmptyTensor\r\n[  FAILED  ] GemmOpTest.GemmNoBiasOpset11\r\n[  FAILED  ] ConvTest.Conv2D_1\r\n[  FAILED  ] ConvTest.Conv2D_Bias_1\r\n[  FAILED  ] ConvTest.Conv2D_Bias_2\r\n[  FAILED  ] ConvTest.Conv2D_AutoPad1\r\n[  FAILED  ] ConvTest.Conv2D_AutoPad2\r\n[  FAILED  ] ConvTest.Conv_AutoPad_with_non_default_strides\r\n[  FAILED  ] PoolTest.MaxPool\r\n[  FAILED  ] PoolTest.GlobalMaxPool\r\n[  FAILED  ] PoolTest.AveragePool\r\n[  FAILED  ] PoolTest.AveragePool_IncludePadPixel\r\n[  FAILED  ] PoolTest.AveragePool_10_ceil1_2d\r\n[  FAILED  ] PoolTest.GlobalAveragePool\r\n[  FAILED  ] ConcatOpTest.Concat1D_1\r\n[  FAILED  ] ConcatOpTest.Concat1D_2\r\n[  FAILED  ] ConcatOpTest.Concat2D_1\r\n[  FAILED  ] ConcatOpTest.Concat2D_2\r\n[  FAILED  ] ConcatOpTest.Concat2D_3\r\n[  FAILED  ] ConcatOpTest.Concat2D_4\r\n[  FAILED  ] ConcatOpTest.Concat3D_1\r\n[  FAILED  ] ConcatOpTest.Concat3D_1_negative_axis\r\n[  FAILED  ] ConcatOpTest.Concat3D_2\r\n[  FAILED  ] ConcatOpTest.Concat3D_3\r\n[  FAILED  ] ConcatOpTest.Concat3D_4\r\n[  FAILED  ] ConcatOpTest.Concat3D_5\r\n[  FAILED  ] ConcatOpTest.Concat4D_1\r\n[  FAILED  ] ConcatOpTest.Concat4D_1_negative_axis\r\n[  FAILED  ] ConcatOpTest.Concat4D_2\r\n\r\nexpected no failed test.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10122",
        "id": 1087884945,
        "node_id": "PR_kwDOCVq1mM4wPRm7",
        "number": 10122,
        "title": "Check size of ThreadOptions.affinity vector",
        "user": {
            "login": "chausner-audeering",
            "id": 64791786,
            "node_id": "MDQ6VXNlcjY0NzkxNzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64791786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner-audeering",
            "html_url": "https://github.com/chausner-audeering",
            "followers_url": "https://api.github.com/users/chausner-audeering/followers",
            "following_url": "https://api.github.com/users/chausner-audeering/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner-audeering/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner-audeering/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner-audeering/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner-audeering/orgs",
            "repos_url": "https://api.github.com/users/chausner-audeering/repos",
            "events_url": "https://api.github.com/users/chausner-audeering/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner-audeering/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "pranavsharma",
                "id": 2732907,
                "node_id": "MDQ6VXNlcjI3MzI5MDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pranavsharma",
                "html_url": "https://github.com/pranavsharma",
                "followers_url": "https://api.github.com/users/pranavsharma/followers",
                "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
                "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
                "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
                "repos_url": "https://api.github.com/users/pranavsharma/repos",
                "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-23T17:23:36Z",
        "updated_at": "2022-08-10T00:46:27Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10122",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10122",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10122.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10122.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\nThis checks the size of the `ThreadOptions.affinity` vector to be either zero or match the number of threads in the thread pool. The thread pool implementations in `onnxruntime/core/platform/windows/env.cc` and `onnxruntime/core/platform/posix/env.cc` depend on the correct size:\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/05d20343ee04990a7082ccb162faab9dd9a8305c/onnxruntime/core/platform/windows/env.cc#L103\r\n\r\nand \r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/05d20343ee04990a7082ccb162faab9dd9a8305c/onnxruntime/core/platform/posix/env.cc#L179\r\n\r\n**Motivation and Context**\r\nMight fix https://github.com/microsoft/onnxruntime/issues/10113.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10123",
        "id": 1087917991,
        "node_id": "PR_kwDOCVq1mM4wPYk4",
        "number": 10123,
        "title": "Correctly set thread affinity on Windows",
        "user": {
            "login": "chausner-audeering",
            "id": 64791786,
            "node_id": "MDQ6VXNlcjY0NzkxNzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64791786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner-audeering",
            "html_url": "https://github.com/chausner-audeering",
            "followers_url": "https://api.github.com/users/chausner-audeering/followers",
            "following_url": "https://api.github.com/users/chausner-audeering/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner-audeering/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner-audeering/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner-audeering/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner-audeering/orgs",
            "repos_url": "https://api.github.com/users/chausner-audeering/repos",
            "events_url": "https://api.github.com/users/chausner-audeering/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner-audeering/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-23T18:25:08Z",
        "updated_at": "2021-12-23T23:47:39Z",
        "closed_at": "2021-12-23T23:47:39Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10123",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10123",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10123.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10123.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\nThis fixes an issue with how thread affinity was set on Windows. `SetThreadAffinityMask` requires a bit vector for the mask, see https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-setthreadaffinitymask and https://stackoverflow.com/questions/5919699/proper-usage-of-setthreadaffinitymask.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10124",
        "id": 1087990728,
        "node_id": "PR_kwDOCVq1mM4wPn0J",
        "number": 10124,
        "title": "Fix props file overwriting AdditionalIncludeDirectories",
        "user": {
            "login": "CarlPoirier",
            "id": 5577772,
            "node_id": "MDQ6VXNlcjU1Nzc3NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5577772?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CarlPoirier",
            "html_url": "https://github.com/CarlPoirier",
            "followers_url": "https://api.github.com/users/CarlPoirier/followers",
            "following_url": "https://api.github.com/users/CarlPoirier/following{/other_user}",
            "gists_url": "https://api.github.com/users/CarlPoirier/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CarlPoirier/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CarlPoirier/subscriptions",
            "organizations_url": "https://api.github.com/users/CarlPoirier/orgs",
            "repos_url": "https://api.github.com/users/CarlPoirier/repos",
            "events_url": "https://api.github.com/users/CarlPoirier/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CarlPoirier/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-23T21:04:01Z",
        "updated_at": "2022-01-12T07:30:42Z",
        "closed_at": "2022-01-12T07:30:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10124",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10124",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10124.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10124.patch",
            "merged_at": "2022-01-12T07:30:41Z"
        },
        "body": "**Description**: In .props file, prepend to AdditionalIncludeDirectories variable instead of overwriting it.\r\n\r\n**Motivation and Context**\r\n- Fixes #9646\r\n- Fixes #9924\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10125",
        "id": 1088050175,
        "node_id": "I_kwDOCVq1mM5A2lP_",
        "number": 10125,
        "title": "Error of building onnxruntime from source",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1805781160,
                "node_id": "MDU6TGFiZWwxODA1NzgxMTYw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Java",
                "name": "api:Java",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to the Java API"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-23T23:59:55Z",
        "updated_at": "2021-12-28T16:22:07Z",
        "closed_at": "2021-12-28T16:22:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi, I was trying to build the onnxruntime from source (with no changes), but it results in the following error when the building was 56%:\r\n\"/home/xx/docker_container/onnxruntime/cmake/external/onnx-tensorrt/onnx2trt_utils.hpp:377:117: error: ‘**nvinfer1::ScatterMode’ has not been declared**\r\n  377 |     IImporterContext* ctx, const ::ONNX_NAMESPACE::NodeProto& node, std::vector<TensorOrWeights>& inputs, nvinfer1::ScatterMode mode, int32_t axis = 0);\r\n      |                                                                                                                     ^~~~~~~~~~~\r\nmake[2]: *** [external/onnx-tensorrt/CMakeFiles/nvonnxparser_static.dir/build.make:76: external/onnx-tensorrt/CMakeFiles/nvonnxparser_static.dir/NvOnnxParser.cpp.o] Error 1\"\r\n\r\nCan you help take a look at what causes this?\r\nI was trying to build an OnnxRuntime with tensorrt, with java bindings inside a nvidia container. I put the details in the \"Reproduce\" section.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: latest master (the last commit is [this](https://github.com/microsoft/onnxruntime/pull/10105))\r\n- Python version: 3.8.10\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): cmake 3.22\r\n- CUDA/cuDNN version:  11.4\r\n- GPU model and memory: V100, 16G\r\n\r\n**To Reproduce**\r\nStart a nvidia tensorrt container 21.10-py3\r\nInstall the cmake cmake-3.22.1-linux-x86_64.sh (from [here](https://cmake.org/download/))\r\nGit clone the onnxruntime repo. The last commit is [this](https://github.com/microsoft/onnxruntime/pull/10105)\r\nRun \"./build.sh --cudnn_home /usr/lib/x86_64-linux-gnu --cuda_home /usr/local/cuda --use_tensorrt --tensorrt_home /opt/tensorrt --build_java\"\r\n\r\n**Expected behavior**\r\nBuild success\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10126",
        "id": 1088215721,
        "node_id": "I_kwDOCVq1mM5A3Nqp",
        "number": 10126,
        "title": "Why I met Type 'seq(tensor(int64))' of operator (MemcpyFromHost) is invalid when using onnxruntime.InferenceSession() in GPU, and How to resolve it?  On emergency hold，thanks!",
        "user": {
            "login": "yuanhuachao",
            "id": 13781668,
            "node_id": "MDQ6VXNlcjEzNzgxNjY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/13781668?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuanhuachao",
            "html_url": "https://github.com/yuanhuachao",
            "followers_url": "https://api.github.com/users/yuanhuachao/followers",
            "following_url": "https://api.github.com/users/yuanhuachao/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuanhuachao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuanhuachao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuanhuachao/subscriptions",
            "organizations_url": "https://api.github.com/users/yuanhuachao/orgs",
            "repos_url": "https://api.github.com/users/yuanhuachao/repos",
            "events_url": "https://api.github.com/users/yuanhuachao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuanhuachao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-24T07:43:48Z",
        "updated_at": "2022-04-17T08:54:28Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nwhen I run exported onnx model of transformers (BARTBeamSearchGenerator model) on GPU. I met this. Who knows how can resolve it?\r\n`Traceback (most recent call last):\r\n  File \"run_onnx_exporter.py\", line 262, in <module>\r\n    main()\r\n  File \"run_onnx_exporter.py\", line 258, in main\r\n    export_and_validate_model(model, tokenizer, output_name, num_beams, max_length, device)\r\n  File \"run_onnx_exporter.py\", line 177, in export_and_validate_model\r\n    ort_sess = onnxruntime.InferenceSession(new_onnx_file_path, providers=['CUDAExecutionProvider'])\r\n  File \"/home/venv/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 283, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/venv/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 321, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. Type Error: Type 'seq(tensor(int64))' of input parameter (best.1) of operator (MemcpyFromHost) in node (Memcpy_token_30) is invalid.`\r\n\r\n**Urgency**\r\nIs very Urgent\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- ONNX Runtime version: 1.8.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CUDA11.2\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10127",
        "id": 1088311406,
        "node_id": "I_kwDOCVq1mM5A3lBu",
        "number": 10127,
        "title": "ORTModule import error : with onnxruntime",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-24T10:48:45Z",
        "updated_at": "2022-08-12T08:33:55Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen both onnxruntime and onnxruntime-training are installed and ORTModule is imported\r\n `from torch_ort import ORTModule` it throws an error.\r\nWhen I uninstall onnxruntime, the same import works fine.\r\n\r\n```\r\nImportError: cannot import name 'TrainingParameters' from 'onnxruntime.capi._pybind_state' (/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/_pybind_state.py)\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- ONNX Runtime installed from (source or binary): Binary\r\n- ONNX Runtime version:  1.9.0 and 1.10.0\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n- install [torch_ort](https://github.com/pytorch/ort) package.\r\n- do ` from torch_ort import ORTModule`\r\n- install onnxruntime (1.9.0 or 1.10.0)\r\n- do ` from torch_ort import ORTModule`. This fails\r\n\r\n**Expected behavior**\r\nImport should happen successfully\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/39181234/147346360-352be3f8-225f-483f-b9c8-4c65f98ce148.png)\r\n![image](https://user-images.githubusercontent.com/39181234/147346382-4b96f686-d84c-4e8c-a17a-89b7c4ccf8d8.png)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10128",
        "id": 1088479826,
        "node_id": "I_kwDOCVq1mM5A4OJS",
        "number": 10128,
        "title": "BatchNorm fails on CUDA EP with zero length sequences",
        "user": {
            "login": "david-macleod",
            "id": 17232877,
            "node_id": "MDQ6VXNlcjE3MjMyODc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/17232877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david-macleod",
            "html_url": "https://github.com/david-macleod",
            "followers_url": "https://api.github.com/users/david-macleod/followers",
            "following_url": "https://api.github.com/users/david-macleod/following{/other_user}",
            "gists_url": "https://api.github.com/users/david-macleod/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david-macleod/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david-macleod/subscriptions",
            "organizations_url": "https://api.github.com/users/david-macleod/orgs",
            "repos_url": "https://api.github.com/users/david-macleod/repos",
            "events_url": "https://api.github.com/users/david-macleod/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david-macleod/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-24T19:09:47Z",
        "updated_at": "2022-08-12T08:42:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen passing tensors with a dimension of zero size e.g. (8, 1024, 0) to BatchNorm1d we hit the following error\r\n```\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node. Name:'BatchNormalization_0' Status Message: CUDNN error executing cudnnSetTensorNdDescriptor(tensor_, dataType, static_cast<int>(rank), dims.data(), strides.data())\r\n```\r\nThis is not an issue for the CPU EP and should be supported according to the ONNX spec\r\n\r\nThank you\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 11.2/8.1.1\r\n- GPU model and memory: Titan RTX 2080 Ti (11 GB)\r\n\r\n**To Reproduce**\r\n```py\r\nimport torch\r\nimport onnxruntime as ort\r\nimport tempfile\r\n\r\nclass Model(torch.nn.Module):\r\n\r\n    def __init__(self) -> None:\r\n        super().__init__()\r\n        self.bnorm = torch.nn.BatchNorm1d(2048)\r\n\r\n    def forward(self, x):\r\n        x = self.bnorm(x)\r\n        return x\r\n\r\nx =  torch.randn(1, 2048, 0)\r\nmodel = torch.jit.script(Model())\r\nmodel.eval()\r\n\r\nwith tempfile.TemporaryDirectory() as temp_dir:\r\n    temp_onnx = temp_dir + \"tmp.onnx\"\r\n    torch.onnx.export(model, x, temp_onnx, opset_version=14, input_names=[\"x\"], dynamic_axes={\"x\":[2]}, example_outputs=x)\r\n\r\n    options = ort.SessionOptions()\r\n    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n\r\n    for providers in (['CPUExecutionProvider'], [\"CUDAExecutionProvider\"]):\r\n        session = ort.InferenceSession(temp_onnx, options, providers=providers)\r\n        print(\"EPs\", session.get_providers())\r\n        output = session.run(None, input_feed={\"x\": x.numpy()})[0]\r\n        print(\"Output\", output.shape)\r\n```\r\n\r\n**Expected behavior**\r\nA successful inference pass, as demonstrated with the CPU EP\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10129",
        "id": 1088517508,
        "node_id": "PR_kwDOCVq1mM4wRRij",
        "number": 10129,
        "title": "Update test script to work with python 3.8+ on Windows",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-24T23:59:20Z",
        "updated_at": "2021-12-28T06:10:28Z",
        "closed_at": "2021-12-28T06:10:26Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10129",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10129",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10129.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10129.patch",
            "merged_at": "2021-12-28T06:10:26Z"
        },
        "body": "**Description**: \r\nOn Windows for Python 3.8+ you need to explicitly add the current directory for libraries to be loaded from it. Update onnxruntime_test_python.py to do that.\r\n\r\n**Motivation and Context**\r\nFix build break if build.py is run on Windows with python 3.8+",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10130",
        "id": 1088546330,
        "node_id": "PR_kwDOCVq1mM4wRWgL",
        "number": 10130,
        "title": "BugFix: quantization tools will throw a ValueError in HistogramCollector",
        "user": {
            "login": "xusworld",
            "id": 13519244,
            "node_id": "MDQ6VXNlcjEzNTE5MjQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13519244?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xusworld",
            "html_url": "https://github.com/xusworld",
            "followers_url": "https://api.github.com/users/xusworld/followers",
            "following_url": "https://api.github.com/users/xusworld/following{/other_user}",
            "gists_url": "https://api.github.com/users/xusworld/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xusworld/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xusworld/subscriptions",
            "organizations_url": "https://api.github.com/users/xusworld/orgs",
            "repos_url": "https://api.github.com/users/xusworld/repos",
            "events_url": "https://api.github.com/users/xusworld/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xusworld/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "chilo-ms",
                "id": 54722500,
                "node_id": "MDQ6VXNlcjU0NzIyNTAw",
                "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/chilo-ms",
                "html_url": "https://github.com/chilo-ms",
                "followers_url": "https://api.github.com/users/chilo-ms/followers",
                "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
                "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
                "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
                "repos_url": "https://api.github.com/users/chilo-ms/repos",
                "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
                "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-12-25T04:51:52Z",
        "updated_at": "2022-01-15T02:57:55Z",
        "closed_at": "2022-01-15T02:57:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10130",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10130",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10130.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10130.patch",
            "merged_at": null
        },
        "body": "Fix bug and spelling errors.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10131",
        "id": 1088582645,
        "node_id": "I_kwDOCVq1mM5A4nP1",
        "number": 10131,
        "title": "What's the most time-consuming process in python's `InferenceSession` class init?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-25T10:38:10Z",
        "updated_at": "2022-08-11T13:51:43Z",
        "closed_at": "2021-12-30T17:46:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "What's the most time-consuming process in python's `InferenceSession` class init?\r\nBy profiling using `cProfile`, I have noticed that the `_create_inference_session` which runs in `InferenceSession`'s init is the most time-consuming.\r\n\r\nI consulted with the great @xadupre which explained to me that the process of `InferenceSession` is generally as follows:\r\nModel Loading -> Graph Optimization -> Data Structure Modifications.\r\n\r\nXavier recommended that saving and using the optimized graph **may** save time. I've tried it, and even though a bit of time was saved, the change wasn't significant.\r\nYou can try it yourself in this Colab notebook: https://colab.research.google.com/drive/1KwtH90g2NPC8P_bmTT31GdytV2OlS8Y7?usp=sharing\r\n\r\nIf the Graph Optimization isn't the bottleneck, then I may assume that `Model Loading` or `Data Structure Modifications` is.\r\n\r\nI want to understand a bit more about the Model Loading process.\r\nIf for example, instead of passing a string (file path) to `InferenceSession`, I'd pass model bytes buffer, will there still be a Model Loading process? I assume No because the model is already loaded in the memory and the CPP code should just get the pointer to the memory location.\r\n\r\nAlso, I want to understand a bit better the Data Structure Modifying process.\r\nWhy is it needed and what's happening in the process?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10132",
        "id": 1088616451,
        "node_id": "PR_kwDOCVq1mM4wRis1",
        "number": 10132,
        "title": "Add `.git` suffix to github URL.",
        "user": {
            "login": "xkszltl",
            "id": 5203025,
            "node_id": "MDQ6VXNlcjUyMDMwMjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5203025?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xkszltl",
            "html_url": "https://github.com/xkszltl",
            "followers_url": "https://api.github.com/users/xkszltl/followers",
            "following_url": "https://api.github.com/users/xkszltl/following{/other_user}",
            "gists_url": "https://api.github.com/users/xkszltl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xkszltl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xkszltl/subscriptions",
            "organizations_url": "https://api.github.com/users/xkszltl/orgs",
            "repos_url": "https://api.github.com/users/xkszltl/repos",
            "events_url": "https://api.github.com/users/xkszltl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xkszltl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-25T15:16:34Z",
        "updated_at": "2022-01-03T22:38:35Z",
        "closed_at": "2022-01-03T22:38:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10132",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10132",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10132.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10132.patch",
            "merged_at": "2022-01-03T22:38:35Z"
        },
        "body": "Although github works with both, this is more precise.\r\nHaving an extension also makes it easy to match with regex, when we want to inject code to reroute traffic to our own git mirror.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10133",
        "id": 1088703093,
        "node_id": "PR_kwDOCVq1mM4wRxuA",
        "number": 10133,
        "title": "fix: clang compile",
        "user": {
            "login": "ganler",
            "id": 38074777,
            "node_id": "MDQ6VXNlcjM4MDc0Nzc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/38074777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ganler",
            "html_url": "https://github.com/ganler",
            "followers_url": "https://api.github.com/users/ganler/followers",
            "following_url": "https://api.github.com/users/ganler/following{/other_user}",
            "gists_url": "https://api.github.com/users/ganler/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ganler/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ganler/subscriptions",
            "organizations_url": "https://api.github.com/users/ganler/orgs",
            "repos_url": "https://api.github.com/users/ganler/repos",
            "events_url": "https://api.github.com/users/ganler/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ganler/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-26T05:35:49Z",
        "updated_at": "2021-12-31T02:47:13Z",
        "closed_at": "2021-12-31T02:47:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10133",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10133",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10133.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10133.patch",
            "merged_at": null
        },
        "body": "**Description**: cannot compile ORT-cuda with clang. \r\nIt says \"hides overloaded virtual function\" which is a common clang compile error (also see [here](https://stackoverflow.com/questions/18515183/c-overloaded-virtual-function-warning-by-clang)).\r\n\r\n**Motivation and Context**\r\n- Fix ORT-cuda compilation on clang (specifically, my platform: Manjaro; clang-13)\r\n\r\n![image](https://user-images.githubusercontent.com/38074777/147400364-63406fcc-9b35-410b-9da5-bbe3a4187f2f.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10134",
        "id": 1088867772,
        "node_id": "I_kwDOCVq1mM5A5s28",
        "number": 10134,
        "title": "Large performance discrepancy between Chrome and Firefox onnxruntime-web WASM inference (unless Chrome profiler is enabled)",
        "user": {
            "login": "ziyadedher",
            "id": 16349988,
            "node_id": "MDQ6VXNlcjE2MzQ5OTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/16349988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ziyadedher",
            "html_url": "https://github.com/ziyadedher",
            "followers_url": "https://api.github.com/users/ziyadedher/followers",
            "following_url": "https://api.github.com/users/ziyadedher/following{/other_user}",
            "gists_url": "https://api.github.com/users/ziyadedher/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ziyadedher/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ziyadedher/subscriptions",
            "organizations_url": "https://api.github.com/users/ziyadedher/orgs",
            "repos_url": "https://api.github.com/users/ziyadedher/repos",
            "events_url": "https://api.github.com/users/ziyadedher/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ziyadedher/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-27T00:00:23Z",
        "updated_at": "2021-12-27T23:22:39Z",
        "closed_at": "2021-12-27T22:42:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThere is a large discrepancy in execution speed of the attached model depending on whether it is running in Chrome or Firefox, being nearly twice as fast on Firefox. Both inference sessions are using the same WASM back-end. However, if we run the model with Chrome profiling enabled, the speeds are much closer.\r\n\r\nAll times are measured using `performance.now` calls. Running regularly on Chrome, model execution time is ~2600ms. Running regularly in Firefox, model execution time is ~1350ms. If we enable profiling on Chrome, model execution time is ~1200ms. I have no clue what is causing this, and I can't really profile it to figure it out :stuck_out_tongue: \r\n\r\n**Urgency**\r\nNone.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- ONNX Runtime installed from (source or binary): Binary\r\n- ONNX Runtime version: 1.10.0\r\n\r\n**Additional context**\r\nThe model is too large to attach to this GitHub Issue, you can download it [here](https://storage.ziyadedher.com/darkarts/models/onnx/stylegan2-ffhq-256x256.generator.onnx.pb).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10135",
        "id": 1089010019,
        "node_id": "I_kwDOCVq1mM5A6Plj",
        "number": 10135,
        "title": "onnxruntime int8 quant slower than pytorch ",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-27T06:48:51Z",
        "updated_at": "2022-04-17T08:54:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\nI have a onnxmodel which was exported from torch, and the fp32 model inference of onnxruntime is faster than pytorch script\r\nhowever, when I quantize the model both in torchscript and onnxruntime, the onnxruntime is slower than pytorch\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- ONNX Runtime installed from (source or binary): pip install and build from source all try\r\n- ONNX Runtime version:1.10.0\r\n- Python version:3.8\r\n- Visual Studio version (if applicable):no\r\n- GCC/Compiler version (if compiling from source):gcc 9.3.0\r\n- CUDA/cuDNN version:no\r\n- GPU model and memory:no\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\nthe pytorch model and quant \r\n```\r\n# model is origin pytorch model\r\nmodel.qconfig = torch.quantization.get_default_qconfig('fbgemm')\r\nquant_model = torch.quantization.quantize_dynamic(model, {FSMNMT, FSMNONLINEMT, FSMNOFF2ON, torch.nn.Linear})\r\n......\r\ntrace_model = torch.jit.trace(model, (inp1, length1, history1))   #torchscript fp32 model\r\ntrace_model_q = torch.jit.trace(quant_model, (inp, length, history))   #torchscript int8 model\r\n```\r\nonnxmodel and quant:\r\n```\r\ntorch.onnx.export(model,\r\n                 (inp1, length1, history1),\r\n                 \"model.onnx\",\r\n                 verbose=False,\r\n                 input_names=input_names,\r\n                 output_names=output_names,\r\n                 opset_version=13,\r\n                 do_constant_folding=True,\r\n                 #dynamic_axes={'input':[0],'length':[0],'pre_state':[0],'output':[0,1],'cur_state':[0]},\r\n                 custom_opsets={\"mydomain\": 2})\r\n\r\nquanttized_model = quantize_dynamic(onnxmodel, onnx_quantmodel, weight_type=QuantType.QUInt8)\r\n\r\n#and do inference with following parameters\r\n\r\nenviron[\"OMP_NUM_THREADS\"] = '1'\r\nenviron[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\r\nopts = ort.SessionOptions()\r\nopts.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nopts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\r\nopts.enable_profiling = True\r\nopts.inter_op_num_threads = 1\r\nopts.intra_op_num_threads = 1\r\n\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nonnxruntime fp32 and int8 all faster than pytorch\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n![图片](https://user-images.githubusercontent.com/41035013/147443218-c62c15a9-7157-46fe-a800-084e964f0a6a.png)\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10138",
        "id": 1089074977,
        "node_id": "I_kwDOCVq1mM5A6fch",
        "number": 10138,
        "title": "Do you have any plan to add 'Round' Operator for gradient builder registry for orttrainer?",
        "user": {
            "login": "jang0977",
            "id": 77316386,
            "node_id": "MDQ6VXNlcjc3MzE2Mzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/77316386?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jang0977",
            "html_url": "https://github.com/jang0977",
            "followers_url": "https://api.github.com/users/jang0977/followers",
            "following_url": "https://api.github.com/users/jang0977/following{/other_user}",
            "gists_url": "https://api.github.com/users/jang0977/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jang0977/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jang0977/subscriptions",
            "organizations_url": "https://api.github.com/users/jang0977/orgs",
            "repos_url": "https://api.github.com/users/jang0977/repos",
            "events_url": "https://api.github.com/users/jang0977/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jang0977/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-27T08:44:58Z",
        "updated_at": "2022-08-12T18:42:59Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\nI want to train a model that must use round node for training process but orttrainer currently does not support such a operation for training session due to gradient registry issue.\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using): I am using onnxruntime 1.10.0 \r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\nHope you to add 'Round' node for gradient builder registry for training.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\nor add some detailed explanation about registering custom round function from pytorch or python to default domain.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n\r\n\r\nThank you.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10139",
        "id": 1089110030,
        "node_id": "I_kwDOCVq1mM5A6oAO",
        "number": 10139,
        "title": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : BatchNormInternal",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-27T09:38:56Z",
        "updated_at": "2022-08-12T18:42:58Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhile trying to use run the model, wrapped with ORTModule from torch_ort on inputs, it throws this error \r\n\r\n```\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for BatchNormInternal(1) node with name 'BatchNormalization_6_BatchNormInternal'\r\n```\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7 \r\n- ONNX Runtime installed from (source or binary): Source\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n- Install torch_ort\r\n- from torch_ort import ORTModule\r\n- Model : Pytorch\r\n```\r\n-  TorchFFNN(\r\n  (model_layers): ModuleDict(\r\n    (nn_layer_0): Linear(in_features=1000, out_features=256, bias=True)\r\n    (activation_layer_0): ReLU()\r\n    (dropout_layer_0): Dropout(p=0.2, inplace=False)\r\n    (bn_layer_0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n    (nn_layer_1): Linear(in_features=256, out_features=128, bias=True)\r\n    (activation_layer_1): ReLU()\r\n    (dropout_layer_1): Dropout(p=0.15, inplace=False)\r\n    (nn_layer_2): Linear(in_features=128, out_features=204, bias=True)\r\n  )\r\n)\r\n```\r\n\r\n**Expected behavior**\r\nTraining should run fine\r\n\r\n**Screenshots**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/nimmaturi.venkatadat/nagini/python/trainer/workflow_pipeline/workflow_pipeline/components/classifier.py\", line 266, in _train_ffnn_model\r\n    clf.train_minibatch(X_train, y_train, x_test=X_test, y_test=y_test, minibatch_size=512, balance=\"none\")\r\n  File \"/home/nimmaturi.venkatadat/nagini/python/trainer/workflow_pipeline/workflow_pipeline/components/model/classifier/feed_forward_neural_network_torch.py\", line 197, in train_minibatch\r\n    y_pred = self.model(x_batch)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/ortmodule.py\", line 81, in _forward\r\n    return self._torch_module.forward(*inputs, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_torch_module_ort.py\", line 32, in _forward\r\n    return self._execution_manager(self.is_training()).forward(*inputs, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 263, in forward\r\n    self._fallback_manager.handle_exception(exception=e,\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_fallback.py\", line 194, in handle_exception\r\n    raise exception\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 121, in forward\r\n    self._create_execution_agent()\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 301, in _create_execution_agent\r\n    self._execution_agent = TrainingAgent(self._onnx_models.optimized_model.SerializeToString(),\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_execution_agent.py\", line 113, in __init__\r\n    self._inference_session = onnxruntime.InferenceSession(path_or_bytes, session_options,\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 324, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 369, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for BatchNormInternal(1) node with name 'BatchNormalization_6_BatchNormInternal'\r\n\r\n```\r\n[https://www.toptal.com/developers/hastebin/fodenuloqi.sql](https://www.toptal.com/developers/hastebin/fodenuloqi.sql)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10140",
        "id": 1089147203,
        "node_id": "I_kwDOCVq1mM5A6xFD",
        "number": 10140,
        "title": "onnxruntime-web build contains browser incompatible requires e.g. worker_threads, fs, os",
        "user": {
            "login": "lincolnneu",
            "id": 39422558,
            "node_id": "MDQ6VXNlcjM5NDIyNTU4",
            "avatar_url": "https://avatars.githubusercontent.com/u/39422558?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lincolnneu",
            "html_url": "https://github.com/lincolnneu",
            "followers_url": "https://api.github.com/users/lincolnneu/followers",
            "following_url": "https://api.github.com/users/lincolnneu/following{/other_user}",
            "gists_url": "https://api.github.com/users/lincolnneu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lincolnneu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lincolnneu/subscriptions",
            "organizations_url": "https://api.github.com/users/lincolnneu/orgs",
            "repos_url": "https://api.github.com/users/lincolnneu/repos",
            "events_url": "https://api.github.com/users/lincolnneu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lincolnneu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-27T10:40:20Z",
        "updated_at": "2023-02-21T16:39:31Z",
        "closed_at": "2023-02-21T16:39:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThe onnxruntime-web npm package 1.10.0 contains node.js exclusive requires, such as\r\n```\r\nvar a=require(\"worker_threads\")\r\nvar r=require(\"fs\")\r\n...\r\n```\r\nin [onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js](https://cdn.jsdelivr.net/npm/onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js)\r\n\r\nThese requires make the onnxruntime-web not usable in browser environment.\r\n\r\n**Urgency**\r\nBlocker.\r\n\r\n**System information**\r\nThis is a universal issue for web users.\r\n\r\n**To Reproduce**\r\nGo to https://cdn.jsdelivr.net/npm/onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js search for a=require(\"worker_threads\")\r\n\r\n\r\n**Expected behavior**\r\nonnxruntime-web for browser should not contains node.js exclusive libraries.\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/39422558/147463652-5b013768-b9bd-486a-b70d-302156610bcc.png)\r\n\r\n\r\n**Additional context**\r\nSuggestion: instead of using require(\"worker_threads\"), use __non_webpack_require__(\"worker_threads\")  [Similar issue in stackoverflow](https://stackoverflow.com/questions/52581441/ignoring-specific-requires-in-webpack)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10141",
        "id": 1089473590,
        "node_id": "PR_kwDOCVq1mM4wUMxU",
        "number": 10141,
        "title": "update tensorrt multi gpu pipeline to tensorrt 8.2",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-27T21:08:38Z",
        "updated_at": "2021-12-27T23:43:28Z",
        "closed_at": "2021-12-27T23:43:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10141",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10141",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10141.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10141.patch",
            "merged_at": "2021-12-27T23:43:28Z"
        },
        "body": "update tensorrt multi gpu pipeline to tensorrt 8.2 - it uses nvidia ngc container , which only recently published 21.12 based on tensorrt 8.2",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10142",
        "id": 1089788173,
        "node_id": "I_kwDOCVq1mM5A9NkN",
        "number": 10142,
        "title": "No Performance Benefit from OnnxRuntime.GPU in ML.NET",
        "user": {
            "login": "noumanqaiser",
            "id": 5542052,
            "node_id": "MDQ6VXNlcjU1NDIwNTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5542052?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noumanqaiser",
            "html_url": "https://github.com/noumanqaiser",
            "followers_url": "https://api.github.com/users/noumanqaiser/followers",
            "following_url": "https://api.github.com/users/noumanqaiser/following{/other_user}",
            "gists_url": "https://api.github.com/users/noumanqaiser/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noumanqaiser/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noumanqaiser/subscriptions",
            "organizations_url": "https://api.github.com/users/noumanqaiser/orgs",
            "repos_url": "https://api.github.com/users/noumanqaiser/repos",
            "events_url": "https://api.github.com/users/noumanqaiser/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noumanqaiser/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            },
            {
                "id": 2233102485,
                "node_id": "MDU6TGFiZWwyMjMzMTAyNDg1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:windows",
                "name": "platform:windows",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to the Windows platform"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "michaelgsharp",
            "id": 51342856,
            "node_id": "MDQ6VXNlcjUxMzQyODU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/51342856?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/michaelgsharp",
            "html_url": "https://github.com/michaelgsharp",
            "followers_url": "https://api.github.com/users/michaelgsharp/followers",
            "following_url": "https://api.github.com/users/michaelgsharp/following{/other_user}",
            "gists_url": "https://api.github.com/users/michaelgsharp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/michaelgsharp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/michaelgsharp/subscriptions",
            "organizations_url": "https://api.github.com/users/michaelgsharp/orgs",
            "repos_url": "https://api.github.com/users/michaelgsharp/repos",
            "events_url": "https://api.github.com/users/michaelgsharp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/michaelgsharp/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "michaelgsharp",
                "id": 51342856,
                "node_id": "MDQ6VXNlcjUxMzQyODU2",
                "avatar_url": "https://avatars.githubusercontent.com/u/51342856?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/michaelgsharp",
                "html_url": "https://github.com/michaelgsharp",
                "followers_url": "https://api.github.com/users/michaelgsharp/followers",
                "following_url": "https://api.github.com/users/michaelgsharp/following{/other_user}",
                "gists_url": "https://api.github.com/users/michaelgsharp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/michaelgsharp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/michaelgsharp/subscriptions",
                "organizations_url": "https://api.github.com/users/michaelgsharp/orgs",
                "repos_url": "https://api.github.com/users/michaelgsharp/repos",
                "events_url": "https://api.github.com/users/michaelgsharp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/michaelgsharp/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 22,
        "created_at": "2021-12-28T10:46:28Z",
        "updated_at": "2023-04-18T18:47:50Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have an Image classification model that was trained using Microsoft CustomVision and exported as an ONNX model. I am able to run inferencing using this model with an average inference time of around 45ms. My computer is equipped with an NVIDIA GPU and I have been trying to reduce the inference time. \r\n\r\nMy application is a .NET console application written in C#. \r\n\r\nI tried utilizing the OnnxRuntime.GPU nuget package version 1.10 and followed in steps given on the link below to install the relevant CUDA Toolkit and Cudnn packages. (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements). Despite this, I have not seem any performance improvement when using OnnxRuntime or OnnxRuntime.GPU. The average inference time is similar and varies between 45 to 60ms.\r\n\r\n**Urgency**\r\nI have been trying various options to improve inference performance but none of them seem to be working. Urgent support would be appreciated.\r\n\r\n**System information**\r\nWindows 10 Home 21H1, Dell Inspiron 5406, Core i7 1165G7, 16GB RAM with Nvidia MX330 2GB GPU\r\nONNX Runtime installed from Nuget\r\nONNX Runtime version: 1.10.0\r\nProgram is written in C#, .NET 5, Console App\r\nVisual Studio 2019 v16.10.3\r\nCUDA/CudNN version: CUDA Tooklit 11.4.3 , CudNN 8.2.2.26 for Cuda 11.4\r\nGPU model and memory: Nvidia MX330 with 2GB Memory\r\n\r\n\r\n**To Reproduce**\r\nI use the following class to initiate an ONNX Scoring class:\r\n`public class OnnxModelScorer\r\n{\r\n\r\n    public class ImageInputData\r\n    {\r\n        [ImageType(300, 300)]\r\n        public Bitmap Image { get; set; }\r\n    }\r\n\r\n    public class ImagePrediction\r\n    {\r\n            \r\n        [ColumnName(\"model_output\")]\r\n        public float[] PredictedLabels;\r\n    }\r\n\r\n    PredictionEngine<ImageInputData, ImagePrediction> predictionEngine;\r\n    ModelMetadataPropertiesClass modelprops;\r\n    Dictionary<int, string> ModelLabels = new Dictionary<int, string>();\r\n\r\n    public void SetupPredictionEngine(string modelFolderPath, out string errors)\r\n    {\r\n        errors = \"\";\r\n        predictionEngine = null;\r\n        try\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n            modelprops = LoadProperties(modelFolderPath + \"metadata_properties.json\", out string error);\r\n\r\n            var pipeline = mlContext.Transforms\r\n                            .ResizeImages(\"image\", modelprops.CustomVisionPreprocessTargetWidth, modelprops.CustomVisionPreprocessTargetHeight, nameof(ImageInputData.Image), ImageResizingEstimator.ResizingKind.Fill)\r\n                            .Append(mlContext.Transforms.ExtractPixels(\"data\", \"image\"))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(\"model_output\", \"data\", modelFolderPath + @\"model.onnx\"));\r\n\r\n            var data = mlContext.Data.LoadFromEnumerable(new List<ImageInputData>());\r\n            var model = pipeline.Fit(data);\r\n\r\n            predictionEngine = mlContext.Model.CreatePredictionEngine<ImageInputData, ImagePrediction>(model);\r\n\r\n            string[] labels = File.ReadAllText(modelFolderPath + @\"labels.txt\").Split('\\n');\r\n\r\n            int i = 0;\r\n            foreach (var label in labels)\r\n            {\r\n                ModelLabels.Add(i, label);\r\n                i++;\r\n            }\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            errors = \"Model Loading Failed: \" + ex.ToString();\r\n        }\r\n            \r\n    }\r\n\r\n    public PredictionResultClass GetModelPrediction(Bitmap sample, out string error)\r\n    {\r\n        PredictionResultClass pr = new PredictionResultClass();\r\n        error = \"\";\r\n        if (predictionEngine != null)\r\n        {\r\n            var input = new ImageInputData { Image = sample };\r\n\r\n            var prediction = predictionEngine.Predict(input);\r\n            Dictionary<int, PredictionResultClass> predictionResults = new Dictionary<int, PredictionResultClass>();\r\n            int indexofMaxProb = -1;\r\n            float maxProbability = 0;\r\n            for (int i = 0; i < prediction.PredictedLabels.Count(); i++)\r\n            {\r\n                predictionResults.Add(i,new PredictionResultClass() { Label = ModelLabels[i], probability = prediction.PredictedLabels[i] });\r\n\r\n                if(prediction.PredictedLabels[i]>maxProbability)\r\n                {\r\n                    maxProbability = prediction.PredictedLabels[i];\r\n                    indexofMaxProb = i;\r\n                }\r\n            }\r\n\r\n            pr = predictionResults[indexofMaxProb];\r\n\r\n        }\r\n        else error = \"Prediction Engine Not initialized\";\r\n\r\n        return pr;\r\n    }\r\n    public class PredictionResultClass\r\n    {\r\n        public string Label = \"\";\r\n        public float probability = 0;\r\n    }\r\n\r\n    public void ModelMassTest(string samplesfolder)\r\n    {\r\n            \r\n        string[] inputfiles = Directory.GetFiles(samplesfolder);\r\n        List<double> analysistimes = new List<double>();\r\n        foreach (var fl in inputfiles)\r\n        {\r\n\r\n            //Emgu.CV.Image<Emgu.CV.Structure.Bgr, byte> Img = new Emgu.CV.Image<Emgu.CV.Structure.Bgr, byte>(fl);\r\n            // Img.ROI = JsonConvert.DeserializeObject<Rectangle>(\"\\\"450, 288, 420, 1478\\\"\");\r\n            // string savePath = @\"C:\\ImageMLProjects\\Tresseme200Ml Soiling Experiment\\Tresseme200MlImages\\ROIApplied\\Bad\\\" + Path.GetFileName(fl);\r\n            // Img.Save(savePath);\r\n\r\n            //Bitmap bitmap = Emgu.CV.BitmapExtension.ToBitmap(Img); // your source of a bitmap\r\n            Bitmap bitmap = new Bitmap(fl);\r\n            Stopwatch sw = new Stopwatch();\r\n            sw.Start();\r\n            var res =  GetModelPrediction(bitmap, out string error);\r\n\r\n            sw.Stop();\r\n            PrintResultsonConsole(res, Path.GetFileName(fl));\r\n\r\n\r\n\r\n\r\n            Console.WriteLine($\"Analysis Time(ms): {sw.ElapsedMilliseconds}\");\r\n            analysistimes.Add(sw.ElapsedMilliseconds);\r\n\r\n        }\r\n\r\n        if(analysistimes.Count()>0)\r\n            Console.WriteLine($\"Average Analysis Time(ms): {analysistimes.Average()}\");\r\n    }\r\n\r\n\r\n    public static ModelMetadataPropertiesClass LoadProperties(string MetadatePropertiesFilepath, out string error)\r\n    {\r\n        string propertiesText = File.ReadAllText(MetadatePropertiesFilepath);\r\n        error = \"\";\r\n        ModelMetadataPropertiesClass mtp = new ModelMetadataPropertiesClass();\r\n\r\n        try\r\n        {\r\n            mtp = JsonConvert.DeserializeObject<ModelMetadataPropertiesClass>(propertiesText);\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            error = ex.ToString();\r\n            mtp = null;\r\n        }\r\n\r\n        return mtp;\r\n    }\r\n    public class ModelMetadataPropertiesClass\r\n    {\r\n        [JsonProperty(\"CustomVision.Metadata.AdditionalModelInfo\")]\r\n        public string CustomVisionMetadataAdditionalModelInfo { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Metadata.Version\")]\r\n        public string CustomVisionMetadataVersion { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Method\")]\r\n        public string CustomVisionPostprocessMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Yolo.Biases\")]\r\n        public string CustomVisionPostprocessYoloBiases { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Yolo.NmsThreshold\")]\r\n        public string CustomVisionPostprocessYoloNmsThreshold { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropHeight\")]\r\n        public string CustomVisionPreprocessCropHeight { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropMethod\")]\r\n        public string CustomVisionPreprocessCropMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropWidth\")]\r\n        public string CustomVisionPreprocessCropWidth { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MaxDimension\")]\r\n        public string CustomVisionPreprocessMaxDimension { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MaxScale\")]\r\n        public string CustomVisionPreprocessMaxScale { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MinDimension\")]\r\n        public string CustomVisionPreprocessMinDimension { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MinScale\")]\r\n        public string CustomVisionPreprocessMinScale { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.NormalizeMean\")]\r\n        public string CustomVisionPreprocessNormalizeMean { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.NormalizeStd\")]\r\n        public string CustomVisionPreprocessNormalizeStd { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.ResizeMethod\")]\r\n        public string CustomVisionPreprocessResizeMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.TargetHeight\")]\r\n        public int CustomVisionPreprocessTargetHeight { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.TargetWidth\")]\r\n        public int CustomVisionPreprocessTargetWidth { get; set; }\r\n\r\n        [JsonProperty(\"Image.BitmapPixelFormat\")]\r\n        public string ImageBitmapPixelFormat { get; set; }\r\n\r\n        [JsonProperty(\"Image.ColorSpaceGamma\")]\r\n        public string ImageColorSpaceGamma { get; set; }\r\n\r\n        [JsonProperty(\"Image.NominalPixelRange\")]\r\n        public string ImageNominalPixelRange { get; set; }\r\n    }\r\n\r\n\r\n    public static void PrintResultsonConsole( PredictionResultClass pr,string  filePath)\r\n    {\r\n        var defaultForeground = Console.ForegroundColor;\r\n        var labelColor = ConsoleColor.Magenta;\r\n        var probColor = ConsoleColor.Blue;\r\n        var exactLabel = ConsoleColor.Green;\r\n        var failLabel = ConsoleColor.Red;\r\n\r\n        Console.Write(\"ImagePath: \");\r\n        Console.ForegroundColor = labelColor;\r\n        Console.Write($\"{Path.GetFileName(filePath)}\");\r\n        Console.ForegroundColor = defaultForeground;\r\n\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.Write(\" predicted as \");\r\n        Console.ForegroundColor = exactLabel;\r\n        Console.Write($\"{pr.Label}\");\r\n\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.Write(\" with probability \");\r\n        Console.ForegroundColor = probColor;\r\n        Console.Write(pr.probability);\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.WriteLine(\"\");\r\n    }\r\n}\r\n`\r\n\r\nTo execute inferencing, I then initiate the modelScorer and consume it.\r\n`static void Main(string[] args)\r\n{\r\n    var onnxModelScorer = new OnnxModelScorer();\r\n\r\n            onnxModelScorer.SetupPredictionEngine(@\"..\\..\\..\\OnnxModel\\\", out string error);\r\n            onnxModelScorer.ModelMassTest(@\"..\\..\\..\\SampleImages\\Bad\\\");\r\n            ConsoleHelpers.ConsolePressAnyKey();\r\n            onnxModelScorer.ModelMassTest(@\"..\\..\\..\\SampleImages\\Good\\\");\r\n\r\n\r\n            ConsoleHelpers.ConsolePressAnyKey();\r\n\r\n            \r\n    ConsoleHelpers.ConsolePressAnyKey();\r\n}\r\n`\r\n\r\nExpected behavior\r\nWhen utilizing the Onnxruntime package, the average inferencing time is ~40ms, with Onnxruntime.GPU I expected it to be less than 10ms\r\n\r\nScreenshots\r\nNA\r\n\r\nAdditional context\r\nThis is a performance oriented question, on how well Onnxruntime.GPU allows .NET developers to exploit benefits of faster inferencing using Nvidia GPUs.\r\n\r\nIf having the full project with OnnxModel and sample images would help you investigate better, please access the following link and request access:\r\nhttps://drive.google.com/drive/folders/1DqnUvTaU9xp2QLuV_X9jFCjkratckMYL?usp=sharing\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]