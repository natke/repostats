[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098136302",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11181#issuecomment-1098136302",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11181",
        "id": 1098136302,
        "node_id": "IC_kwDOCVq1mM5BdDru",
        "user": {
            "login": "CanyonWind",
            "id": 8852730,
            "node_id": "MDQ6VXNlcjg4NTI3MzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8852730?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CanyonWind",
            "html_url": "https://github.com/CanyonWind",
            "followers_url": "https://api.github.com/users/CanyonWind/followers",
            "following_url": "https://api.github.com/users/CanyonWind/following{/other_user}",
            "gists_url": "https://api.github.com/users/CanyonWind/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CanyonWind/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CanyonWind/subscriptions",
            "organizations_url": "https://api.github.com/users/CanyonWind/orgs",
            "repos_url": "https://api.github.com/users/CanyonWind/repos",
            "events_url": "https://api.github.com/users/CanyonWind/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CanyonWind/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-13T14:41:45Z",
        "updated_at": "2022-04-13T14:41:45Z",
        "author_association": "NONE",
        "body": "Hello community, any help on this? Thanks a lot",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098136302/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098810531",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11181#issuecomment-1098810531",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11181",
        "id": 1098810531,
        "node_id": "IC_kwDOCVq1mM5BfoSj",
        "user": {
            "login": "ncianeo",
            "id": 27893450,
            "node_id": "MDQ6VXNlcjI3ODkzNDUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/27893450?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ncianeo",
            "html_url": "https://github.com/ncianeo",
            "followers_url": "https://api.github.com/users/ncianeo/followers",
            "following_url": "https://api.github.com/users/ncianeo/following{/other_user}",
            "gists_url": "https://api.github.com/users/ncianeo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ncianeo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ncianeo/subscriptions",
            "organizations_url": "https://api.github.com/users/ncianeo/orgs",
            "repos_url": "https://api.github.com/users/ncianeo/repos",
            "events_url": "https://api.github.com/users/ncianeo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ncianeo/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-14T07:48:38Z",
        "updated_at": "2022-04-14T07:48:38Z",
        "author_association": "CONTRIBUTOR",
        "body": "For a single function, it is true that webassembly could give you near-native speed on web.\r\nHowever, the inference processes of some DNN models call sequences of a number of functions corresponding to the layers that compose the network. Since Javascript function call overheads are not neglectable, there should be performance issue in whole inference time of the network.\r\nYou may profile your JS inference using devtools (Ctrl + Shift + I), performance tab.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098810531/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098826345",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11181#issuecomment-1098826345",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11181",
        "id": 1098826345,
        "node_id": "IC_kwDOCVq1mM5BfsJp",
        "user": {
            "login": "ncianeo",
            "id": 27893450,
            "node_id": "MDQ6VXNlcjI3ODkzNDUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/27893450?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ncianeo",
            "html_url": "https://github.com/ncianeo",
            "followers_url": "https://api.github.com/users/ncianeo/followers",
            "following_url": "https://api.github.com/users/ncianeo/following{/other_user}",
            "gists_url": "https://api.github.com/users/ncianeo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ncianeo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ncianeo/subscriptions",
            "organizations_url": "https://api.github.com/users/ncianeo/orgs",
            "repos_url": "https://api.github.com/users/ncianeo/repos",
            "events_url": "https://api.github.com/users/ncianeo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ncianeo/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-14T08:07:17Z",
        "updated_at": "2022-04-14T08:07:17Z",
        "author_association": "CONTRIBUTOR",
        "body": "(Add) Current ort-web implementation consists of:\r\n1. onnx model parsing & loading weights: Javascript(Typescript)\r\n2. infer each layer (wasm function call): Javascript(Typescript)\r\n3. actual computation of each layer: wasm(WebAssembly)\r\n\r\nI think 2-3 should be merged into wasm part in order to get more performance, but there will be possible issues like:\r\n1. model weights should be sent to wasm buffer at first (memory usage issue)\r\n2. it will be not compatible with webgl backend (whole webgl backend is written in javascript(typescript) + glsl). In this moment (at the development stage), this will decrease productivity of the library because the development of webgl backend is not even completed yet.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1098826345/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1260387791",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11181#issuecomment-1260387791",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11181",
        "id": 1260387791,
        "node_id": "IC_kwDOCVq1mM5LH_3P",
        "user": {
            "login": "vacing",
            "id": 6896966,
            "node_id": "MDQ6VXNlcjY4OTY5NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6896966?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vacing",
            "html_url": "https://github.com/vacing",
            "followers_url": "https://api.github.com/users/vacing/followers",
            "following_url": "https://api.github.com/users/vacing/following{/other_user}",
            "gists_url": "https://api.github.com/users/vacing/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vacing/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vacing/subscriptions",
            "organizations_url": "https://api.github.com/users/vacing/orgs",
            "repos_url": "https://api.github.com/users/vacing/repos",
            "events_url": "https://api.github.com/users/vacing/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vacing/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-28T04:56:43Z",
        "updated_at": "2022-09-28T04:56:43Z",
        "author_association": "NONE",
        "body": "> **Describe the bug** Hi, in the [onnxruntime-web blog](https://cloudblogs.microsoft.com/opensource/2021/09/02/onnx-runtime-web-running-your-machine-learning-model-in-browser/), it claims near-native speed on the web. I tested mobilenetv2 as a benchmark and our own panoptic segmentation model as well. It runs 11 and 17 times slower than native inference for mobilenet v2 and our model. Wonder whether this is expected or if some inference configs are messed up on our side?\r\n> \r\n> Just for reference, `tensorflow-js` with SIMD and multi-thread enabled runs 12ms for mobilenetv2, and `onnxruntime-web` takes about 45ms. Native inference with onnxruntime takes 4ms on my 2019 MacBook pro.\r\n> \r\n> We would like to use onnxruntime-web as the inference engine because of the easy portability for our existing onnx models. But the speed difference between tf-js is quite significant. Help would be appreciated.\r\n> \r\n> **Urgency** High\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 12.0.1\r\n> * ONNX Runtime web installed from (source or binary): binary from npm\r\n> * ONNX Runtime web version: 1.11 (latest from https://www.npmjs.com/package/onnxruntime-web)\r\n> \r\n> **To Reproduce** For mobilenetv2:\r\n> \r\n> * onnxruntime-web: used [this repo](https://github.com/microsoft/onnxruntime-web-demo), with the latest onnxruntime-web version\r\n> * tf-js: used [this demo](https://tensorflow.github.io/tfjs/e2e/benchmarks/local-benchmark/index.html)\r\n> \r\n> For our model:\r\n> \r\n> * cannot share because of confidentiality.\r\n\r\nsame problem, I want to know your final decision or solution, please",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1260387791/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1262166918",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11181#issuecomment-1262166918",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11181",
        "id": 1262166918,
        "node_id": "IC_kwDOCVq1mM5LOyOG",
        "user": {
            "login": "vacing",
            "id": 6896966,
            "node_id": "MDQ6VXNlcjY4OTY5NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6896966?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vacing",
            "html_url": "https://github.com/vacing",
            "followers_url": "https://api.github.com/users/vacing/followers",
            "following_url": "https://api.github.com/users/vacing/following{/other_user}",
            "gists_url": "https://api.github.com/users/vacing/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vacing/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vacing/subscriptions",
            "organizations_url": "https://api.github.com/users/vacing/orgs",
            "repos_url": "https://api.github.com/users/vacing/repos",
            "events_url": "https://api.github.com/users/vacing/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vacing/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-29T11:50:36Z",
        "updated_at": "2022-09-29T11:51:59Z",
        "author_association": "NONE",
        "body": "> * tf-js: used [this demo](https://tensorflow.github.io/tfjs/e2e/benchmarks/local-benchmark/index.html)\r\n\r\ntfjs demo may has bug, if you select multi-thread, then the speed will be very slow, and can't recover even unselect it.\r\n\r\nI wonder your wasm test result may be not correct, tfjs used webgl because of bug",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1262166918/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]