[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179257082",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12126#issuecomment-1179257082",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12126",
        "id": 1179257082,
        "node_id": "IC_kwDOCVq1mM5GSgj6",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-08T18:25:41Z",
        "updated_at": "2022-07-08T18:25:41Z",
        "author_association": "MEMBER",
        "body": "@andylucny,\r\n\r\nRegarding to 'after 11 calls, it crashes`. What's the error in crash? Could you try python api to see whether the crash are still there if you used other language previously?\r\n\r\nIf your input shape is same, you shall not notice memory usage increasing after first inference with default session options.\r\nIf input shape changes, you will observe increasing in used memory when larger input is used in inference. It is because Arena allocation is used.\r\n\r\nNormally, model (initializers) could stay in GPU after first inference using cuda execution provider, and buffer used for input will stay due to Arena allocation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179257082/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179277820",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12126#issuecomment-1179277820",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12126",
        "id": 1179277820,
        "node_id": "IC_kwDOCVq1mM5GSln8",
        "user": {
            "login": "andylucny",
            "id": 12858649,
            "node_id": "MDQ6VXNlcjEyODU4NjQ5",
            "avatar_url": "https://avatars.githubusercontent.com/u/12858649?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/andylucny",
            "html_url": "https://github.com/andylucny",
            "followers_url": "https://api.github.com/users/andylucny/followers",
            "following_url": "https://api.github.com/users/andylucny/following{/other_user}",
            "gists_url": "https://api.github.com/users/andylucny/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/andylucny/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/andylucny/subscriptions",
            "organizations_url": "https://api.github.com/users/andylucny/orgs",
            "repos_url": "https://api.github.com/users/andylucny/repos",
            "events_url": "https://api.github.com/users/andylucny/events{/privacy}",
            "received_events_url": "https://api.github.com/users/andylucny/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-08T18:56:06Z",
        "updated_at": "2022-07-08T18:56:06Z",
        "author_association": "NONE",
        "body": "Thank you for your response.\r\n\r\nThe reported error is\r\n2022-07-07 10:48:51.3056749 [E:onnxruntime:, sequential_executor.cc:364 onnxruntime::SequentialExecutor::Execute] \r\nNon-zero status code returned while running Loop node. Name:'Loop_2310' Status Message: \r\nD:\\a\\_work\\1\\s\\onnxruntime\\core\\framework\\bfc_arena.cc:342 onnxruntime::BFCArena::AllocateRawInternal \r\nFailed to allocate memory for requested buffer of size 1079000064\r\n\r\nIt is the same in C++ and Python.\r\n\r\nBut perhaps, it is just a lack of memory on GPU. My model has variable output, so memory is lower and lower as cases with bigger and bigger outputs appear and finally it out of memory. And the optimization level has impact on the memory consumption only.\r\n\r\nThank you for your support. I think it is clear now.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179277820/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]