[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1658698746",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16934#issuecomment-1658698746",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16934",
        "id": 1658698746,
        "node_id": "IC_kwDOCVq1mM5i3bv6",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-31T16:09:50Z",
        "updated_at": "2023-07-31T16:09:50Z",
        "author_association": "MEMBER",
        "body": "> So I wondered if the ONNX model is executed on CPU or not when it is incompatible with CoreML.\r\n\r\nThe CPU execution provider is the default, fall back provider. If the CoreML EP is the only one specified, then nodes not supported by it will be assigned to the CPU EP. You can see the node assignment details in the logs by setting the log severity level to verbose.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1658698746/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1659445899",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16934#issuecomment-1659445899",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16934",
        "id": 1659445899,
        "node_id": "IC_kwDOCVq1mM5i6SKL",
        "user": {
            "login": "helloooideeeeea",
            "id": 5425553,
            "node_id": "MDQ6VXNlcjU0MjU1NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5425553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/helloooideeeeea",
            "html_url": "https://github.com/helloooideeeeea",
            "followers_url": "https://api.github.com/users/helloooideeeeea/followers",
            "following_url": "https://api.github.com/users/helloooideeeeea/following{/other_user}",
            "gists_url": "https://api.github.com/users/helloooideeeeea/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/helloooideeeeea/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/helloooideeeeea/subscriptions",
            "organizations_url": "https://api.github.com/users/helloooideeeeea/orgs",
            "repos_url": "https://api.github.com/users/helloooideeeeea/repos",
            "events_url": "https://api.github.com/users/helloooideeeeea/events{/privacy}",
            "received_events_url": "https://api.github.com/users/helloooideeeeea/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-01T01:54:46Z",
        "updated_at": "2023-08-01T02:37:10Z",
        "author_association": "NONE",
        "body": "@edgchen1 \r\n\r\nThanks for the reply!\r\n\r\nAfter changing the log level to VERBOSE and reducing the number of nodes in the sample ONNX model, warnings are no longer output.\r\n\r\nHowever, the VERBOSE log still makes me wonder if it is being executed on the CPU.\r\n\r\nI don't know if it is because a copy of the tensor data is transferred to the host memory, or if the method call (*1) is wrong in the first place.\r\n\r\nHere is the log that I suspect is being executed on the CPU.\r\n\r\n```\r\n[I:onnxruntime:, inference_session.cc:1437 Initialize] Adding default CPU execution provider.\r\n```\r\n\r\n*1...\r\nMethod to specify EP to CoreML\r\n```\r\nOrt::ThrowOnError(OrtSessionOptionsAppendExecutionProvider_CoreML(session_options, 1));\r\n```\r\n\r\nFull log\r\n\r\n```\r\n[I::onnxruntime:, inference_session.cc:328 operator()] Flush-to-zero and denormal-as-zero are off\r\n[I::onnxruntime:, inference_session.cc:336 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n[I::onnxruntime:, inference_session.cc:354 ConstructorCommon] Dynamic block base set to 0\r\n[I::onnxruntime:, inference_session.cc:1400 Initialize] Initializing session.\r\n[I::onnxruntime:, inference_session.cc:1437 Initialize] Adding default CPU execution provider.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cpu with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0\r\n[V::onnxruntime:TestONNXRuntime, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456\r\n[V::onnxruntime:, helper.cc:115 HasNeuralEngine] Current Apple hardware info: x86_64\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [0] name: [/block1/block1.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [1] name: [/block1/block1.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [2] name: [/block2/block2.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [3] name: [/block2/block2.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [4] name: [/block3/block3.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [5] name: [/block3/block3.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [6] name: [/fc/Gemm] supported: [1]\r\n[I::onnxruntime:, coreml_execution_provider.cc:78 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 1 number of nodes in the graph: 7 number of nodes supported by CoreML: 7\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block1/block1.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block1/block1.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block2/block2.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block2/block2.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block3/block3.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block3/block3.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/fc/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, session_state.cc:1142 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n[V::onnxruntime:, session_state.cc:1145 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [CoreMLExecutionProvider]. Number of nodes: 1\r\n[V::onnxruntime:, session_state.cc:126 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n[V::onnxruntime:, session_state.cc:172 CreateGraphInfo] Done saving OrtValue mappings.\r\n[I::onnxruntime:, allocation_planner.cc:2393 CreateGraphPartitioner] Use DeviceBasedPartition as default\r\n[I::onnxruntime:, session_state_utils.cc:201 SaveInitializedTensors] Saving initialized tensors.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:7 (requested) num_bytes: 40000 (actual) rounded_bytes:40192\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7fec40090000 to 0x7fec40190000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 640000000 (actual) rounded_bytes:640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1074790400\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7fe86ef00000 to 0x7fe8aef00000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 400000000 (actual) rounded_bytes:400000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 2148532224\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7fe8aef00000 to 0x7fe8eef00000\r\n[I::onnxruntime:, session_state_utils.cc:344 SaveInitializedTensors] Done saving initialized tensors\r\n[I::onnxruntime:, inference_session.cc:1767 Initialize] Session successfully initialized.\r\n[V::onnxruntime:, sequential_executor.cc:534 ExecuteThePlan] Number of streams: 1\r\n[V::onnxruntime:, sequential_executor.cc:184 SessionScope] Begin execution\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 7\r\n\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1659445899/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1659473943",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16934#issuecomment-1659473943",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16934",
        "id": 1659473943,
        "node_id": "IC_kwDOCVq1mM5i6ZAX",
        "user": {
            "login": "helloooideeeeea",
            "id": 5425553,
            "node_id": "MDQ6VXNlcjU0MjU1NTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5425553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/helloooideeeeea",
            "html_url": "https://github.com/helloooideeeeea",
            "followers_url": "https://api.github.com/users/helloooideeeeea/followers",
            "following_url": "https://api.github.com/users/helloooideeeeea/following{/other_user}",
            "gists_url": "https://api.github.com/users/helloooideeeeea/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/helloooideeeeea/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/helloooideeeeea/subscriptions",
            "organizations_url": "https://api.github.com/users/helloooideeeeea/orgs",
            "repos_url": "https://api.github.com/users/helloooideeeeea/repos",
            "events_url": "https://api.github.com/users/helloooideeeeea/events{/privacy}",
            "received_events_url": "https://api.github.com/users/helloooideeeeea/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-01T02:33:59Z",
        "updated_at": "2023-08-01T03:19:49Z",
        "author_association": "NONE",
        "body": "Postscript.\r\n\r\n\r\n**It may still be working with COREML.**\r\nThe VERBOSE logs were different compared to when I ran it on CPU.\r\n\r\nBut what I am concerned about is that CoreMLEP is slower in calculation speed.\r\n\r\nFull log when executed with explicitly specifying COREML in EP\r\n```\r\n[I::onnxruntime:, inference_session.cc:328 operator()] Flush-to-zero and denormal-as-zero are off\r\n[I::onnxruntime:, inference_session.cc:336 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n[I::onnxruntime:, inference_session.cc:354 ConstructorCommon] Dynamic block base set to 0\r\n[I::onnxruntime:, inference_session.cc:1400 Initialize] Initializing session.\r\n[I::onnxruntime:, inference_session.cc:1437 Initialize] Adding default CPU execution provider.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cpu with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0\r\n[V::onnxruntime:TestONNXRuntime, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456\r\n[V::onnxruntime:, helper.cc:115 HasNeuralEngine] Current Apple hardware info: x86_64\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [0] name: [/block1/block1.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [1] name: [/block1/block1.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [2] name: [/block2/block2.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [3] name: [/block2/block2.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [4] name: [/block3/block3.0/Gemm] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Relu] index: [5] name: [/block3/block3.1/Relu] supported: [1]\r\n[V::onnxruntime:, helper.cc:96 GetSupportedNodes] Operator type: [Gemm] index: [6] name: [/fc/Gemm] supported: [1]\r\n[I::onnxruntime:, coreml_execution_provider.cc:78 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 1 number of nodes in the graph: 7 number of nodes supported by CoreML: 7\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block1/block1.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block1/block1.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block2/block2.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block2/block2.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block3/block3.0/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/block3/block3.1/Relu] type: [Relu] was added\r\n[V::onnxruntime:, base_op_builder.cc:52 AddToModelBuilder] Operator name: [/fc/Gemm] type: [Gemm] was added\r\n[V::onnxruntime:, session_state.cc:1142 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n[V::onnxruntime:, session_state.cc:1145 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [CoreMLExecutionProvider]. Number of nodes: 1\r\n[V::onnxruntime:, session_state.cc:126 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n[V::onnxruntime:, session_state.cc:172 CreateGraphInfo] Done saving OrtValue mappings.\r\n[I::onnxruntime:, allocation_planner.cc:2393 CreateGraphPartitioner] Use DeviceBasedPartition as default\r\n[I::onnxruntime:, session_state_utils.cc:201 SaveInitializedTensors] Saving initialized tensors.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:7 (requested) num_bytes: 40000 (actual) rounded_bytes:40192\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f93c8048000 to 0x7f93c8148000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 640000000 (actual) rounded_bytes:640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1074790400\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f9212800000 to 0x7f9252800000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 640000000 (actual) rounded_bytes:640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 2148532224\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f9252800000 to 0x7f9292800000\r\n[I::onnxruntime:, session_state_utils.cc:344 SaveInitializedTensors] Done saving initialized tensors\r\n[I::onnxruntime:, inference_session.cc:1767 Initialize] Session successfully initialized.\r\n[V::onnxruntime:, sequential_executor.cc:534 ExecuteThePlan] Number of streams: 1\r\n[V::onnxruntime:, sequential_executor.cc:184 SessionScope] Begin execution\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 7\r\nInference time: 163 ms\r\n```\r\n\r\nFull log when executed without explicitly specifying EP\r\n```\r\n[I::onnxruntime:, inference_session.cc:328 operator()] Flush-to-zero and denormal-as-zero are off\r\n[I::onnxruntime:, inference_session.cc:336 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n[I::onnxruntime:, inference_session.cc:354 ConstructorCommon] Dynamic block base set to 0\r\n[I::onnxruntime:, inference_session.cc:1400 Initialize] Initializing session.\r\n[I::onnxruntime:, inference_session.cc:1437 Initialize] Adding default CPU execution provider.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cpu with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0\r\n[V::onnxruntime:TestONNXRuntime, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456\r\n[V::onnxruntime:, session_state.cc:1142 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n[V::onnxruntime:, session_state.cc:1145 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [CPUExecutionProvider]. Number of nodes: 4\r\n[V::onnxruntime:, session_state.cc:126 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n[V::onnxruntime:, session_state.cc:172 CreateGraphInfo] Done saving OrtValue mappings.\r\n[I::onnxruntime:, allocation_planner.cc:2393 CreateGraphPartitioner] Use DeviceBasedPartition as default\r\n[I::onnxruntime:, session_state_utils.cc:201 SaveInitializedTensors] Saving initialized tensors.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:7 (requested) num_bytes: 64000 (actual) rounded_bytes:64000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f8328028000 to 0x7f8328128000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 640000000 (actual) rounded_bytes:640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 1074790400\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f8274700000 to 0x7f82b4700000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:20 (requested) num_bytes: 400000000 (actual) rounded_bytes:400000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:206 Extend] Extended allocation by 1073741824 bytes.\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:209 Extend] Total allocated bytes: 2148532224\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:212 Extend] Allocated memory at 0x7f8234700000 to 0x7f8274700000\r\n[I::onnxruntime:, session_state_utils.cc:344 SaveInitializedTensors] Done saving initialized tensors\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:281 Reserve] Reserving memory in BFCArena for Cpu size: 640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:281 Reserve] Reserving memory in BFCArena for Cpu size: 640000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:281 Reserve] Reserving memory in BFCArena for Cpu size: 400000000\r\n[I::onnxruntime:TestONNXRuntime, bfc_arena.cc:281 Reserve] Reserving memory in BFCArena for Cpu size: 400000000\r\n[I::onnxruntime:, inference_session.cc:1767 Initialize] Session successfully initialized.\r\n[V::onnxruntime:, sequential_executor.cc:534 ExecuteThePlan] Number of streams: 1\r\n[V::onnxruntime:, sequential_executor.cc:184 SessionScope] Begin execution\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 7\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 8\r\n[V::onnxruntime:, stream_execution_context.cc:171 RecycleNodeInputs] ort value 10 released\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 9\r\n[V::onnxruntime:, stream_execution_context.cc:171 RecycleNodeInputs] ort value 7 released\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 6\r\nInference time: 82 ms\r\n```\r\n\r\nFull log when executed with CPU explicitly specified in EP (*1)\r\n```\r\n[I::onnxruntime:, inference_session.cc:328 operator()] Flush-to-zero and denormal-as-zero are off\r\n[I::onnxruntime:, inference_session.cc:336 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n[I::onnxruntime:, inference_session.cc:354 ConstructorCommon] Dynamic block base set to 0\r\n[I::onnxruntime:, inference_session.cc:1400 Initialize] Initializing session.\r\n[V::onnxruntime:, session_state.cc:1142 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n[V::onnxruntime:, session_state.cc:1145 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [CPUExecutionProvider]. Number of nodes: 4\r\n[V::onnxruntime:, session_state.cc:126 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n[V::onnxruntime:, session_state.cc:172 CreateGraphInfo] Done saving OrtValue mappings.\r\n[I::onnxruntime:, allocation_planner.cc:2393 CreateGraphPartitioner] Use DeviceBasedPartition as default\r\n[I::onnxruntime:, session_state_utils.cc:201 SaveInitializedTensors] Saving initialized tensors.\r\n[I::onnxruntime:, session_state_utils.cc:344 SaveInitializedTensors] Done saving initialized tensors\r\n[I::onnxruntime:, inference_session.cc:1767 Initialize] Session successfully initialized.\r\n[V::onnxruntime:, sequential_executor.cc:534 ExecuteThePlan] Number of streams: 1\r\n[V::onnxruntime:, sequential_executor.cc:184 SessionScope] Begin execution\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 7\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 8\r\n[V::onnxruntime:, stream_execution_context.cc:171 RecycleNodeInputs] ort value 10 released\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 9\r\n[V::onnxruntime:, stream_execution_context.cc:171 RecycleNodeInputs] ort value 7 released\r\n[V::onnxruntime:, sequential_executor.cc:518 ExecuteKernel] stream 0 launch kernel with idx 6\r\nInference time: 78 ms\r\n```\r\n\r\n\r\nOne point of concern is that COREML is slower in execution speed, but this may be because the tensor data is stored in host memory?\r\n\r\n(I don't know how to transfer it to GPU memory...) (*2)\r\n\r\n\r\n*1\r\nThis is an interface explicitly appended to the HEADER.\r\n```\r\nORT_API_STATUS(OrtSessionOptionsAppendExecutionProvider_CPU, _In_ OrtSessionOptions* options, int use_arena);\r\n```\r\n\r\n*2\r\nCode to copy the current tensor data to memory.\r\n```\r\nOrt::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\r\n    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(memory_info, input_tensor_values.data(), input_tensor_values.size(), input_shape.data(), input_shape.size());\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1659473943/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1664847816",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16934#issuecomment-1664847816",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16934",
        "id": 1664847816,
        "node_id": "IC_kwDOCVq1mM5jO4_I",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-04T01:32:07Z",
        "updated_at": "2023-08-04T01:32:07Z",
        "author_association": "MEMBER",
        "body": "This is the log line that shows all nodes are assigned to the CoreML EP.\r\n```\r\n[V::onnxruntime:, session_state.cc:1145 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [CoreMLExecutionProvider]. Number of nodes: 1\r\n```\r\n\r\n```\r\nOrt::ThrowOnError(OrtSessionOptionsAppendExecutionProvider_CoreML(session_options, 1));\r\n```\r\nIf this is how you add the CoreML EP, you are passing the flag `COREML_FLAG_USE_CPU_ONLY`. That would explain the slower performance.\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/f98d3f8a2340fa82e8530ada18c32175176c9aa9/include/onnxruntime/core/providers/coreml/coreml_provider_factory.h#L15-L17\r\n\r\nTry passing 0 instead.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1664847816/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]