[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1229791146",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1229791146",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1229791146,
        "node_id": "IC_kwDOCVq1mM5JTR-q",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-29T05:23:07Z",
        "updated_at": "2022-08-29T05:23:07Z",
        "author_association": "MEMBER",
        "body": "No, we don't have any async APIs today. What's your use case?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1229791146/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1230648814",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1230648814",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1230648814,
        "node_id": "IC_kwDOCVq1mM5JWjXu",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-29T17:49:13Z",
        "updated_at": "2022-08-29T17:49:13Z",
        "author_association": "MEMBER",
        "body": "It also depends on what you mean by the word `asynchronous`. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1230648814/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1378236245",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1378236245",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1378236245,
        "node_id": "IC_kwDOCVq1mM5SJjdV",
        "user": {
            "login": "sharvil",
            "id": 391004,
            "node_id": "MDQ6VXNlcjM5MTAwNA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/391004?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sharvil",
            "html_url": "https://github.com/sharvil",
            "followers_url": "https://api.github.com/users/sharvil/followers",
            "following_url": "https://api.github.com/users/sharvil/following{/other_user}",
            "gists_url": "https://api.github.com/users/sharvil/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sharvil/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sharvil/subscriptions",
            "organizations_url": "https://api.github.com/users/sharvil/orgs",
            "repos_url": "https://api.github.com/users/sharvil/repos",
            "events_url": "https://api.github.com/users/sharvil/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sharvil/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-11T04:48:21Z",
        "updated_at": "2023-01-11T04:48:21Z",
        "author_association": "NONE",
        "body": "In the Python context, I would like to see a coroutine implementation of `InferenceSession.run` with the GIL released while the computation is taking place.\r\n\r\nWe have a user-interactive service that occasionally needs predictions from a model. Ideally, we'd be able to run the interactive code concurrently with the long-running computation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1378236245/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410394889",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1410394889",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1410394889,
        "node_id": "IC_kwDOCVq1mM5UEOsJ",
        "user": {
            "login": "timstokman",
            "id": 41363,
            "node_id": "MDQ6VXNlcjQxMzYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41363?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/timstokman",
            "html_url": "https://github.com/timstokman",
            "followers_url": "https://api.github.com/users/timstokman/followers",
            "following_url": "https://api.github.com/users/timstokman/following{/other_user}",
            "gists_url": "https://api.github.com/users/timstokman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/timstokman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/timstokman/subscriptions",
            "organizations_url": "https://api.github.com/users/timstokman/orgs",
            "repos_url": "https://api.github.com/users/timstokman/repos",
            "events_url": "https://api.github.com/users/timstokman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/timstokman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-31T13:51:13Z",
        "updated_at": "2023-01-31T13:51:13Z",
        "author_association": "NONE",
        "body": "> No, we don't have any async APIs today. What's your use case?\r\n\r\nI'd be nice if we can use our CPU cores for something else then waiting for the GPU to finish with inference. Our pipeline is heavily multithreaded, so it would improve throughput and reduce CPU load if there was an async option available. I'm using the c# version of this library, so it's not just python that has this usecase.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410394889/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410821596",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1410821596",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1410821596,
        "node_id": "IC_kwDOCVq1mM5UF23c",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-31T17:53:55Z",
        "updated_at": "2023-01-31T17:53:55Z",
        "author_association": "MEMBER",
        "body": "> In the Python context, I would like to see a coroutine implementation of `InferenceSession.run` with the GIL released while the computation is taking place.\r\n> \r\n> We have a user-interactive service that occasionally needs predictions from a model. Ideally, we'd be able to run the interactive code concurrently with the long-running computation.\r\n\r\nWe do release GIL while in [run overloads](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/onnxruntime_pybind_state.cc#L1515).\r\n\r\nWould you like to contribute a coroutine PR?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410821596/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410832669",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12768#issuecomment-1410832669",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12768",
        "id": 1410832669,
        "node_id": "IC_kwDOCVq1mM5UF5kd",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-31T18:01:57Z",
        "updated_at": "2023-01-31T18:01:57Z",
        "author_association": "MEMBER",
        "body": "> > No, we don't have any async APIs today. What's your use case?\r\n> \r\n> I'd be nice if we can use our CPU cores for something else then waiting for the GPU to finish with inference. Our pipeline is heavily multithreaded, so it would improve throughput and reduce CPU load if there was an async option available. I'm using the c# version of this library, so it's not just python that has this usecase.\r\n\r\nIn a heavily multithreaded pipeline, would other threads do something anyway? I assume the context switch overhead is already taken into consideration.\r\n\r\nWe do not have any I/O going on and copying to GPU is minimized. Also CPU is overlayed with GPU to hide latency a lot of times. Are you observing lots of idle cpu for your model?\r\n\r\nThe request you are making requires lots of Invesment, but the gain is unclear.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1410832669/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]