[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1220980502",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12654#issuecomment-1220980502",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12654",
        "id": 1220980502,
        "node_id": "IC_kwDOCVq1mM5Ixq8W",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-19T18:30:12Z",
        "updated_at": "2022-08-19T18:30:12Z",
        "author_association": "MEMBER",
        "body": "You want to inference multiple models in parallel across multiple GPUs. To achieve this you need a session per model with each session tied to a separate GPU device id. How many sessions are you creating? Have you tried limiting the # of threads to 1 per session by setting intra_op_num_threads? Assuming the GPU is going to execute the full or a large part of the model, setting this to 1 shouldn't matter for perf.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1220980502/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1221028753",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12654#issuecomment-1221028753",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12654",
        "id": 1221028753,
        "node_id": "IC_kwDOCVq1mM5Ix2uR",
        "user": {
            "login": "insightless",
            "id": 111591430,
            "node_id": "U_kgDOBqbABg",
            "avatar_url": "https://avatars.githubusercontent.com/u/111591430?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/insightless",
            "html_url": "https://github.com/insightless",
            "followers_url": "https://api.github.com/users/insightless/followers",
            "following_url": "https://api.github.com/users/insightless/following{/other_user}",
            "gists_url": "https://api.github.com/users/insightless/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/insightless/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/insightless/subscriptions",
            "organizations_url": "https://api.github.com/users/insightless/orgs",
            "repos_url": "https://api.github.com/users/insightless/repos",
            "events_url": "https://api.github.com/users/insightless/events{/privacy}",
            "received_events_url": "https://api.github.com/users/insightless/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-19T19:29:51Z",
        "updated_at": "2022-08-19T19:30:01Z",
        "author_association": "NONE",
        "body": "I'm creating anywhere between 1-5 sessions per GPU depending on the model and available VRAM. I've tried limiting the number of threads per session to 1 but there still seems to be a performance hit. The models are being used for batch semantic inference, so each session uses a tensor of multiple images.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1221028753/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1221095308",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12654#issuecomment-1221095308",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12654",
        "id": 1221095308,
        "node_id": "IC_kwDOCVq1mM5IyG-M",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-19T21:11:28Z",
        "updated_at": "2022-08-19T21:11:28Z",
        "author_association": "MEMBER",
        "body": "With 5 sessions, only 5 threads will get created in the session threadpools. As far as allocators go, the maximum memory consumption comes from the arena and you can disable this for CPU by setting DisableCpuMemArena on each of the sessions. The GPU based arenas are not shared. If this doesn't resolve the issue, let us know what specifically you're observing.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1221095308/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]