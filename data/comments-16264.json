[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595560622",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16264#issuecomment-1595560622",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16264",
        "id": 1595560622,
        "node_id": "IC_kwDOCVq1mM5fGlKu",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-17T01:06:01Z",
        "updated_at": "2023-06-17T01:06:01Z",
        "author_association": "MEMBER",
        "body": "For bert model, try optimizing it like the following:\r\n\r\n```\r\npip install onnxruntime-gpu==1.15\r\npython -m onnxruntime.transformers.optimizer --input bert.onnx --output bert_fp16.onnx --float16 --use_gpu\r\n```\r\n\r\nIf everything is good, it will use fused attention kernel (like flash attention etc), which could save memory for long sequence.\r\n\r\nNote that 1.6 does not have fused attention so you will need upgrade onnxruntime-gpu to latest version.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595560622/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595610320",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16264#issuecomment-1595610320",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16264",
        "id": 1595610320,
        "node_id": "IC_kwDOCVq1mM5fGxTQ",
        "user": {
            "login": "feng-1985",
            "id": 8215563,
            "node_id": "MDQ6VXNlcjgyMTU1NjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8215563?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/feng-1985",
            "html_url": "https://github.com/feng-1985",
            "followers_url": "https://api.github.com/users/feng-1985/followers",
            "following_url": "https://api.github.com/users/feng-1985/following{/other_user}",
            "gists_url": "https://api.github.com/users/feng-1985/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/feng-1985/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/feng-1985/subscriptions",
            "organizations_url": "https://api.github.com/users/feng-1985/orgs",
            "repos_url": "https://api.github.com/users/feng-1985/repos",
            "events_url": "https://api.github.com/users/feng-1985/events{/privacy}",
            "received_events_url": "https://api.github.com/users/feng-1985/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-17T04:04:51Z",
        "updated_at": "2023-06-17T04:17:25Z",
        "author_association": "NONE",
        "body": "Thanks for response. For the production environment, only cuda 10.2 is available, so i use the onnxruntime-gpu=1.6. \r\nAnother relate question\r\n1. If I convert the model to float16, does the cuda 10.2 support ?\r\n2. python -m onnxruntime.transformers.optimizer --input bert.onnx --output bert_fp16.onnx --float16 --use_gpu\r\nuse_gpu the default value is false, use the parameter seems just rename the model name and set the EPs [url](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/optimizer.py) ?  \r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595610320/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1596515029",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16264#issuecomment-1596515029",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16264",
        "id": 1596515029,
        "node_id": "IC_kwDOCVq1mM5fKOLV",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-19T05:11:42Z",
        "updated_at": "2023-06-19T05:11:42Z",
        "author_association": "MEMBER",
        "body": "@feng-1985, \r\n1. float16 is supported in cuda 10.2 and onnxruntime-gpu 1.6.\r\n2. run `python -m onnxruntime.transformers.optimizer --help` to see the usage. The tool will apply graph optimization to convert the model graph to a new one. You can try add `--use_mask_index` which is not default in onnxruntime-gpu 1.6.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1596515029/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]