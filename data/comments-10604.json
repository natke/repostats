[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1095907632",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10604#issuecomment-1095907632",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10604",
        "id": 1095907632,
        "node_id": "IC_kwDOCVq1mM5BUjkw",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "created_at": "2022-04-12T03:13:11Z",
        "updated_at": "2022-04-12T03:13:11Z",
        "author_association": "MEMBER",
        "body": "CC @fdwr ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1095907632/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1095919036",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10604#issuecomment-1095919036",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10604",
        "id": 1095919036,
        "node_id": "IC_kwDOCVq1mM5BUmW8",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-12T03:22:29Z",
        "updated_at": "2022-04-13T20:22:42Z",
        "author_association": "MEMBER",
        "body": "What GPU model? Is xxx_fp16.onnx private? I see nothing suspicious about the Python code, but float16 is not *always* faster. I'd be curious if your GPU is using typed UAV's or native float16 support via structured buffers? Could you run this little command line .exe locally and report the results?\r\n\r\n[D3DDeviceCapabilities.zip](https://github.com/microsoft/onnxruntime/files/8469218/D3DDeviceCapabilities.zip)\r\n\r\ne.g. my output:\r\n```\r\nC:\\Users\\dwayner.REDMOND>\"D:\\programs\\graphics\\D3DDeviceCapabilities.exe\"\r\nAdapter 'NVIDIA Quadro P400' (30.0.14.7111)\r\nGetFeatureLevel: 49408\r\nIsTypedUAVSupported: 1\r\nIsTypedUAVLoadAdditionalFormatsSupported: 1 (uint8/int8/uint16/int16/float16)\r\nIsNativeFloat16Supported: 0 (uint16/int16/float16)\r\nIsInt64ShaderOpsSupported: 1 (uint64/int64)\r\nIsFloat64ShaderOpsSupported: 1 (float64)\r\nIsMin16FloatSupported: 0\r\nIsMcdmDevice: 0\r\nIsGraphNoopRemovalDisabled: 0\r\nIsGraphAutoHalfPrecisionDisabled: 0\r\nIsNvidia: 1\r\nIsAmd: 0\r\nIsIntel: 0\r\nIsQualcomm: 0\r\nIs16LaneWaveIntrinsicSupported: 0\r\nIsWaveIntrinsicSupported: 1\r\nIsDxilSupported: 1\r\nIsWaveSizeAttributeSupported: 0\r\nIsDP4ASupported: 1\r\nGetTotalLaneCount: 256\r\nGetWarpCount: 8\r\nVendorID: 4318\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1095919036/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1097634296",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10604#issuecomment-1097634296",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10604",
        "id": 1097634296,
        "node_id": "IC_kwDOCVq1mM5BbJH4",
        "user": {
            "login": "StayYouth1993",
            "id": 7048449,
            "node_id": "MDQ6VXNlcjcwNDg0NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7048449?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/StayYouth1993",
            "html_url": "https://github.com/StayYouth1993",
            "followers_url": "https://api.github.com/users/StayYouth1993/followers",
            "following_url": "https://api.github.com/users/StayYouth1993/following{/other_user}",
            "gists_url": "https://api.github.com/users/StayYouth1993/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/StayYouth1993/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/StayYouth1993/subscriptions",
            "organizations_url": "https://api.github.com/users/StayYouth1993/orgs",
            "repos_url": "https://api.github.com/users/StayYouth1993/repos",
            "events_url": "https://api.github.com/users/StayYouth1993/events{/privacy}",
            "received_events_url": "https://api.github.com/users/StayYouth1993/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-13T07:06:17Z",
        "updated_at": "2022-04-13T07:06:17Z",
        "author_association": "NONE",
        "body": "@fdwr thanks for your patient answerï¼Œ\r\n\r\nI run this exe you provided on my laptop shows result as follow(the exe seems not able to switch gpu index):\r\n```cmd\r\nAdapter 'Intel(R) HD Graphics 630' (27.20.100.8854)\r\nGetFeatureLevel: 49408\r\nIsTypedUAVSupported: 1\r\nIsTypedUAVLoadAdditionalFormatsSupported: 1 (uint8/int8/uint16/int16/float16)\r\nIsNativeFloat16Supported: 1 (uint16/int16/float16)\r\nIsInt64ShaderOpsSupported: 1 (uint64/int64)\r\nIsFloat64ShaderOpsSupported: 1 (float64)\r\nIsMin16FloatSupported: 1\r\nIsMcdmDevice: 0\r\nIsGraphNoopRemovalDisabled: 0\r\nIsGraphAutoHalfPrecisionDisabled: 0\r\nIsNvidia: 0\r\nIsAmd: 0\r\nIsIntel: 1\r\nIsQualcomm: 0\r\nIs16LaneWaveIntrinsicSupported: 1\r\nIsWaveIntrinsicSupported: 1\r\nIsDxilSupported: 1\r\nIsWaveSizeAttributeSupported: 0\r\nIsDP4ASupported: 1\r\nGetTotalLaneCount: 384\r\nGetWarpCount: 24\r\nVendorID: 32902\r\n```\r\n\r\nI run a test on both of my laptop gpu, code like this:\r\n```python\r\nimport time\r\nimport numpy as np\r\nimport onnxruntime as rt\r\n\r\n\r\n# use hd630 igpu*************************************************************************************************\r\n# --------------------------fp32 start----------------------------\r\nops = rt.SessionOptions()\r\nops.enable_mem_pattern = False\r\n\r\nsess = rt.InferenceSession(\"bres256_core_sim.onnx\", sess_options=ops, providers=[('DmlExecutionProvider', {\r\n    'device_id': 0,\r\n})])\r\n\r\nout_names = [each.name for each in sess.get_outputs()]\r\nresult = sess.run(out_names, {\"img\": np.random.random((1, 3, 256, 256)).astype(np.float32)})\r\ndata = [np.random.random((1, 3, 256, 256)).astype(np.float32) for _ in range(50)]\r\n\r\nstart = time.time()\r\nfor i in range(50):\r\n    result = sess.run(out_names, {\"img\": data[i]})\r\nend = time.time()\r\navg_time = (end - start) / 50.0\r\nprint(f'resnet 50 infer with hd630 use onnx directml fps is :{1 / avg_time}')\r\ndel sess\r\n# --------------------------fp32 end----------------------------\r\n\r\n\r\n# --------------------------fp16 start----------------------------\r\nops = rt.SessionOptions()\r\nops.enable_mem_pattern = False\r\n\r\nsess = rt.InferenceSession(\"bres256_core_sim_fp16.onnx\", sess_options=ops, providers=[('DmlExecutionProvider', {\r\n    'device_id': 0,\r\n})])\r\n\r\nout_names = [each.name for each in sess.get_outputs()]\r\nresult = sess.run(out_names, {\"img\": np.random.random((1, 3, 256, 256)).astype(np.float16)})\r\ndata = [np.random.random((1, 3, 256, 256)).astype(np.float16) for _ in range(50)]\r\n\r\nstart = time.time()\r\nfor i in range(50):\r\n    result = sess.run(out_names, {\"img\": data[i]})\r\nend = time.time()\r\navg_time = (end - start) / 50.0\r\nprint(f'resnet 50 infer with hd630 use onnx directml fp16 fps is :{1 / avg_time}')\r\ndel sess\r\n# --------------------------fp16 end----------------------------\r\n\r\n\r\n# use nvidia 940M gpu *************************************************************************************************\r\n# --------------------------fp32 start----------------------------\r\nops = rt.SessionOptions()\r\nops.enable_mem_pattern = False\r\n\r\nsess = rt.InferenceSession(\"bres256_core_sim.onnx\", sess_options=ops, providers=[('DmlExecutionProvider', {\r\n    'device_id': 1,\r\n})])\r\n\r\nout_names = [each.name for each in sess.get_outputs()]\r\nresult = sess.run(out_names, {\"img\": np.random.random((1, 3, 256, 256)).astype(np.float32)})\r\ndata = [np.random.random((1, 3, 256, 256)).astype(np.float32) for _ in range(50)]\r\n\r\nstart = time.time()\r\nfor i in range(50):\r\n    result = sess.run(out_names, {\"img\": data[i]})\r\nend = time.time()\r\navg_time = (end - start) / 50.0\r\nprint(f'resnet 50 infer with nvidia 940M use onnx directml fps is :{1 / avg_time}')\r\ndel sess\r\n# --------------------------fp32 end----------------------------\r\n\r\n\r\n# --------------------------fp16 start----------------------------\r\nops = rt.SessionOptions()\r\nops.enable_mem_pattern = False\r\n\r\nsess = rt.InferenceSession(\"bres256_core_sim_fp16.onnx\", sess_options=ops, providers=[('DmlExecutionProvider', {\r\n    'device_id': 1,\r\n})])\r\n\r\nout_names = [each.name for each in sess.get_outputs()]\r\nresult = sess.run(out_names, {\"img\": np.random.random((1, 3, 256, 256)).astype(np.float16)})\r\ndata = [np.random.random((1, 3, 256, 256)).astype(np.float16) for _ in range(50)]\r\n\r\nstart = time.time()\r\nfor i in range(50):\r\n    result = sess.run(out_names, {\"img\": data[i]})\r\nend = time.time()\r\navg_time = (end - start) / 50.0\r\nprint(f'resnet 50 infer with nvidia 940M use onnx directml fp16 fps is :{1 / avg_time}')\r\ndel sess\r\n# --------------------------fp16 end----------------------------\r\n```\r\nresult is:\r\n```shell\r\nresnet 50 infer with hd630 use onnx directml fps is :11.71859092062222\r\nresnet 50 infer with hd630 use onnx directml fp16 fps is :15.214315132300175\r\nresnet 50 infer with nvidia 940M use onnx directml fps is :28.60388253535604\r\nresnet 50 infer with nvidia 940M use onnx directml fp16 fps is :31.6515174497095\r\n```\r\n\r\nyou could check code and model from: [https://github.com/StayYouth1993/benchmark_onnx_directml](https://github.com/StayYouth1993/benchmark_onnx_directml)\r\n\r\nAlsoï¼Œ I tested this onnx model on openvino, which could accelerate from 15 fps to 30fps with fp16 mode on hd630 igpu.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1097634296/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]