[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070318478",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10905#issuecomment-1070318478",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10905",
        "id": 1070318478,
        "node_id": "IC_kwDOCVq1mM4_y8OO",
        "user": {
            "login": "wschin",
            "id": 3524474,
            "node_id": "MDQ6VXNlcjM1MjQ0NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3524474?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wschin",
            "html_url": "https://github.com/wschin",
            "followers_url": "https://api.github.com/users/wschin/followers",
            "following_url": "https://api.github.com/users/wschin/following{/other_user}",
            "gists_url": "https://api.github.com/users/wschin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wschin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wschin/subscriptions",
            "organizations_url": "https://api.github.com/users/wschin/orgs",
            "repos_url": "https://api.github.com/users/wschin/repos",
            "events_url": "https://api.github.com/users/wschin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wschin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T04:37:59Z",
        "updated_at": "2022-03-17T04:37:59Z",
        "author_association": "MEMBER",
        "body": "Some graph fusion could take place and generate ONNX model with non-standard operators. You can do\r\n```\r\nimport onnx\r\nm = onnx.load(\"model_repo/1/model.onnx\")\r\nfor n in m.graph.node:\r\n print(n.type)\r\n```\r\nto see if every operator is defined in the official ONNX [spec](https://github.com/onnx/onnx/blob/main/docs/Operators.md). Note that ONNXRuntime and TensorRT are two different computation engines, so they can support different sets of operators. On the other hand, if speed is the only concern, ONNXRuntime has buil-in TensorRT support. You don't need to run TensorRT by yourself.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070318478/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1072649358",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10905#issuecomment-1072649358",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10905",
        "id": 1072649358,
        "node_id": "IC_kwDOCVq1mM4_71SO",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-18T17:47:05Z",
        "updated_at": "2022-03-18T17:47:05Z",
        "author_association": "MEMBER",
        "body": "The error is because some fused ops in the model is not supported by TensorRT. Those fused ops are generated by onnxruntime.transformers.optimizer and only work for ORT-CUDA EP. Please use original ONNX model without transformer optimization in ORT-TRT EP, where TRT will apply its own optimizations.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1072649358/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]