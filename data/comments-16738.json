[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638121965",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16738#issuecomment-1638121965",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16738",
        "id": 1638121965,
        "node_id": "IC_kwDOCVq1mM5ho8Ht",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-17T13:15:49Z",
        "updated_at": "2023-07-17T13:15:49Z",
        "author_association": "MEMBER",
        "body": "Looks like tensor in the model with name \"/duration_predictor/flows.4/Reshape_27_output_0\" has size 0. I think it may be because you are using random generated calibration data. For quantization, you need to use carefully selected real data set to get good accuracy. \r\n\r\nAnd could you please share the augmented model?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638121965/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638240686",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16738#issuecomment-1638240686",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16738",
        "id": 1638240686,
        "node_id": "IC_kwDOCVq1mM5hpZGu",
        "user": {
            "login": "mllopartbsc",
            "id": 133785234,
            "node_id": "U_kgDOB_lmkg",
            "avatar_url": "https://avatars.githubusercontent.com/u/133785234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mllopartbsc",
            "html_url": "https://github.com/mllopartbsc",
            "followers_url": "https://api.github.com/users/mllopartbsc/followers",
            "following_url": "https://api.github.com/users/mllopartbsc/following{/other_user}",
            "gists_url": "https://api.github.com/users/mllopartbsc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mllopartbsc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mllopartbsc/subscriptions",
            "organizations_url": "https://api.github.com/users/mllopartbsc/orgs",
            "repos_url": "https://api.github.com/users/mllopartbsc/repos",
            "events_url": "https://api.github.com/users/mllopartbsc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mllopartbsc/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-17T14:16:13Z",
        "updated_at": "2023-07-17T14:18:23Z",
        "author_association": "NONE",
        "body": "Hi @yufenglee,\r\n\r\nThank you for the prompt response. The Coqui VITS ONNX is a text to speech model. Therefore, since the input data needed are English sentences, that is precisely what I'm generating inside the sentences list. I don't see any problem with that. What do you mean by carefully selected real datasets? And what would be the difference with what I'm inputting? \r\n\r\nOn the other hand, when I run my script, no \"augmented_model.onnx\" is created. Because of that, I can't share it with you. However, at some point there was an augmented_model.onnx created, but I deleted it because it was from the bert static quantization example I believe. Isn't it supposedly created after every instance?\r\n\r\n[Here's the script](https://github.com/coqui-ai/TTS/blob/dev/TTS/tts/models/vits.py) used to convert the VITS model to ONNX. It may give you some insights on the workings of the dummy inputs and the expected input. \r\n\r\nKind Regards",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638240686/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638306727",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16738#issuecomment-1638306727",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16738",
        "id": 1638306727,
        "node_id": "IC_kwDOCVq1mM5hppOn",
        "user": {
            "login": "mllopartbsc",
            "id": 133785234,
            "node_id": "U_kgDOB_lmkg",
            "avatar_url": "https://avatars.githubusercontent.com/u/133785234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mllopartbsc",
            "html_url": "https://github.com/mllopartbsc",
            "followers_url": "https://api.github.com/users/mllopartbsc/followers",
            "following_url": "https://api.github.com/users/mllopartbsc/following{/other_user}",
            "gists_url": "https://api.github.com/users/mllopartbsc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mllopartbsc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mllopartbsc/subscriptions",
            "organizations_url": "https://api.github.com/users/mllopartbsc/orgs",
            "repos_url": "https://api.github.com/users/mllopartbsc/repos",
            "events_url": "https://api.github.com/users/mllopartbsc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mllopartbsc/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-17T14:50:01Z",
        "updated_at": "2023-07-17T15:01:53Z",
        "author_association": "NONE",
        "body": "In regards to the last comment, I commented  out the following section of my script:\r\n\r\n```\r\n# Generate 50 random sentences\r\nsubjects = [\"I\", \"You\", \"Bob\", \"Alice\", \"The cat\", \"The robot\"]\r\nverbs = [\"like\", \"hate\", \"see\", \"touch\", \"admire\", \"love\"]\r\nobjects = [\"apples\", \"the moon\", \"the rain\", \"a beautiful painting\", \"the idea of existence\", \"the sound of the ocean\"]\r\n\r\n\r\nsentences = []\r\nfor i in range(50):\r\n    subject = random.choice(subjects)\r\n    verb = random.choice(verbs)\r\n    object = random.choice(objects)\r\n    sentence = f\"{subject} {verb} {object}.\"\r\n    sentences.append(sentence)\r\n```\r\n\r\nAnd changed for this hand-made list of 50 English sentences:\r\n\r\n```\r\nsentences = [\r\n    \"The sky is blue.\",\r\n    \"I love apples.\",\r\n    \"She is reading a book.\",\r\n    \"I have a pet dog.\",\r\n    \"I like to play soccer.\",\r\n    \"Python is a powerful language.\",\r\n    \"The sun sets in the west.\",\r\n    \"The food here is delicious.\",\r\n    \"I am going to the park.\",\r\n    \"The cake is in the oven.\",\r\n    \"He is playing the guitar.\",\r\n    \"It is raining outside.\",\r\n    \"I am baking cookies.\",\r\n    \"I enjoy reading novels.\",\r\n    \"She likes to play tennis.\",\r\n    \"We are going on a trip.\",\r\n    \"I am learning Spanish.\",\r\n    \"He is practicing the piano.\",\r\n    \"She loves to dance.\",\r\n    \"The dog is sleeping.\",\r\n    \"I am eating a sandwich.\",\r\n    \"They are watching a movie.\",\r\n    \"She has a red bicycle.\",\r\n    \"I am visiting my grandparents.\",\r\n    \"I lost my keys.\",\r\n    \"The birds are singing.\",\r\n    \"I am drinking coffee.\",\r\n    \"He is studying for the exam.\",\r\n    \"I went to the beach.\",\r\n    \"I am learning to cook.\",\r\n    \"The cat is playing with a ball.\",\r\n    \"She is brushing her hair.\",\r\n    \"He has a blue car.\",\r\n    \"I am painting a picture.\",\r\n    \"She is feeding the birds.\",\r\n    \"The pizza is delicious.\",\r\n    \"I saw a beautiful sunset.\",\r\n    \"I am playing video games.\",\r\n    \"She is knitting a scarf.\",\r\n    \"They are planting flowers.\",\r\n    \"The moon is full tonight.\",\r\n    \"I am writing a letter.\",\r\n    \"The ice cream is melting.\",\r\n    \"She is washing the dishes.\",\r\n    \"I am going for a run.\",\r\n    \"He is fixing the computer.\",\r\n    \"I am listening to music.\",\r\n    \"The coffee is hot.\",\r\n    \"I am cleaning the house.\",\r\n    \"He is driving a truck.\"\r\n]\r\n```\r\nSo that they're not randomly generated.\r\n\r\nWithout modifying the path of the augmented model in the calibrate.py script, this is the error that emerges:\r\n\r\n```\r\nWARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \r\n2023-07-17 16:41:31.575414164 [W:onnxruntime:, execution_frame.cc:651 AllocateMLValueTensorPreAllocateBuffer] Shape mismatch attempting to re-use buffer. {1} != {0}. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.\r\n2023-07-17 16:41:31.575516224 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Reshape node. Name:'/duration_predictor/flows.2/Reshape_27_output_0_ReduceMax_Reshape' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:40 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, onnxruntime::TensorShapeVector&, bool) gsl::narrow_cast<int64_t>(input_shape.Size()) == size was false. The input tensor cannot be reshaped to the requested shape. Input shape:{0}, requested shape:{1}\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/tts-api/server/static_quantization.py\", line 196, in <module>\r\n    quantize_static(model_name, quantize_name, calibration_data_reader=DataReader(x, x_lengths, scales), quant_format=QuantFormat.QDQ)\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/quantization/quantize.py\", line 369, in quantize_static\r\n    calibrator.collect_data(calibration_data_reader)\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/quantization/calibrate.py\", line 243, in collect_data\r\n    self.intermediate_outputs.append(self.infer_session.run(None, inputs))\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 217, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Reshape node. Name:'/duration_predictor/flows.2/Reshape_27_output_0_ReduceMax_Reshape' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:40 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, onnxruntime::TensorShapeVector&, bool) gsl::narrow_cast<int64_t>(input_shape.Size()) == size was false. The input tensor cannot be reshaped to the requested shape. Input shape:{0}, requested shape:{1}\r\n\r\n```\r\n\r\nIf I modify the path of the session to the VITS model, then this error emerges from the quantize.py script:\r\n\r\n```\r\nWARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\r\nWARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\r\n.\r\n.\r\n.\r\nWARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\r\nTraceback (most recent call last):\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/tts-api/server/static_quantization.py\", line 201, in <module>\r\n    quantize_static(model_name, quantize_name, calibration_data_reader=DataReader(x, x_lengths, scales), quant_format=QuantFormat.QDQ)\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/quantization/quantize.py\", line 406, in quantize_static\r\n    quantizer.quantize_model()\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/quantization/qdq_quantizer.py\", line 217, in quantize_model\r\n    self._quantize_normal_tensors()\r\n  File \"/home/mllopart/PycharmProjects/ttsAPI/venv/lib/python3.10/site-packages/onnxruntime/quantization/qdq_quantizer.py\", line 385, in _quantize_normal_tensors\r\n    raise ValueError(\r\nValueError: Quantization parameters are not specified for param /text_encoder/Constant_output_0. In static mode quantization params for inputs and outputs of nodes to be quantized are required.\r\n\r\n```\r\n\r\nTherefore, I get the same errors if I don't generate the input data randomly.\r\n\r\nAgain, thank you for the quick answer.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1638306727/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]