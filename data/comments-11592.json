[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1134930287",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1134930287",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1134930287,
        "node_id": "IC_kwDOCVq1mM5Dpalv",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-23T17:08:28Z",
        "updated_at": "2022-05-23T17:16:51Z",
        "author_association": "MEMBER",
        "body": "The error image might have been more helpful if you simply copied text in full, rather than cropped image. However, it is clear, that CUDA is probably less forgiving in accessing memory regions that are not allocated. \r\n\r\nWhen you pass in input image size and output size, you calculate them off the dimension vectors that you declared. But do those dimensions and sizes match the actual buffers from the matrices on the input ?\r\n\r\nIt is also not clear what `max_element` is doing? Is it `std::max_element`? If it is, not clear what kind of function it is using to compare Ort::Values that are stored in the vectors, there is only one output anyway, and it is not an integer, so it is not clear how it is compiling.\r\n\r\nAs a side note, you are also leaking small pieces of memory obtained from `GetInputName`, `GetOutputName`",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1134930287/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1135460215",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1135460215",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1135460215,
        "node_id": "IC_kwDOCVq1mM5Drb93",
        "user": {
            "login": "abilashravi-ta",
            "id": 53215532,
            "node_id": "MDQ6VXNlcjUzMjE1NTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/53215532?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abilashravi-ta",
            "html_url": "https://github.com/abilashravi-ta",
            "followers_url": "https://api.github.com/users/abilashravi-ta/followers",
            "following_url": "https://api.github.com/users/abilashravi-ta/following{/other_user}",
            "gists_url": "https://api.github.com/users/abilashravi-ta/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abilashravi-ta/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abilashravi-ta/subscriptions",
            "organizations_url": "https://api.github.com/users/abilashravi-ta/orgs",
            "repos_url": "https://api.github.com/users/abilashravi-ta/repos",
            "events_url": "https://api.github.com/users/abilashravi-ta/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abilashravi-ta/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-24T06:24:40Z",
        "updated_at": "2022-05-24T06:24:40Z",
        "author_association": "NONE",
        "body": "> The error image might have been more helpful if you simply copied text in full, rather than cropped image. However, it is clear, that CUDA is probably less forgiving in accessing memory regions that are not allocated.\r\n> \r\n> When you pass in input image size and output size, you calculate them off the dimension vectors that you declared. But do those dimensions and sizes match the actual buffers from the matrices on the input ?\r\n> \r\n> It is also not clear what `max_element` is doing? Is it `std::max_element`? If it is, not clear what kind of function it is using to compare Ort::Values that are stored in the vectors, there is only one output anyway, and it is not an integer, so it is not clear how it is compiling.\r\n> \r\n> As a side note, you are also leaking small pieces of memory obtained from `GetInputName`, `GetOutputName`\r\n\r\nI modified the code as per your suggestion @yuslepukhin.\r\nThis is the new `inference.cpp` script\r\n```\r\n#include<onnxruntime_cxx_api.h>\r\n\r\n#include<opencv2/dnn/dnn.hpp>\r\n#include<opencv2/imgcodecs.hpp>\r\n#include<opencv2/imgproc.hpp>\r\n\r\n#include<fstream>\r\n#include<iostream>\r\n#include<string>\r\n#include<vector>\r\n#include<numeric>\r\n\r\nusing namespace std;\r\n\r\ntemplate<class T>\r\nT vectorProduct(vector<T>& v)\r\n{\r\n        return accumulate(v.begin(), v.end(), 1, multiplies<T>());\r\n}\r\n\r\nint main()\r\n{\r\n\r\n        string modelFilepath{\"squeezenet1.1-7.onnx\"};\r\n        Ort::Env env;\r\n        Ort::SessionOptions sessionOptions;\r\n\r\n        //following 2 lines are commented to run on CPU\r\n        OrtCUDAProviderOptions cuda_options{0};\r\n        sessionOptions.AppendExecutionProvider_CUDA(cuda_options);\r\n\r\n        Ort::Session session(env, modelFilepath.c_str(), sessionOptions);\r\n        Ort::AllocatorWithDefaultOptions allocator;\r\n\r\n        string imageFilepath{\"european-bee-eater-224X224.jpg\"};\r\n        cv::Mat imageBGR = cv::imread(imageFilepath);\r\n        cv::Mat preprocessedImage, resizedImage;\r\n        cv::dnn::blobFromImage(imageBGR, preprocessedImage);\r\n        preprocessedImage.convertTo(resizedImage, CV_32F, 1.0);\r\n\r\n        //for input\r\n        string inputName = session.GetInputName(0, allocator);\r\n        vector<string> inputNames{inputName};\r\n\r\n        Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);\r\n        auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n        vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n        size_t inputTensorSize = vectorProduct(inputDims);\r\n        vector<Ort::Value> inputTensors;\r\n\r\n        //for output\r\n        string outputName = session.GetOutputName(0, allocator);\r\n        vector<string> outputNames{outputName};\r\n\r\n        Ort::TypeInfo outputTypeInfo = session.GetOutputTypeInfo(0);\r\n        auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();\r\n        vector<int64_t> outputDims = outputTensorInfo.GetShape();\r\n        size_t outputTensorSize = vectorProduct(outputDims);\r\n        vector<float> outputTensorValues(outputTensorSize);\r\n        vector<Ort::Value> outputTensors;\r\n\r\n        Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n        inputTensors.push_back(Ort::Value::CreateTensor<float>(memoryInfo, (float*)resizedImage.data, inputTensorSize, inputDims.data(), inputDims.size()));\r\n        outputTensors.push_back(Ort::Value::CreateTensor<float>(memoryInfo, outputTensorValues.data(), outputTensorSize, outputDims.data(), outputDims.size()));\r\n\r\n        cout << \"Code ran till here 1.\" << endl;\r\n        session.Run(Ort::RunOptions{nullptr}, (char* const*)inputNames.data(), inputTensors.data(), 1, (char* const*)outputNames.data(), outputTensors.data(), 1);\r\n        cout << \"Code ran till here 2.\" << endl;\r\n\r\n        return 0;\r\n}\r\n```\r\n\r\nWhen I run on **CPU**, I get this\r\n```\r\nCode ran till here 1.\r\nCode ran till here 2.\r\n```\r\n\r\nBut, when I run on **GPU**, I get this\r\n```\r\nCode ran till here 1.\r\n2022-05-24 06:18:15.633984721 [E:onnxruntime:, cuda_call.cc:117 CudaCall] CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; GPU=0 ; hostname=gpuvm-perfprofiling ; expr=cudnnFindConvolutionForwardAlgorithmEx( CudnnHandle(), s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), AlgoSearchWorkspaceSize);\r\n2022-05-24 06:18:15.634050020 [E:onnxruntime:, sequential_executor.cc:339 Execute] Non-zero status code returned while running FusedConv node. Name:'squeezenet0_conv0_fwd_squeezenet0_relu0_fwd' Status Message: CUDNN error executing cudnnFindConvolutionForwardAlgorithmEx( CudnnHandle(), s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), AlgoSearchWorkspaceSize)\r\n2022-05-24 06:18:15.634097220 [E:onnxruntime:, cuda_call.cc:117 CudaCall] CUDA failure 700: an illegal memory access was encountered ; GPU=0 ; hostname=gpuvm-perfprofiling ; expr=cudaEventRecord(current_deferred_release_event, static_cast<cudaStream_t>(GetComputeStream()));\r\nAborted (core dumped)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1135460215/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136236771",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1136236771",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1136236771,
        "node_id": "IC_kwDOCVq1mM5DuZjj",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-24T17:27:06Z",
        "updated_at": "2022-05-24T17:39:19Z",
        "author_association": "MEMBER",
        "body": "> 2022-05-24 06:18:15.634097220 [E:onnxruntime:, cuda_call.cc:117 CudaCall] CUDA failure 700: an illegal memory access was encountered ; GPU=0 ; hostname=gpuvm-perfprofiling ; \r\n\r\nI think the program is still trying to access the unallocated memory. Make sure that the size of the input data is what your dimensions indicate. You are passing metadata dimensions now for input. However, you are just passing in what the system expects, not necessarily what your image is in the reality.\r\n\r\nOne way to debug on CPU is to disable memory arena and run memory profiler. You need to use a debugger, logging would not help.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136236771/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136711756",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1136711756",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1136711756,
        "node_id": "IC_kwDOCVq1mM5DwNhM",
        "user": {
            "login": "abilashravi-ta",
            "id": 53215532,
            "node_id": "MDQ6VXNlcjUzMjE1NTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/53215532?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abilashravi-ta",
            "html_url": "https://github.com/abilashravi-ta",
            "followers_url": "https://api.github.com/users/abilashravi-ta/followers",
            "following_url": "https://api.github.com/users/abilashravi-ta/following{/other_user}",
            "gists_url": "https://api.github.com/users/abilashravi-ta/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abilashravi-ta/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abilashravi-ta/subscriptions",
            "organizations_url": "https://api.github.com/users/abilashravi-ta/orgs",
            "repos_url": "https://api.github.com/users/abilashravi-ta/repos",
            "events_url": "https://api.github.com/users/abilashravi-ta/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abilashravi-ta/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-25T04:26:47Z",
        "updated_at": "2022-05-25T04:26:47Z",
        "author_association": "NONE",
        "body": "> I think the program is still trying to access the unallocated memory. Make sure that the size of the input data is what your dimensions indicate. You are passing metadata dimensions now for input. However, you are just passing in what the system expects, not necessarily what your image is in the reality.\r\n\r\nI modified the code to print out the _input image size_ and _inference input size_ @yuslepukhin.\r\nThis is the new `inference.cpp` script\r\n```\r\n#include<onnxruntime_cxx_api.h>\r\n\r\n#include<opencv2/dnn/dnn.hpp>\r\n#include<opencv2/imgcodecs.hpp>\r\n#include<opencv2/imgproc.hpp>\r\n\r\n#include<fstream>\r\n#include<iostream>\r\n#include<string>\r\n#include<vector>\r\n#include<numeric>\r\n\r\nusing namespace std;\r\n\r\ntemplate<class T>\r\nT vectorProduct(vector<T>& v)\r\n{\r\n        return accumulate(v.begin(), v.end(), 1, multiplies<T>());\r\n}\r\n\r\ntemplate<class T>\r\nostream& operator<<(ostream& os, vector<T>& v)\r\n{\r\n        os << \"[\";\r\n        for (int i=0; i<v.size(); ++i)\r\n        {\r\n                os << v[i];\r\n                if (i != v.size()-1)\r\n                        os << \", \";\r\n        }\r\n        os << \"]myPrintFunc\";\r\n        return os;\r\n}\r\n\r\nint main()\r\n{\r\n\r\n        string modelFilepath{\"squeezenet1.1-7.onnx\"};\r\n        Ort::Env env;\r\n        Ort::SessionOptions sessionOptions;\r\n\r\n        //following 2 lines are commented to run on CPU\r\n        OrtCUDAProviderOptions cuda_options{0};\r\n        sessionOptions.AppendExecutionProvider_CUDA(cuda_options);\r\n\r\n        Ort::Session session(env, modelFilepath.c_str(), sessionOptions);\r\n        Ort::AllocatorWithDefaultOptions allocator;\r\n\r\n        string imageFilepath{\"european-bee-eater-224X224.jpg\"};\r\n        cv::Mat imageBGR = cv::imread(imageFilepath);\r\n        cv::Mat preprocessedImage, resizedImage;\r\n        cv::dnn::blobFromImage(imageBGR, preprocessedImage);\r\n        preprocessedImage.convertTo(resizedImage, CV_32F, 1.0);\r\n        cout << \"resizedImage.size: \" << resizedImage.size << endl;\r\n\r\n        //for input\r\n        string inputName = session.GetInputName(0, allocator);\r\n        vector<string> inputNames{inputName};\r\n\r\n        Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);\r\n        auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n        vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n        size_t inputTensorSize = vectorProduct(inputDims);\r\n        vector<Ort::Value> inputTensors;\r\n        cout << \"inputDims: \" << inputDims << endl;\r\n\r\n        //for output\r\n        string outputName = session.GetOutputName(0, allocator);\r\n        vector<string> outputNames{outputName};\r\n\r\n        Ort::TypeInfo outputTypeInfo = session.GetOutputTypeInfo(0);\r\n        auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();\r\n        vector<int64_t> outputDims = outputTensorInfo.GetShape();\r\n        size_t outputTensorSize = vectorProduct(outputDims);\r\n        vector<float> outputTensorValues(outputTensorSize);\r\n        vector<Ort::Value> outputTensors;\r\n        cout << \"outputDims: \" << outputDims << endl;\r\n\r\n        Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n        inputTensors.push_back(Ort::Value::CreateTensor<float>(memoryInfo, (float*)resizedImage.data, inputTensorSize, inputDims.data(), inputDims.size()));\r\n        outputTensors.push_back(Ort::Value::CreateTensor<float>(memoryInfo, outputTensorValues.data(), outputTensorSize, outputDims.data(), outputDims.size()));\r\n        cout << \"Code ran till here 1.\" << endl;\r\n        session.Run(Ort::RunOptions{nullptr}, (char* const*)inputNames.data(), inputTensors.data(), 1, (char* const*)outputNames.data(), outputTensors.data(), 1);\r\n        cout << \"Code ran till here 2.\" << endl;\r\n\r\n        return 0;\r\n}\r\n```\r\n\r\nWhen I run on **CPU**, I get this (successful execution.!)\r\n```\r\nresizedImage.size: 1 x 3 x 224 x 224\r\ninputDims: [1, 3, 224, 224]myPrintFunc\r\noutputDims: [1, 1000]myPrintFunc\r\nCode ran till here 1.\r\nCode ran till here 2.\r\n```\r\n\r\nBut, when I run on **GPU**, I get this\r\n```\r\nresizedImage.size: 1 x 3 x 224 x 224\r\ninputDims: [1, 3, 224, 224]myPrintFunc\r\noutputDims: [1, 1000]myPrintFunc\r\nCode ran till here 1.\r\n2022-05-25 04:20:23.895368568 [E:onnxruntime:, cuda_call.cc:117 CudaCall] CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; GPU=0 ; hostname=gpuvm-perfprofiling ; expr=cudnnFindConvolutionForwardAlgorithmEx( CudnnHandle(), s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), AlgoSearchWorkspaceSize);\r\n2022-05-25 04:20:23.895430369 [E:onnxruntime:, sequential_executor.cc:339 Execute] Non-zero status code returned while running FusedConv node. Name:'squeezenet0_conv0_fwd_squeezenet0_relu0_fwd' Status Message: CUDNN error executing cudnnFindConvolutionForwardAlgorithmEx( CudnnHandle(), s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.y_tensor, s_.y_data, 1, &algo_count, &perf, algo_search_workspace.get(), AlgoSearchWorkspaceSize)\r\n2022-05-25 04:20:23.895509669 [E:onnxruntime:, cuda_call.cc:117 CudaCall] CUDA failure 700: an illegal memory access was encountered ; GPU=0 ; hostname=gpuvm-perfprofiling ; expr=cudaEventRecord(current_deferred_release_event, static_cast<cudaStream_t>(GetComputeStream()));\r\nAborted (core dumped)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136711756/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136712783",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1136712783",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1136712783,
        "node_id": "IC_kwDOCVq1mM5DwNxP",
        "user": {
            "login": "abilashravi-ta",
            "id": 53215532,
            "node_id": "MDQ6VXNlcjUzMjE1NTMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/53215532?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abilashravi-ta",
            "html_url": "https://github.com/abilashravi-ta",
            "followers_url": "https://api.github.com/users/abilashravi-ta/followers",
            "following_url": "https://api.github.com/users/abilashravi-ta/following{/other_user}",
            "gists_url": "https://api.github.com/users/abilashravi-ta/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abilashravi-ta/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abilashravi-ta/subscriptions",
            "organizations_url": "https://api.github.com/users/abilashravi-ta/orgs",
            "repos_url": "https://api.github.com/users/abilashravi-ta/repos",
            "events_url": "https://api.github.com/users/abilashravi-ta/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abilashravi-ta/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-25T04:28:48Z",
        "updated_at": "2022-05-25T04:29:16Z",
        "author_association": "NONE",
        "body": "> One way to debug on CPU is to disable memory arena and run memory profiler. You need to use a debugger, logging would not help.\r\n\r\nIs there any documentation or demo which elaborates on _memory arena_ and _memory profiler_ that I can follow?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1136712783/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1137845283",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11592#issuecomment-1137845283",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11592",
        "id": 1137845283,
        "node_id": "IC_kwDOCVq1mM5D0iQj",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-25T21:02:11Z",
        "updated_at": "2022-05-25T21:02:11Z",
        "author_association": "MEMBER",
        "body": "To disable memory arena you need to call [DisableMemoryArena()](https://github.com/microsoft/onnxruntime/blob/cd7fd808e7557cf08c8786e1c04de654d353b342/include/onnxruntime/core/session/onnxruntime_cxx_api.h#L339) on `SessonOptions`. I would also recomment to call `DisableMemPattern()`.\r\n\r\nWhat this would do is to disable our memory allocator and pass on all memory allocation calls to the operating system where the profiler can track them. The assumption is that if there is a problem with accessing memory that is not allocated or used after it was deallocated, it can still be tracked in normal (no-GPU) memory.\r\n\r\nWe do not ship memory profilers and do not document them, you can choose your favorite one, such as `valgrind` for linux. There are great tools for that on windows, such as Application Verifier. All of them require some expertise.\r\n\r\nLikely, though, if you followed my recommendation and simply check the length of the data being passed, you would avoid doing any of that.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1137845283/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]