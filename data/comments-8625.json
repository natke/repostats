[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894733832",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-894733832",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 894733832,
        "node_id": "IC_kwDOCVq1mM41VI4I",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-08T02:40:29Z",
        "updated_at": "2021-08-08T02:40:29Z",
        "author_association": "MEMBER",
        "body": "@MoranMahabi, it is expected that quantization can introduce accuracy loss. It depends on the model how much accuracy loss there will be. You can try per-channel and reduce range and see if the option can improve the accuracy: https://onnxruntime.ai/docs/how-to/quantization.html#when-to-use-per-channel-and-reduce-range.\r\n\r\nBTW, why do you do padding? OnnxRuntime/ONNX supports dynamic shape. Does it work for you case? Search dynamic_axes from https://pytorch.org/docs/stable/onnx.html if your original framework is PyTorch.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894733832/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894741286",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-894741286",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 894741286,
        "node_id": "IC_kwDOCVq1mM41VKsm",
        "user": {
            "login": "MoranMahabi",
            "id": 37874078,
            "node_id": "MDQ6VXNlcjM3ODc0MDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/37874078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MoranMahabi",
            "html_url": "https://github.com/MoranMahabi",
            "followers_url": "https://api.github.com/users/MoranMahabi/followers",
            "following_url": "https://api.github.com/users/MoranMahabi/following{/other_user}",
            "gists_url": "https://api.github.com/users/MoranMahabi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MoranMahabi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MoranMahabi/subscriptions",
            "organizations_url": "https://api.github.com/users/MoranMahabi/orgs",
            "repos_url": "https://api.github.com/users/MoranMahabi/repos",
            "events_url": "https://api.github.com/users/MoranMahabi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MoranMahabi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-08T04:28:52Z",
        "updated_at": "2021-08-08T07:31:34Z",
        "author_association": "NONE",
        "body": "Thanks! \r\n\r\nI understand that quantization can introduce accuracy loss, but why accuracy is different with different padding on the same sentences?\r\n\r\nI used padding since I want perform Batch inferencing as in https://github.com/microsoft/onnxruntime/issues/8030, and I used dynamic_axes.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894741286/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894948296",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-894948296",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 894948296,
        "node_id": "IC_kwDOCVq1mM41V9PI",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-09T04:50:14Z",
        "updated_at": "2021-08-09T04:50:14Z",
        "author_association": "MEMBER",
        "body": "So you are inferencing with multi-batch? As you are using dynamic quantization, the scale and zero point will be calculated dynamically with the whole batch data, so the scale and zero point will be different with different batch size. For an example, you have 2 different tensors [-2.f, 1.f], [-1.f, 2.f, 0.3f]. If you compute them one by one, the scales are 3.f/256 for both of them. If you compute them as batch, the scale will be 4.f/256, thus the result will be different with the cases that each sentence is computed one by one.\r\n\r\nI don't see why the padding has impact on the accuracy though. Are you testing the result with random/different orders? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/894948296/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/895024035",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-895024035",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 895024035,
        "node_id": "IC_kwDOCVq1mM41WPuj",
        "user": {
            "login": "MoranMahabi",
            "id": 37874078,
            "node_id": "MDQ6VXNlcjM3ODc0MDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/37874078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MoranMahabi",
            "html_url": "https://github.com/MoranMahabi",
            "followers_url": "https://api.github.com/users/MoranMahabi/followers",
            "following_url": "https://api.github.com/users/MoranMahabi/following{/other_user}",
            "gists_url": "https://api.github.com/users/MoranMahabi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MoranMahabi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MoranMahabi/subscriptions",
            "organizations_url": "https://api.github.com/users/MoranMahabi/orgs",
            "repos_url": "https://api.github.com/users/MoranMahabi/repos",
            "events_url": "https://api.github.com/users/MoranMahabi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MoranMahabi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-09T07:58:04Z",
        "updated_at": "2021-08-09T16:16:08Z",
        "author_association": "NONE",
        "body": "Thanks @yufenglee!\r\n\r\nWhy the scale is 4.f/256 if compute them as batch? As I understand it should be (2-(-1))/256=3/256.\r\n\r\nSo, with multi-batch inferencing I should expect the results will be different if the batch size is different in different runs?\r\n\r\nActually, in the results table above I computed the sentences one by one. I was interested in checking the running time per sentence but with different padding and I got different results. I didn't test the result with random/different orders, the order is the same order in different runs.\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/895024035/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/895642634",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-895642634",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 895642634,
        "node_id": "IC_kwDOCVq1mM41YmwK",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-10T00:35:48Z",
        "updated_at": "2021-08-10T00:35:48Z",
        "author_association": "MEMBER",
        "body": "For batch [[-2.f, 1.f, 0.f], [-1.f, 2.f, 0.3f]], scale is computed with whole tensor, so it is (2-(-2))/256. So, yes, it is expected to get different results if batch size is different. \r\n\r\nIf you are running sentences one by one, it is not caused by this. Could you share a set of input and model that can repro this issue? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/895642634/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896027423",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-896027423",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 896027423,
        "node_id": "IC_kwDOCVq1mM41aEsf",
        "user": {
            "login": "MoranMahabi",
            "id": 37874078,
            "node_id": "MDQ6VXNlcjM3ODc0MDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/37874078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MoranMahabi",
            "html_url": "https://github.com/MoranMahabi",
            "followers_url": "https://api.github.com/users/MoranMahabi/followers",
            "following_url": "https://api.github.com/users/MoranMahabi/following{/other_user}",
            "gists_url": "https://api.github.com/users/MoranMahabi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MoranMahabi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MoranMahabi/subscriptions",
            "organizations_url": "https://api.github.com/users/MoranMahabi/orgs",
            "repos_url": "https://api.github.com/users/MoranMahabi/repos",
            "events_url": "https://api.github.com/users/MoranMahabi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MoranMahabi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-10T13:26:05Z",
        "updated_at": "2021-08-10T14:33:17Z",
        "author_association": "NONE",
        "body": "Thanks!\r\n\r\nI did some experiments. In the all experiment I run ONNX model and quantified ONNX model on the same 100 sentences, but I check in depth two sentences (the same sentences in all experiments):\r\n1. The first sentence is with 38 tokens.\r\n2. The second sentence is with 118 tokens.\r\n\r\n**Experiment 1:** \r\n1. In both sentences, the results of ONNX model are the same with different padding (no padding, padding 118, padding 128, padding 512) - **as expected**. \r\n2. In both sentences, the results of quantified ONNX model are different with different padding (in the second sentence the results with no padding and padding 118 are the same since the number of tokens with no padding is 118) - **so maybe the padding affect on the results?**\r\n3. The results of the first sentence are **different** with padding 128 and padding 512 with quantified ONNX model - if padding affect on the results, in this test should be the same results since the min_data_range and max_data_range are the same (128 > 38 and 512 > 38), but I got different results, so I think also the **position ids** of padding tokens affect on the results.\r\n\r\n\r\nIn Experiment 2, Experiment 3, I generated new ONNX model and new quantified ONNX model that got also position_ids as input. I used the same models in these experiments. \r\n\r\n**Experiment 2:** \r\n1. In both sentences, same results as in Experiment 1 - **as expected, since I send to model the default position_ids**. \r\n\r\n****Experiment 3:** send the same position_id to all padding tokens, for example [0,1,2,3,...,35,36,37,38,38,38,38,...,38]**\r\n1. In both sentences, the results of ONNX model are the same with different padding (no padding, padding 118, padding 128, padding 512) - **as expected**. \r\n2. The results of the first sentence are different with no padding  and padding 118 with quantified ONNX model - as expected, if scale also dependent on padding weights. \r\n3. The results of the first sentence are the **same** with padding 128 and padding 512 with quantified ONNX model - as expected, if scale also dependent on padding weights and dependent on position embeddings weights - the min_data_range and max_data_range are the same (128 > 38 and 512 > 38). \r\n\r\n\r\n\r\nIf this is not the expected behavior I will share the models and input example.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896027423/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896226088",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-896226088",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 896226088,
        "node_id": "IC_kwDOCVq1mM41a1Mo",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-10T18:41:10Z",
        "updated_at": "2021-08-10T18:41:10Z",
        "author_association": "MEMBER",
        "body": "Yes, it is expected. I think if you always pad 0 for position_id and an ever existed token id for input_id, it will get same result as non-padding one. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896226088/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896549934",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-896549934",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 896549934,
        "node_id": "IC_kwDOCVq1mM41cEQu",
        "user": {
            "login": "MoranMahabi",
            "id": 37874078,
            "node_id": "MDQ6VXNlcjM3ODc0MDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/37874078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MoranMahabi",
            "html_url": "https://github.com/MoranMahabi",
            "followers_url": "https://api.github.com/users/MoranMahabi/followers",
            "following_url": "https://api.github.com/users/MoranMahabi/following{/other_user}",
            "gists_url": "https://api.github.com/users/MoranMahabi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MoranMahabi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MoranMahabi/subscriptions",
            "organizations_url": "https://api.github.com/users/MoranMahabi/orgs",
            "repos_url": "https://api.github.com/users/MoranMahabi/repos",
            "events_url": "https://api.github.com/users/MoranMahabi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MoranMahabi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-08-11T06:53:18Z",
        "updated_at": "2021-08-11T06:53:18Z",
        "author_association": "NONE",
        "body": "I think so too.\r\nThank you @yufenglee!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/896549934/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/999344265",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-999344265",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 999344265,
        "node_id": "IC_kwDOCVq1mM47kMiJ",
        "user": {
            "login": "rohanshingade",
            "id": 18469762,
            "node_id": "MDQ6VXNlcjE4NDY5NzYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/18469762?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rohanshingade",
            "html_url": "https://github.com/rohanshingade",
            "followers_url": "https://api.github.com/users/rohanshingade/followers",
            "following_url": "https://api.github.com/users/rohanshingade/following{/other_user}",
            "gists_url": "https://api.github.com/users/rohanshingade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rohanshingade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rohanshingade/subscriptions",
            "organizations_url": "https://api.github.com/users/rohanshingade/orgs",
            "repos_url": "https://api.github.com/users/rohanshingade/repos",
            "events_url": "https://api.github.com/users/rohanshingade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rohanshingade/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-22T07:22:34Z",
        "updated_at": "2021-12-22T07:22:34Z",
        "author_association": "NONE",
        "body": "@MoranMahabi did you find a solution to run batch inference for quantized model? i tried batch inferencing, but results are varying\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/999344265/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/999640498",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-999640498",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8625",
        "id": 999640498,
        "node_id": "IC_kwDOCVq1mM47lU2y",
        "user": {
            "login": "MoranMahabi",
            "id": 37874078,
            "node_id": "MDQ6VXNlcjM3ODc0MDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/37874078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MoranMahabi",
            "html_url": "https://github.com/MoranMahabi",
            "followers_url": "https://api.github.com/users/MoranMahabi/followers",
            "following_url": "https://api.github.com/users/MoranMahabi/following{/other_user}",
            "gists_url": "https://api.github.com/users/MoranMahabi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MoranMahabi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MoranMahabi/subscriptions",
            "organizations_url": "https://api.github.com/users/MoranMahabi/orgs",
            "repos_url": "https://api.github.com/users/MoranMahabi/repos",
            "events_url": "https://api.github.com/users/MoranMahabi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MoranMahabi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-22T15:02:03Z",
        "updated_at": "2021-12-22T15:02:03Z",
        "author_association": "NONE",
        "body": "@rohanshingade, I run batch inference as in #8030. \r\n\r\nIt is expected to get varying results if you test the results with random/different orders or different batch size as explained in https://github.com/microsoft/onnxruntime/issues/8625#issuecomment-894948296.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/999640498/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]