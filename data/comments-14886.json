[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1452705140",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1452705140",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1452705140,
        "node_id": "IC_kwDOCVq1mM5WloV0",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-02T23:12:53Z",
        "updated_at": "2023-03-02T23:12:53Z",
        "author_association": "MEMBER",
        "body": "@wangyems, could you take a look?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1452705140/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1452709672",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1452709672",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1452709672,
        "node_id": "IC_kwDOCVq1mM5Wlpco",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-02T23:17:05Z",
        "updated_at": "2023-03-02T23:17:05Z",
        "author_association": "MEMBER",
        "body": "The T-5 optimization is in progress. we will take a look at this model then.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1452709672/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1509023465",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1509023465",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1509023465,
        "node_id": "IC_kwDOCVq1mM5Z8d7p",
        "user": {
            "login": "argideritzalpea",
            "id": 8315310,
            "node_id": "MDQ6VXNlcjgzMTUzMTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8315310?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/argideritzalpea",
            "html_url": "https://github.com/argideritzalpea",
            "followers_url": "https://api.github.com/users/argideritzalpea/followers",
            "following_url": "https://api.github.com/users/argideritzalpea/following{/other_user}",
            "gists_url": "https://api.github.com/users/argideritzalpea/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/argideritzalpea/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/argideritzalpea/subscriptions",
            "organizations_url": "https://api.github.com/users/argideritzalpea/orgs",
            "repos_url": "https://api.github.com/users/argideritzalpea/repos",
            "events_url": "https://api.github.com/users/argideritzalpea/events{/privacy}",
            "received_events_url": "https://api.github.com/users/argideritzalpea/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-14T17:54:40Z",
        "updated_at": "2023-04-14T17:54:40Z",
        "author_association": "NONE",
        "body": "@wangyems Thanks for looking into this. Do you know if there is an estimation for when this feature might be integrated into onnxruntime?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1509023465/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1512139132",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1512139132",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1512139132,
        "node_id": "IC_kwDOCVq1mM5aIWl8",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-17T22:02:05Z",
        "updated_at": "2023-04-17T22:02:05Z",
        "author_association": "MEMBER",
        "body": "hi @Matthieu-Tinycoaching and @argideritzalpea, we have checked in major part of optimizations for t5 and mt-5. I just found that there's minor graph discrepancies that block the optimization script targeting flan-t5. Fix should be available in a week or so.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1512139132/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1513606550",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1513606550",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1513606550,
        "node_id": "IC_kwDOCVq1mM5aN82W",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-18T18:16:21Z",
        "updated_at": "2023-04-18T18:16:21Z",
        "author_association": "MEMBER",
        "body": "you can pull this [branch](https://github.com/microsoft/onnxruntime/commit/784ba8e94c04834f96867faa3d5baa9b83304dcf) and use [convert_to_onnx.py](https://github.com/microsoft/onnxruntime/blob/784ba8e94c04834f96867faa3d5baa9b83304dcf/onnxruntime/python/tools/transformers/models/t5/convert_to_onnx.py) to export flan-t5 graphs.\r\n\r\nwe also have a one-line command to export flan-t5 with beam search using [convert_generation.py](https://github.com/microsoft/onnxruntime/blob/784ba8e94c04834f96867faa3d5baa9b83304dcf/onnxruntime/python/tools/transformers/convert_generation.py). A beam search model with decoder and encoder graph will be generated under /google\r\n```\r\npython convert_generation.py -m google/flan-t5-large --model_type t5 --output flan-t5-beamsearch.onnx -e --use_gpu\r\n```\r\n\r\nFor T5 inference, you'll need to use an ORT [nightly build](https://onnxruntime.ai/docs/install/#inference-install-table-for-all-languages)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1513606550/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1551446250",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14886#issuecomment-1551446250",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14886",
        "id": 1551446250,
        "node_id": "IC_kwDOCVq1mM5ceTDq",
        "user": {
            "login": "Taytay",
            "id": 1330693,
            "node_id": "MDQ6VXNlcjEzMzA2OTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1330693?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Taytay",
            "html_url": "https://github.com/Taytay",
            "followers_url": "https://api.github.com/users/Taytay/followers",
            "following_url": "https://api.github.com/users/Taytay/following{/other_user}",
            "gists_url": "https://api.github.com/users/Taytay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Taytay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Taytay/subscriptions",
            "organizations_url": "https://api.github.com/users/Taytay/orgs",
            "repos_url": "https://api.github.com/users/Taytay/repos",
            "events_url": "https://api.github.com/users/Taytay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Taytay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-17T13:56:10Z",
        "updated_at": "2023-05-17T13:56:10Z",
        "author_association": "NONE",
        "body": "@wangyems: Thank you! Is it still the case that I need another branch for this? Also, do I still need nightly for inference?\r\n\r\nYour branch added some flan models to the list of defaults here: https://github.com/microsoft/onnxruntime/compare/wangye/flan#diff-593772fa94b2b631576ee280ae1c0ee320f532593b9e723c5f3496be6b26647aR28-R37\r\n\r\nI don't think they are necessary though, right?\r\n\r\nI downloaded nightly it looks like I can run this on flan-t5-base okay:\r\n`python -m onnxruntime.transformers.convert_generation -m google/flan-t5-base --model_type t5 -e --use_gpu --output ./output/models/t5/onnx_models/flan_t5_base_beam_search.onnx --output_sequences_scores --num_beams=5 --num_return_sequences=5 --length_penalty=0`\r\n\r\nHowever, it doesn't work for flan-t5-small due to this error:\r\n```\r\npython -m onnxruntime.transformers.convert_generation -m google/flan-t5-small --model_type t5 -e --use_gpu --output ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx --output_sequences_scores --num_beams=5 --num_return_sequences=5 --length_penalty=0\r\n**** past_present_share_buffer=False\r\nConvert model google/flan-t5-small to onnx ...\r\nExporting ONNX model to output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx\r\n/opt/conda/envs/jupyter/lib/python3.10/site-packages/transformers/modeling_utils.py:832: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if causal_mask.shape[1] < attention_mask.shape[1]:\r\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nDelete the existed onnx file: output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx\r\nDelete the existed external data file: output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx.data\r\nOptimizing model to output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init_fp32.onnx\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/convert_generation.py\", line 2699, in <module>\r\n    main()\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/convert_generation.py\", line 2681, in main\r\n    convert_generation_model(args)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/convert_generation.py\", line 1731, in convert_generation_model\r\n    t5_to_onnx(args)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/convert_generation.py\", line 535, in t5_to_onnx\r\n    paths = export_t5_onnx_models(\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/../../models/t5/convert_to_onnx.py\", line 198, in export_onnx_models\r\n    T5Helper.optimize_onnx(\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/t5/t5_helper.py\", line 248, in optimize_onnx\r\n    m = optimize_model(\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/../../optimizer.py\", line 294, in optimize_model\r\n    optimizer = optimize_by_fusion(model, model_type, num_heads, hidden_size, optimization_options)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/../../optimizer.py\", line 178, in optimize_by_fusion\r\n    optimizer = optimizer_class(model, num_heads, hidden_size)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/../../onnx_model_t5.py\", line 751, in __init__\r\n    super().__init__(model, num_heads, hidden_size)\r\n  File \"/opt/conda/envs/jupyter/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/../../onnx_model_bert.py\", line 51, in __init__\r\n    assert (num_heads == 0 and hidden_size == 0) or (num_heads > 0 and hidden_size % num_heads == 0)\r\nAssertionError\r\n```\r\n\r\nThen I tried again, but this time without nightly - just whatever version I get when I install `optimum[onnxruntime-gpu]`, which appears to be `onnxruntime-gpu            1.14.1`\r\n\r\n\r\n```\r\npython -m onnxruntime.transformers.convert_generation -m google/flan-t5-small --model_type t5 -e --use_gpu --output ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx --output_sequences_scores --num_beams=5 --num_return_sequences=5 --length_penalty=0\r\n**** past_present_share_buffer=False, is_greedysearch=False\r\nConvert model google/flan-t5-small to onnx ...\r\nExporting ONNX model to output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx\r\n/opt/conda/envs/jupyter/lib/python3.10/site-packages/transformers/modeling_utils.py:832: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if causal_mask.shape[1] < attention_mask.shape[1]:\r\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nDelete the existed onnx file: output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx\r\nDelete the existed external data file: output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx.data\r\nbatch_size=4 encode_sequence_length=11, max_diff=0.013242721557617188\r\nbatch_size=1 encode_sequence_length=2, max_diff=7.152557373046875e-06\r\nbatch_size=3 encode_sequence_length=1, max_diff=0.0006928443908691406\r\nbatch_size=8 encode_sequence_length=5, max_diff=0.019624948501586914\r\nPyTorch and OnnxRuntime results max difference = 0.019624948501586914\r\nPyTorch and OnnxRuntime results are NOT close\r\nExporting ONNX model to output/models/t5/onnx_models/google/flan-t5-small_decoder.onnx\r\n/opt/conda/envs/jupyter/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:507: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  elif past_key_value.shape[2] != key_value_states.shape[1]:\r\nIn-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\r\nIn-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\r\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nDelete the existed onnx file: output/models/t5/onnx_models/google/flan-t5-small_decoder.onnx\r\nDelete the existed external data file: output/models/t5/onnx_models/google/flan-t5-small_decoder.onnx.data\r\nbatch_size=4, encode_sequence_length=11, past_decode_sequence_length=3, max_diff=0.013082504272460938\r\nbatch_size=1, encode_sequence_length=2, past_decode_sequence_length=5, max_diff=4.76837158203125e-06\r\nbatch_size=3, encode_sequence_length=1, past_decode_sequence_length=1, max_diff=0.0006706714630126953\r\nbatch_size=8, encode_sequence_length=5, past_decode_sequence_length=2, max_diff=0.012537002563476562\r\nPyTorch and OnnxRuntime results max difference = 0.012537002563476562\r\nPyTorch and OnnxRuntime results are NOT close\r\nT5 encoder graph verified: name and data type of inputs and outputs are good.\r\n26 shared initializers (['s_d_decoder.embed_tokens.weight', 's_d_onnx::MatMul_1366', 's_d_onnx::MatMul_1367', 's_d_onnx::MatMul_1368', 's_d_onnx::MatMul_1391', 's_d_onnx::MatMul_1392', 's_d_onnx::MatMul_1393', 's_d_onnx::MatMul_1416', 's_d_onnx::MatMul_1417', 's_d_onnx::MatMul_1418', 's_d_onnx::MatMul_1441', 's_d_onnx::MatMul_1442', 's_d_onnx::MatMul_1443', 's_d_onnx::MatMul_1466', 's_d_onnx::MatMul_1467', 's_d_onnx::MatMul_1468', 's_d_onnx::MatMul_1491', 's_d_onnx::MatMul_1492', 's_d_onnx::MatMul_1493', 's_d_onnx::MatMul_1516', 's_d_onnx::MatMul_1517', 's_d_onnx::MatMul_1518', 's_d_onnx::MatMul_1541', 's_d_onnx::MatMul_1542', 's_d_onnx::MatMul_1543', 's_d_onnx::MatMul_1544']) in encoder and decoder subgraphs are moved to the main graph\r\nDelete the existed onnx file: ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx\r\nDelete the existed external data file: ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx.data\r\nmodel save to ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx\r\nstart testing model...\r\n--------------------------------------------------\r\nTest PyTorch model and beam search with huggingface transformers...\r\ninput_ids tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0, 13959,  1566,    12,  2379,    10,\r\n            37,   556,    19,  1883,     1],\r\n        [21603,    10,   585,  3256,    12,   504,    24,  8636,   830,   490,\r\n           533,  1393,    12,    70,  2713,     5,  3985,     3,     9,  1782,\r\n           300,    54,   991,    12,  1364,  1425,    13,  2189,    21,   321,\r\n          3513,    11,  1082,     5,     1]])\r\nhuggingface transformers outputs:\r\nsequences tensor([[    0,   312,  5789,   259, 13833,     1,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   312,  5789,   259, 13833,     5,     1,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 27549,   721,     5,     1,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 13833,    15,     1,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 13833,    15,     5,     1,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n           248,   194,    12,  1428,  2189,     5,     1,     0,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  1428,  2189,     5,     1,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  4888,    39,  1879,   533,     5,     1],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n           248,   194,    12,  1428,  2189,    11,  2189,     5,     1,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  4888,    39,  1879, 19016,     5,     1]])\r\nsequences_scores tensor([ -4.6146,  -4.8925,  -5.4252,  -5.4902,  -5.7130, -17.0220, -18.1770,\r\n        -19.5306, -19.7267, -20.4909])\r\n0: Le produit est publié\r\n1: Le produit est publié.\r\n2: La product est libérée.\r\n3: La product est publiée\r\n4: La product est publiée.\r\n5: Keeping a dog around is a great way to reduce stress.\r\n6: Keeping a dog around can be a great way to reduce stress.\r\n7: Keeping a dog around can be a great way to boost your overall health.\r\n8: Keeping a dog around is a great way to reduce stress and stress.\r\n9: Keeping a dog around can be a great way to boost your overall wellbeing.\r\n--------------------------------------------------\r\nTesting beam search with onnxruntime...\r\nuse CUDAExecutionProvider\r\nORT outputs:\r\nsequences [[[    0   312  5789   259 13833     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833     5     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833    15     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833    15     5     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833     3    85     3    40    31   154\r\n    9456   257     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]]\r\n\r\n [[    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189     5     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082     5     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11   502     5     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082  9391     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082  9391     5     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]]]\r\nsequences_scores [[ -47.827347  -57.368763  -57.407936  -66.94655  -124.13513 ]\r\n [-143.51146  -190.83138  -190.88016  -191.01337  -200.34917 ]]\r\nbatch 0 sequence 0: Le produit est publié\r\nbatch 0 sequence 1: Le produit est publié.\r\nbatch 0 sequence 2: Le produit est publiée\r\nbatch 0 sequence 3: Le produit est publiée.\r\nbatch 0 sequence 4: Le produit est publié à l'élaboration\r\nbatch 1 sequence 0: Keeping a dog is a great way to reduce stress.\r\nbatch 1 sequence 1: Keeping a dog is a great way to reduce stress for both adults and kids.\r\nbatch 1 sequence 2: Keeping a dog is a great way to reduce stress for both adults and children.\r\nbatch 1 sequence 3: Keeping a dog is a great way to reduce stress for both adults and kids alike\r\nbatch 1 sequence 4: Keeping a dog is a great way to reduce stress for both adults and kids alike.\r\n--------------------------------------------------\r\nTorch Sequences:\r\ntensor([[[    0,   312,  5789,   259, 13833,     1,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     5,     1,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 27549,   721,     5,     1,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 13833,    15,     1,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 13833,    15,     5,     1,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\r\n\r\n        [[    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n            248,   194,    12,  1428,  2189,     5,     1,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  1428,  2189,     5,     1,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  4888,    39,  1879,   533,     5,     1],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n            248,   194,    12,  1428,  2189,    11,  2189,     5,     1,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  4888,    39,  1879, 19016,     5,     1]]])\r\n['Le produit est publié', 'Le produit est publié.', 'La product est libérée.', 'La product est publiée', 'La product est publiée.', 'Keeping a dog around is a great way to reduce stress.', 'Keeping a dog around can be a great way to reduce stress.', 'Keeping a dog around can be a great way to boost your overall health.', 'Keeping a dog around is a great way to reduce stress and stress.', 'Keeping a dog around can be a great way to boost your overall wellbeing.']\r\n--------------------------------------------------\r\nORT Sequences:\r\ntensor([[[    0,   312,  5789,   259, 13833,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     5,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,    15,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,    15,     5,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     3,    85,     3,    40,    31,\r\n            154,  9456,   257,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\r\n\r\n        [[    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,     5,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,     5,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,   502,     5,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,  9391,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,  9391,\r\n              5,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]])\r\n['Le produit est publié', 'Le produit est publié.', 'Le produit est publiée', 'Le produit est publiée.', \"Le produit est publié à l'élaboration\", 'Keeping a dog is a great way to reduce stress.', 'Keeping a dog is a great way to reduce stress for both adults and kids.', 'Keeping a dog is a great way to reduce stress for both adults and children.', 'Keeping a dog is a great way to reduce stress for both adults and kids alike', 'Keeping a dog is a great way to reduce stress for both adults and kids alike.']\r\n--------------------------------------------------\r\nTorch and ORT result is  different\r\nORT {'test_times': 1, 'latency_variance': '0.00', 'latency_90_percentile': '282.23', 'latency_95_percentile': '282.23', 'latency_99_percentile': '282.23', 'average_latency_ms': '282.23', 'QPS': '7.09', 'parity': False}\r\nOutput files: ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx, ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx.data\r\n(jupyter) ubuntu@ip-172-31-3-120:~/sky_workdir$ ls ./output/models/t5/onnx_models/\r\nflan_t5_base_beam_search.onnx  flan_t5_base_beam_search.onnx.data  flan_t5_small_beam_search.onnx  flan_t5_small_beam_search.onnx.data  google\r\n(jupyter) ubuntu@ip-172-31-3-120:~/sky_workdir$ rm -rf ./output/models/t5/onnx_models/\r\n(jupyter) ubuntu@ip-172-31-3-120:~/sky_workdir$ python -m onnxruntime.transformers.convert_generation -m google/flan-t5-small --model_type t5 -e --use_gpu --output ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx --output_sequences_scores --num_beams=5 --num_return_sequences=5 --length_penalty=0\r\n**** past_present_share_buffer=False, is_greedysearch=False\r\nConvert model google/flan-t5-small to onnx ...\r\nExporting ONNX model to output/models/t5/onnx_models/google/flan-t5-small_encoder_decoder_init.onnx\r\n/opt/conda/envs/jupyter/lib/python3.10/site-packages/transformers/modeling_utils.py:832: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if causal_mask.shape[1] < attention_mask.shape[1]:\r\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nbatch_size=4 encode_sequence_length=11, max_diff=0.015545368194580078\r\nbatch_size=1 encode_sequence_length=2, max_diff=4.291534423828125e-06\r\nbatch_size=3 encode_sequence_length=1, max_diff=0.0006568431854248047\r\nbatch_size=8 encode_sequence_length=5, max_diff=0.01646888256072998\r\nPyTorch and OnnxRuntime results max difference = 0.01646888256072998\r\nPyTorch and OnnxRuntime results are NOT close\r\nExporting ONNX model to output/models/t5/onnx_models/google/flan-t5-small_decoder.onnx\r\n/opt/conda/envs/jupyter/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:507: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  elif past_key_value.shape[2] != key_value_states.shape[1]:\r\nIn-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\r\nIn-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\r\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nbatch_size=4, encode_sequence_length=11, past_decode_sequence_length=3, max_diff=0.008085250854492188\r\nbatch_size=1, encode_sequence_length=2, past_decode_sequence_length=5, max_diff=7.62939453125e-06\r\nbatch_size=3, encode_sequence_length=1, past_decode_sequence_length=1, max_diff=0.00025200843811035156\r\nbatch_size=8, encode_sequence_length=5, past_decode_sequence_length=2, max_diff=0.01223444938659668\r\nPyTorch and OnnxRuntime results max difference = 0.01223444938659668\r\nPyTorch and OnnxRuntime results are NOT close\r\nT5 encoder graph verified: name and data type of inputs and outputs are good.\r\n26 shared initializers (['s_d_decoder.embed_tokens.weight', 's_d_onnx::MatMul_1366', 's_d_onnx::MatMul_1367', 's_d_onnx::MatMul_1368', 's_d_onnx::MatMul_1391', 's_d_onnx::MatMul_1392', 's_d_onnx::MatMul_1393', 's_d_onnx::MatMul_1416', 's_d_onnx::MatMul_1417', 's_d_onnx::MatMul_1418', 's_d_onnx::MatMul_1441', 's_d_onnx::MatMul_1442', 's_d_onnx::MatMul_1443', 's_d_onnx::MatMul_1466', 's_d_onnx::MatMul_1467', 's_d_onnx::MatMul_1468', 's_d_onnx::MatMul_1491', 's_d_onnx::MatMul_1492', 's_d_onnx::MatMul_1493', 's_d_onnx::MatMul_1516', 's_d_onnx::MatMul_1517', 's_d_onnx::MatMul_1518', 's_d_onnx::MatMul_1541', 's_d_onnx::MatMul_1542', 's_d_onnx::MatMul_1543', 's_d_onnx::MatMul_1544']) in encoder and decoder subgraphs are moved to the main graph\r\nmodel save to ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx\r\nstart testing model...\r\n--------------------------------------------------\r\nTest PyTorch model and beam search with huggingface transformers...\r\ninput_ids tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0, 13959,  1566,    12,  2379,    10,\r\n            37,   556,    19,  1883,     1],\r\n        [21603,    10,   585,  3256,    12,   504,    24,  8636,   830,   490,\r\n           533,  1393,    12,    70,  2713,     5,  3985,     3,     9,  1782,\r\n           300,    54,   991,    12,  1364,  1425,    13,  2189,    21,   321,\r\n          3513,    11,  1082,     5,     1]])\r\nhuggingface transformers outputs:\r\nsequences tensor([[    0,   312,  5789,   259, 13833,     1,     0,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   312,  5789,   259, 13833,     5,     1,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 27549,   721,     5,     1,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 13833,    15,     1,     0,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,   325,   556,   259, 13833,    15,     5,     1,     0,     0,\r\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n           248,   194,    12,  1428,  2189,     5,     1,     0,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  1428,  2189,     5,     1,     0,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  4888,    39,  1879,   533,     5,     1],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n           248,   194,    12,  1428,  2189,    11,  2189,     5,     1,     0],\r\n        [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n             9,   248,   194,    12,  4888,    39,  1879, 19016,     5,     1]])\r\nsequences_scores tensor([ -4.6146,  -4.8925,  -5.4252,  -5.4902,  -5.7130, -17.0220, -18.1770,\r\n        -19.5306, -19.7267, -20.4909])\r\n0: Le produit est publié\r\n1: Le produit est publié.\r\n2: La product est libérée.\r\n3: La product est publiée\r\n4: La product est publiée.\r\n5: Keeping a dog around is a great way to reduce stress.\r\n6: Keeping a dog around can be a great way to reduce stress.\r\n7: Keeping a dog around can be a great way to boost your overall health.\r\n8: Keeping a dog around is a great way to reduce stress and stress.\r\n9: Keeping a dog around can be a great way to boost your overall wellbeing.\r\n--------------------------------------------------\r\nTesting beam search with onnxruntime...\r\nuse CUDAExecutionProvider\r\nORT outputs:\r\nsequences [[[    0   312  5789   259 13833     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833     5     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833    15     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833    15     5     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0   312  5789   259 13833     3    85     3    40    31   154\r\n    9456   257     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]]\r\n\r\n [[    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189     5     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082     5     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11   502     5     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082  9391     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]\r\n  [    0     3 18536     3     9  1782    19     3     9   248   194\r\n      12  1428  2189    21   321  3513    11  1082  9391     5     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0     0     0     0     0     0\r\n       0     0     0     0     0     0]]]\r\nsequences_scores [[ -47.827347  -57.368763  -57.407936  -66.94655  -124.13513 ]\r\n [-143.51146  -190.83138  -190.88016  -191.01337  -200.34917 ]]\r\nbatch 0 sequence 0: Le produit est publié\r\nbatch 0 sequence 1: Le produit est publié.\r\nbatch 0 sequence 2: Le produit est publiée\r\nbatch 0 sequence 3: Le produit est publiée.\r\nbatch 0 sequence 4: Le produit est publié à l'élaboration\r\nbatch 1 sequence 0: Keeping a dog is a great way to reduce stress.\r\nbatch 1 sequence 1: Keeping a dog is a great way to reduce stress for both adults and kids.\r\nbatch 1 sequence 2: Keeping a dog is a great way to reduce stress for both adults and children.\r\nbatch 1 sequence 3: Keeping a dog is a great way to reduce stress for both adults and kids alike\r\nbatch 1 sequence 4: Keeping a dog is a great way to reduce stress for both adults and kids alike.\r\n--------------------------------------------------\r\nTorch Sequences:\r\ntensor([[[    0,   312,  5789,   259, 13833,     1,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     5,     1,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 27549,   721,     5,     1,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 13833,    15,     1,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   325,   556,   259, 13833,    15,     5,     1,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\r\n\r\n        [[    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n            248,   194,    12,  1428,  2189,     5,     1,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  1428,  2189,     5,     1,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  4888,    39,  1879,   533,     5,     1],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    19,     3,     9,\r\n            248,   194,    12,  1428,  2189,    11,  2189,     5,     1,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,   300,    54,    36,     3,\r\n              9,   248,   194,    12,  4888,    39,  1879, 19016,     5,     1]]])\r\n['Le produit est publié', 'Le produit est publié.', 'La product est libérée.', 'La product est publiée', 'La product est publiée.', 'Keeping a dog around is a great way to reduce stress.', 'Keeping a dog around can be a great way to reduce stress.', 'Keeping a dog around can be a great way to boost your overall health.', 'Keeping a dog around is a great way to reduce stress and stress.', 'Keeping a dog around can be a great way to boost your overall wellbeing.']\r\n--------------------------------------------------\r\nORT Sequences:\r\ntensor([[[    0,   312,  5789,   259, 13833,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     5,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,    15,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,    15,     5,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,   312,  5789,   259, 13833,     3,    85,     3,    40,    31,\r\n            154,  9456,   257,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\r\n\r\n        [[    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,     5,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,     5,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,   502,     5,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,  9391,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\r\n         [    0,     3, 18536,     3,     9,  1782,    19,     3,     9,   248,\r\n            194,    12,  1428,  2189,    21,   321,  3513,    11,  1082,  9391,\r\n              5,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]])\r\n['Le produit est publié', 'Le produit est publié.', 'Le produit est publiée', 'Le produit est publiée.', \"Le produit est publié à l'élaboration\", 'Keeping a dog is a great way to reduce stress.', 'Keeping a dog is a great way to reduce stress for both adults and kids.', 'Keeping a dog is a great way to reduce stress for both adults and children.', 'Keeping a dog is a great way to reduce stress for both adults and kids alike', 'Keeping a dog is a great way to reduce stress for both adults and kids alike.']\r\n--------------------------------------------------\r\nTorch and ORT result is  different\r\nORT {'test_times': 1, 'latency_variance': '0.00', 'latency_90_percentile': '248.05', 'latency_95_percentile': '248.05', 'latency_99_percentile': '248.05', 'average_latency_ms': '248.05', 'QPS': '8.06', 'parity': False}\r\nOutput files: ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx, ./output/models/t5/onnx_models/flan_t5_small_beam_search.onnx.data\r\n```\r\n\r\nI presume that the Torch and ORT result being different is a legitimate error?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1551446250/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]