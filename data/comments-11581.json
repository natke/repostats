[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132668955",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132668955",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132668955,
        "node_id": "IC_kwDOCVq1mM5Dgygb",
        "user": {
            "login": "RoudyES",
            "id": 76808707,
            "node_id": "MDQ6VXNlcjc2ODA4NzA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76808707?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RoudyES",
            "html_url": "https://github.com/RoudyES",
            "followers_url": "https://api.github.com/users/RoudyES/followers",
            "following_url": "https://api.github.com/users/RoudyES/following{/other_user}",
            "gists_url": "https://api.github.com/users/RoudyES/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RoudyES/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RoudyES/subscriptions",
            "organizations_url": "https://api.github.com/users/RoudyES/orgs",
            "repos_url": "https://api.github.com/users/RoudyES/repos",
            "events_url": "https://api.github.com/users/RoudyES/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RoudyES/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T09:12:55Z",
        "updated_at": "2022-05-20T09:12:55Z",
        "author_association": "NONE",
        "body": "Hello! Are you re-initializing the session on each inference run?\r\nI tried re-creating your issue in C# also on Yolov5 like so:\r\n\r\n```\r\nwhile (true)\r\n    {\r\n        Stopwatch watch = Stopwatch.StartNew();\r\n\r\n        UnmanagedMemoryManager<float> test = new UnmanagedMemoryManager<float>((float*)inputBlob.DataPointer, 3 * 640 * 640);\r\n\r\n        // create input tensor\r\n        var inputTensor = new DenseTensor<float>(test.Memory, new int[] { 1, 3, 640, 640 });\r\n\r\n        // Create input data for session.\r\n        var input = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor<float>(\"images\", inputTensor) };\r\n\r\n        // Run session and send input data in to get inference output.\r\n        var output = session.Run(input);\r\n        watch.Stop();\r\n        Debug.WriteLine(watch.ElapsedMilliseconds);\r\n        Thread.Sleep(5000);\r\n    }\r\n```\r\n\r\nThe first inference takes a bit of time (which is normal because the runtime is initializing and loading everything to memory), after that it was stable at 15ms. I initialized the `InferenceSession` outside the while loop so it is being created only once and re-using it inside the loop, it performs as expected.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132668955/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132788998",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132788998",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132788998,
        "node_id": "IC_kwDOCVq1mM5DhP0G",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T11:26:10Z",
        "updated_at": "2022-05-20T11:26:10Z",
        "author_association": "NONE",
        "body": "> Hello! Are you re-initializing the session on each inference run? I tried re-creating your issue in C# also on Yolov5 like so:\r\n> \r\n> ```\r\n> while (true)\r\n>     {\r\n>         Stopwatch watch = Stopwatch.StartNew();\r\n> \r\n>         UnmanagedMemoryManager<float> test = new UnmanagedMemoryManager<float>((float*)inputBlob.DataPointer, 3 * 640 * 640);\r\n> \r\n>         // create input tensor\r\n>         var inputTensor = new DenseTensor<float>(test.Memory, new int[] { 1, 3, 640, 640 });\r\n> \r\n>         // Create input data for session.\r\n>         var input = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor<float>(\"images\", inputTensor) };\r\n> \r\n>         // Run session and send input data in to get inference output.\r\n>         var output = session.Run(input);\r\n>         watch.Stop();\r\n>         Debug.WriteLine(watch.ElapsedMilliseconds);\r\n>         Thread.Sleep(5000);\r\n>     }\r\n> ```\r\n> \r\n> The first inference takes a bit of time (which is normal because the runtime is initializing and loading everything to memory), after that it was stable at 15ms. I initialized the `InferenceSession` outside the while loop so it is being created only once and re-using it inside the loop, it performs as expected.\r\n\r\n\r\n\r\n\r\nI think not , just initialize the session only once. my python code cannot obtain right nowï¼Œbut i have a c++ version, i has the same problem. the code like below:\r\n\r\nC++ code:\r\n```C++\r\nModelLoader::ModelLoader(std::wstring modelFilePath_): modelFilePath(std::move(modelFilePath_)) {\r\n    env = new Ort::Env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING, \"logs\");\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(4);\r\n    sessionOptions.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);\r\n    OrtSessionOptionsAppendExecutionProvider_CUDA(sessionOptions, 0);\r\n    session = new Ort::Session(*env, modelFilePath.c_str(), sessionOptions);\r\n    ioBinding = new Ort::IoBinding{ *session };\r\n}\r\n \r\n\r\nstd::vector<cv::Mat> ModelLoader::_detect(cv::Mat &blob) {\r\n    std::vector<int64_t> inputDimsInFact{ batchSize, 3, imgH, imgW };\r\n    size_t inputTensorSize = vectorProduct(inputDimsInFact);\r\n    std::vector<float> inputTensorValues(inputTensorSize);\r\n    inputTensorValues.assign(blob.begin<float>(), blob.end<float>());\r\n    std::vector<const char*> inputNames{\"input\"};\r\n    std::vector<const char*> outputNames{\"output\"};\r\n    std::vector<Ort::Value> inputTensors;\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n    inputTensors.push_back(Ort::Value::CreateTensor<float>(memoryInfo, inputTensorValues.data(), inputTensorSize, inputDimsInFact.data(), inputDimsInFact.size()));\r\n\r\n\r\n    auto output = session->Run(Ort::RunOptions{ nullptr }, inputNames.data(), inputTensors.data(), 1, outputNames.data(), 1);\r\n\r\n \r\n    return output;\r\n}",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132788998/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132802323",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132802323",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132802323,
        "node_id": "IC_kwDOCVq1mM5DhTET",
        "user": {
            "login": "RoudyES",
            "id": 76808707,
            "node_id": "MDQ6VXNlcjc2ODA4NzA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76808707?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RoudyES",
            "html_url": "https://github.com/RoudyES",
            "followers_url": "https://api.github.com/users/RoudyES/followers",
            "following_url": "https://api.github.com/users/RoudyES/following{/other_user}",
            "gists_url": "https://api.github.com/users/RoudyES/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RoudyES/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RoudyES/subscriptions",
            "organizations_url": "https://api.github.com/users/RoudyES/orgs",
            "repos_url": "https://api.github.com/users/RoudyES/repos",
            "events_url": "https://api.github.com/users/RoudyES/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RoudyES/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T11:43:19Z",
        "updated_at": "2022-05-20T11:43:19Z",
        "author_association": "NONE",
        "body": "Are you calling `ModelLoader::_detect` in a loop? I'm not very familiar with the C++ API but I think you have some unnecessary operations in there. Example:\r\n```\r\nstd::vector<const char*> inputNames{\"input\"};\r\nstd::vector<const char*> outputNames{\"output\"};\r\nstd::vector<Ort::Value> inputTensors;\r\nOrt::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n```\r\nThese lines never change so why re-initialize them on each iteration (especially the Ort::MemoryInfo::CreateCPU() call)?\r\n\r\nAlso, assuming your image dimensions arent't changing, you can also initialize those lines only once:\r\n\r\n```\r\nstd::vector<int64_t> inputDimsInFact{ batchSize, 3, imgH, imgW };\r\nsize_t inputTensorSize = vectorProduct(inputDimsInFact);\r\nstd::vector<float> inputTensorValues(inputTensorSize);\r\n```\r\n\r\nThis way your detect method will simply overwrite data on existing memory.\r\nAgain, I'm not very familiar with the C++ API so correct me if I'm wrong there.\r\nAs for your problem, I'd say use a timer to check the `session->Run()` operation alone and see if it is slower when there's a slight pause between its calls.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132802323/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132811622",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132811622",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132811622,
        "node_id": "IC_kwDOCVq1mM5DhVVm",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T11:52:47Z",
        "updated_at": "2022-05-20T11:52:47Z",
        "author_association": "NONE",
        "body": "> Are you calling `ModelLoader::_detect` in a loop? I'm not very familiar with the C++ API but I think you have some unnecessary operations in there. Example:\n> ```\n> std::vector<const char*> inputNames{\"input\"};\n> std::vector<const char*> outputNames{\"output\"};\n> std::vector<Ort::Value> inputTensors;\n> Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\n> ```\n> These lines never change so why re-initialize them on each iteration (especially the Ort::MemoryInfo::CreateCPU() call)?\n> \n> Also, assuming your image dimensions arent't changing, you can also initialize those lines only once:\n> \n> ```\n> std::vector<int64_t> inputDimsInFact{ batchSize, 3, imgH, imgW };\n> size_t inputTensorSize = vectorProduct(inputDimsInFact);\n> std::vector<float> inputTensorValues(inputTensorSize);\n> ```\n> \n> This way your detect method will simply overwrite data on existing memory.\n> Again, I'm not very familiar with the C++ API so correct me if I'm wrong there.\n> As for your problem, I'd say use a timer to check the `session->Run()` operation alone and see if it is slower when there's a slight pause between its calls.\n\n\n\nyeah, you idea is nice. in addition, I only measure the time of session->run().",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132811622/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132820662",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132820662",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132820662,
        "node_id": "IC_kwDOCVq1mM5DhXi2",
        "user": {
            "login": "RoudyES",
            "id": 76808707,
            "node_id": "MDQ6VXNlcjc2ODA4NzA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76808707?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RoudyES",
            "html_url": "https://github.com/RoudyES",
            "followers_url": "https://api.github.com/users/RoudyES/followers",
            "following_url": "https://api.github.com/users/RoudyES/following{/other_user}",
            "gists_url": "https://api.github.com/users/RoudyES/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RoudyES/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RoudyES/subscriptions",
            "organizations_url": "https://api.github.com/users/RoudyES/orgs",
            "repos_url": "https://api.github.com/users/RoudyES/repos",
            "events_url": "https://api.github.com/users/RoudyES/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RoudyES/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T12:04:15Z",
        "updated_at": "2022-05-20T12:04:15Z",
        "author_association": "NONE",
        "body": "If that's the case then it could be that your GPU is shifting resources away from your application when there's a wait between runs. This happens on my machine but it's a 1050Ti in my case..\r\n\r\nThat's just my 2 cents though, I'm sorry I couldn't help you further. Hope someone with more experience than me can better help you in your issue.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132820662/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132829156",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1132829156",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1132829156,
        "node_id": "IC_kwDOCVq1mM5DhZnk",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-20T12:10:35Z",
        "updated_at": "2022-05-20T12:10:35Z",
        "author_association": "NONE",
        "body": "> If that's the case then it could be that your GPU is shifting resources away from your application when there's a wait between runs. This happens on my machine but it's a 1050Ti in my case..\n> \n> That's just my 2 cents though, I'm sorry I couldn't help you further. Hope someone with more experience than me can better help you in your issue.\n\n\n\nIt may seems that way, and I try to see if I can figure out why. Thank you for your idea",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1132829156/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133521315",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1133521315",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1133521315,
        "node_id": "IC_kwDOCVq1mM5DkCmj",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-21T03:32:18Z",
        "updated_at": "2022-05-21T03:32:18Z",
        "author_association": "NONE",
        "body": "> Are you calling `ModelLoader::_detect` in a loop? I'm not very familiar with the C++ API but I think you have some unnecessary operations in there. Example:\r\n> \r\n> ```\r\n> std::vector<const char*> inputNames{\"input\"};\r\n> std::vector<const char*> outputNames{\"output\"};\r\n> std::vector<Ort::Value> inputTensors;\r\n> Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n> ```\r\n> \r\n> These lines never change so why re-initialize them on each iteration (especially the Ort::MemoryInfo::CreateCPU() call)?\r\n> \r\n> Also, assuming your image dimensions arent't changing, you can also initialize those lines only once:\r\n> \r\n> ```\r\n> std::vector<int64_t> inputDimsInFact{ batchSize, 3, imgH, imgW };\r\n> size_t inputTensorSize = vectorProduct(inputDimsInFact);\r\n> std::vector<float> inputTensorValues(inputTensorSize);\r\n> ```\r\n> \r\n> This way your detect method will simply overwrite data on existing memory. Again, I'm not very familiar with the C++ API so correct me if I'm wrong there. As for your problem, I'd say use a timer to check the `session->Run()` operation alone and see if it is slower when there's a slight pause between its calls.\r\n\r\n\r\nSorry to bother you again, I wonder how to avoid the long Inference time of the first inference on CUDA? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133521315/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133541793",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1133541793",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1133541793,
        "node_id": "IC_kwDOCVq1mM5DkHmh",
        "user": {
            "login": "RoudyES",
            "id": 76808707,
            "node_id": "MDQ6VXNlcjc2ODA4NzA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76808707?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RoudyES",
            "html_url": "https://github.com/RoudyES",
            "followers_url": "https://api.github.com/users/RoudyES/followers",
            "following_url": "https://api.github.com/users/RoudyES/following{/other_user}",
            "gists_url": "https://api.github.com/users/RoudyES/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RoudyES/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RoudyES/subscriptions",
            "organizations_url": "https://api.github.com/users/RoudyES/orgs",
            "repos_url": "https://api.github.com/users/RoudyES/repos",
            "events_url": "https://api.github.com/users/RoudyES/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RoudyES/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-21T05:56:27Z",
        "updated_at": "2022-05-21T05:56:27Z",
        "author_association": "NONE",
        "body": "I'm afraid there's no avoiding this first slow inference. This doesn't only happen with onnxruntime. Even in torch and TF the first inference on gpu takes a bit of time just to initialize everything.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133541793/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133826691",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1133826691",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1133826691,
        "node_id": "IC_kwDOCVq1mM5DlNKD",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-22T06:12:51Z",
        "updated_at": "2022-05-22T06:12:51Z",
        "author_association": "NONE",
        "body": "> I'm afraid there's no avoiding this first slow inference. This doesn't only happen with onnxruntime. Even in torch and TF the first inference on gpu takes a bit of time just to initialize everything.\r\n\r\nOKï¼Œ thanks.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1133826691/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1204700436",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1204700436",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1204700436,
        "node_id": "IC_kwDOCVq1mM5HzkUU",
        "user": {
            "login": "Mihir-Gajera1",
            "id": 26799024,
            "node_id": "MDQ6VXNlcjI2Nzk5MDI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26799024?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Mihir-Gajera1",
            "html_url": "https://github.com/Mihir-Gajera1",
            "followers_url": "https://api.github.com/users/Mihir-Gajera1/followers",
            "following_url": "https://api.github.com/users/Mihir-Gajera1/following{/other_user}",
            "gists_url": "https://api.github.com/users/Mihir-Gajera1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Mihir-Gajera1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Mihir-Gajera1/subscriptions",
            "organizations_url": "https://api.github.com/users/Mihir-Gajera1/orgs",
            "repos_url": "https://api.github.com/users/Mihir-Gajera1/repos",
            "events_url": "https://api.github.com/users/Mihir-Gajera1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Mihir-Gajera1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-04T03:00:58Z",
        "updated_at": "2022-08-04T03:00:58Z",
        "author_association": "NONE",
        "body": "Experiencing the same issue with hifigan vocoder fp16 quantized onnx model? First inference and inference after a pause is taking 10x time than continuous inference. How to avoid this?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1204700436/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1217681631",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1217681631",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1217681631,
        "node_id": "IC_kwDOCVq1mM5IlFjf",
        "user": {
            "login": "g782373711",
            "id": 36449632,
            "node_id": "MDQ6VXNlcjM2NDQ5NjMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36449632?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/g782373711",
            "html_url": "https://github.com/g782373711",
            "followers_url": "https://api.github.com/users/g782373711/followers",
            "following_url": "https://api.github.com/users/g782373711/following{/other_user}",
            "gists_url": "https://api.github.com/users/g782373711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/g782373711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/g782373711/subscriptions",
            "organizations_url": "https://api.github.com/users/g782373711/orgs",
            "repos_url": "https://api.github.com/users/g782373711/repos",
            "events_url": "https://api.github.com/users/g782373711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/g782373711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-17T08:31:10Z",
        "updated_at": "2022-08-17T08:31:10Z",
        "author_association": "NONE",
        "body": "> Experiencing the same issue with hifigan vocoder fp16 quantized onnx model? First inference and inference after a pause is taking 10x time than continuous inference. How to avoid this?\r\n\r\nthe issue be solved here.   https://github.com/NVIDIA/TensorRT/issues/2042#issue-1264440607\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1217681631/reactions",
            "total_count": 3,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1309255531",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11581#issuecomment-1309255531",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11581",
        "id": 1309255531,
        "node_id": "IC_kwDOCVq1mM5OCadr",
        "user": {
            "login": "Mihir-Gajera1",
            "id": 26799024,
            "node_id": "MDQ6VXNlcjI2Nzk5MDI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26799024?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Mihir-Gajera1",
            "html_url": "https://github.com/Mihir-Gajera1",
            "followers_url": "https://api.github.com/users/Mihir-Gajera1/followers",
            "following_url": "https://api.github.com/users/Mihir-Gajera1/following{/other_user}",
            "gists_url": "https://api.github.com/users/Mihir-Gajera1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Mihir-Gajera1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Mihir-Gajera1/subscriptions",
            "organizations_url": "https://api.github.com/users/Mihir-Gajera1/orgs",
            "repos_url": "https://api.github.com/users/Mihir-Gajera1/repos",
            "events_url": "https://api.github.com/users/Mihir-Gajera1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Mihir-Gajera1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-09T19:29:17Z",
        "updated_at": "2022-11-09T19:29:17Z",
        "author_association": "NONE",
        "body": "Thanks.  @g782373711.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1309255531/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]