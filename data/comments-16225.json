[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575215957",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16225#issuecomment-1575215957",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16225",
        "id": 1575215957,
        "node_id": "IC_kwDOCVq1mM5d4-NV",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-03T21:53:45Z",
        "updated_at": "2023-06-03T21:53:45Z",
        "author_association": "MEMBER",
        "body": "Good question.\r\n\r\nIf your input data is in CPU (For example, tokenizer is implemented in CPU), you will need copy the input tensor to GPU (either in your application, or by ONNX Runtime).\r\n\r\nIf your input data is already in GPU, it is recommended to use IO Binding. See https://onnxruntime.ai/docs/api/python/api_summary.html#data-on-device for example.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575215957/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575579135",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16225#issuecomment-1575579135",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16225",
        "id": 1575579135,
        "node_id": "IC_kwDOCVq1mM5d6W3_",
        "user": {
            "login": "feng-1985",
            "id": 8215563,
            "node_id": "MDQ6VXNlcjgyMTU1NjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8215563?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/feng-1985",
            "html_url": "https://github.com/feng-1985",
            "followers_url": "https://api.github.com/users/feng-1985/followers",
            "following_url": "https://api.github.com/users/feng-1985/following{/other_user}",
            "gists_url": "https://api.github.com/users/feng-1985/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/feng-1985/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/feng-1985/subscriptions",
            "organizations_url": "https://api.github.com/users/feng-1985/orgs",
            "repos_url": "https://api.github.com/users/feng-1985/repos",
            "events_url": "https://api.github.com/users/feng-1985/events{/privacy}",
            "received_events_url": "https://api.github.com/users/feng-1985/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-04T13:54:52Z",
        "updated_at": "2023-06-04T13:56:46Z",
        "author_association": "NONE",
        "body": "Thanks for quick response!  I get it. \r\nCan you help me another problem related to this notebook example ?\r\n\r\nHow to use the optimized model ? I have seen the following three ways:\r\nfirst - enable it for debugging only \r\n`sess_options.optimized_model_filepath = os.path.join(output_dir, \"optimized_model_{}.onnx\".format(device_name))`\r\n[the former refered notebook](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/notebooks/PyTorch_Bert-Squad_OnnxRuntime_GPU.ipynb)\r\nsecond - enable model serialization \r\n`sess_options.optimized_model_filepath = \"<model_output_path\\optimized_model.onnx>\"`\r\n[refer](https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html#offline-mode)\r\nthird - direct used for inference\r\n```\r\npredictor = ort.InferenceSession(optimized_model,\r\n                                                 sess_options=sess_options,\r\n                                                 providers=providers)\r\n```\r\nI am not very understand the former two ways  (The third one is our optimize purpose, just optimize the model and use it for inference.).\r\n\r\nThanks for you time !\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575579135/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1577230937",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16225#issuecomment-1577230937",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16225",
        "id": 1577230937,
        "node_id": "IC_kwDOCVq1mM5eAqJZ",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-05T17:58:11Z",
        "updated_at": "2023-06-05T17:58:11Z",
        "author_association": "MEMBER",
        "body": "@feng-1985, For first and second case, the optimized model is for debugging purpose, and it could show you the optimized graph. \r\n\r\nUsing sess_options.optimized_model_filepath will slow the inference since it involves I/O. For production, you shall avoid saving the optimized model. \r\n\r\nThe third usage has pros and cons. \r\n**Pros**:  It reduces session creation time if you disable graph optimization since it has been optimized. \r\n**Cons**: \r\n(1) The optimized model is not portable. That means it might not run well if you changes the device or execution provider (like CUDA -> CPU, or CPU -> CUDA, or CUDA -> TensorRT)\r\n(2) It is not compatible in different ONNX runtime version. It might not run in older version of onnx runtime since some optimized operators were just added. It might encounter issue using newer ONNX runtime since we might change some experimental operator in com.microsoft domain and break the backward compatible.\r\nOverall, it is not recommended considering the pros and cons.\r\n\r\nHowever, sometimes it is needed to use optimized model when optimization is done by script (like https://onnxruntime.ai/docs/performance/transformers-optimization.html). The optimized graph might be different from the one saved directly from session options.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1577230937/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1584110491",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16225#issuecomment-1584110491",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16225",
        "id": 1584110491,
        "node_id": "IC_kwDOCVq1mM5ea5ub",
        "user": {
            "login": "feng-1985",
            "id": 8215563,
            "node_id": "MDQ6VXNlcjgyMTU1NjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8215563?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/feng-1985",
            "html_url": "https://github.com/feng-1985",
            "followers_url": "https://api.github.com/users/feng-1985/followers",
            "following_url": "https://api.github.com/users/feng-1985/following{/other_user}",
            "gists_url": "https://api.github.com/users/feng-1985/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/feng-1985/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/feng-1985/subscriptions",
            "organizations_url": "https://api.github.com/users/feng-1985/orgs",
            "repos_url": "https://api.github.com/users/feng-1985/repos",
            "events_url": "https://api.github.com/users/feng-1985/events{/privacy}",
            "received_events_url": "https://api.github.com/users/feng-1985/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-09T07:33:09Z",
        "updated_at": "2023-06-09T07:33:09Z",
        "author_association": "NONE",
        "body": "Thanks for clarify! ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1584110491/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]