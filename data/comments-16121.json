[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564857225",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1564857225",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1564857225,
        "node_id": "IC_kwDOCVq1mM5dRdOJ",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-26T19:51:56Z",
        "updated_at": "2023-05-26T19:51:56Z",
        "author_association": "MEMBER",
        "body": "we have a more generic way of supporting TRT plugins which does not require contrib op schema updates.  see https://github.com/microsoft/onnxruntime/pull/13847\r\n+@chilo-ms to provide more details.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564857225/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564893498",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1564893498",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1564893498,
        "node_id": "IC_kwDOCVq1mM5dRmE6",
        "user": {
            "login": "laggui",
            "id": 7225623,
            "node_id": "MDQ6VXNlcjcyMjU2MjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7225623?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laggui",
            "html_url": "https://github.com/laggui",
            "followers_url": "https://api.github.com/users/laggui/followers",
            "following_url": "https://api.github.com/users/laggui/following{/other_user}",
            "gists_url": "https://api.github.com/users/laggui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laggui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laggui/subscriptions",
            "organizations_url": "https://api.github.com/users/laggui/orgs",
            "repos_url": "https://api.github.com/users/laggui/repos",
            "events_url": "https://api.github.com/users/laggui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laggui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-26T20:11:22Z",
        "updated_at": "2023-05-26T20:11:22Z",
        "author_association": "NONE",
        "body": "Sweet, that went under my radar! Will wait for further details.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564893498/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564925714",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1564925714",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1564925714,
        "node_id": "IC_kwDOCVq1mM5dRt8S",
        "user": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-26T20:41:41Z",
        "updated_at": "2023-05-26T20:47:58Z",
        "author_association": "MEMBER",
        "body": "Hi laggui,\r\n\r\nAs George mentioned, please use the new generic way of [supporting TRT plugins](https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html#tensorrt-plugins-support).\r\nAll you need to do is change the EfficientNMS_TRT node in the onnx model with the domain `trt.plugins` (you can use python to easy modify the onnx node) instead of the default onnx domain which is null string. The old way of using TRT plugins is through contrib op and it checks domain `kOnnxDomain` which is null string and as you already found out it doesn't add the new attribute that's why ORT failed to run the model.\r\n\r\nThanks for pointing out this issue and we can think of better ways to let people use the newer way of supporting TRT plugin. Let me know if you encounter any issues.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1564925714/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567145971",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1567145971",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1567145971,
        "node_id": "IC_kwDOCVq1mM5daL_z",
        "user": {
            "login": "laggui",
            "id": 7225623,
            "node_id": "MDQ6VXNlcjcyMjU2MjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7225623?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laggui",
            "html_url": "https://github.com/laggui",
            "followers_url": "https://api.github.com/users/laggui/followers",
            "following_url": "https://api.github.com/users/laggui/following{/other_user}",
            "gists_url": "https://api.github.com/users/laggui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laggui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laggui/subscriptions",
            "organizations_url": "https://api.github.com/users/laggui/orgs",
            "repos_url": "https://api.github.com/users/laggui/repos",
            "events_url": "https://api.github.com/users/laggui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laggui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-29T13:32:42Z",
        "updated_at": "2023-05-29T13:32:42Z",
        "author_association": "NONE",
        "body": "That seems pretty straightforward, thanks!\r\n\r\nJust tried this very quickly and I am getting an error though. When I simply change the domain to `\"trt.plugins\"` as below, I get\r\n`Error No opset import for domain 'trt.plugins'.`\r\n\r\n<details>\r\n  <summary>Full error message</summary>\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. In Node, (\"NMS_Op_sg344\", EfficientNMS_TRT, \"trt.plugins\", -1) : (\"/_wrapper/postprocess/Slice_19_output_0\": tensor(float),\"/_wrapper/postprocess/Mul_42_output_0\": tensor(float),) -> (\"num_boxes\": tensor(int32),\"/_wrapper/postprocess/CustomNMS_output_1\": tensor(float),\"/_wrapper/postprocess/CustomNMS_output_2\": tensor(float),\"/_wrapper/postprocess/CustomNMS_output_3\": tensor(int32),) , Error No opset import for domain 'trt.plugins'\r\n</details>\r\n\r\n```py\r\n# Make node attributes\r\nscore_threshold = helper.make_attribute(\"score_threshold\", score_thresh)\r\niou_threshold = helper.make_attribute(\"iou_threshold\", iou_thresh)\r\nmax_output_boxes = helper.make_attribute(\"max_output_boxes\", detections_per_img)\r\nbackground_class = helper.make_attribute(\"background_class\", background_class)\r\nscore_activation = helper.make_attribute(\"score_activation\", 0)  # False\r\nbox_coding = helper.make_attribute(\"box_coding\", 0)\r\nplugin_version = helper.make_attribute(\"plugin_version\", \"1\")\r\nclass_agnostic = helper.make_attribute(\"class_agnostic\", class_agnostic)\r\n\r\n# Create NMS node\r\nnms_node = helper.make_node(\r\n    \"EfficientNMS_TRT\",\r\n    inputs=inputs,\r\n    outputs=outputs,\r\n    name=\"NMS_Op\",\r\n    domain=\"trt.plugins\", # new TRT plugins\r\n)\r\nnms_node.attribute.extend(\r\n    [\r\n        background_class,\r\n        box_coding,\r\n        iou_threshold,\r\n        max_output_boxes,\r\n        plugin_version,\r\n        score_activation,\r\n        score_threshold,\r\n        class_agnostic,\r\n    ]\r\n)\r\n```\r\n\r\nI thought maybe it's because I forgot to export de `ModelProto` with the `trt.plugins` opset even if it wasn't mentioned anywhere\r\n```py\r\nopsets = [helper.make_opsetid(\"\", self.opset_version), helper.make_opsetid(\"trt.plugins\", 1)]\r\nhelper.make_model(\r\n    graph,\r\n    opset_imports=opsets,\r\n)\r\n```\r\n\r\nbut that didn't seem to help. Instead I got the following error\r\n`[ONNXRuntimeError] : 1 : FAIL : Fatal error: trt.plugins: EfficientNMS_TRT(-1) is not a registered function/op`\r\n\r\nGonna double check my node definition to make sure I didn't miss anything and will report back later.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567145971/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567290311",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1567290311",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1567290311,
        "node_id": "IC_kwDOCVq1mM5davPH",
        "user": {
            "login": "laggui",
            "id": 7225623,
            "node_id": "MDQ6VXNlcjcyMjU2MjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7225623?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laggui",
            "html_url": "https://github.com/laggui",
            "followers_url": "https://api.github.com/users/laggui/followers",
            "following_url": "https://api.github.com/users/laggui/following{/other_user}",
            "gists_url": "https://api.github.com/users/laggui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laggui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laggui/subscriptions",
            "organizations_url": "https://api.github.com/users/laggui/orgs",
            "repos_url": "https://api.github.com/users/laggui/repos",
            "events_url": "https://api.github.com/users/laggui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laggui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-29T15:44:26Z",
        "updated_at": "2023-05-29T16:57:38Z",
        "author_association": "NONE",
        "body": "@chilo-ms I've managed to narrow it down to a MWE for a graph with a single node. It works with the old way of using EfficientNMS_TRT via contrib ops, but not with the latest `trt.plugins`.\r\n\r\nI double checked that the [EfficientNMS](https://github.com/NVIDIA/TensorRT/tree/v8.6.0/plugin/efficientNMSPlugin) definition hasn't changed for TensorRT 8.6. Everything seems to be in accordance w.r.t the node definition (inputs, outputs and attributes).\r\n\r\n**Code**\r\n```py\r\nfrom typing import Sequence\r\n\r\nimport numpy as np\r\nimport onnxruntime as ort\r\nfrom onnx import ModelProto, NodeProto, TensorProto, helper\r\n\r\n\r\ndef make_nms_node_trt(\r\n    inputs: Sequence[str],\r\n    outputs: Sequence[str],\r\n    score_thresh: float = 0.5,\r\n    iou_thresh: float = 0.45,\r\n    detections_per_img: int = 200,\r\n    background_class: int = -1,\r\n    class_agnostic: bool = False,\r\n) -> NodeProto:\r\n    \"\"\"\r\n    Create EfficientNMS_TRT plugin node.\r\n\r\n    Inputs:\r\n      - boxes (float): [batch_size, num_boxes, 4]\r\n      - scores (float): [batch_size, num_boxes, num_classes]\r\n\r\n    Outputs:\r\n      - num_detections (int32): [batch_size, 1]\r\n      - detection_boxes (float): [batch_size, max_output_boxes, 4]\r\n      - detection_scores (float): [batch_size, max_output_boxes]\r\n      - detection_classes (int32): [batch_size, max_output_boxes]\r\n\r\n    \"\"\"\r\n    # Ref: https://github.com/NVIDIA/TensorRT/tree/main/plugin/efficientNMSPlugin\r\n    assert len(inputs) == 2, \"EfficientNMS_TRT expects two inputs\"\r\n    assert len(outputs) == 4, \"EfficientNMS_TRT expects four outputs\"\r\n\r\n    # Make node attributes\r\n    score_threshold = helper.make_attribute(\"score_threshold\", score_thresh)\r\n    iou_threshold = helper.make_attribute(\"iou_threshold\", iou_thresh)\r\n    max_output_boxes = helper.make_attribute(\"max_output_boxes\", detections_per_img)\r\n    background_class = helper.make_attribute(\"background_class\", background_class)\r\n    score_activation = helper.make_attribute(\"score_activation\", 0)  # False\r\n    box_coding = helper.make_attribute(\"box_coding\", 0)\r\n    plugin_version = helper.make_attribute(\"plugin_version\", \"1\")\r\n\r\n    # Create NMS node\r\n    nms_node = helper.make_node(\r\n        \"EfficientNMS_TRT\",\r\n        inputs=inputs,\r\n        outputs=outputs,\r\n        name=\"NMS_Op\",\r\n        domain=\"trt.plugins\" if class_agnostic else \"\",  # new trt.plugins domain\r\n    )\r\n    nms_node.attribute.extend(\r\n        [\r\n            background_class,\r\n            box_coding,\r\n            iou_threshold,\r\n            max_output_boxes,\r\n            plugin_version,\r\n            score_activation,\r\n            score_threshold,\r\n        ]\r\n    )\r\n\r\n    # Only add class_agnostic attribute w/ \"trt.plugins\" domain\r\n    if class_agnostic:\r\n        class_agnostic = helper.make_attribute(\"class_agnostic\", class_agnostic)\r\n        nms_node.attribute.extend([class_agnostic])\r\n\r\n    return nms_node\r\n\r\n\r\ndef make_nms_model(\r\n    batch_size: int = 1,\r\n    num_boxes: int = 4,\r\n    num_classes: int = 2,\r\n    max_output_boxes: int = 200,\r\n    class_agnostic: bool = False,\r\n) -> ModelProto:\r\n    \"\"\"Create ONNX model with EfficientNMS_TRT plugin node.\"\"\"\r\n    # Inputs\r\n    boxes = helper.make_tensor_value_info(\"boxes\", TensorProto.FLOAT, [1, num_boxes, 4])\r\n    scores = helper.make_tensor_value_info(\r\n        \"scores\", TensorProto.FLOAT, [batch_size, num_boxes, num_classes]\r\n    )\r\n\r\n    # Outputs\r\n    num_detections = helper.make_tensor_value_info(\r\n        \"num_detections\", TensorProto.INT32, [batch_size, 1]\r\n    )\r\n    detection_boxes = helper.make_tensor_value_info(\r\n        \"detection_boxes\", TensorProto.FLOAT, [batch_size, max_output_boxes, 4]\r\n    )\r\n    detection_scores = helper.make_tensor_value_info(\r\n        \"detection_scores\", TensorProto.FLOAT, [batch_size, max_output_boxes]\r\n    )\r\n    detection_classes = helper.make_tensor_value_info(\r\n        \"detection_classes\", TensorProto.INT32, [batch_size, max_output_boxes]\r\n    )\r\n\r\n    # ONNX graph\r\n    node = make_nms_node_trt(\r\n        [boxes.name, scores.name],\r\n        [\r\n            num_detections.name,\r\n            detection_boxes.name,\r\n            detection_scores.name,\r\n            detection_classes.name,\r\n        ],\r\n        score_thresh=0.1,\r\n        iou_thresh=0.5,\r\n        detections_per_img=max_output_boxes,\r\n        class_agnostic=class_agnostic,\r\n    )\r\n\r\n    graph = helper.make_graph(\r\n        [node],\r\n        \"NMS_Graph_TRT\",\r\n        [boxes, scores],\r\n        [num_detections, detection_boxes, detection_scores, detection_classes],\r\n    )\r\n\r\n    # NOTE: To register \"trt.plugins\" opset domain or not?\r\n    m = helper.make_model(graph)\r\n    # m = helper.make_model(\r\n    #     graph, opset_imports=[helper.make_opsetid(\"trt.plugins\", 1)]\r\n    # )\r\n    return m\r\n\r\n\r\nclass ORTModel:\r\n    def __init__(\r\n        self,\r\n        model: ModelProto,\r\n        providers: Sequence[str] = (\r\n            \"TensorrtExecutionProvider\",\r\n            \"CUDAExecutionProvider\",\r\n        ),\r\n    ) -> None:\r\n        # Initialize ORT session\r\n        self.model = model\r\n        self.outputs = [\r\n            \"num_detections\",\r\n            \"detection_boxes\",\r\n            \"detection_scores\",\r\n            \"detection_classes\",\r\n        ]\r\n        self.session = ort.InferenceSession(\r\n            self.model.SerializeToString(), providers=providers\r\n        )\r\n\r\n    def __call__(self, boxes: np.ndarray, scores: np.ndarray) -> Sequence[np.ndarray]:\r\n        ndet, nms_boxes, nms_scores, nms_classes = self.session.run(\r\n            self.outputs,\r\n            {\"boxes\": boxes, \"scores\": scores},\r\n        )\r\n\r\n        # NOTE: ndet = 2 if not class_agnostic else 1\r\n        print(f\"Num. boxes: {ndet.item()}\")\r\n\r\n\r\ndef test_efficient_nms(class_agnostic: bool = False) -> None:\r\n    # Boxes [1, 4, 4]\r\n    boxes = np.array(\r\n        [[[1, 3, 3, 0.95], [1, 3, 4, 0.93], [0.9, 3.6, 3, 0.98], [0.9, 3.5, 3, 0.97]]],\r\n        dtype=np.float32,\r\n    )\r\n    # Scores [1, 4, 2]\r\n    scores = np.array(\r\n        [\r\n            [\r\n                [0.80, 0.20],\r\n                [0.70, 0.30],\r\n                [0.40, 0.60],\r\n                [0.75, 0.25],\r\n            ]\r\n        ],\r\n        dtype=np.float32,\r\n    )\r\n\r\n    print(\"-\" * 32)\r\n    op_domain = \"trt.plugins\" if class_agnostic else \"contrib_ops\"\r\n    print(f\"EfficientNMS_TRT w/ {op_domain}\")\r\n    model = make_nms_model(class_agnostic=class_agnostic)\r\n    model = ORTModel(model)\r\n    model(boxes, scores)\r\n    print(\"[OK] Inference test passed\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # Mute anything below error level (3)\r\n    ort.set_default_logger_severity(3)\r\n    # NOTE: uncomment `class_agnostic=False` to run the model w/ old contrib ops\r\n    # test_efficient_nms(class_agnostic=False)\r\n    test_efficient_nms(class_agnostic=True)\r\n\r\n```\r\n\r\n\r\n**Console output w/ error**\r\n\r\nOld contrib ops model runs correctly\r\n```\r\n--------------------------------\r\nEfficientNMS_TRT w/ contrib_ops\r\nNum. boxes: 2\r\n[OK] Inference test passed\r\n```\r\n\r\nNew trt.plugins model crashes\r\n```\r\n--------------------------------\r\nEfficientNMS_TRT w/ trt.plugins\r\nTraceback (most recent call last):\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 193, in <module>\r\n    test_efficient_nms(class_agnostic=True)\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 184, in test_efficient_nms\r\n    model = ORTModel(model)\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 147, in __init__\r\n    self.session = ort.InferenceSession(\r\n  File \"/home/prime/miniconda3/envs/ort115/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 383, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/prime/miniconda3/envs/ort115/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 426, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. In Node, (\"NMS_Op\", EfficientNMS_TRT, \"trt.plugins\", -1) : (\"boxes\": tensor(float),\"scores\": tensor(float),) -> (\"num_detections\": tensor(int32),\"detection_boxes\": tensor(float),\"detection_scores\": tensor(float),\"detection_classes\": tensor(int32),) , Error No opset import for domain 'trt.plugins'\r\n```\r\n\r\nAnd if I add the domain to the `ModelProto` opset imports w/ `opset_imports=[helper.make_opsetid(\"trt.plugins\", 1)]`, I get this instead.\r\n\r\n```\r\n--------------------------------\r\nEfficientNMS_TRT w/ trt.plugins\r\nTraceback (most recent call last):\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 193, in <module>\r\n    test_efficient_nms(class_agnostic=True)\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 184, in test_efficient_nms\r\n    model = ORTModel(model)\r\n  File \"/workspace/ort_inference/python/nms_mwe.py\", line 147, in __init__\r\n    self.session = ort.InferenceSession(\r\n  File \"/home/prime/miniconda3/envs/ort115/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 383, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/prime/miniconda3/envs/ort115/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 426, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Fatal error: trt.plugins: EfficientNMS_TRT(-1) is not a registered function/op\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567290311/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567415992",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1567415992",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1567415992,
        "node_id": "IC_kwDOCVq1mM5dbN64",
        "user": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-29T18:37:27Z",
        "updated_at": "2023-05-29T18:39:18Z",
        "author_association": "MEMBER",
        "body": "Hi @laggui,\r\n\r\nThanks for sharing the test python code. \r\nI found the issue when using ORT python binding to run TRT EP with the new way of supporting TRT plugins. The issue is from ORT python binding, not your python code. Please note that when using ORT C++ binding, there is no such issue. I tested the single-node model from your python code with `onnxruntime_perf_test`, and it can run successfully.\r\n\r\nThe issue of ORT python binding is because:\r\nFirst, the registration of the custom op (in your case is EfficientNMS_TRT node) happens during TRT EP initialization. \r\nThis custom op registration is needed before ORT performs graph validation. From the ORT session initialization [using python](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/onnxruntime_inference_collection.py#L426), you will see it's doing a kind of preliminary initialization (including graph validation) and the real inference session initialization (including TRT EP initialization) won't happen until [here](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/onnxruntime_inference_collection.py#L435). So that's why you were seeing the error message indicating the graph is invalid.\r\n`onnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. In Node, (\"NMS_Op\", EfficientNMS_TRT, \"trt.plugins\", -1)`\r\n\r\nC++ inference session is slightly different than Python, so it won't have this issue.\r\n\r\nI will work on how to fix this Python issue and thanks for raising this.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567415992/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567464408",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16121#issuecomment-1567464408",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16121",
        "id": 1567464408,
        "node_id": "IC_kwDOCVq1mM5dbZvY",
        "user": {
            "login": "laggui",
            "id": 7225623,
            "node_id": "MDQ6VXNlcjcyMjU2MjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7225623?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laggui",
            "html_url": "https://github.com/laggui",
            "followers_url": "https://api.github.com/users/laggui/followers",
            "following_url": "https://api.github.com/users/laggui/following{/other_user}",
            "gists_url": "https://api.github.com/users/laggui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laggui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laggui/subscriptions",
            "organizations_url": "https://api.github.com/users/laggui/orgs",
            "repos_url": "https://api.github.com/users/laggui/repos",
            "events_url": "https://api.github.com/users/laggui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laggui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-29T19:51:20Z",
        "updated_at": "2023-05-29T19:51:20Z",
        "author_association": "NONE",
        "body": "Hi @chilo-ms, good catch! The final application will be in C++ anyway, only the current prototype is written w/ the python bindings.\r\n\r\nI guess I'll move along to the C++ interface until this is fixed :)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1567464408/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]