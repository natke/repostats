[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1111752796",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1111752796",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1111752796,
        "node_id": "IC_kwDOCVq1mM5CRABc",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-28T05:12:08Z",
        "updated_at": "2022-04-28T05:12:08Z",
        "author_association": "CONTRIBUTOR",
        "body": "What TRT version are you using? Would you mind sharing the model?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1111752796/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1112305810",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1112305810",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1112305810,
        "node_id": "IC_kwDOCVq1mM5CTHCS",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-28T14:52:21Z",
        "updated_at": "2022-05-04T04:12:43Z",
        "author_association": "NONE",
        "body": "TRT is `8.0.1.6-1+cuda10.2`. You can download the model [here](https://whoi-my.sharepoint.com/:u:/g/personal/rgovostes_whoi_edu/EZ0ppoqoeBRBt3cH-XSyGDMBALZZX_7mTz964-6ljgc5uQ?e=qzcWOX) (there's a \"Download\" button along the top). This is basically a vanilla Inception v4 model that has been trained on my own data.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1112305810/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116235178",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1116235178",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1116235178,
        "node_id": "IC_kwDOCVq1mM5CiGWq",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-03T15:30:21Z",
        "updated_at": "2022-05-04T03:12:47Z",
        "author_association": "NONE",
        "body": "I have tried:\r\n\r\n* Updating to L4T r32.7, with tensorRT 8.2.1.8-1+cuda10.2, cuDNN 8.2.1.32-1+cuda10.2. There was no significant performance change.\r\n* Updating the version of PyTorch that I use to export my model to ONNX, and update to a newer opset.\r\n* Changing from a model that takes a dynamic input size to one that takes a fixed input size.\r\n\r\nI have tried using the TensorRT `polygraph` tool to run the benchmark. Representative example:\r\n\r\n## ONNX Runtime\r\n\r\n```\r\nORT_TENSORRT_ENGINE_CACHE_ENABLE=1 \\\r\nORT_TENSORRT_CACHE_PATH=./engine/ \\\r\nORT_TENSORRT_FP16_ENABLE=1 \\\r\npolygraphy run \\\r\n    --onnxrt --execution-providers tensorrt \\\r\n    --warm-up 100 --iters 100 \\\r\n    my_model.onnx\r\n```\r\n\r\n```\r\nCompleted 100 iteration(s) in 1865 ms\r\nAverage inference time: 18.65 ms.\r\n```\r\n\r\n\r\n## TensorRT\r\n\r\n```\r\npolygraphy run \\\r\n    --trt --fp16 \\\r\n    --save-engine ./trt.engine --save-timing-cache ./trt.timing \\\r\n    --warm-up 100 --iters 100 \\\r\n    my_model.onnx\r\n```\r\n\r\n```\r\nCompleted 100 iteration(s) in 993 ms\r\nAverage inference time: 9.93 ms.\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116235178/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116872126",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1116872126",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1116872126,
        "node_id": "IC_kwDOCVq1mM5Ckh2-",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-04T02:26:21Z",
        "updated_at": "2022-05-04T02:58:37Z",
        "author_association": "NONE",
        "body": "Using `polygraphy inspect model` to compare the TensorRT engines from the two methods, we have:\r\n\r\n| Method | Perf | # of Layers | Device Memory (bytes) |\r\n|---|---|---|--|\r\n| ONNX Runtime | slower | 133 | 5689344 |\r\n| TensorRT | faster | 115 | 5632000 |\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116872126/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116923499",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1116923499",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1116923499,
        "node_id": "IC_kwDOCVq1mM5CkuZr",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-04T04:44:07Z",
        "updated_at": "2022-05-04T05:23:19Z",
        "author_association": "NONE",
        "body": "I invoked ONNX Runtime with the TensorRT execution provider to force it to serialize the engine to disk, and also invoked TensorRT directly on the same ONNX base model, which serialized a second engine file. \r\n\r\nThen I benchmarked the performance of the two engine files loaded directly by TensorRT. The performance difference between the two TensorRT engines is small, maybe 5%.\r\n\r\nYet when I compare ONNX Runtime + TRT execution provider (with cached engine) to TensorRT, the performance difference is 30% or greater. Therefore I think the ONNX Runtime API itself is introducing overhead on each inference.\r\n\r\nThe base model was a standard Inception v3 model in ONNX format (exported with PyTorch). All testing was done using the `polygraphy` tool.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1116923499/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1117557413",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1117557413",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1117557413,
        "node_id": "IC_kwDOCVq1mM5CnJKl",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-04T16:27:28Z",
        "updated_at": "2022-05-05T03:42:01Z",
        "author_association": "NONE",
        "body": "Captured Nsight traces of both executions. Some observations:\r\n\r\n  * With ONNX Runtime, it takes about 1.4 ms from the beginning of `cudaMemcpyAsync` to the beginning of `ExecutionContext::enqueue`. It is only 0.7 ms for this on TensorRT.\r\n\r\n  * Only ONNX Runtime calls `cudaStreamSynchronize` but this only accounts for ~0.2 ms of the slowdown.  \r\n\r\n  * The networks are definitely slightly different, even though they originated with the same ONNX file.\r\n\r\n    <img width=\"470\" alt=\"image\" src=\"https://user-images.githubusercontent.com/108767/166724717-c30b5c2a-e1f9-4809-8d42-0ebb205fa2b8.png\">\r\n    <img width=\"547\" alt=\"image\" src=\"https://user-images.githubusercontent.com/108767/166724764-f05ee721-441c-40e5-b6aa-b81faf94f111.png\">\r\n\r\n* With ONNX Runtime are ~16.8 ms between one query and the next, compared to 12.6 ms with TensorRT. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1117557413/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1117973806",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11356#issuecomment-1117973806",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11356",
        "id": 1117973806,
        "node_id": "IC_kwDOCVq1mM5Cou0u",
        "user": {
            "login": "rgov",
            "id": 108767,
            "node_id": "MDQ6VXNlcjEwODc2Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/108767?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rgov",
            "html_url": "https://github.com/rgov",
            "followers_url": "https://api.github.com/users/rgov/followers",
            "following_url": "https://api.github.com/users/rgov/following{/other_user}",
            "gists_url": "https://api.github.com/users/rgov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rgov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rgov/subscriptions",
            "organizations_url": "https://api.github.com/users/rgov/orgs",
            "repos_url": "https://api.github.com/users/rgov/repos",
            "events_url": "https://api.github.com/users/rgov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rgov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-04T21:58:46Z",
        "updated_at": "2022-05-04T21:58:46Z",
        "author_association": "NONE",
        "body": "I guess it's not too much of a surprise when there's 430 lines of C++ between the `cudaMemcpyAsync` and the input being enqueued inside `compute_info.compute_func()`... wonder if it could be optimized.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1117973806/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 1,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]