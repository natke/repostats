[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/763566984",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/6304#issuecomment-763566984",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/6304",
        "id": 763566984,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc2MzU2Njk4NA==",
        "user": {
            "login": "MaajidKhan",
            "id": 29036417,
            "node_id": "MDQ6VXNlcjI5MDM2NDE3",
            "avatar_url": "https://avatars.githubusercontent.com/u/29036417?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MaajidKhan",
            "html_url": "https://github.com/MaajidKhan",
            "followers_url": "https://api.github.com/users/MaajidKhan/followers",
            "following_url": "https://api.github.com/users/MaajidKhan/following{/other_user}",
            "gists_url": "https://api.github.com/users/MaajidKhan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MaajidKhan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MaajidKhan/subscriptions",
            "organizations_url": "https://api.github.com/users/MaajidKhan/orgs",
            "repos_url": "https://api.github.com/users/MaajidKhan/repos",
            "events_url": "https://api.github.com/users/MaajidKhan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MaajidKhan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-01-20T12:19:06Z",
        "updated_at": "2021-01-20T12:19:06Z",
        "author_association": "CONTRIBUTOR",
        "body": "1.\r\nFirstly, I would suggest the user to install the latest **OpenVINO version (2021.2)**\r\nhttps://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html?elq_cid=6757375_ts1611141610167&erpm_id=9826563_ts1611141610167\r\n\r\n2.\r\nI see that the user is using a MNIST onnx model. The MNIST model from the onnx model zoo is usually a static model with input_shape as **1x1x28x28** and we can't do batching on a static model. I hope the user is using a dynamic onnx model with a input_shape, say Nx1x28x28. Only when using a dynamic model, we can do batch Inferencing.\r\n**I downloaded the MNIST onnx model from here:**\r\nhttps://github.com/onnx/models/tree/master/vision/classification/mnist\r\n\r\n3.\r\nSay, The user is using a dynamic_model and from the code above, a batch_size=50 is being used which might be a little too much for a MyriadX device(Memory Limitation). I would suggest the user to use a smaller batch_size.\r\n\r\n4.\r\ncurrently, OpenVINO-EP will be built as a shared_lib  by default. we need to add an additional flag **--build_shared_lib** while building openvino-ep.\r\n\r\n**OpenVINO-EP Build Instructions Page:**\r\nhttps://github.com/microsoft/onnxruntime/blob/master/BUILD.md#openvino\r\n\r\n**OpenVINO-EP Docx:**\r\nhttps://github.com/microsoft/onnxruntime/blob/master/docs/execution_providers/OpenVINO-ExecutionProvider.md\r\n\r\nso, the build command would look something like this now:\r\n**command:**\r\n./build.sh --config RelWithDebInfo --use_openvino MYRIAD_FP16 --build_shared_lib\r\n\r\nAfter EP is built successfully and we navigate to ../onnxruntime/build/Linux/RelWithDebInfo/\r\n**Now, we will have the following shared libraries here.**\r\nlibonnxruntime_providers_openvino.so  \r\nlibonnxruntime_providers_shared.so    \r\nlibonnxruntime.so.1.6.0      (This only gets added when you use --build_shared_lib flag while building)\r\n\r\n5.\r\nThere is no need to create a seperate Ort::MemoryInfo object specific for openvino. As you are already using the OpenVINO c++ API ( sessionOptions.AppendExecutionProvider_OpenVINO(ovOptions); ), it would be taken care of.\r\n\r\n6.\r\nFor your reference, Attaching a working **cpp sample code** for mnist.onnx model (static model) which I got from the model zoo.\r\n[mnist_openvino_ep_sample.txt](https://github.com/microsoft/onnxruntime/files/5842244/mnist_openvino_ep_sample.txt)\r\n\r\n**Adding steps I used to compile on Linux (ubuntu os):**\r\n\r\n**step 1:**\r\n**command to compile (compiling from this path: ./onnxruntime/build/Linux/RelWithDebInfo/)**\r\ng++ -o run_mnist mnist_openvino_sample.cpp -I ../../../include/onnxruntime/core/session/ -L ./ -lonnxruntime_providers_openvino -lonnxruntime_providers_shared -lonnxruntime\r\n\r\n**step 2:**\r\n./run_mnist\r\n\r\nPrior to compiling, make sure all the three shared libraries mentioned at the top are copied to this location.\r\n**/usr/lib/x86_64-linux-gnu/**\r\n\r\nHere's the output from MNIST model using MYRIADX device with OpenVINO-EP:\r\n![image](https://user-images.githubusercontent.com/29036417/105173723-6cbc0880-5b47-11eb-8adf-3b76e0b6052c.png)\r\n\r\nI have extra prints in the picture, because I was running in debug mode.\r\n\r\nLet me know, if you need any more information or if you run into issue again.\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/763566984/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]