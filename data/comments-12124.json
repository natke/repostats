[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178114456",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12124#issuecomment-1178114456",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12124",
        "id": 1178114456,
        "node_id": "IC_kwDOCVq1mM5GOJmY",
        "user": {
            "login": "YUNQIUGUO",
            "id": 35738743,
            "node_id": "MDQ6VXNlcjM1NzM4NzQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/35738743?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YUNQIUGUO",
            "html_url": "https://github.com/YUNQIUGUO",
            "followers_url": "https://api.github.com/users/YUNQIUGUO/followers",
            "following_url": "https://api.github.com/users/YUNQIUGUO/following{/other_user}",
            "gists_url": "https://api.github.com/users/YUNQIUGUO/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YUNQIUGUO/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YUNQIUGUO/subscriptions",
            "organizations_url": "https://api.github.com/users/YUNQIUGUO/orgs",
            "repos_url": "https://api.github.com/users/YUNQIUGUO/repos",
            "events_url": "https://api.github.com/users/YUNQIUGUO/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YUNQIUGUO/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T19:21:21Z",
        "updated_at": "2022-07-07T19:21:21Z",
        "author_association": "MEMBER",
        "body": "I am not sure if beam search support large t5 model yet. @tianleiwu Any insights?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178114456/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178189858",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12124#issuecomment-1178189858",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12124",
        "id": 1178189858,
        "node_id": "IC_kwDOCVq1mM5GOcAi",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T20:30:00Z",
        "updated_at": "2022-07-07T20:34:28Z",
        "author_association": "MEMBER",
        "body": "@[NouamaneTazi](https://github.com/NouamaneTazi), the bottleneck is memory size of hardware. You might notice that the pytorch model itself is 42GB. Convert the model need space (both memory and disk) of multiple times of model size. Even A100 might not have enough GPU memory for this task.\r\n\r\nCould you remove `--use_gpu` and use a machine with enough CPU memory (like 256GB)? Also, please use nightly package instead of ORT 1.11.1, since some change in BeamSearch interface is not backward compatible.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178189858/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178202871",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12124#issuecomment-1178202871",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12124",
        "id": 1178202871,
        "node_id": "IC_kwDOCVq1mM5GOfL3",
        "user": {
            "login": "NouamaneTazi",
            "id": 29777165,
            "node_id": "MDQ6VXNlcjI5Nzc3MTY1",
            "avatar_url": "https://avatars.githubusercontent.com/u/29777165?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NouamaneTazi",
            "html_url": "https://github.com/NouamaneTazi",
            "followers_url": "https://api.github.com/users/NouamaneTazi/followers",
            "following_url": "https://api.github.com/users/NouamaneTazi/following{/other_user}",
            "gists_url": "https://api.github.com/users/NouamaneTazi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NouamaneTazi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NouamaneTazi/subscriptions",
            "organizations_url": "https://api.github.com/users/NouamaneTazi/orgs",
            "repos_url": "https://api.github.com/users/NouamaneTazi/repos",
            "events_url": "https://api.github.com/users/NouamaneTazi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NouamaneTazi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T20:41:45Z",
        "updated_at": "2022-07-07T20:41:45Z",
        "author_association": "NONE",
        "body": "Thank you @tianleiwu. How can I run inference for such large models on a multi GPU setup? Can you point me to some example?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178202871/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178268597",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12124#issuecomment-1178268597",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12124",
        "id": 1178268597,
        "node_id": "IC_kwDOCVq1mM5GOvO1",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T21:57:41Z",
        "updated_at": "2022-07-07T23:59:45Z",
        "author_association": "MEMBER",
        "body": "I guess one A100 with 80GB might be able to inference t5-11b model in float32. \r\n![image](https://user-images.githubusercontent.com/30328909/177890544-cbc8d6b8-637e-4156-b225-a177b71d98f8.png)\r\n\r\nIf you convert the ONNX model to mixed precision (with potential loss in accuracy), it might be able to run in 40GB A100 (I have not tried it so it is not sure).\r\n\r\n@NouamaneTazi, currently ORT supports one session in one GPU (That also means BeamSearch operator can only run in one GPU).\r\n\r\nFor t5-11b, you might try create one session for encoder in one GPU, and a session for decoder in another GPU.\r\n\r\nFor larger model, a possible walkaround is to split a large model to multiple models (like split 24 layers to 2 models with 12 layers in each model), then create one inference session for each model, and each session is running in different GPU. You will need implement a custom version of beam search for this purpose.\r\n \r\n@viboga, could you share prototype of beam search custom operator when it is ready. Other users could modify it to support multiple models.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178268597/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]