[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1180075426",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11986#issuecomment-1180075426",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986",
        "id": 1180075426,
        "node_id": "IC_kwDOCVq1mM5GVoWi",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-11T07:48:19Z",
        "updated_at": "2022-07-11T07:48:19Z",
        "author_association": "MEMBER",
        "body": "LSTM is implemented as a single kernel. Scan is implemented by calling the subgraph in the Scan node sequentially for each input. i.e. you can think of LSTM as calling one big function that does all the work, and Scan as calling one function per node in the subgraph, and repeating that for each value in the input sequence. Due to this the amount of optimization and parallelism in the implementation of LSTM is going to be significantly better.\r\n\r\nTensorRT is potentially able to create a compiled version of the Scan if all nodes in the subgraph are supported by the TensorRT execution provider. I would guess this is the case with your test model, and the compiled version can do a lot more optimizations and execute more operations in parallel.\r\n\r\nNote that it's non-trivial to correctly handle calling the subgraph in parallel as there can be state variables which may change between each iteration. We could potentially optimize to execute a Scan node with no state variables in parallel, however doing so would have implications on memory usage.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1180075426/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1182083097",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11986#issuecomment-1182083097",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986",
        "id": 1182083097,
        "node_id": "IC_kwDOCVq1mM5GdSgZ",
        "user": {
            "login": "rakib-hasan",
            "id": 1003393,
            "node_id": "MDQ6VXNlcjEwMDMzOTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1003393?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rakib-hasan",
            "html_url": "https://github.com/rakib-hasan",
            "followers_url": "https://api.github.com/users/rakib-hasan/followers",
            "following_url": "https://api.github.com/users/rakib-hasan/following{/other_user}",
            "gists_url": "https://api.github.com/users/rakib-hasan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rakib-hasan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rakib-hasan/subscriptions",
            "organizations_url": "https://api.github.com/users/rakib-hasan/orgs",
            "repos_url": "https://api.github.com/users/rakib-hasan/repos",
            "events_url": "https://api.github.com/users/rakib-hasan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rakib-hasan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-12T17:36:39Z",
        "updated_at": "2022-07-12T17:36:39Z",
        "author_association": "NONE",
        "body": "Thanks for the explanation, Scott. Since this is the expected behavior for CUDA EP, I will close this issue.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1182083097/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]