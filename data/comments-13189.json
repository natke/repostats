[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1360652084",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13189#issuecomment-1360652084",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13189",
        "id": 1360652084,
        "node_id": "IC_kwDOCVq1mM5RGec0",
        "user": {
            "login": "kunal-vaishnavi",
            "id": 115581922,
            "node_id": "U_kgDOBuOj4g",
            "avatar_url": "https://avatars.githubusercontent.com/u/115581922?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kunal-vaishnavi",
            "html_url": "https://github.com/kunal-vaishnavi",
            "followers_url": "https://api.github.com/users/kunal-vaishnavi/followers",
            "following_url": "https://api.github.com/users/kunal-vaishnavi/following{/other_user}",
            "gists_url": "https://api.github.com/users/kunal-vaishnavi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kunal-vaishnavi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kunal-vaishnavi/subscriptions",
            "organizations_url": "https://api.github.com/users/kunal-vaishnavi/orgs",
            "repos_url": "https://api.github.com/users/kunal-vaishnavi/repos",
            "events_url": "https://api.github.com/users/kunal-vaishnavi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kunal-vaishnavi/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-12-21T01:37:52Z",
        "updated_at": "2022-12-21T01:37:52Z",
        "author_association": "MEMBER",
        "body": "You can export the LongT5 model with optimum\r\n\r\n```\r\npython3 -m optimum.exporters.onnx --model google/long-t5-tglobal-xl xl/\r\n```\r\n\r\nand then optimize directly with the optimizer script\r\n\r\n```\r\npython3 -m onnxruntime.transformers.optimizer --input xl/model.onnx --output xl/model.onnx --use_external_data_format\r\n```\r\n\r\nThen you can test your model\r\n\r\n```\r\nimport onnxruntime\r\nimport numpy as np\r\n\r\n# Replace these values with your data\r\nbatch_size = 4\r\nsequence_length = 16\r\ninputs = {\r\n     ‘input_ids’: np.ones((batch_size, sequence_length)).astype(np.int64),\r\n     ‘attention_mask’: np.ones((batch_size, sequence_length)).astype(np.int64),\r\n     ‘decoder_input_ids’: np.ones((batch_size, sequence_length)).astype(np.int64)\r\n}\r\n\r\n# Run inference session\r\nsess = onnxruntime.InferenceSession(‘xl/model.onnx’, providers=[‘CUDAExecutionProvider’, ‘CPUExecutionProvider’])\r\noutputs = sess.run(None, inputs)\r\nprint(outputs)\r\n```\r\nby replacing the values in `batch_size`, `sequence_length`, and `inputs` with your data.\r\n\r\nEnvironment:\r\n- onnx: v1.12.0\r\n- onnxruntime: v1.13.1\r\n- optimum: v1.5.1\r\n- transformers: v4.24.0\r\n- torch: v1.11.0",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1360652084/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1374139583",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13189#issuecomment-1374139583",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13189",
        "id": 1374139583,
        "node_id": "IC_kwDOCVq1mM5R57S_",
        "user": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-06T21:14:21Z",
        "updated_at": "2023-01-06T21:14:21Z",
        "author_association": "MEMBER",
        "body": "PR in Optimum: [Add support for LongT5 optimization using ORT transformer optimizer script](https://github.com/huggingface/optimum/pull/683)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1374139583/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]