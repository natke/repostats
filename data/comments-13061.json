[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1256669687",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1256669687",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1256669687,
        "node_id": "IC_kwDOCVq1mM5K50H3",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-23T20:57:01Z",
        "updated_at": "2022-09-23T20:57:01Z",
        "author_association": "MEMBER",
        "body": "Can you paste the results from the different runs?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1256669687/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1256941604",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1256941604",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1256941604,
        "node_id": "IC_kwDOCVq1mM5K62gk",
        "user": {
            "login": "snow-tyan",
            "id": 52491224,
            "node_id": "MDQ6VXNlcjUyNDkxMjI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/52491224?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snow-tyan",
            "html_url": "https://github.com/snow-tyan",
            "followers_url": "https://api.github.com/users/snow-tyan/followers",
            "following_url": "https://api.github.com/users/snow-tyan/following{/other_user}",
            "gists_url": "https://api.github.com/users/snow-tyan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snow-tyan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snow-tyan/subscriptions",
            "organizations_url": "https://api.github.com/users/snow-tyan/orgs",
            "repos_url": "https://api.github.com/users/snow-tyan/repos",
            "events_url": "https://api.github.com/users/snow-tyan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snow-tyan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-24T11:05:32Z",
        "updated_at": "2022-09-24T11:07:40Z",
        "author_association": "NONE",
        "body": "> Can you paste the results from the different runs?\r\n\r\n\r\nI rewrote a demo in Python and found that the same problem only occurred in CUDAExecutionProvider, but not in CPUExecutionProvider and TensorrtExecutionProvider.\r\n\r\nI'm sorry that model weights and test images cannot be uploaded due to work reasons. However, I have tested the same problem with other models.\r\n\r\n```shell\r\n### Using CUDAExecutionProvider (Executed multiple times with the different result)\r\n[301.5984001159668, 181.84381484985352, 51.91532, 68.349724, 0.9654644]\r\n[301.59935569763184, 181.84461975097656, 51.91408, 68.34961, 0.96547186]\r\n[301.59963607788086, 181.84502029418945, 51.913155, 68.34878, 0.9654721]\r\n[301.5995502471924, 181.84505081176758, 51.913326, 68.34872, 0.9654721]\r\n[301.59913063049316, 181.84360122680664, 51.914288, 68.35012, 0.9654635]\r\n\r\n### Using CPUExecutionProvider (Executed multiple times with the same result)\r\n[301.59936714172363, 181.8446159362793, 51.91412, 68.34959, 0.9654717]\r\n\r\n### Using TensorrtExecutionProvider (Executed multiple times with the same result)\r\n[301.5961723327637, 181.84202194213867, 51.91575, 68.35517, 0.9654652]\r\n```\r\n\r\nThe following is the python test code\r\n\r\n```python\r\nimport onnxruntime as ort\r\n\r\nimport cv2\r\nfrom PIL import Image\r\nimport numpy as np\r\nfrom typing import List\r\nimport os\r\nimport argparse\r\n\r\n\r\ndef PreProcess(input_data):\r\n    input_data = input_data.astype('float32')\r\n\r\n    mean = np.array([0., 0., 0.])\r\n    std = np.array([255., 255., 255.])\r\n\r\n    norm_input_data = np.zeros(input_data.shape).astype('float32')\r\n\r\n    for i in range(input_data.shape[0]):\r\n        norm_input_data[i, :, :] = ((input_data[i, :, :]) - mean[i]) / std[i]\r\n\r\n    norm_input_data = norm_input_data.reshape(1, 3, 640, 640).astype('float32')\r\n    return norm_input_data\r\n\r\n\r\ndef Nms(bboxes: List[List[float]], nms_thresh: float) -> None:\r\n    bboxes.sort(key=lambda x: x[4], reverse=True)\r\n    i = 0\r\n    while i < len(bboxes):\r\n        box_i = [bboxes[i][0], bboxes[i][1], bboxes[i][2], bboxes[i][3]]\r\n        box_i_area = box_i[2] * box_i[3]\r\n        j = i + 1\r\n        while j < len(bboxes):\r\n            box_j = [bboxes[j][0], bboxes[j][1], bboxes[j][2], bboxes[j][3]]\r\n            box_j_area = box_j[2] * box_j[3]\r\n            xx1 = max(box_i[0], box_j[0])\r\n            yy1 = max(box_i[1], box_j[1])\r\n            xx2 = min(box_i[0] + box_i[2], box_j[0] + box_j[2])\r\n            yy2 = min(box_i[1] + box_i[3], box_j[1] + box_j[3])\r\n            intersection = max(0., xx2 - xx1) * max(0., yy2 - yy1)\r\n            union_f = box_i_area + box_j_area - intersection\r\n            iou = intersection / union_f\r\n            if (iou >= nms_thresh):\r\n                bboxes.pop(j)\r\n            else:\r\n                j += 1\r\n        i += 1\r\n\r\n\r\ndef ArgsParser():\r\n    parser = argparse.ArgumentParser(\"meter_recon onnxruntime inference\")\r\n    parser.add_argument(\r\n        '-m', '--model',\r\n        default='models/sim/meter_det.sim.onnx',\r\n        # default='models/remove_initializer/meter_det.onnx',\r\n        type=str,\r\n        help=\"model path\")\r\n    parser.add_argument(\r\n        '-i', '--image',\r\n        default='test_imgs/MeterRecon/cb1/20211102154627459008378666406441.jpg',\r\n        type=str,\r\n        help=\"image path\")\r\n\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = ArgsParser()\r\n\r\n    in_mat = cv2.imread(args.image)\r\n    # image = Image.open(image_path).resize((640, 640))\r\n    in_mat = cv2.cvtColor(in_mat, cv2.COLOR_BGR2RGB)\r\n    in_mat = cv2.resize(in_mat, (640, 640))\r\n    image_data = np.array(in_mat).transpose(2, 0, 1)\r\n    input_data = PreProcess(image_data)\r\n\r\n    print(f'ort.get_device()={ort.get_device()}')\r\n    print(f'ort.get_available_providers()={ort.get_available_providers()}')\r\n    session_options = ort.SessionOptions()\r\n    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\r\n    cpu_providers = ['CPUExecutionProvider']\r\n    cuda_providers = [\r\n        ('CUDAExecutionProvider', {\r\n            'device_id': 0\r\n        }),\r\n        'CPUExecutionProvider',\r\n    ]\r\n    tensorrt_providers = [\r\n        ('TensorrtExecutionProvider', {\r\n            'device_id': 0,\r\n            'trt_engine_cache_enable': True,\r\n            'trt_engine_cache_path': './trtcache'\r\n        }),\r\n        ('CUDAExecutionProvider', {\r\n            'device_id': 0\r\n        }),\r\n        'CPUExecutionProvider',\r\n    ]\r\n    ### 'gpu_mem_limit': '18446744073709551615' size_t::max (2^64-1)\r\n    '''\r\n    'providers' can contain either names or names and options. \r\n    When any options are given in 'providers', 'provider_options' should not be used.\r\n    The list of providers is ordered by precedence. \r\n    For example `['CUDAExecutionProvider', 'CPUExecutionProvider']` means execute a node using `CUDAExecutionProvider`\r\n    if capable, otherwise execute using `CPUExecutionProvider`.\r\n    '''\r\n    session = ort.InferenceSession(args.model,\r\n                                   sess_options=session_options,\r\n                                   providers=tensorrt_providers)\r\n                                #    providers=cuda_providers)\r\n                                #    providers=cpu_providers)\r\n    print(session.get_providers())\r\n    print(session.get_provider_options())\r\n\r\n    ### inference\r\n    # ortvalue = ort.OrtValue.ortvalue_from_numpy(input_data, 'cuda', 0)\r\n    ortvalue = ort.OrtValue.ortvalue_from_numpy(input_data)\r\n    print(ortvalue.device_name())  ## cpu or cuda\r\n    print(ortvalue.shape())  ## [1, 3, 640, 640]\r\n    print(ortvalue.data_type())  ## tensor(float)\r\n    print(ortvalue.is_tensor())  ## True\r\n    raw_result = session.run(['output'], {'images': ortvalue})\r\n    # raw_result = session.run(['output'], {'images': ortvalue})\r\n    print(f'raw_result[0].shape={raw_result[0].shape}')\r\n\r\n    classes = 1\r\n    background = -1\r\n    total_classes = classes + (0 if background == -1 else -1)\r\n    confidence_thresh = [0.3] * total_classes\r\n    nms_thresh = [0.5] * total_classes\r\n    boxes_number = raw_result[0].shape[1]\r\n    print(f'boxes_number={boxes_number}')\r\n    prediction = raw_result[0][0]  ## (1, 25200, 6)\r\n    results = []  # [[x, y, w, h], score]\r\n    for box_index in range(boxes_number):\r\n        for total_class_index in range(total_classes):\r\n            if background != -1 and total_class_index == background:\r\n                continue\r\n            class_index = total_class_index - 1 if background != -1 and total_class_index > background else total_class_index\r\n            if prediction[box_index][4] > confidence_thresh[class_index]:\r\n                center_x = prediction[box_index][0]\r\n                center_y = prediction[box_index][1]\r\n                w = prediction[box_index][2]\r\n                h = prediction[box_index][3]\r\n                results.append([\r\n                    center_x - w / 2, center_y - h / 2, w, h,\r\n                    prediction[box_index][4] * prediction[box_index][5]\r\n                ])\r\n    print(\r\n        \"Before NMS----------------------------------------------------------\")\r\n    print(f'result.size={len(results)}')\r\n    # print(results)\r\n    # print(results[0])\r\n    # results[0].sort(key=lambda x: x[])\r\n    if len(results) != 0:\r\n        Nms(results, nms_thresh[0])\r\n    print(\r\n        \"After NMS----------------------------------------------------------\")\r\n    print(f'result.size={len(results)}')\r\n    print(results[0])\r\n    # PostProcess()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1256941604/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257078756",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1257078756",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1257078756,
        "node_id": "IC_kwDOCVq1mM5K7X_k",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-24T22:55:53Z",
        "updated_at": "2022-09-25T18:23:31Z",
        "author_association": "MEMBER",
        "body": "No, it is not related to data copy. It is likely caused by implementation of some operators, which need aggregation (like softmax, LayerNorm, Gemm). Since blocks of threads might be executed in different orders, so aggregation result might be slightly different. Running PyTorch model might also have similar issue.\r\n\r\nTo find the operator that causes the issue, you can refer to this code: https://github.com/microsoft/onnxconverter-common/blob/814cdf494d987900d30b16971c0e8334aaca9ae6/onnxconverter_common/auto_mixed_precision.py#L128-L148 to inspect the output of each node in multiple runs. Then you can do some statistics to see the first node that has large variance in result.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257078756/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257127895",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1257127895",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1257127895,
        "node_id": "IC_kwDOCVq1mM5K7j_X",
        "user": {
            "login": "snow-tyan",
            "id": 52491224,
            "node_id": "MDQ6VXNlcjUyNDkxMjI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/52491224?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snow-tyan",
            "html_url": "https://github.com/snow-tyan",
            "followers_url": "https://api.github.com/users/snow-tyan/followers",
            "following_url": "https://api.github.com/users/snow-tyan/following{/other_user}",
            "gists_url": "https://api.github.com/users/snow-tyan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snow-tyan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snow-tyan/subscriptions",
            "organizations_url": "https://api.github.com/users/snow-tyan/orgs",
            "repos_url": "https://api.github.com/users/snow-tyan/repos",
            "events_url": "https://api.github.com/users/snow-tyan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snow-tyan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-25T06:00:01Z",
        "updated_at": "2022-09-25T06:00:01Z",
        "author_association": "NONE",
        "body": "> No, it is not related to data copy. It is likely caused by implementation of some operators, which need aggregation (like softmax, LayerNorm, Gemm). Since blocks of threads might be executed in different orders, so aggregation result might be slightly different. Running PyTorch model might also have similar issue.\r\n> \r\n> To find the operator that causes the issue, you can refer to this code: https://github.com/microsoft/onnxconverter-common/blob/814cdf494d987900d30b16971c0e8334aaca9ae6/onnxconverter_common/auto_mixed_precision.py#L128-L148 to inspect the output of each node in multiple runs. Then you can do some statistics to see the first node that cause significant difference.\r\n\r\nThanks for reply. Does this problem occur even with a single thread?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257127895/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257251153",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1257251153",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1257251153,
        "node_id": "IC_kwDOCVq1mM5K8CFR",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-25T18:29:23Z",
        "updated_at": "2022-09-25T18:29:32Z",
        "author_association": "MEMBER",
        "body": "Cuda still uses multiple threads even though you have only one cpu thread. \r\n\r\nThis problem does not occur to every model so I suggest to investigate a little just in case it is a bug.\r\n\r\nAnother way is to add --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=1 in build command line to build a package from source code. Set environment variable  ORT_DEBUG_NODE_IO_DUMP_OUTPUT_DATA to be 1 before running your application. In this way, you can see of output of each node. Compare the stdout of two runs can find out the root cause.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257251153/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257359626",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1257359626",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1257359626,
        "node_id": "IC_kwDOCVq1mM5K8ckK",
        "user": {
            "login": "snow-tyan",
            "id": 52491224,
            "node_id": "MDQ6VXNlcjUyNDkxMjI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/52491224?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snow-tyan",
            "html_url": "https://github.com/snow-tyan",
            "followers_url": "https://api.github.com/users/snow-tyan/followers",
            "following_url": "https://api.github.com/users/snow-tyan/following{/other_user}",
            "gists_url": "https://api.github.com/users/snow-tyan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snow-tyan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snow-tyan/subscriptions",
            "organizations_url": "https://api.github.com/users/snow-tyan/orgs",
            "repos_url": "https://api.github.com/users/snow-tyan/repos",
            "events_url": "https://api.github.com/users/snow-tyan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snow-tyan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-26T01:34:32Z",
        "updated_at": "2022-09-26T01:34:32Z",
        "author_association": "NONE",
        "body": "> Cuda still uses multiple threads even though you have only one cpu thread.\r\n> \r\n> This problem does not occur to every model so I suggest to investigate a little just in case it is a bug.\r\n> \r\n> Another way is to add --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=1 in build command line to build a package from source code. Set environment variable ORT_DEBUG_NODE_IO_DUMP_OUTPUT_DATA to be 1 before running your application. In this way, you can see of output of each node. Compare the stdout of two runs can find out the root cause.\r\n\r\nThanks again for your reply. I will recompile the ort to try the second method",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257359626/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1285322692",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1285322692",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1285322692,
        "node_id": "IC_kwDOCVq1mM5MnHfE",
        "user": {
            "login": "snow-tyan",
            "id": 52491224,
            "node_id": "MDQ6VXNlcjUyNDkxMjI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/52491224?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snow-tyan",
            "html_url": "https://github.com/snow-tyan",
            "followers_url": "https://api.github.com/users/snow-tyan/followers",
            "following_url": "https://api.github.com/users/snow-tyan/following{/other_user}",
            "gists_url": "https://api.github.com/users/snow-tyan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snow-tyan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snow-tyan/subscriptions",
            "organizations_url": "https://api.github.com/users/snow-tyan/orgs",
            "repos_url": "https://api.github.com/users/snow-tyan/repos",
            "events_url": "https://api.github.com/users/snow-tyan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snow-tyan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-20T10:50:01Z",
        "updated_at": "2022-10-20T10:50:01Z",
        "author_association": "NONE",
        "body": "> Cuda still uses multiple threads even though you have only one cpu thread.\r\n> \r\n> This problem does not occur to every model so I suggest to investigate a little just in case it is a bug.\r\n> \r\n> Another way is to add --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=1 in build command line to build a package from source code. Set environment variable ORT_DEBUG_NODE_IO_DUMP_OUTPUT_DATA to be 1 before running your application. In this way, you can see of output of each node. Compare the stdout of two runs can find out the root cause.\r\n\r\nI add --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=1 in build command.\r\nAnd I use `ORT_DEBUG_NODE_IO_DUMP_OUTPUT_DATA=1 ./a.out` to see the output of each node successfully.\r\nBut when I use `ORT_DEBUG_NODE_IO_DUMP_OUTPUT_DATA=0 ./a.out`, it also prints the name of each node. How can I close this print information",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1285322692/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1288368380",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1288368380",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1288368380,
        "node_id": "IC_kwDOCVq1mM5MyvD8",
        "user": {
            "login": "snow-tyan",
            "id": 52491224,
            "node_id": "MDQ6VXNlcjUyNDkxMjI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/52491224?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snow-tyan",
            "html_url": "https://github.com/snow-tyan",
            "followers_url": "https://api.github.com/users/snow-tyan/followers",
            "following_url": "https://api.github.com/users/snow-tyan/following{/other_user}",
            "gists_url": "https://api.github.com/users/snow-tyan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snow-tyan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snow-tyan/subscriptions",
            "organizations_url": "https://api.github.com/users/snow-tyan/orgs",
            "repos_url": "https://api.github.com/users/snow-tyan/repos",
            "events_url": "https://api.github.com/users/snow-tyan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snow-tyan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-24T03:34:30Z",
        "updated_at": "2022-10-24T03:34:30Z",
        "author_association": "NONE",
        "body": "@tianleiwu I found that OrtCUDAProviderOptionsV2 was OK. And No previous problems. Thanks, I know the reason for the new version of optionsv2",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1288368380/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1289906133",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13061#issuecomment-1289906133",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13061",
        "id": 1289906133,
        "node_id": "IC_kwDOCVq1mM5M4mfV",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-25T02:50:58Z",
        "updated_at": "2022-10-25T02:50:58Z",
        "author_association": "MEMBER",
        "body": "@snow-tyan, it is good to know that OrtCUDAProviderOptionsV2 is OK. Maybe it is caused by convolution search settings for cuDNN.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1289906133/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]