[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1031134764",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1031134764",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1031134764,
        "node_id": "IC_kwDOCVq1mM49dd4s",
        "user": {
            "login": "zerovirus123",
            "id": 9401015,
            "node_id": "MDQ6VXNlcjk0MDEwMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9401015?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zerovirus123",
            "html_url": "https://github.com/zerovirus123",
            "followers_url": "https://api.github.com/users/zerovirus123/followers",
            "following_url": "https://api.github.com/users/zerovirus123/following{/other_user}",
            "gists_url": "https://api.github.com/users/zerovirus123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zerovirus123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zerovirus123/subscriptions",
            "organizations_url": "https://api.github.com/users/zerovirus123/orgs",
            "repos_url": "https://api.github.com/users/zerovirus123/repos",
            "events_url": "https://api.github.com/users/zerovirus123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zerovirus123/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-07T07:01:04Z",
        "updated_at": "2022-02-07T20:40:49Z",
        "author_association": "NONE",
        "body": ">Hi all,\r\n> What is the correct way to create an ORTSession object and returning it safely?\r\n\r\n`Ort` namespace are thin wrapper objects around pointers to the actual objects with interfaces added. They are move only objects to ensure unique ownership of the underlying ORT object. Very much like std::unique_ptr.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1031134764/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032189861",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1032189861",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1032189861,
        "node_id": "IC_kwDOCVq1mM49hfel",
        "user": {
            "login": "zerovirus123",
            "id": 9401015,
            "node_id": "MDQ6VXNlcjk0MDEwMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9401015?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zerovirus123",
            "html_url": "https://github.com/zerovirus123",
            "followers_url": "https://api.github.com/users/zerovirus123/followers",
            "following_url": "https://api.github.com/users/zerovirus123/following{/other_user}",
            "gists_url": "https://api.github.com/users/zerovirus123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zerovirus123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zerovirus123/subscriptions",
            "organizations_url": "https://api.github.com/users/zerovirus123/orgs",
            "repos_url": "https://api.github.com/users/zerovirus123/repos",
            "events_url": "https://api.github.com/users/zerovirus123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zerovirus123/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-08T04:00:57Z",
        "updated_at": "2022-02-08T04:00:57Z",
        "author_association": "NONE",
        "body": "Oddly enough, this is only an issue when the CUDA provider is used. If I use the CPU provider then returning a session object is not a problem.\r\n\r\nAlso, since the OrtSessions are move only objects, is it possible to transfer ownership from the called function to the calling function?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032189861/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032215057",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1032215057",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1032215057,
        "node_id": "IC_kwDOCVq1mM49hloR",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-08T04:57:27Z",
        "updated_at": "2022-02-08T04:57:27Z",
        "author_association": "MEMBER",
        "body": "`Ort::Env env;` is defined in a local scope and will get destroyed as the function scope ends. The environment must be alive when performing inferencing (as it hosts some crucial components like the default logger). \r\n\r\nIt is hard to say why this works for the CPU EP and not for the CUDA EP without running it through the debugger, but it is possible that some component in the CUDA EP is trying to use the default logger from the environment and the environment instance is destroyed (one possible explanation).\r\n\r\nAs a mild aside, this line doesn't seem right `cuda_options.has_user_compute_stream = 1;` especially since there is no compute stream being passed in for the CUDA EP to use. I would have expected this to be 0 to allow the CUDA EP to use its own stream.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032215057/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032422208",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1032422208",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1032422208,
        "node_id": "IC_kwDOCVq1mM49iYNA",
        "user": {
            "login": "zerovirus123",
            "id": 9401015,
            "node_id": "MDQ6VXNlcjk0MDEwMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9401015?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zerovirus123",
            "html_url": "https://github.com/zerovirus123",
            "followers_url": "https://api.github.com/users/zerovirus123/followers",
            "following_url": "https://api.github.com/users/zerovirus123/following{/other_user}",
            "gists_url": "https://api.github.com/users/zerovirus123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zerovirus123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zerovirus123/subscriptions",
            "organizations_url": "https://api.github.com/users/zerovirus123/orgs",
            "repos_url": "https://api.github.com/users/zerovirus123/repos",
            "events_url": "https://api.github.com/users/zerovirus123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zerovirus123/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-08T09:59:03Z",
        "updated_at": "2022-02-08T09:59:03Z",
        "author_association": "NONE",
        "body": "@hariharans29 thanks for the explanation. Would ```cuda_options.has_user_compute_stream = 1;``` slow down the CUDA runs?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032422208/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032532123",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1032532123",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1032532123,
        "node_id": "IC_kwDOCVq1mM49izCb",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-08T12:01:29Z",
        "updated_at": "2022-02-08T12:01:29Z",
        "author_association": "MEMBER",
        "body": "> @hariharans29 thanks for the explanation. Would `cuda_options.has_user_compute_stream = 1;` slow down the CUDA runs?\r\n\r\nNo it wouldn't. But it would mean that you would have to provide the user stream for ORT to use. I suggest setting it to 0 and let ORT create and use its own stream for compute.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032532123/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032551001",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1032551001",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1032551001,
        "node_id": "IC_kwDOCVq1mM49i3pZ",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-08T12:23:01Z",
        "updated_at": "2022-02-08T12:23:01Z",
        "author_association": "MEMBER",
        "body": "Closing this as it seems there is nothing left to be discussed here. Feel free to re-open if you feel otherwise. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1032551001/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1101843740",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10472#issuecomment-1101843740",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10472",
        "id": 1101843740,
        "node_id": "IC_kwDOCVq1mM5BrM0c",
        "user": {
            "login": "adnan134j2",
            "id": 101260877,
            "node_id": "U_kgDOBgkeTQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/101260877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adnan134j2",
            "html_url": "https://github.com/adnan134j2",
            "followers_url": "https://api.github.com/users/adnan134j2/followers",
            "following_url": "https://api.github.com/users/adnan134j2/following{/other_user}",
            "gists_url": "https://api.github.com/users/adnan134j2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adnan134j2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adnan134j2/subscriptions",
            "organizations_url": "https://api.github.com/users/adnan134j2/orgs",
            "repos_url": "https://api.github.com/users/adnan134j2/repos",
            "events_url": "https://api.github.com/users/adnan134j2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adnan134j2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-18T23:13:17Z",
        "updated_at": "2022-04-18T23:13:17Z",
        "author_association": "NONE",
        "body": "@hariharans29 would you please look at the issue  #11235 i shared. I am stuck at this issue since many days. Please Please help me solve this issue. \r\n![Capture](https://user-images.githubusercontent.com/101260877/163891320-78923968-109b-4bb0-9adf-e3b7dca3ca1f.PNG)\r\nthis is the issue i am facing while running the model on GPU. The object detection model runs perfectly on CPU.\r\n\r\nHere is the code :\r\n\r\n\r\n// https://github.com/microsoft/onnxruntime/blob/v1.8.2/csharp/test/Microsoft.ML.OnnxRuntime.EndToEndTests.Capi/CXX_Api_Sample.cpp\r\n// https://github.com/microsoft/onnxruntime/blob/v1.8.2/include/onnxruntime/core/session/onnxruntime_cxx_api.h\r\n#include <onnxruntime_cxx_api.h>\r\n\r\n#include <opencv2/dnn/dnn.hpp>\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <opencv2/imgproc.hpp>\r\n\r\n#include <chrono>\r\n#include <cmath>\r\n#include <exception>\r\n#include <fstream>\r\n#include <iostream>\r\n#include <limits>\r\n#include <numeric>\r\n#include <string>\r\n#include <vector>\r\n\r\ntemplate <typename T>\r\nT vectorProduct(const std::vector<T>& v)\r\n{\r\n    return accumulate(v.begin(), v.end(), 1, std::multiplies<T>());\r\n}\r\n\r\n\r\ntemplate <typename T>\r\nstd::ostream& operator<<(std::ostream& os, const std::vector<T>& v)\r\n{\r\n    os << \"[\";\r\n    for (int i = 0; i < v.size(); ++i)\r\n    {\r\n        os << v[i];\r\n        if (i != v.size() - 1)\r\n        {\r\n            os << \", \";\r\n        }\r\n    }\r\n    os << \"]\";\r\n    return os;\r\n}\r\n\r\nstd::ostream& operator<<(std::ostream& os,\r\n    const ONNXTensorElementDataType& type)\r\n{\r\n    switch (type)\r\n    {\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_UNDEFINED:\r\n        os << \"undefined\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT:\r\n        os << \"float\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8:\r\n        os << \"uint8_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8:\r\n        os << \"int8_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16:\r\n        os << \"uint16_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16:\r\n        os << \"int16_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32:\r\n        os << \"int32_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64:\r\n        os << \"int64_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_STRING:\r\n        os << \"std::string\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL:\r\n        os << \"bool\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16:\r\n        os << \"float16\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE:\r\n        os << \"double\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32:\r\n        os << \"uint32_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64:\r\n        os << \"uint64_t\";\r\n        break;\r\n    case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX64:\r\n        os << \"float real + float imaginary\";\r\n        break;\r\n        case ONNXTensorElementDataType::\r\n        ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX128:\r\n            os << \"double real + float imaginary\";\r\n            break;\r\n        case ONNXTensorElementDataType::ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16:\r\n            os << \"bfloat16\";\r\n            break;\r\n        default:\r\n            break;\r\n    }\r\n\r\n    return os;\r\n}\r\n\r\nstd::vector<std::string> readLabels(std::string& labelFilepath)\r\n{\r\n    std::vector<std::string> labels;\r\n    std::string line;\r\n    std::ifstream fp(labelFilepath);\r\n    while (std::getline(fp, line))\r\n    {\r\n        labels.push_back(line);\r\n    }\r\n    return labels;\r\n}\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n    bool useCUDA{ false };\r\n    if (useCUDA)\r\n    {\r\n        std::cout << \"Inference Execution Provider: CUDA\" << std::endl;\r\n    }\r\n    else\r\n    {\r\n        std::cout << \"Inference Execution Provider: CPU\" << std::endl;\r\n    }\r\n    std::string instanceName{ \"image-classification-inference\" };\r\n    std::string imageFilepath{ \"D:\\\\OOOOOONNNNNXXXXX\\\\cpp-onnxruntime-resnet-console-app-main\\\\OnnxRuntimeResNet\\\\assets\\\\dog.png\" };\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING, instanceName.c_str());\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(1);\r\n    if (useCUDA)\r\n    {\r\n        OrtCUDAProviderOptions cuda_options{ 0 };\r\n        sessionOptions.AppendExecutionProvider_CUDA(cuda_options);\r\n    }\r\n    sessionOptions.SetGraphOptimizationLevel(\r\n        GraphOptimizationLevel::ORT_ENABLE_EXTENDED);\r\n    Ort::Session session(env, L\"D:\\\\OOOOOONNNNNXXXXX\\\\cpp-onnxruntime-resnet-console-app-main\\\\OnnxRuntimeResNet\\\\assets\\\\model.onnx\", sessionOptions);\r\n\r\n\r\n    Ort::AllocatorWithDefaultOptions allocator;\r\n    size_t numInputNodes = session.GetInputCount();\r\n    size_t numOutputNodes = session.GetOutputCount();\r\n    std::cout << \"Number of Input Nodes: \" << numInputNodes << std::endl;\r\n    std::cout << \"Number of Output Nodes: \" << numOutputNodes << std::endl;\r\n    Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);\r\n    auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n    ONNXTensorElementDataType inputType = inputTensorInfo.GetElementType();\r\n    std::cout << \"Input Type: \" << inputType << std::endl;\r\n    Ort::TypeInfo outputTypeInfo = session.GetOutputTypeInfo(0);\r\n    auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();\r\n    ONNXTensorElementDataType outputType = outputTensorInfo.GetElementType();\r\n    std::cout << \"Output Type: \" << outputType << std::endl;\r\n\r\n\r\n    ///Things used later on\r\n    const char* inputName = session.GetInputName(0, allocator);\r\n    std::cout << \"Input Name: \" << inputName << std::endl;\r\n    std::vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n    std::cout << \"Input Dimensions: \" << inputDims << std::endl;\r\n    const char* outputName = session.GetOutputName(0, allocator);\r\n    std::cout << \"Output Name: \" << outputName << std::endl;\r\n    std::vector<int64_t> outputDims = outputTensorInfo.GetShape();\r\n    std::cout << \"Output Dimensions: \" << outputDims << std::endl;\r\n\r\n\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n    std::vector<Ort::Value> inputTensors;\r\n    static constexpr const int width = 500;\r\n    static constexpr const int height = 500;\r\n    static constexpr const int channel = 3;\r\n    std::array<int64_t, 4> input_shape_{ 1,height, width,channel };\r\n\r\n\r\n    std::array<int64_t, 2> outputt_shape_{ 1, 8 };\r\n\r\n    std::string img_path = \"D:\\\\cpp-onnxruntime-resnet-console-app-main\\\\OnnxRuntimeResNet\\\\assets\\\\dog.jpg\";\r\n    cv::Mat imgSource = cv::imread(img_path);\r\n    std::array<uint8_t, width* height* channel> input_image_{};\r\n    uint8_t* input = input_image_.data();\r\n    for (int i = 0; i < imgSource.rows; i++) {\r\n        for (int j = 0; j < imgSource.cols; j++) {\r\n            for (int c = 0; c < 3; c++)\r\n            {\r\n                //NHWC \r\n                if (c == 0)\r\n                    input[i * imgSource.cols * 3 + j * 3 + c] = imgSource.ptr<uint8_t>(i)[j * 3 + 2];\r\n                if (c == 1)\r\n                    input[i * imgSource.cols * 3 + j * 3 + c] = imgSource.ptr<uint8_t>(i)[j * 3 + 1];\r\n                if (c == 2)\r\n                    input[i * imgSource.cols * 3 + j * 3 + c] = imgSource.ptr<uint8_t>(i)[j * 3 + 0];\r\n            }\r\n        }\r\n    }\r\n    inputTensors.push_back(Ort::Value::CreateTensor<uint8_t>(\r\n        memoryInfo, input, input_image_.size(), input_shape_.data(), input_shape_.size()));\r\n \r\n\r\n\r\n   // size_t outputTensorSize = vectorProduct(outputt_shape_);\r\n\r\n    std::vector<const char*> inputNames{ inputName };\r\n    std::vector<const char*> outputNames{ \"detection_anchor_indices\", \"detection_boxes\", \"detection_classes\", \"detection_multiclass_scores\", \"detection_scores\", \"num_detections\", \"raw_detection_boxes\", \"raw_detection_scores\" };\r\n\r\n\r\n\r\n\r\n\r\n\r\n    std::vector<float> outputTensorValues(outputt_shape_.size());\r\n\r\n\r\n    // inputTensors.push_back(Ort::Value::CreateTensor<uint8_t>(\r\n       //  memoryInfo, input, input_image_.size(), input_shape_.data(), input_shape_.size()));\r\n     /////////////////////////////////////////////////////////////////////////////////\r\n    std::vector<Ort::Value> outputTensors;                                         //\r\n    /////////////////////////////////////////////////////////////////////////////////\r\n\r\n    //std::cout << \"memoryInfo: \" << memoryInfo << std::endl;\r\n    //std::cout << \"outputTensorValues.data(): \" << outputTensorValues.data() << std::endl;\r\n    //std::cout << \"outputDims.data(): \" << outputDims.data() << std::endl;\r\n    //std::cout << \"outputDims.size(): \" << outputDims.size() << std::endl;\r\n    std::cout << \"memoryInfo: \" << memoryInfo << std::endl;\r\n\r\n    outputTensors.push_back(Ort::Value::CreateTensor<float>(\r\n        memoryInfo, outputTensorValues.data(), 8,\r\n        outputt_shape_.data(), outputt_shape_.size()));\r\n\r\n\r\n\r\n    //std::cout << \"memoryInfo: \" << memoryInfo << std::endl;\r\n    //std::cout << \"inputDims.data(): \" << inputDims.data() << std::endl;\r\n    //std::cout << \"inputDims.size(): \" << inputDims.size() << std::endl;\r\n    //std::cout << \"memoryInfo: \" << memoryInfo << std::endl;\r\n    ///std::cout << \"outputTensorValues.data(): \" << outputTensorValues.data() << std::endl;\r\n    ////std::cout << \"outputTensorSize: \" << outputTensorSize << std::endl;\r\n\r\n\r\n\r\n\r\n\r\n    //std::cout << \"inputNames.data(): \" << inputNames.data() << std::endl;\r\n    //std::cout << \"inputTensors.data() \" << inputTensors.data() << std::endl;\r\n    //std::cout << \"outputNames.data()  \" << outputNames.data() << std::endl;\r\n    //std::cout << \"outputTensors.data() \" << outputTensors.data() << std::endl;\r\n    std::cout << \"Done with test 1\" << std::endl;\r\n\r\n    //session.Run(Ort::RunOptions{ nullptr }, inputNames.data(),\r\n      //  inputTensors.data(), 1, outputNames.data(), outputTensors.data(),\r\n        //outputNames.size());\r\n   \r\n\r\n\r\n    try {\r\n        session.Run(Ort::RunOptions{ nullptr }, inputNames.data(),\r\n            inputTensors.data(), 1, outputNames.data(),\r\n            outputNames.size());\r\n    }\r\n    catch (const std::runtime_error& re) {\r\n        std::cerr << \"Runtime error: \" << re.what() << std::endl;\r\n    }\r\n}",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1101843740/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]