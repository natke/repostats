[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1518123647",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1518123647",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1518123647,
        "node_id": "IC_kwDOCVq1mM5afLp_",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-21T17:21:01Z",
        "updated_at": "2023-04-21T17:21:01Z",
        "author_association": "NONE",
        "body": "Just to add to my question some more evidence for my question. I converted the `r200_trained.onnx` model to ncnn using this tool [here](https://github.com/Tencent/ncnn/blob/master/tools/onnx/onnx2ncnn.cpp) using ncnn project commit: `5e4ea0b`. The resulting model file can be found [here](https://drive.google.com/file/d/1mIqfmcs90p_Mk43ftRJIYqZoYIJosuZC/view?usp=share_link).\r\n\r\nUsing the below c++ ncnn inference code, on the same hardware used to run the above benchmarks, with the same 8 threads, the inference time is 94ms, compared to the same 158ms when using onnxruntime. \r\n\r\n```c++\r\n#include <iostream>\r\n#include <opencv2/opencv.hpp>\r\n#include \"net.h\"\r\n#include <chrono>\r\ntypedef std::chrono::high_resolution_clock Clock;\r\n\r\nint main() {\r\n    // Load the image for inference\r\n    auto img = cv::imread(\"../img/chip.jpg\");\r\n    if (img.empty()) {\r\n        throw std::runtime_error(\"unable to read image at provided path\");\r\n    }\r\n\r\n    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\r\n\r\n    if (img.cols != 112 || img.rows != 112) {\r\n        throw std::runtime_error(\"The image is of the wrong dims\");\r\n    }\r\n\r\n    ncnn::Net net;\r\n    net.load_param(\"../models/r200_trained/ncnn.param\");\r\n    net.load_model(\"../models/r200_trained/ncnn.bin\");\r\n\r\n    // Run 5 times to warm things up\r\n    for (int i = 0; i < 5; ++i) {\r\n        auto ex = net.create_extractor();\r\n        ex.set_num_threads(8);\r\n\r\n        ncnn::Mat in = ncnn::Mat::from_pixels(img.data, ncnn::Mat::PIXEL_RGB, 112, 112);\r\n        const float meanVals[3] = {127.5, 127.5, 127.5};\r\n        const float normVals[3] = {1 / 127.5, 1 / 127.5, 1 / 127.5};\r\n        in.substract_mean_normalize(meanVals, normVals);\r\n\r\n        ex.input(\"input\", in);\r\n        ncnn::Mat out;\r\n        ex.extract(\"output\", out);\r\n    }\r\n\r\n    size_t numIts = 100;\r\n    auto start = Clock::now();\r\n    for (size_t i = 0; i < numIts; ++i) {\r\n        auto ex = net.create_extractor();\r\n        ex.set_num_threads(8);\r\n        ex.set_light_mode(true);\r\n\r\n        ncnn::Mat in = ncnn::Mat::from_pixels(img.data, ncnn::Mat::PIXEL_RGB, 112, 112);\r\n        const float meanVals[3] = {127.5, 127.5, 127.5};\r\n        const float normVals[3] = {1 / 127.5, 1 / 127.5, 1 / 127.5};\r\n        in.substract_mean_normalize(meanVals, normVals);\r\n\r\n        ex.input(\"input\", in);\r\n        ncnn::Mat out;\r\n        ex.extract(\"output\", out);\r\n    }\r\n    auto end = Clock::now();\r\n    double avgTime = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() / static_cast<double>(numIts);\r\n    std::cout << \"Avg time: \" << avgTime << \"ms\" << std::endl;\r\n\r\n}\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1518123647/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520511593",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1520511593",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1520511593,
        "node_id": "IC_kwDOCVq1mM5aoSpp",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-24T16:49:52Z",
        "updated_at": "2023-04-24T16:49:52Z",
        "author_association": "MEMBER",
        "body": "Here is a snapshot of what the optimization is doing in your case on the beginning of your model (right side is optimized). I need to profile both models to check which added operator is causing the performance issue.\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/234061938-91d461bc-9f09-4ae2-bed8-3c85db6a841b.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520511593/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520664261",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1520664261",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1520664261,
        "node_id": "IC_kwDOCVq1mM5ao37F",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-24T18:53:27Z",
        "updated_at": "2023-04-24T18:53:27Z",
        "author_association": "NONE",
        "body": "Interesting @xadupre , I look forward to seeing the results of your analysis. \r\nTomorrow, I will also provide you with the r100 models I mention above, in which the inference time for one model is 2-4x slower than the other. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520664261/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520876124",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1520876124",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1520876124,
        "node_id": "IC_kwDOCVq1mM5aprpc",
        "user": {
            "login": "yf711",
            "id": 109183385,
            "node_id": "U_kgDOBoIBmQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/109183385?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yf711",
            "html_url": "https://github.com/yf711",
            "followers_url": "https://api.github.com/users/yf711/followers",
            "following_url": "https://api.github.com/users/yf711/following{/other_user}",
            "gists_url": "https://api.github.com/users/yf711/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yf711/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yf711/subscriptions",
            "organizations_url": "https://api.github.com/users/yf711/orgs",
            "repos_url": "https://api.github.com/users/yf711/repos",
            "events_url": "https://api.github.com/users/yf711/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yf711/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-24T21:50:02Z",
        "updated_at": "2023-04-24T21:50:02Z",
        "author_association": "MEMBER",
        "body": "Quick question @cyrusbehr, have you experienced regression when setting ORT_ENABLE_BASIC as optimization level?\r\n\r\nOn my side the regression issue is verified on all optimization levels except the basic level, which showed 20% gain compared to DISABLE_ALL",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1520876124/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522164107",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1522164107",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1522164107,
        "node_id": "IC_kwDOCVq1mM5aumGL",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-25T17:33:06Z",
        "updated_at": "2023-04-25T17:33:06Z",
        "author_association": "MEMBER",
        "body": "Here are some results.\r\n\r\nFirst graph shows that the issue comes operator Conv. The optimized has more Conv operator and they take much longer.\r\n\r\n![plot_profiling](https://user-images.githubusercontent.com/22452781/234355356-687ee1d0-4424-44d0-bed2-be786ff0d70d.png)\r\n\r\nSecond graph shows that for the same operation Conv (same type and shape for the input and output), it takes much longer in the optimized model. The reason is they don't use the same implementation. The non-optimized model is using Conv from **ai.onnx**, the optimized model is using operator Conv from domain **com.microsoft.nchwc**.\r\n\r\nThe implementation is probably optimized for a different and the optimizer should not change the graph or the implementation is slower and needs to be fixed.\r\n\r\n![plot_profiling_side_by_side](https://user-images.githubusercontent.com/22452781/234356081-cff98c7f-2ef1-43d5-b35e-7822517c6fd0.png)\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522164107/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522416640",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1522416640",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1522416640,
        "node_id": "IC_kwDOCVq1mM5avjwA",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-25T21:06:05Z",
        "updated_at": "2023-04-25T21:59:27Z",
        "author_association": "NONE",
        "body": "@yf711 even setting the opt level to `ORT_ENABLE_BASIC` I still get: \r\n```\r\nR200 dummy avg inference time: 104.35541868209839 ms\r\nR200 trained avg inference time: 159.80592012405396 ms\r\n``` \r\n\r\n@xadupre thank you for the above breakdown. Based on what you observed, what are you recommendations? \r\n\r\nHere is another even more extreme example (perhaps I should have started with this example). I have these two r100 models, exact same architecture, both trained, both using same pytorch / onnx opset version. One of them takes 2x as long as the other for inference. I have no idea why. \r\n\r\nI used the following benchmark script to cycle through all the optimizations:\r\n```python\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nfrom time import time\r\n\r\n\r\ndef benchmark_model(model_path, opt_level):\r\n    sess_opt = ort.SessionOptions()\r\n    sess_opt.intra_op_num_threads = 8\r\n    sess_opt.graph_optimization_level = opt_level\r\n\r\n    ort_session = ort.InferenceSession(model_path, sess_opt, providers=['CPUExecutionProvider'])\r\n    output_names = [ort_session.get_outputs()[0].name]\r\n    input_name = ort_session.get_inputs()[0].name\r\n\r\n    # Run on dummy input\r\n    img = np.ones((1,3,112,112)).astype('float32')\r\n\r\n    # Run 5 times to warm things up\r\n    for i in range(5):\r\n        tp = ort_session.run(None, {input_name:img})\r\n\r\n    # Benchmark\r\n    num_iterations = 100\r\n    start = time()\r\n    for i in range(num_iterations):\r\n        op = ort_session.run(None, {input_name:img})\r\n\r\n    end = time()\r\n    total_time = (end-start)/num_iterations * 1000\r\n    print(\"Model:\", model_path, \", time:\", total_time)\r\n\r\n\r\nopt_levels = [ort.GraphOptimizationLevel.ORT_DISABLE_ALL, ort.GraphOptimizationLevel.ORT_ENABLE_BASIC, \r\nort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED, ort.GraphOptimizationLevel.ORT_ENABLE_ALL]\r\n\r\nfor opt_level in opt_levels:\r\n    print(\"Optimization level:\", opt_level)\r\n    benchmark_model(\"./r100_v1.onnx\", opt_level)\r\n    benchmark_model(\"./r100_v2.onnx\", opt_level)\r\n    print(\"\")\r\n```\r\n\r\nHere are the results on the same hardware as above:\r\n```\r\nOptimization level: GraphOptimizationLevel.ORT_DISABLE_ALL\r\nModel: ./r100_v1.onnx , time: 111.38367891311646\r\nModel: ./r100_v2.onnx , time: 62.790102958679206\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_BASIC\r\nModel: ./r100_v1.onnx , time: 117.80040979385376\r\nModel: ./r100_v2.onnx , time: 65.80243587493896\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_EXTENDED\r\nModel: ./r100_v1.onnx , time: 121.04552745819092\r\nModel: ./r100_v2.onnx , time: 66.17196321487427\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_ALL\r\nModel: ./r100_v1.onnx , time: 250.7680940628052\r\nModel: ./r100_v2.onnx , time: 41.043078899383545\r\n```\r\nAs can be seen, v1 is 2-5x slower than v2! @xadupre are you able to look into this as well please. Is this a bug in onnxruntime? Or what exactly is going on. With a different framework such as ncnn, both take ~40ms to run inference. \r\n\r\n[v1 download](https://drive.google.com/file/d/1gP1512xaFvS82kQDPHek9cpYqdt638V-/view?usp=share_link)\r\n[v2 download](https://drive.google.com/file/d/1OLA2ZryMBL7WinkPEEU2qjFCzrQyYcBX/view?usp=share_link)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522416640/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522476407",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1522476407",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1522476407,
        "node_id": "IC_kwDOCVq1mM5avyV3",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-25T22:01:53Z",
        "updated_at": "2023-04-25T22:01:53Z",
        "author_association": "MEMBER",
        "body": "About the two new models you shared, v1 and v2 and two models similar or coming from different training? The fact the optimizations produce completely different results is interesting. For the time being, I suggest selecting the faster optimization parameter as @yf711 suggests. I'll see if I can determine a rule which makes one fast and the other one slow and then a fix.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522476407/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522489032",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1522489032",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1522489032,
        "node_id": "IC_kwDOCVq1mM5av1bI",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-25T22:14:07Z",
        "updated_at": "2023-04-25T22:14:07Z",
        "author_association": "NONE",
        "body": "I am told by our ML team that both v1 and v2 models used the same training script (if any changes were made to the script, they were very minor). v1 was trained a while back and is epoch 17 of our training, while v2 was trained this morning and epoch 1. The version of pytorch used to train the models was the same, and we exported both models to use the same onnx opset.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522489032/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522498814",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1522498814",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1522498814,
        "node_id": "IC_kwDOCVq1mM5av3z-",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-25T22:25:52Z",
        "updated_at": "2023-04-25T22:25:52Z",
        "author_association": "NONE",
        "body": "@xadupre I also had a coworker run the same test as me using the v1 and v2 models for the `ORT_ENABLE_ALL` optimization level, limiting to 8 threads, but instead of running on an intel CPU, he ran on an AMD EPYC 7502, and he got the same inference time for both v1 and v2 models (57ms). So seems this issue may only be present on intel CPUs. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1522498814/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1529120702",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1529120702",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1529120702,
        "node_id": "IC_kwDOCVq1mM5bJIe-",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-30T19:23:33Z",
        "updated_at": "2023-04-30T19:23:48Z",
        "author_association": "NONE",
        "body": "@xadupre  did you have a chance to look into the discrepancy between the two r100 models? This is somewhat urgent for my commercial deployment. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1529120702/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1531632292",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1531632292",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1531632292,
        "node_id": "IC_kwDOCVq1mM5bStqk",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-02T14:58:41Z",
        "updated_at": "2023-05-02T14:58:41Z",
        "author_association": "MEMBER",
        "body": "Sorry for the delay. Your models is still puzzling. I compared your two last model and profiled one specific node. The two first executions of two nodes sharing the same input and outputs shapes.\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235703570-df64a66b-77a0-4eb7-aad4-7aeca41511f6.png)\r\n\r\nAnd for your second model for a same node with the same input shapes:\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235703905-4a5e19a5-1fea-4ba5-b1eb-30e7a0a365e4.png)\r\n\r\nSo I need to understand why the execution is faster or slower for some specific nodes.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1531632292/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1533442245",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1533442245",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1533442245,
        "node_id": "IC_kwDOCVq1mM5bZnjF",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-03T17:36:13Z",
        "updated_at": "2023-05-03T17:36:13Z",
        "author_association": "MEMBER",
        "body": "Some intermediate results. All non-optimized models are using the same code, all optimized models are also using the same code. I looked into one particular configuration: Conv(X:[1, 256, 14, 14], W: [256, 256, 3, 3], B[256]). This is the duration of the execution of every node like this for 6 iterations. There is a pattern and the only difference are the coefficients.\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235994411-af328de3-f0dc-4419-8386-6b200bfbb1fb.png)\r\n\r\nSo I made a small onnx graph with only one Conv operator with the same setting Conv(X:[1, 256, 14, 14], W: [256, 256, 3, 3], B[256]) where X is constant equal to 1, W is either drawn with a random law or the same weights as Conv_166 from r100_v1.onnx. B is null. I multiplied the coefficients by a factor called *scale*.\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235995962-e923a8c0-5cb6-4cd4-ac01-0d309c8e8a63.png)\r\n\r\nSo there is something going on. I need to check if this behaviour is the same with the optimized implementation (based on your results, it is very likely), compare with torch, gpu, or with other types (float16).\r\n\r\nBelow, the slow model with just one Conv operator using one of the worse W matrix from r100_v1.onnx.\r\n\r\n[slow_conv.zip](https://github.com/microsoft/onnxruntime/files/11388184/slow_conv.zip)\r\n\r\nAppendix:\r\n\r\nThe same graph for model r100_v2.onnx:\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235996862-601723c1-314f-43e6-a259-b40178a44e54.png)\r\n\r\nThe distribution of W coefficients in r100_v1.onnx:\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235997402-de8bbbc2-43bf-4b45-86fb-d5faf976d893.png)\r\n\r\nSame with r100_v2.onnx:\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/235997553-73b57858-fc38-4bd4-b354-f7c17e023478.png)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1533442245/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1534075920",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1534075920",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1534075920,
        "node_id": "IC_kwDOCVq1mM5bcCQQ",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-04T04:17:18Z",
        "updated_at": "2023-05-04T04:17:18Z",
        "author_association": "NONE",
        "body": "That is very interesting, thank you for the update. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1534075920/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535042008",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535042008",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1535042008,
        "node_id": "IC_kwDOCVq1mM5bfuHY",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-04T16:26:22Z",
        "updated_at": "2023-05-04T16:26:22Z",
        "author_association": "MEMBER",
        "body": "I did the same with torch and cuda and it gives the same results. I still need to figure out why exactly. In that graph, I took the model linked above and I measure the computation time of Conv(X, W * scale, B=0). scale is the X-axis.\r\n\r\n![image](https://user-images.githubusercontent.com/22452781/236265102-9b6159f0-d62b-4130-8100-18ca7aa197e3.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535042008/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535106939",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535106939",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1535106939,
        "node_id": "IC_kwDOCVq1mM5bf997",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-04T17:06:42Z",
        "updated_at": "2023-05-04T17:06:42Z",
        "author_association": "MEMBER",
        "body": "I think this is caused by subnormal values. Could you please try enabling flushing subnormal as zero, like this:\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/8e610f25d8a14d6a4f311106d15d90d4f85aef91/onnxruntime/test/perftest/ort_test_session.cc#L769",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535106939/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535174249",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535174249",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1535174249,
        "node_id": "IC_kwDOCVq1mM5bgOZp",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-04T17:49:17Z",
        "updated_at": "2023-05-04T17:52:43Z",
        "author_association": "MEMBER",
        "body": "The corresponding code in python to make it work.\r\n\r\n```python\r\nsess_options0 = SessionOptions()\r\nsess_options0.add_session_config_entry(\"session.set_denormal_as_zero\", \"1\")\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535174249/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535351513",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535351513",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1535351513,
        "node_id": "IC_kwDOCVq1mM5bg5rZ",
        "user": {
            "login": "cyrusbehr",
            "id": 17056751,
            "node_id": "MDQ6VXNlcjE3MDU2NzUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17056751?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyrusbehr",
            "html_url": "https://github.com/cyrusbehr",
            "followers_url": "https://api.github.com/users/cyrusbehr/followers",
            "following_url": "https://api.github.com/users/cyrusbehr/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyrusbehr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyrusbehr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyrusbehr/subscriptions",
            "organizations_url": "https://api.github.com/users/cyrusbehr/orgs",
            "repos_url": "https://api.github.com/users/cyrusbehr/repos",
            "events_url": "https://api.github.com/users/cyrusbehr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyrusbehr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-04T20:11:47Z",
        "updated_at": "2023-05-04T20:11:47Z",
        "author_association": "NONE",
        "body": "@yufenglee @xadupre that appears to have done the trick! After setting the above option, the inference time between the two models is basically the same: \r\n\r\n```\r\n1.14.1\r\nONNX Runtime version: None\r\nOptimization level: GraphOptimizationLevel.ORT_DISABLE_ALL\r\nModel: ./r100_v1.onnx , time: 56.450605392456055\r\nModel: ./r100_v2.onnx , time: 57.254767417907715\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_BASIC\r\nModel: ./r100_v1.onnx , time: 62.66589164733887\r\nModel: ./r100_v2.onnx , time: 73.20928573608398\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_EXTENDED\r\nModel: ./r100_v1.onnx , time: 64.86527919769287\r\nModel: ./r100_v2.onnx , time: 63.22221755981445\r\n\r\nOptimization level: GraphOptimizationLevel.ORT_ENABLE_ALL\r\nModel: ./r100_v1.onnx , time: 36.83876991271973\r\nModel: ./r100_v2.onnx , time: 36.867451667785645\r\n```\r\n\r\nThank you both for your help, I very much appreciate it! ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535351513/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535543779",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535543779",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15630",
        "id": 1535543779,
        "node_id": "IC_kwDOCVq1mM5bhonj",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-05T00:04:47Z",
        "updated_at": "2023-05-05T00:04:47Z",
        "author_association": "MEMBER",
        "body": "No, it doesn't. only for CPU.\n\nFrom: Xavier Dupr ***@***.***>\nSent: Thursday, May 4, 2023 10:49 AM\nTo: microsoft/onnxruntime ***@***.***>\nCc: Yufeng Li ***@***.***>; Comment ***@***.***>\nSubject: Re: [microsoft/onnxruntime] [Performance] Inference speed discrepancy between two r200 models on CPU (Issue #15630)\n\nThanks, it works.\n\nDoes it have an impact on GPU as well?\n\nXavier\n\n\nSent from Outlook<http://aka.ms/weboutlook>\n\n________________________________\nDe : Yufeng Li ***@***.***<mailto:***@***.***>>\nEnvoy : jeudi 4 mai 2023 19:06\n : microsoft/onnxruntime ***@***.***<mailto:***@***.***>>\nCc : Xavier Dupre ***@***.***<mailto:***@***.***>>; Mention ***@***.***<mailto:***@***.***>>\nObjet : Re: [microsoft/onnxruntime] [Performance] Inference speed discrepancy between two r200 models on CPU (Issue #15630)\n\n\nI think this is caused by subnormal values. Could you please try enabling flushing subnormal as zero, like this:\n\nhttps://github.com/microsoft/onnxruntime/blob/8e610f25d8a14d6a4f311106d15d90d4f85aef91/onnxruntime/test/perftest/ort_test_session.cc#L769\n\n-\nReply to this email directly, view it on GitHub<https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535106939>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFLJULILNF5OBAJWEVBBPDLXEPO23ANCNFSM6AAAAAAXHDDRQU>.\nYou are receiving this because you were mentioned.Message ID: ***@***.***<mailto:***@***.***>>\n\n\n-\nReply to this email directly, view it on GitHub<https://github.com/microsoft/onnxruntime/issues/15630#issuecomment-1535174249>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHITBNW3L5ZDM44IC3DCTM3XEPT2PANCNFSM6AAAAAAXHDDRQU>.\nYou are receiving this because you commented.Message ID: ***@***.******@***.***>>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1535543779/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]