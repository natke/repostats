[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/536719069",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-536719069",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 536719069,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzNjcxOTA2OQ==",
        "user": {
            "login": "askhade",
            "id": 6475296,
            "node_id": "MDQ6VXNlcjY0NzUyOTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6475296?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/askhade",
            "html_url": "https://github.com/askhade",
            "followers_url": "https://api.github.com/users/askhade/followers",
            "following_url": "https://api.github.com/users/askhade/following{/other_user}",
            "gists_url": "https://api.github.com/users/askhade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/askhade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/askhade/subscriptions",
            "organizations_url": "https://api.github.com/users/askhade/orgs",
            "repos_url": "https://api.github.com/users/askhade/repos",
            "events_url": "https://api.github.com/users/askhade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/askhade/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-09-30T19:38:49Z",
        "updated_at": "2019-09-30T19:38:49Z",
        "author_association": "MEMBER",
        "body": "Before using the tool make sure your model's opset version is set to 10. This is because when we quantize the model we need to update the opset version to 10 as the quantization ops were introduced in this version. \r\nYou are seeing this error because your model has some other op which was also updated for version 10. \r\nI will submit a change to error check this case and report this... but this wont fix your problem... you will still need to update your model to opset 10 and then use the quantization tool ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/536719069/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538033629",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-538033629",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 538033629,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODAzMzYyOQ==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T17:00:15Z",
        "updated_at": "2019-10-03T17:00:15Z",
        "author_association": "NONE",
        "body": "Hi Ashwini Khade,\nThank you, I converted my pytorch model to get the onnx model, so please\ntell me how can I know which ops in pytorch is opset version 10?\nthanks.\n\nAshwini Khade <notifications@github.com> 于2019年10月1日周二 上午3:38写道：\n\n> Before using the tool make sure your model's opset version is set to 10.\n> This is because when we quantize the model we need to update the opset\n> version to 10 as the quantization ops were introduced in this version.\n> You are seeing this error because your model has some other op which was\n> also updated for version 10.\n> I will submit a change to error check this case and report this... but\n> this wont fix your problem... you will still need to update your model to\n> opset 10 and then use the quantization tool\n>\n> —\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microsoft/onnxruntime/issues/1950?email_source=notifications&email_token=AIWSN2IJ5SCRA4XOF4DW33TQMJIVBA5CNFSM4I3ORPX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7625XI#issuecomment-536719069>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIWSN2MUK4OQ55IN476WD43QMJIVBANCNFSM4I3ORPXQ>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538033629/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538038353",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-538038353",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 538038353,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODAzODM1Mw==",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "created_at": "2019-10-03T17:12:15Z",
        "updated_at": "2019-10-03T17:12:15Z",
        "author_association": "MEMBER",
        "body": "Re: Pytorch version - see their documentation ONNX export for setting opset_version - https://pytorch.org/docs/stable/onnx.html\r\n\r\nYou can also verify opsets by loading your ONNX model using a visualizer like Netron. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538038353/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538039972",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-538039972",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 538039972,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzODAzOTk3Mg==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-03T17:16:35Z",
        "updated_at": "2019-10-03T17:16:35Z",
        "author_association": "NONE",
        "body": "okay, thank you Faith,\nBTW, can I  get inference acceleration when I inference quantized model\nthan before quantized?\n\nFaith Xu <notifications@github.com> 于2019年10月4日周五 上午1:12写道：\n\n> Re: Pytorch version - see their documentation ONNX export for setting\n> opset_version - https://pytorch.org/docs/stable/onnx.html\n>\n> You can also verify opsets by loading your ONNX model using a visualizer\n> like Netron.\n>\n> —\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microsoft/onnxruntime/issues/1950?email_source=notifications&email_token=AIWSN2OLPQSRVH37K7VFTTTQMYRXLA5CNFSM4I3ORPX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAI5AUI#issuecomment-538038353>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIWSN2I3MLED6AQLRBQHJE3QMYRXLANCNFSM4I3ORPXQ>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/538039972/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539262191",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-539262191",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 539262191,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzOTI2MjE5MQ==",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "created_at": "2019-10-08T00:34:22Z",
        "updated_at": "2019-10-08T00:34:22Z",
        "author_association": "MEMBER",
        "body": "Could you clarify your question? Quantization may result in some performance improvements at the expense of precision, though the current level of quantization support is still limited to just a few operators. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539262191/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539283119",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-539283119",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 539283119,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzOTI4MzExOQ==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-08T02:19:18Z",
        "updated_at": "2019-10-08T02:19:18Z",
        "author_association": "NONE",
        "body": "Yes, my question is: after I quantized my model, can I speed up my\ninference process even though at the expense of precision, a faster\ninference speed is more important than accuracy for me.\nI guess the answer is yes as you said.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539283119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539296409",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-539296409",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 539296409,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzOTI5NjQwOQ==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-08T03:20:57Z",
        "updated_at": "2019-10-08T03:20:57Z",
        "author_association": "NONE",
        "body": "Hi Faith Xu,\n\nyou told me for Pytorch version: - see their documentation ONNX export for\nsetting opset_version - https://pytorch.org/docs/stable/onnx.html\n\nAre the ops in this link is opset10? but I can converted my pytorch model\nto onnx model using torch.onnx successfully, only for quantized model,\nthere are something wrong, so maybe my modle are already meeting the ops in\nthe link, but not for quantization tools.\n\nplease tell me how can I found the op in pytorch that quantization tools do\nnot support.\n\nthanks.\n\n\n\nZhiyuan Zhao <zhiyuan.zhaochn@gmail.com> 于2019年10月8日周二 上午10:19写道：\n\n> Yes, my question is: after I quantized my model, can I speed up my\n> inference process even though at the expense of precision, a faster\n> inference speed is more important than accuracy for me.\n> I guess the answer is yes as you said.\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539296409/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539361443",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-539361443",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 539361443,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUzOTM2MTQ0Mw==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-08T06:32:22Z",
        "updated_at": "2019-10-08T06:32:22Z",
        "author_association": "NONE",
        "body": "Hi Faith Xu,\nI saw the quantized model in Netron, there are many extra ops, e.g.\nreduceMax/reduceMin/Sub/Div/Floor/Cast/QuantizeLinear, with those ops, I\ncan speed up my model inference process?\nthanks.\n\nZhiyuan Zhao <zhiyuan.zhaochn@gmail.com> 于2019年10月8日周二 上午11:20写道：\n\n> Hi Faith Xu,\n>\n> you told me for Pytorch version: - see their documentation ONNX export for\n> setting opset_version - https://pytorch.org/docs/stable/onnx.html\n>\n> Are the ops in this link is opset10? but I can converted my pytorch model\n> to onnx model using torch.onnx successfully, only for quantized model,\n> there are something wrong, so maybe my modle are already meeting the ops in\n> the link, but not for quantization tools.\n>\n> please tell me how can I found the op in pytorch that quantization tools\n> do not support.\n>\n> thanks.\n>\n>\n>\n> Zhiyuan Zhao <zhiyuan.zhaochn@gmail.com> 于2019年10月8日周二 上午10:19写道：\n>\n>> Yes, my question is: after I quantized my model, can I speed up my\n>> inference process even though at the expense of precision, a faster\n>> inference speed is more important than accuracy for me.\n>> I guess the answer is yes as you said.\n>>\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/539361443/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548111061",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-548111061",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 548111061,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0ODExMTA2MQ==",
        "user": {
            "login": "askhade",
            "id": 6475296,
            "node_id": "MDQ6VXNlcjY0NzUyOTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6475296?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/askhade",
            "html_url": "https://github.com/askhade",
            "followers_url": "https://api.github.com/users/askhade/followers",
            "following_url": "https://api.github.com/users/askhade/following{/other_user}",
            "gists_url": "https://api.github.com/users/askhade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/askhade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/askhade/subscriptions",
            "organizations_url": "https://api.github.com/users/askhade/orgs",
            "repos_url": "https://api.github.com/users/askhade/repos",
            "events_url": "https://api.github.com/users/askhade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/askhade/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-30T21:02:38Z",
        "updated_at": "2019-10-30T21:02:38Z",
        "author_association": "MEMBER",
        "body": "@WilliamZhaoz : These ops are added for dynamic quantization .i.e converting the input from FP32 to 8 bit during inference. In opset 11 we have added onnx functions to fuse these ops into 1 op \"DynamicQuantizeLinear\" This is a newly added function in opset 11 and you will need to covert your model to opset 11 first and then quantize it...",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548111061/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548295400",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-548295400",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 548295400,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0ODI5NTQwMA==",
        "user": {
            "login": "WilliamZhaoz",
            "id": 36513513,
            "node_id": "MDQ6VXNlcjM2NTEzNTEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/36513513?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilliamZhaoz",
            "html_url": "https://github.com/WilliamZhaoz",
            "followers_url": "https://api.github.com/users/WilliamZhaoz/followers",
            "following_url": "https://api.github.com/users/WilliamZhaoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilliamZhaoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilliamZhaoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilliamZhaoz/subscriptions",
            "organizations_url": "https://api.github.com/users/WilliamZhaoz/orgs",
            "repos_url": "https://api.github.com/users/WilliamZhaoz/repos",
            "events_url": "https://api.github.com/users/WilliamZhaoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilliamZhaoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-31T10:02:17Z",
        "updated_at": "2019-10-31T10:02:17Z",
        "author_association": "NONE",
        "body": "How can I convert my model to opset11? is there any tools for that?\n\nAshwini Khade <notifications@github.com> 于2019年10月31日周四 上午5:02写道：\n\n> @WilliamZhaoz <https://github.com/WilliamZhaoz> : These ops are added for\n> dynamic quantization .i.e converting the input from FP32 to 8 bit during\n> inference. In opset 11 we have added onnx functions to fuse these ops into\n> 1 op \"DynamicQuantizeLinear\" This is a newly added function in opset 11 and\n> you will need to covert your model to opset 11 first and then quantize it...\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microsoft/onnxruntime/issues/1950?email_source=notifications&email_token=AIWSN2OMQHJWTRFYGRHQI7LQRHY7JA5CNFSM4I3ORPX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECVYFVI#issuecomment-548111061>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIWSN2JAJJJ2ETBCAQX2NCDQRHY7JANCNFSM4I3ORPXQ>\n> .\n>\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548295400/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548513837",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-548513837",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 548513837,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0ODUxMzgzNw==",
        "user": {
            "login": "askhade",
            "id": 6475296,
            "node_id": "MDQ6VXNlcjY0NzUyOTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6475296?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/askhade",
            "html_url": "https://github.com/askhade",
            "followers_url": "https://api.github.com/users/askhade/followers",
            "following_url": "https://api.github.com/users/askhade/following{/other_user}",
            "gists_url": "https://api.github.com/users/askhade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/askhade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/askhade/subscriptions",
            "organizations_url": "https://api.github.com/users/askhade/orgs",
            "repos_url": "https://api.github.com/users/askhade/repos",
            "events_url": "https://api.github.com/users/askhade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/askhade/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-10-31T18:38:26Z",
        "updated_at": "2019-10-31T18:38:26Z",
        "author_association": "MEMBER",
        "body": "Currently the only way is to reconvert your model from original framework... \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/548513837/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/549983928",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1950#issuecomment-549983928",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1950",
        "id": 549983928,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU0OTk4MzkyOA==",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "created_at": "2019-11-05T19:34:33Z",
        "updated_at": "2019-11-05T19:34:33Z",
        "author_association": "MEMBER",
        "body": "@WilliamZhaoz any other questions on this?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/549983928/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]