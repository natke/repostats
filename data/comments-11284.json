[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108522955",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11284#issuecomment-1108522955",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11284",
        "id": 1108522955,
        "node_id": "IC_kwDOCVq1mM5CErfL",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-25T12:44:34Z",
        "updated_at": "2022-04-25T12:44:34Z",
        "author_association": "MEMBER",
        "body": "Hi @totesarana, the discrepancies are mostly due to the conversion from float to double. onnxruntime converts double to float before computing the probabilities in SVMClassifier and coefficients are converted into float when the model is converted. To reduce the discrepancies, ONNX specifications must be extended to support double coefficients (similar to this https://github.com/onnx/onnx/pull/3897) and onnxruntime must be updated to support this new specifications. Here is an experiment I ran with a python runtime. It shows that discrepancies are lower when the runtime computes the probabilities with double. Which version of onnxruntime did you use to compute the probabilities? The latest version of onnxruntime fails at loading the model.\r\n\r\n```python\r\nimport pickle\r\nimport numpy\r\nimport onnx\r\nfrom onnxruntime import InferenceSession\r\nfrom mlprodict.plotting.text_plot import onnx_simple_text_plot\r\nfrom mlprodict.onnx_tools.onnx_manipulations import select_model_inputs_outputs\r\nfrom mlprodict.onnx_conv import to_onnx\r\nfrom mlprodict.onnxrt import OnnxInference\r\n\r\n\r\nskl_name = \"Onnx_and_sklearn_Models/svm.model\"\r\nonx_name = \"Onnx_and_sklearn_Models/Convert_svm.onnx\"\r\n\r\nwith open(skl_name, \"rb\") as f:\r\n    model = pickle.load(f)\r\nwith open(onx_name, \"rb\") as f:\r\n    onx = onnx.load(f)\r\n\r\nprint(\"--ONNX--\")\r\nprint(onnx_simple_text_plot(onx))\r\n\r\nrnd = numpy.random.rand(5, 17).astype(numpy.float64) + 50\r\nexpected = model.predict_proba(rnd)\r\nprint(\"--EXPECTED--\")\r\nprint(expected)\r\n\r\ntry:\r\n    model1 = InferenceSession(onx.SerializeToString())\r\nexcept Exception as e:\r\n    print(\"--FAIL--\", e)\r\n\r\nonx2 = select_model_inputs_outputs(onx, outputs=['output_label', 'probabilities'])\r\nmodel1 = InferenceSession(onx2.SerializeToString())\r\ngot = model1.run(None, {'double_input': rnd})[1]\r\nprint(\"--ORT--\")\r\nprint(got)\r\nprint('--DIFF--')\r\ndiff = numpy.abs(got - expected)\r\nprint(diff)\r\nprint(\"MAX:\", diff.max())\r\n\r\n####################################\r\n# With a runtime supported double for SVMClassifier\r\n\r\nonx64 = to_onnx(model, rnd, options={'zipmap': False}, rewrite_ops=True)\r\n\r\nprint(\"--ONNX-64--\")\r\nprint(onnx_simple_text_plot(onx64))\r\n\r\noinf = OnnxInference(onx64)\r\ngot64 = oinf.run({'X': rnd})['probabilities']\r\nprint(\"--PYRT--\")\r\nprint(got64)\r\nprint('--DIFF--')\r\ndiff = numpy.abs(got64 - expected)\r\nprint(diff)\r\nprint(\"MAX:\", diff.max())\r\n```\r\n\r\noutput:\r\n\r\n```\r\n--ONNX--\r\nopset: domain='ai.onnx.ml' version=1\r\nopset: domain='' version=9\r\ninput: name='double_input' type=dtype('float64') shape=(0, 17)\r\nSVMClassifier(double_input) -> label, SVM02\r\n  Cast(label, to=7) -> output_label\r\nCast(SVM02, to=11) -> probabilities\r\n  ZipMap(probabilities) -> output_probability\r\noutput: name='output_label' type=dtype('int64') shape=(0,)\r\noutput: name='output_probability' type='?' shape=()\r\n--EXPECTED--\r\n[[0.08900157 0.91099843]\r\n [0.09689244 0.90310756]\r\n [0.08190482 0.91809518]\r\n [0.08410505 0.91589495]\r\n [0.09315535 0.90684465]]\r\n--FAIL-- [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. Type Error: Type 'tensor(double)' of input parameter (probabilities) of operator (ZipMap) in node (ZipMap) is invalid.\r\n--ORT--\r\n[[0.10351969 0.89648026]\r\n [0.09738901 0.9026109 ]\r\n [0.0982206  0.90177947]\r\n [0.08161405 0.91838592]\r\n [0.11160246 0.88839757]]\r\n--DIFF--\r\n[[0.01451812 0.01451817]\r\n [0.00049657 0.00049666]\r\n [0.01631578 0.01631571]\r\n [0.002491   0.00249097]\r\n [0.01844711 0.01844708]]\r\nMAX: 0.0184471088385028\r\n--ONNX-64--\r\nopset: domain='mlprodict' version=1\r\nopset: domain='' version=9\r\ninput: name='X' type=dtype('float64') shape=(0, 17)\r\nSVMClassifierDouble[mlprodict](X) -> label, SVM02\r\n  Cast(SVM02, to=11) -> probabilities\r\noutput: name='label' type=dtype('int64') shape=(0,)\r\noutput: name='probabilities' type=dtype('float64') shape=(0, 2)\r\n--PYRT--\r\n[[0.08987652 0.91012348]\r\n [0.09784254 0.90215746]\r\n [0.08271638 0.91728362]\r\n [0.08493528 0.91506472]\r\n [0.09407032 0.90592968]]\r\n--DIFF--\r\n[[0.00087495 0.00087495]\r\n [0.0009501  0.0009501 ]\r\n [0.00081156 0.00081156]\r\n [0.00083023 0.00083023]\r\n [0.00091497 0.00091497]]\r\nMAX: 0.0009501018942673634\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108522955/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108766774",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11284#issuecomment-1108766774",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11284",
        "id": 1108766774,
        "node_id": "IC_kwDOCVq1mM5CFnA2",
        "user": {
            "login": "totesarana",
            "id": 19392451,
            "node_id": "MDQ6VXNlcjE5MzkyNDUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/19392451?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/totesarana",
            "html_url": "https://github.com/totesarana",
            "followers_url": "https://api.github.com/users/totesarana/followers",
            "following_url": "https://api.github.com/users/totesarana/following{/other_user}",
            "gists_url": "https://api.github.com/users/totesarana/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/totesarana/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/totesarana/subscriptions",
            "organizations_url": "https://api.github.com/users/totesarana/orgs",
            "repos_url": "https://api.github.com/users/totesarana/repos",
            "events_url": "https://api.github.com/users/totesarana/events{/privacy}",
            "received_events_url": "https://api.github.com/users/totesarana/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-25T16:07:52Z",
        "updated_at": "2022-04-25T16:07:52Z",
        "author_association": "NONE",
        "body": "Hi @xadupre, thanks for your reply. I tried your code and it did reduce the maximum discrepancy to 0.001 level.\r\n\r\nI assume this means there is no way to fully eliminate the discrepancy, and the solution you have provided is the best we could go with, right?\r\n\r\nIs it possible to train a SVM under onnx directly, instead of using sklearn to train and onnx to convert? Is there any example code for training under onnxruntime for SVM models? \r\n\r\nby the way, the onnxruntime version I am using is 1.11.0.\r\n\r\nThanks",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108766774/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108816610",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11284#issuecomment-1108816610",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11284",
        "id": 1108816610,
        "node_id": "IC_kwDOCVq1mM5CFzLi",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-25T16:58:31Z",
        "updated_at": "2022-04-25T16:58:31Z",
        "author_association": "MEMBER",
        "body": "It is the best today. It does not use onnxruntime but a custom runtime I developped to check that kind of situations and see whether or not it makes sense to bring a new operator into ONNX. I should be able to modify that runtime to reduce the discrepancies to 1e-5 after using double coefficients instead of floats. (1- 2 days) It would take 3,4 months to bring the same in onnx / onnxruntime (part of the release cycle).\r\n\r\nAbout training, it is possible to train an ONNX model with onnxruntime-training but it assumes the model can be trained with a gradient algorithm. We could also write a custom training algorithm only with ONNX primitives. Both options require to have an existing implementation of a training algorithm with torch or numpy.\r\n\r\nWe could also to create a fork of scikit-learn and change type double into float in the code and recompile. But I don't see that kind of modifications be merged in the official scikit-learn library.\r\n\r\nLast comment, you may want to remove operator ZipMap in the ONNX graph by using `options={'zipmap': False}`. The inference time is faster.\r\n\r\nMaybe we could also use a neural network or a random forest using the onnx output and trying to fit the sklearn output to reduce the discrepancies.\r\n\r\nMaybe there is another idea I did not see.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1108816610/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1109203854",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11284#issuecomment-1109203854",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11284",
        "id": 1109203854,
        "node_id": "IC_kwDOCVq1mM5CHRuO",
        "user": {
            "login": "totesarana",
            "id": 19392451,
            "node_id": "MDQ6VXNlcjE5MzkyNDUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/19392451?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/totesarana",
            "html_url": "https://github.com/totesarana",
            "followers_url": "https://api.github.com/users/totesarana/followers",
            "following_url": "https://api.github.com/users/totesarana/following{/other_user}",
            "gists_url": "https://api.github.com/users/totesarana/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/totesarana/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/totesarana/subscriptions",
            "organizations_url": "https://api.github.com/users/totesarana/orgs",
            "repos_url": "https://api.github.com/users/totesarana/repos",
            "events_url": "https://api.github.com/users/totesarana/events{/privacy}",
            "received_events_url": "https://api.github.com/users/totesarana/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-26T01:32:25Z",
        "updated_at": "2022-04-26T01:32:25Z",
        "author_association": "NONE",
        "body": "Hi @xadupre, thanks for replying. Is there a reason why onnxruntime did not support double computing to begin with? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1109203854/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1109478356",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11284#issuecomment-1109478356",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11284",
        "id": 1109478356,
        "node_id": "IC_kwDOCVq1mM5CIUvU",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-26T08:01:16Z",
        "updated_at": "2022-04-26T08:01:16Z",
        "author_association": "MEMBER",
        "body": "SVMClassifier only allows float coefficients in the current version of onnx and onnxruntime just implements the same. We noticed significant discrepancies with non continuous functions (trees) and models with big matrix multiplications. Trees specifications was modified, matrix multiplication is already implementation with double. SVMClassifier is the last one. It is unclear whether we should enable double coefficient or try to decompose the operator into other ONNX primitives. I did not check if that was possible without introducing a new operator.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1109478356/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]