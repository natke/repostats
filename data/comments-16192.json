[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1572052177",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16192#issuecomment-1572052177",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16192",
        "id": 1572052177,
        "node_id": "IC_kwDOCVq1mM5ds5zR",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-01T13:26:24Z",
        "updated_at": "2023-06-01T13:26:24Z",
        "author_association": "CONTRIBUTOR",
        "body": "You should also call `setInterOpNumThreads` to fully fix the per inference call threading. Using `int[][]` and `float[][]` to create the tensors is a slower path than using direct `ByteBuffer` as the native code has to do a bunch of pointer chasing to unpick them, so that will also impact the amount of computation, which in turn might affect the throughput.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1572052177/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582055462",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16192#issuecomment-1582055462",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16192",
        "id": 1582055462,
        "node_id": "IC_kwDOCVq1mM5eTEAm",
        "user": {
            "login": "ColainCYY",
            "id": 30071492,
            "node_id": "MDQ6VXNlcjMwMDcxNDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/30071492?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ColainCYY",
            "html_url": "https://github.com/ColainCYY",
            "followers_url": "https://api.github.com/users/ColainCYY/followers",
            "following_url": "https://api.github.com/users/ColainCYY/following{/other_user}",
            "gists_url": "https://api.github.com/users/ColainCYY/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ColainCYY/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ColainCYY/subscriptions",
            "organizations_url": "https://api.github.com/users/ColainCYY/orgs",
            "repos_url": "https://api.github.com/users/ColainCYY/repos",
            "events_url": "https://api.github.com/users/ColainCYY/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ColainCYY/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-08T07:33:48Z",
        "updated_at": "2023-06-08T07:33:48Z",
        "author_association": "NONE",
        "body": "> You should also call `setInterOpNumThreads` to fully fix the per inference call threading. Using `int[][]` and `float[][]` to create the tensors is a slower path than using direct `ByteBuffer` as the native code has to do a bunch of pointer chasing to unpick them, so that will also impact the amount of computation, which in turn might affect the throughput.\r\n\r\nThanks for your reply!\r\n\r\nI have tried to use ByteBuffer directly but it seems not to account for my poor multi-threading performance. Neither is \"setInterOpNumThreads\".\r\nI found neither InterOpNumThreads > 1 nor IntraOpNumThreads > 1 could contribute to an ideal throughput.\r\nMy CPU has 48 cores. But double threads just can't afford double throughput.\r\nwhen multiple threads start on the same OrtSession object invoking the run() method, do they wait for each other? Is there something like mutex inside?\r\nI'm not sure, if it is a problem only for java-api.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582055462/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582559850",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16192#issuecomment-1582559850",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16192",
        "id": 1582559850,
        "node_id": "IC_kwDOCVq1mM5eU_Jq",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-08T13:12:19Z",
        "updated_at": "2023-06-08T13:12:19Z",
        "author_association": "CONTRIBUTOR",
        "body": "Ok. The Java API has some overhead in getting data in and out, and we don't expose the ability to pin GPU memory, but otherwise everything is passed directly through to the native library and should behave the same across different languages.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582559850/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]