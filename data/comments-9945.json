[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993884681",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-993884681",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 993884681,
        "node_id": "IC_kwDOCVq1mM47PXoJ",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T18:58:59Z",
        "updated_at": "2021-12-14T18:58:59Z",
        "author_association": "MEMBER",
        "body": "I run your script in ORT1.9+TRT8.0+CUDA11.3 and it finished without error.\r\nHowever I see NaN in output. Can you share your FP32 model? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993884681/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993941479",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-993941479",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 993941479,
        "node_id": "IC_kwDOCVq1mM47Plfn",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T20:11:08Z",
        "updated_at": "2021-12-14T20:11:45Z",
        "author_association": "MEMBER",
        "body": "@stevenlix  Here is the FP32 model: https://drive.google.com/file/d/1LIFFxD8O39VITABQuH0H0Zx4kT3Wk-xd/view?usp=sharing\r\nFYI, ORT1.9 has a bug on FP16 of InstanceNorm op, it was fixed in this PR: https://github.com/microsoft/onnxruntime/pull/9879 and was merged in ORT1.10.\r\nThat's why I was using ORT1.10 to test. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993941479/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993944361",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-993944361",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 993944361,
        "node_id": "IC_kwDOCVq1mM47PmMp",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T20:14:52Z",
        "updated_at": "2021-12-14T20:14:52Z",
        "author_association": "MEMBER",
        "body": "Thanks. It's ok to use ORT1.10 or ORT master. But please use TRT8.0 with it. TRT8.2 is not officially supported in ORT yet.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993944361/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993951992",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-993951992",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 993951992,
        "node_id": "IC_kwDOCVq1mM47PoD4",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T20:24:57Z",
        "updated_at": "2021-12-14T20:24:57Z",
        "author_association": "MEMBER",
        "body": "I run your FP32 model in ORT1.9+TRT8.0+CUDA11.3. The script finished successfully and generated correct output. The NaN issue on the FP16 model is probably because certain attribute constants in the FP16 model is underflowed (too small) in FP16 precision. \r\nYou can actually directly run FP32 model in TRT EP. Just enable trt_fp16_enable to run it in FP16 precision. No FP16 model is needed for TRT.\r\nI will try your model in ORT1.10+TRT8.0 to see if there is any issue.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/993951992/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994013263",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-994013263",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 994013263,
        "node_id": "IC_kwDOCVq1mM47P3BP",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T21:10:54Z",
        "updated_at": "2021-12-14T21:10:54Z",
        "author_association": "MEMBER",
        "body": "Thanks. For this `The NaN issue on the FP16 model is probably because certain attribute constants in the FP16 model is underflowed (too small) in FP16 precision.` I actually tried ORT1.10+CUDA11.5, there is no issue at all. I am not sure why there is a NaN issue when using TRT8. I feel it is a bug on TRT8. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994013263/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994015989",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-994015989",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 994015989,
        "node_id": "IC_kwDOCVq1mM47P3r1",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T21:13:35Z",
        "updated_at": "2021-12-14T21:13:35Z",
        "author_association": "MEMBER",
        "body": "TRT may handle FP32->FP16 conversion differently to CUDA implementation. We see similar behavior before.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994015989/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994019137",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-994019137",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 994019137,
        "node_id": "IC_kwDOCVq1mM47P4dB",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T21:16:26Z",
        "updated_at": "2021-12-14T21:20:25Z",
        "author_association": "MEMBER",
        "body": "For downgrading from TRT8.2 to TRT8.0, should I build the ORT code again? Is there easier way to install ORT like pip? It takes me days on installing different CUDA version, TRT version and compiling the ORT code. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994019137/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994027519",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-994027519",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 994027519,
        "node_id": "IC_kwDOCVq1mM47P6f_",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T21:23:52Z",
        "updated_at": "2021-12-14T21:23:52Z",
        "author_association": "MEMBER",
        "body": "https://github.com/microsoft/onnxruntime/releases/tag/v1.10.0\r\n\"Starting from ORT1.10, Python GPU package now includes both TensorRT and CUDA EPs. Note: EPs need to be explicitly registered to ensure the correct provider is used. e.g. InferenceSession('model.onnx', providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider']). Please also ensure you have appropriate TensorRT dependencies and CUDA dependencies installed.\"\r\nHere is the python wheel, https://pypi.org/project/onnxruntime-gpu/#files\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994027519/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994031477",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-994031477",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 994031477,
        "node_id": "IC_kwDOCVq1mM47P7d1",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-14T21:28:10Z",
        "updated_at": "2021-12-14T21:28:10Z",
        "author_association": "MEMBER",
        "body": "\r\n\r\n\r\n> https://github.com/microsoft/onnxruntime/releases/tag/v1.10.0 \"Starting from ORT1.10, Python GPU package now includes both TensorRT and CUDA EPs. Note: EPs need to be explicitly registered to ensure the correct provider is used. e.g. InferenceSession('model.onnx', providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider']). Please also ensure you have appropriate TensorRT dependencies and CUDA dependencies installed.\" Here is the python wheel, https://pypi.org/project/onnxruntime-gpu/#files\r\n\r\nThis is great! ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/994031477/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100843566",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9945#issuecomment-1100843566",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9945",
        "id": 1100843566,
        "node_id": "IC_kwDOCVq1mM5BnYou",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2022-04-17T09:53:53Z",
        "updated_at": "2022-04-17T09:53:53Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100843566/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]