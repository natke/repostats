[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1172880865",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12070#issuecomment-1172880865",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12070",
        "id": 1172880865,
        "node_id": "IC_kwDOCVq1mM5F6L3h",
        "user": {
            "login": "nicken",
            "id": 42902092,
            "node_id": "MDQ6VXNlcjQyOTAyMDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/42902092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nicken",
            "html_url": "https://github.com/nicken",
            "followers_url": "https://api.github.com/users/nicken/followers",
            "following_url": "https://api.github.com/users/nicken/following{/other_user}",
            "gists_url": "https://api.github.com/users/nicken/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nicken/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nicken/subscriptions",
            "organizations_url": "https://api.github.com/users/nicken/orgs",
            "repos_url": "https://api.github.com/users/nicken/repos",
            "events_url": "https://api.github.com/users/nicken/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nicken/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-02T11:12:14Z",
        "updated_at": "2022-07-04T02:33:14Z",
        "author_association": "NONE",
        "body": "I get same question, and i don't known how to solve it;\r\n\r\nThis my test env:\r\n* GPU device: T4\r\n* [yolox onnx](https://github.com/Megvii-BaseDetection/YOLOX/tree/main/demo/ONNXRuntime)\r\n* docker: nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04\r\n* onnxruntime-gpu: 1.11.1\r\n* data: COCO dataset random 1000 images\r\n\r\nthis my test result:\r\n*  yolox_m\r\n\r\n| env/provider             | PyTorch | ONNX             | \r\n| ------------------------ | ---- | ---------------- | \r\n| T4 | 1393Mib, 28.420s | 1811MiB, 24.646s |\r\n| 1060  | | 593 MiB, 47.36s |\r\n| 3080  |  | 1427MiB, 11.03s |\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1172880865/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1172882108",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12070#issuecomment-1172882108",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12070",
        "id": 1172882108,
        "node_id": "IC_kwDOCVq1mM5F6MK8",
        "user": {
            "login": "nicken",
            "id": 42902092,
            "node_id": "MDQ6VXNlcjQyOTAyMDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/42902092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nicken",
            "html_url": "https://github.com/nicken",
            "followers_url": "https://api.github.com/users/nicken/followers",
            "following_url": "https://api.github.com/users/nicken/following{/other_user}",
            "gists_url": "https://api.github.com/users/nicken/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nicken/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nicken/subscriptions",
            "organizations_url": "https://api.github.com/users/nicken/orgs",
            "repos_url": "https://api.github.com/users/nicken/repos",
            "events_url": "https://api.github.com/users/nicken/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nicken/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-02T11:22:24Z",
        "updated_at": "2022-07-02T11:22:24Z",
        "author_association": "NONE",
        "body": "#9289 Similar problems",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1172882108/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1173012175",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12070#issuecomment-1173012175",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12070",
        "id": 1173012175,
        "node_id": "IC_kwDOCVq1mM5F6r7P",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-03T05:01:37Z",
        "updated_at": "2022-07-03T05:01:37Z",
        "author_association": "MEMBER",
        "body": "@[nicken](https://github.com/nicken)\r\n\r\nSometime, the default arena extend strategy might allocate more memory than needed.\r\n\r\nCould you try set execution provider options like the following python code:\r\n```\r\nimport onnxruntime as ort\r\nsess_options = ort.SessionOptions()\r\ncuda_provider_options = {\r\n\"arena_extend_strategy\": \"kSameAsRequested\",\r\n}\r\nexecution_providers = [(\"CUDAExecutionProvider\", cuda_provider_options), \"CPUExecutionProvider\"]\r\nort_sess = ort.InferenceSession(onnx_path, sess_options, providers=execution_providers)\r\n```\r\n\r\nThen use one input (warm up query) that need most memory to inference after session is created. That will allocate just enough memory for your need, and also ensure that future inference does not allocate heap memory.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1173012175/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1173274676",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12070#issuecomment-1173274676",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12070",
        "id": 1173274676,
        "node_id": "IC_kwDOCVq1mM5F7sA0",
        "user": {
            "login": "nicken",
            "id": 42902092,
            "node_id": "MDQ6VXNlcjQyOTAyMDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/42902092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nicken",
            "html_url": "https://github.com/nicken",
            "followers_url": "https://api.github.com/users/nicken/followers",
            "following_url": "https://api.github.com/users/nicken/following{/other_user}",
            "gists_url": "https://api.github.com/users/nicken/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nicken/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nicken/subscriptions",
            "organizations_url": "https://api.github.com/users/nicken/orgs",
            "repos_url": "https://api.github.com/users/nicken/repos",
            "events_url": "https://api.github.com/users/nicken/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nicken/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-04T02:34:44Z",
        "updated_at": "2022-07-04T02:34:44Z",
        "author_association": "NONE",
        "body": "> @[nicken](https://github.com/nicken)\r\n> \r\n> Sometime, the default arena extend strategy might allocate more memory than needed.\r\n> \r\n> Could you try set execution provider options like the following python code:\r\n> \r\n> ```\r\n> import onnxruntime as ort\r\n> sess_options = ort.SessionOptions()\r\n> cuda_provider_options = {\r\n> \"arena_extend_strategy\": \"kSameAsRequested\",\r\n> }\r\n> execution_providers = [(\"CUDAExecutionProvider\", cuda_provider_options), \"CPUExecutionProvider\"]\r\n> ort_sess = ort.InferenceSession(onnx_path, sess_options, providers=execution_providers)\r\n> ```\r\n> \r\n> Then use one input (warm up query) that need most memory to inference after session is created. That will allocate just enough memory for your need, and also ensure that future inference does not allocate heap memory.\r\n\r\nThank you you can help me! @tianleiwu \r\n\r\nI try this method on 3080, I get similar result:\r\n| device | ONNX|\r\n| --- | ---|\r\n| 3080  | 1463MB 11.41s|\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1173274676/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178357919",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12070#issuecomment-1178357919",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12070",
        "id": 1178357919,
        "node_id": "IC_kwDOCVq1mM5GPFCf",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T23:16:51Z",
        "updated_at": "2022-07-07T23:16:51Z",
        "author_association": "MEMBER",
        "body": "@[hariharans29](https://github.com/hariharans29), is there some session options that could reduce cudnn convolution memory usage (The Yolo model has many Conv operators)?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178357919/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]