[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/587444215",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-587444215",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 587444215,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU4NzQ0NDIxNQ==",
        "user": {
            "login": "lxl910915",
            "id": 8842010,
            "node_id": "MDQ6VXNlcjg4NDIwMTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8842010?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lxl910915",
            "html_url": "https://github.com/lxl910915",
            "followers_url": "https://api.github.com/users/lxl910915/followers",
            "following_url": "https://api.github.com/users/lxl910915/following{/other_user}",
            "gists_url": "https://api.github.com/users/lxl910915/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lxl910915/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lxl910915/subscriptions",
            "organizations_url": "https://api.github.com/users/lxl910915/orgs",
            "repos_url": "https://api.github.com/users/lxl910915/repos",
            "events_url": "https://api.github.com/users/lxl910915/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lxl910915/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-02-18T12:49:54Z",
        "updated_at": "2020-02-19T13:36:21Z",
        "author_association": "NONE",
        "body": "In TensorrtExecutionProvider::GetCapability() method, the code\r\n```\r\n        if (input_shape) {\r\n          for (auto dim : input_shape->dim()) {\r\n            std::string dim_name = dim.dim_param();\r\n            std::string exclude_dim_name1 = \"NonZero\";\r\n            std::string exclude_dim_name2 = \"NonMaxSuppression\";\r\n            if (!dim_name.empty()) {\r\n              if ((dim_name.find(exclude_dim_name1) != std::string::npos) || (dim_name.find(exclude_dim_name2) != std::string::npos)) {\r\n                exclude_node = true;\r\n                LOGS(default_logger, INFO) << \"exclude node \" << node->name();\r\n                break;\r\n              }\r\n            }\r\n          }\r\n        }\r\n```\r\nsome input's shape is empty. So we exclude those node whose shape is empty using\r\n```\r\n        if (input_shape) {\r\n          for (auto dim : input_shape->dim()) {\r\n            std::string dim_name = dim.dim_param();\r\n            std::string exclude_dim_name1 = \"NonZero\";\r\n            std::string exclude_dim_name2 = \"NonMaxSuppression\";\r\n            if (!dim_name.empty()) {\r\n              if ((dim_name.find(exclude_dim_name1) != std::string::npos) || (dim_name.find(exclude_dim_name2) != std::string::npos)) {\r\n                exclude_node = true;\r\n                LOGS(default_logger, INFO) << \"exclude node \" << node->name();\r\n                break;\r\n              }\r\n            }\r\n          }\r\n        } else {\r\n          LOGS(default_logger, INFO) << \"input->Shape() is 0 \";\r\n          LOGS(default_logger, INFO) << \"exclude node \" << node->name();\r\n          exclude_node = true;\r\n          break;\r\n        }\r\n```\r\nThe above code can work. But some kernel fallback to CPU, and a lot of CPUs are comsumed.\r\n\r\nIf the input shape is fix, node placements is\r\n```\r\n2020-02-18 11:37:15.557084658 [V:onnxruntime:, inference_session.cc:642 TransformGraph] Node placements\r\n2020-02-18 11:37:15.557123641 [V:onnxruntime:, inference_session.cc:649 TransformGraph]  Provider: [TensorrtExecutionProvider]: [TRTKernel_0 (TensorrtExecutionProvider_TRTKernel_0_0), TRTKernel_1 (TensorrtExecutionProvider_TRTKernel_1_1), TRTKernel_2 (TensorrtExecutionProvider_TRTKernel_2_2), TRTKernel_3 (TensorrtExecutionProvider_TRTKernel_3_3), ]\r\n2020-02-18 11:37:15.557141208 [V:onnxruntime:, inference_session.cc:649 TransformGraph]  Provider: [CUDAExecutionProvider]: [Resize (Resize__275), Resize (Resize__295), Resize (Resize__315), ]\r\n```\r\nIf the input shape is dynamic, more kernel are generated. And node placements is\r\n```\r\n2020-02-18 12:16:59.711728565 [V:onnxruntime:, inference_session.cc:642 TransformGraph] Node placements\r\n2020-02-18 12:16:59.711749824 [V:onnxruntime:, inference_session.cc:649 TransformGraph]  Provider: [TensorrtExecutionProvider]: [TRTKernel_0 (TensorrtExecutionProvider_TRTKernel_0_0), TRTKernel_1 (TensorrtExecutionProvider_TRTKernel_1_1), TRTKernel_2 (TensorrtExecutionProvider_TRTKernel_2_2), TRTKernel_3 (TensorrtExecutionProvider_TRTKernel_3_3), TRTKernel_4 (TensorrtExecutionProvider_TRTKernel_4_4), TRTKernel_5 (TensorrtExecutionProvider_TRTKernel_5_5), TRTKernel_6 (TensorrtExecutionProvider_TRTKernel_6_6), TRTKernel_7 (TensorrtExecutionProvider_TRTKernel_7_7), TRTKernel_8 (TensorrtExecutionProvider_TRTKernel_8_8), TRTKernel_9 (TensorrtExecutionProvider_TRTKernel_9_9), TRTKernel_10 (TensorrtExecutionProvider_TRTKernel_10_10), TRTKernel_11 (TensorrtExecutionProvider_TRTKernel_11_11), TRTKernel_12 (TensorrtExecutionProvider_TRTKernel_12_12), TRTKernel_13 (TensorrtExecutionProvider_TRTKernel_13_13), TRTKernel_14 (TensorrtExecutionProvider_TRTKernel_14_14), TRTKernel_15 (TensorrtExecutionProvider_TRTKernel_15_15), TRTKernel_16 (TensorrtExecutionProvider_TRTKernel_16_16), TRTKernel_17 (TensorrtExecutionProvider_TRTKernel_17_17), ]\r\n2020-02-18 12:16:59.711764805 [V:onnxruntime:, inference_session.cc:649 TransformGraph]  Provider: [CUDAExecutionProvider]: [Shape (Shape__1411), Mul (feature_fusion/mul_1), Mul (feature_fusion/mul), Cast (Cast__495), Cast (Cast__494), Resize (Resize__499), Concat (feature_fusion/concat), Conv (Conv__1139), Relu (feature_fusion/Conv/Relu), Conv (Conv__1143), Relu (feature_fusion/Conv_1/Relu), Shape (Shape__1387), Mul (feature_fusion/mul_3), Mul (feature_fusion/mul_2), Cast (Cast__545), Cast (Cast__544), Resize (Resize__549), Concat (feature_fusion/concat_1), Conv (Conv__1171), Relu (feature_fusion/Conv_2/Relu), Conv (Conv__1175), Relu (feature_fusion/Conv_3/Relu), Shape (Shape__1393), Mul (feature_fusion/mul_5), Mul (feature_fusion/mul_4), Cast (Cast__595), Cast (Cast__594), Resize (Resize__599), Concat (feature_fusion/concat_2), Conv (Conv__1195), Relu (feature_fusion/Conv_4/Relu), Conv (Conv__1199), Relu (feature_fusion/Conv_5/Relu), Conv (Conv__1203), Relu (feature_fusion/Conv_6/Relu), Conv (Conv__1227), Shape (Shape__1438), Reshape (feature_fusion/Conv_7/Conv2D__647), Conv (Conv__1223), Transpose (feature_fusion/Conv_8/Conv2D__639), Sigmoid (feature_fusion/Conv_8/Sigmoid), Mul (feature_fusion/mul_6), Conv (Conv__1219), Shape (Shape__1429), Reshape (feature_fusion/Conv_9/Conv2D__631), Sub (feature_fusion/sub), Mul (feature_fusion/mul_7), Div (feature_fusion/truediv), Concat (feature_fusion/concat_3), ]\r\n2020-02-18 12:16:59.711774907 [V:onnxruntime:, inference_session.cc:649 TransformGraph]  Provider: [CPUExecutionProvider]: [Gather (Gather__1428), Cast (feature_fusion/Shape_1__469), Gather (Gather__1386), Cast (feature_fusion/Shape_3__519), Gather (Gather__1398), Cast (feature_fusion/Shape_4__574), Gather (Gather__1443), Gather (Gather__1434), ]\r\n```\r\nFrom this, the node placements logic is bad for dynamic shape. So what is the better way to solve this problem? For example, like Tensorrt, generating a graph for each shape, and those graph are cached. For a new shape, if the corresponding graph exists, just using. Otherwise, generating a new graph. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/587444215/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/590467505",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-590467505",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 590467505,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU5MDQ2NzUwNQ==",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-02-24T18:00:38Z",
        "updated_at": "2020-02-24T18:03:57Z",
        "author_association": "MEMBER",
        "body": "@stevenlix \r\ntypically for dynamic input models, you'll need to run symbolic shape inference script to process the onnx model and fill in additional shape information to be able to execute with TensorRT EP. (Nuphar EP has similar requirement)\r\ntensorrt is unable to create engines , without having shape information.\r\nsee https://github.com/microsoft/onnxruntime/blob/master/docs/execution_providers/TensorRT-ExecutionProvider.md\r\nfor information on how to run the symbolic_shape_infer.py script",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/590467505/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/691720092",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-691720092",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 691720092,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY5MTcyMDA5Mg==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-09-13T20:20:44Z",
        "updated_at": "2020-09-13T20:20:44Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/691720092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/695833575",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-695833575",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 695833575,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY5NTgzMzU3NQ==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-09-20T20:39:53Z",
        "updated_at": "2020-09-20T20:39:53Z",
        "author_association": "NONE",
        "body": "This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/695833575/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778700719",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-778700719",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 778700719,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3ODcwMDcxOQ==",
        "user": {
            "login": "JadeCoding",
            "id": 16364775,
            "node_id": "MDQ6VXNlcjE2MzY0Nzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/16364775?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JadeCoding",
            "html_url": "https://github.com/JadeCoding",
            "followers_url": "https://api.github.com/users/JadeCoding/followers",
            "following_url": "https://api.github.com/users/JadeCoding/following{/other_user}",
            "gists_url": "https://api.github.com/users/JadeCoding/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JadeCoding/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JadeCoding/subscriptions",
            "organizations_url": "https://api.github.com/users/JadeCoding/orgs",
            "repos_url": "https://api.github.com/users/JadeCoding/repos",
            "events_url": "https://api.github.com/users/JadeCoding/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JadeCoding/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-14T00:46:23Z",
        "updated_at": "2021-02-14T00:47:21Z",
        "author_association": "NONE",
        "body": "> @stevenlix\r\n> typically for dynamic input models, you'll need to run symbolic shape inference script to process the onnx model and fill in additional shape information to be able to execute with TensorRT EP. (Nuphar EP has similar requirement)\r\n> tensorrt is unable to create engines , without having shape information.\r\n> see https://github.com/microsoft/onnxruntime/blob/master/docs/execution_providers/TensorRT-ExecutionProvider.md\r\n> for information on how to run the symbolic_shape_infer.py script\r\n\r\n@jywu-msft , I'm trying get familiar with the symbolic_shape_infer.py. But I can't find the TensorRT-ExecutionProvider.md, was this link removed for some reason? Thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778700719/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778701110",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3034#issuecomment-778701110",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3034",
        "id": 778701110,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3ODcwMTExMA==",
        "user": {
            "login": "JadeCoding",
            "id": 16364775,
            "node_id": "MDQ6VXNlcjE2MzY0Nzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/16364775?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JadeCoding",
            "html_url": "https://github.com/JadeCoding",
            "followers_url": "https://api.github.com/users/JadeCoding/followers",
            "following_url": "https://api.github.com/users/JadeCoding/following{/other_user}",
            "gists_url": "https://api.github.com/users/JadeCoding/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JadeCoding/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JadeCoding/subscriptions",
            "organizations_url": "https://api.github.com/users/JadeCoding/orgs",
            "repos_url": "https://api.github.com/users/JadeCoding/repos",
            "events_url": "https://api.github.com/users/JadeCoding/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JadeCoding/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-14T00:50:23Z",
        "updated_at": "2021-02-14T00:50:23Z",
        "author_association": "NONE",
        "body": "> > @stevenlix\r\n> > typically for dynamic input models, you'll need to run symbolic shape inference script to process the onnx model and fill in additional shape information to be able to execute with TensorRT EP. (Nuphar EP has similar requirement)\r\n> > tensorrt is unable to create engines , without having shape information.\r\n> > see https://github.com/microsoft/onnxruntime/blob/master/docs/execution_providers/TensorRT-ExecutionProvider.md\r\n> > for information on how to run the symbolic_shape_infer.py script\r\n> \r\n> @jywu-msft , I'm trying get familiar with the symbolic_shape_infer.py. But I can't find the TensorRT-ExecutionProvider.md, was this link removed for some reason? Thanks.\r\n\r\nnever mind, I found it in another location: https://www.onnxruntime.ai/docs/reference/execution-providers/TensorRT-ExecutionProvider.html\r\nPut it here as reference in case anyone else also look for it.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778701110/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]