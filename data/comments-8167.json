[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869211024",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-869211024",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 869211024,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg2OTIxMTAyNA==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-27T19:08:57Z",
        "updated_at": "2021-06-28T01:16:39Z",
        "author_association": "CONTRIBUTOR",
        "body": "You shouldn't need to download `onnxruntime.dll` separately, it should be packaged into the `onnxruntime_gpu` Maven artifact you downloaded. I can't quite tell if it's actually using the GPU there, is process 8888 your Java test process, or just something else on your machine using the GPU from Java?\r\n\r\nTesting against ONNX Runtime in Python on Windows is a good idea. How are you feeding inputs to & retrieving outputs from the model, and what model are you using? To get the best speed out of the Java API you need to use a `java.nio.FloatBuffer` as the input, using a multidimensional array will induce a *lot* of very slow copying which could cause slow inference performance (though it should be equivalently slow between CPU and GPU). This might account for why you're not seeing much of a speedup, depending on how the input is presented.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869211024/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869738997",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-869738997",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 869738997,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg2OTczODk5Nw==",
        "user": {
            "login": "MianMianMeow",
            "id": 86562720,
            "node_id": "MDQ6VXNlcjg2NTYyNzIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/86562720?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MianMianMeow",
            "html_url": "https://github.com/MianMianMeow",
            "followers_url": "https://api.github.com/users/MianMianMeow/followers",
            "following_url": "https://api.github.com/users/MianMianMeow/following{/other_user}",
            "gists_url": "https://api.github.com/users/MianMianMeow/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MianMianMeow/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MianMianMeow/subscriptions",
            "organizations_url": "https://api.github.com/users/MianMianMeow/orgs",
            "repos_url": "https://api.github.com/users/MianMianMeow/repos",
            "events_url": "https://api.github.com/users/MianMianMeow/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MianMianMeow/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-28T14:35:11Z",
        "updated_at": "2021-06-28T14:39:42Z",
        "author_association": "NONE",
        "body": "Thanks for your reply~ For the questions you mentioned above,  I did some tests and here are the answers. \r\n\r\n1. You shouldn't need to download onnxruntime.dll separately, it should be packaged into the onnxruntime_gpu Maven artifact you downloaded.\r\nTest 1: Using onnxruntime_gpu Maven artifact only -> still has the same problem.\r\n\r\n2. is process 8888 your Java test process?\r\nYes. The GPU is working for my Java test here.\r\n\r\n3. Test on Windows+Python+Onnxruntime\r\nTest 2: GPU-Util is about 76% and inferencing speed is about 65ms / frame, which seems the performances on Windows and Ubuntu with Python+Onnxruntime are the same.\r\n\r\n4.  Model, inputs, outputs\r\nModel network: https://github.com/MianMianMeow/testJavaOnnxruntime/blob/main/swimming512.onnx.svg\r\nInput: NodeInfo(name=input,info=TensorInfo(javaType=FLOAT,onnxType=ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT,shape=[1, 3, 512, 512]))\r\nOutput: NodeInfo(name=pts,info=TensorInfo(javaType=FLOAT,onnxType=ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT,shape=[-1, 7]))\r\nMultidimensional array was used for the input and output.\r\n\r\n5. java.nio.FloatBuffer as the input rather than using a multidimensional array \r\nTest 3: Following _https://github.com/microsoft/onnxruntime/blob/user/dwayner/FixRoiAlign/java/src/test/java/ai/onnxruntime/InferenceTest.java_ and its function _testModelInputBuffer()_ to use **java.nio.FloatBuffer** as the input and output, the inference speed is about 420 ms/frame on CPU and 320 ms/frame on GPU (with the problem of low GPU-Util), which brings a speed up compared to using multidimential array as input and output (multidimential array: about 450ms/frame on CPU, 350ms/frame on GPU).\r\n\r\n6. I extracted onnxruntime.dll from the onnxruntime_gpu-1.8.0.jar downloaded by Maven, and then I used _Dependency Walker_ to check if there are any dependencies are absent. The result is shown below.Not sure if the problem is caused by the absent .dll files.\r\n![image](https://user-images.githubusercontent.com/86562720/123655477-98af8880-d861-11eb-8ff7-30c970e05520.png)\r\n\r\nBased on the tests above, it seems the problem is related to the system environment of Java + onnxruntime_gpu(Maven), but I still cannot figure out the solution.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869738997/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869747555",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-869747555",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 869747555,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg2OTc0NzU1NQ==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-28T14:46:27Z",
        "updated_at": "2021-06-28T14:46:47Z",
        "author_association": "CONTRIBUTOR",
        "body": "The code in `testModelInputBuffer` is better than an array, but still does a few too many copies (as it's designed to test the direct buffer allocation functionality), so there might be further ways to improve that, though I agree it doesn't appear to be the whole issue.\r\n\r\nIs it 350ms for the first iteration of inference, or after everything has warmed up some? Would it be possible to show the code from your inference loop for both Java and Python?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869747555/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869772791",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-869772791",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 869772791,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg2OTc3Mjc5MQ==",
        "user": {
            "login": "MianMianMeow",
            "id": 86562720,
            "node_id": "MDQ6VXNlcjg2NTYyNzIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/86562720?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MianMianMeow",
            "html_url": "https://github.com/MianMianMeow",
            "followers_url": "https://api.github.com/users/MianMianMeow/followers",
            "following_url": "https://api.github.com/users/MianMianMeow/following{/other_user}",
            "gists_url": "https://api.github.com/users/MianMianMeow/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MianMianMeow/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MianMianMeow/subscriptions",
            "organizations_url": "https://api.github.com/users/MianMianMeow/orgs",
            "repos_url": "https://api.github.com/users/MianMianMeow/repos",
            "events_url": "https://api.github.com/users/MianMianMeow/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MianMianMeow/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-28T15:16:50Z",
        "updated_at": "2021-06-28T15:16:50Z",
        "author_association": "NONE",
        "body": "Wow~Really thanks for your quick reply.\r\n350ms is for the warmed up inference. The first frame inference is much slower.\r\n![image](https://user-images.githubusercontent.com/86562720/123657634-8c2c2f80-d863-11eb-8ff8-7b15aee63c4b.png)\r\n\r\nHere's my code for inferencing:\r\nJava, multidimension array (this produce the correct boundingboxes):\r\n```\r\n   // model loading and session create\r\n   OrtEnvironment env = OrtEnvironment.getEnvironment();\r\n   OrtSession.SessionOptions opts = new OrtSession.SessionOptions();\r\n   opts.setExecutionMode(OrtSession.SessionOptions.ExecutionMode.PARALLEL);\r\n   opts.addCUDA(0); \r\n\r\n   opts.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT);\r\n   logger.info(\"Loading model from \" + modelPath);\r\n   OrtSession session = env.createSession(modelPath, opts);\r\n```\r\n\r\n        // inference on one image\r\n        private static Mat processOneImage512(Mat imgBGR, double w, double h, String inputName, OrtEnvironment env, OrtSession \r\n        session, boolean singleImage) throws OrtException {\r\n        Mat paddedImage = pad2(imgBGR, w,  h);\r\n\r\n        Mat processedImage = Dnn.blobFromImage(paddedImage, 1.0/255.0, new Size(512, 512), new Scalar(0, 0, 0), true, false);\r\n        float[][][][] imgArray = convertMatArray3chNoScale(processedImage);\r\n        OnnxTensor input_tensor = OnnxTensor.createTensor(env, imgArray);\r\n        OrtSession.Result output = session.run(Collections.singletonMap(inputName, input_tensor));\r\n\r\n        float[][] result = (float[][])output.get(0).getValue();\r\n        // draw boundingboxes on the paddedImage\r\n        List<Rect> rectList = getBoundingBoxesToInputSizeImage512(result);\r\n        Mat resizedPaddedImage = new Mat();\r\n        Imgproc.resize(paddedImage, resizedPaddedImage, new Size(INPUT_SIZE, INPUT_SIZE));\r\n        return draw(resizedPaddedImage,  rectList, singleImage);\r\n    }`\r\n\r\n```\r\n// convert image to multidimensional array\r\nprivate static float[][][][] convertMatArray3chNoScale(Mat img) {\r\n        // img: rgb\r\n        int ch = 3;\r\n        float [][][][] input = new float[1][ch][INPUT_SIZE][INPUT_SIZE];\r\n        for (int c = 0; c < ch; c++) {\r\n            for (int i = 0; i < INPUT_SIZE; i++){\r\n                for (int j = 0; j < INPUT_SIZE; j++){\r\n                    double[] temp = img.get(new int[]{0, c, i, j});\r\n                    input[0][c][j][i] = (float)temp[0];\r\n                }\r\n            }\r\n        }\r\n        return input;\r\n    }\r\n```\r\n\r\nJava, FloatBuffer (here may have some problems in dimenstions for converting the image into FloatBuffer so it cannot produce correct boundingboxes. I will correct it later.). TestHelpers is from https://github.com/microsoft/onnxruntime/blob/user/dwayner/FixRoiAlign/java/src/test/java/ai/onnxruntime/TestHelpers.java:\r\n```\r\n// the model loading part is the same as above\r\nprivate static Mat processOneImage512(Mat imgBGR, double w, double h, String inputName, OrtEnvironment env, OrtSession session, boolean singleImage) throws OrtException {\r\n        Mat paddedImage = pad2(imgBGR, w,  h);\r\n\r\n        Mat processedImage = Dnn.blobFromImage(paddedImage, 1.0/255.0, new Size(512, 512), new Scalar(0, 0, 0), true, false);\r\n        float[] imgArray = convertMatArray1chNoScale(processedImage);\r\n        FloatBuffer buffer = FloatBuffer.wrap(imgArray);\r\n        long[] shape = new long[] {1, 3, INPUT_SIZE, INPUT_SIZE};\r\n\r\n        OnnxTensor input_tensor = OnnxTensor.createTensor(env, buffer, shape);\r\n        Map<String, OnnxTensor> container = new HashMap<>();\r\n        container.put(inputName, input_tensor);\r\n        float[] resultArray;\r\n        try (OrtSession.Result res = session.run(container)) {\r\n            resultArray = TestHelpers.flattenFloat(res.get(0).getValue());\r\n            OnnxValue.close(container);\r\n\r\n        }\r\n        container.clear();\r\n}\r\n\r\nprivate static float[] convertMatArray1chNoScale(Mat img) {\r\n        // img: rgb\r\n        int ch = 3;\r\n        float [] input = new float[ch * INPUT_SIZE * INPUT_SIZE];\r\n        int index = 0;\r\n        for (int c = 0; c < ch; c++) {\r\n            for (int i = 0; i < INPUT_SIZE; i++){\r\n                for (int j = 0; j < INPUT_SIZE; j++){\r\n                    double[] temp = img.get(new int[]{0, c, i, j});\r\n                    input[index] = (float)temp[0];\r\n                    index++;\r\n                }\r\n            }\r\n        }\r\n\r\n        return input;\r\n    }\r\n```\r\nPython\r\n```\r\nsess = ort.InferenceSession(onnx_file)\r\nsess.set_providers(['CUDAExecutionProvider'], [{'device_id': 0}])\r\n\r\n    while ret:\r\n        cnt += 1\r\n        ret, img = cap.read()\r\n        if cnt % 10 != 0 : continue\r\n\r\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n        org_img = img.copy()\r\n        img = padding2square(img)\r\n        start = time.time()\r\n        onnx_result = sess.run(None, {'input': img})[0]\r\n\r\ndef padding2square(input):\r\n    H, W = input.shape[0], input.shape[1]\r\n    max_length = max(H, W)\r\n    pad_r = max_length - H\r\n    pad_d = max_length - W\r\n    output = cv2.copyMakeBorder(input, 0, pad_r, 0, pad_d, cv2.BORDER_CONSTANT, value=0)\r\n    output = cv2.resize(output, inres) / 255.\r\n    output = np.array(output, dtype=np.float32)\r\n    output = output.transpose(2, 1, 0)\r\n    output = output[np.newaxis, ...]\r\n    return output\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/869772791/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870035405",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-870035405",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 870035405,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3MDAzNTQwNQ==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-28T20:56:24Z",
        "updated_at": "2021-06-28T20:56:24Z",
        "author_association": "CONTRIBUTOR",
        "body": "Ok, so I think there is still quite a lot of overhead in how you're copying the data in and out. It looks like there are bulk copies available on OpenCV's `Mat` but I'm not sure if those will dump out the data in the right shape (you can try `img.get(0,0,input)` but I'm not sure what order the bytes are stored in). One quick thing you could do is to allocate the indexing array at the start of the `convertMatArray1chNoScale` function, and then update its values in the for loop as appropriate. Making a fresh array each time is going to trigger a lot of allocations and if it's actually bottoming out in a JNI call in OpenCV, I'm not sure that the escape analysis will manage to elide the allocation.\r\n\r\nOn the outbound side, the code in `TestHelpers.flattenFloat` is slow & recursive which is definitely not what you want in a tight loop. It's in the tests because it's correct and works across a wide variety of shapes so it's useful in the unit tests, but it's definitely not fast. You can copy the output to a `FloatBuffer` using `((OnnxTensor) res.get(0)).getFloatBuffer()` and that should be much faster.\r\n\r\nOne final element of the baseline, how fast is the python code you posted running on the CPU?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870035405/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870652460",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-870652460",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 870652460,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3MDY1MjQ2MA==",
        "user": {
            "login": "MianMianMeow",
            "id": 86562720,
            "node_id": "MDQ6VXNlcjg2NTYyNzIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/86562720?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MianMianMeow",
            "html_url": "https://github.com/MianMianMeow",
            "followers_url": "https://api.github.com/users/MianMianMeow/followers",
            "following_url": "https://api.github.com/users/MianMianMeow/following{/other_user}",
            "gists_url": "https://api.github.com/users/MianMianMeow/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MianMianMeow/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MianMianMeow/subscriptions",
            "organizations_url": "https://api.github.com/users/MianMianMeow/orgs",
            "repos_url": "https://api.github.com/users/MianMianMeow/repos",
            "events_url": "https://api.github.com/users/MianMianMeow/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MianMianMeow/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-29T14:30:01Z",
        "updated_at": "2021-06-29T14:30:01Z",
        "author_association": "NONE",
        "body": "@Craigacp \r\n### Problem solved.\r\n\r\nThe problem of low GPU_Util is exactly caused by the nested loop through every element of a Mat to generate an one-dimensional array as the input,  as you mentioned above. Also following your suggestions, I used `img.get(0,0,input) `to generate the array without the multidimentional array or nested loop. Here's my code for input data generation:\r\n```\r\nprivate static Mat processOneImage512(Mat imgBGR, double w, double h, String inputName, OrtEnvironment env, OrtSession session, boolean singleImage) throws OrtException {\r\n        Mat paddedImage = pad2(imgBGR, w,  h);\r\n        Mat processedImage = Dnn.blobFromImage(paddedImage, 1.0/255.0, new Size(512, 512), new Scalar(0.0, 0.0, 0.0), true, false, CvType.CV_32F);\r\n\r\n        float[] imgArray = new float[512 * 512 * 3];\r\n        int[] idx = {0, 0, 0, 0};\r\n\r\n        processedImage.get(idx, imgArray); // processedImage: CvType.depth(t) == 5, CV_32F, processedImage.dims() = 4\r\n\r\n        FloatBuffer buffer = FloatBuffer.wrap(imgArray);\r\n        long[] shape = new long[] {1, 3, INPUT_SIZE, INPUT_SIZE};\r\n\r\n        OnnxTensor input_tensor = OnnxTensor.createTensor(env, buffer, shape);\r\n        float[][] result;\r\n        try (OrtSession.Result res = session.run(Collections.singletonMap(inputName, input_tensor))) {\r\n            result = (float[][])res.get(0).getValue();\r\n        }\r\n\r\n    }\r\n```\r\nI will improve the output by copying it to a FloatBuffer later.\r\nFor your reference, currently the inferencing speeds and GPU_Util on Windows+Java+Onnxrumtime,  Windows+Python+Onnxrumtime, Ubuntu+Python+Onnxrumtime seem no big difference : CPU 145ms/frame, GPU(CUDA) 65ms/frame. GPU_Util for Java is about 80%, and is about 75% for Python.\r\n\r\nThanks again and have a nice day :)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870652460/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870700827",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8167#issuecomment-870700827",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8167",
        "id": 870700827,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3MDcwMDgyNw==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-29T15:30:17Z",
        "updated_at": "2021-06-29T15:30:17Z",
        "author_association": "CONTRIBUTOR",
        "body": "Excellent, I'm glad that resolved your issue.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/870700827/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]