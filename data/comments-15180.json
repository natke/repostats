[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1481820710",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15180#issuecomment-1481820710",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15180",
        "id": 1481820710,
        "node_id": "IC_kwDOCVq1mM5YUsom",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-23T20:04:22Z",
        "updated_at": "2023-03-23T20:04:22Z",
        "author_association": "MEMBER",
        "body": "@yufenglee any insights?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1481820710/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1494126873",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15180#issuecomment-1494126873",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15180",
        "id": 1494126873,
        "node_id": "IC_kwDOCVq1mM5ZDpEZ",
        "user": {
            "login": "PhilippShemetov",
            "id": 42965011,
            "node_id": "MDQ6VXNlcjQyOTY1MDEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42965011?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PhilippShemetov",
            "html_url": "https://github.com/PhilippShemetov",
            "followers_url": "https://api.github.com/users/PhilippShemetov/followers",
            "following_url": "https://api.github.com/users/PhilippShemetov/following{/other_user}",
            "gists_url": "https://api.github.com/users/PhilippShemetov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PhilippShemetov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PhilippShemetov/subscriptions",
            "organizations_url": "https://api.github.com/users/PhilippShemetov/orgs",
            "repos_url": "https://api.github.com/users/PhilippShemetov/repos",
            "events_url": "https://api.github.com/users/PhilippShemetov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PhilippShemetov/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-03T11:09:18Z",
        "updated_at": "2023-04-03T11:09:18Z",
        "author_association": "NONE",
        "body": "I forgot to mention computer specifications:\r\n\r\n- OS: Ubuntu 20.04 focal\r\n- CPU: Intel Core i7-8700 @ 12x 4,6GHz \r\n- GPU: NVIDIA GeForce GTX 1080 Ti\r\n- RAM: 32 GB\r\n\r\nAlso! I did another experiment on a different device (laptop). Laptop specifications:\r\n\r\n- OS: Ubuntu 22.04 jammy(on the Windows Subsystem for Linux)\r\n- CPU: Intel Core i7-10870H @ 16x 2.208GHz\r\n- GPU: NVIDIA GeForce RTX 3060 Laptop GPU\r\n- RAM: 12 GB\r\n\r\nResults:\r\nPerfomance for first model (1 Conv):\r\n\r\n- With `ORT::ENABLE_BASIC` or `ORT::ENABLE_EXTENDED`: Average - 3.38 ms, median - 3.32, std - 0.34 ms\r\n- With `ORT::ENABLE_ALL`: Average - 2.86 ms, median - 2.95, std - 0.46 ms\r\n\r\nPerfomance for second model (1 Conv + Max-Pool):\r\n\r\n- With  `ORT::ENABLE_BASIC` or `ORT::ENABLE_EXTENDED`: Average - 4.05 ms, median - 3.88, std - 0.38 ms\r\n- With `ORT::ENABLE_ALL`: Average - 2.55 ms, median - 2.52, std - 0.33 ms",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1494126873/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1549360895",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15180#issuecomment-1549360895",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15180",
        "id": 1549360895,
        "node_id": "IC_kwDOCVq1mM5cWV7_",
        "user": {
            "login": "duanqn",
            "id": 21275667,
            "node_id": "MDQ6VXNlcjIxMjc1NjY3",
            "avatar_url": "https://avatars.githubusercontent.com/u/21275667?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/duanqn",
            "html_url": "https://github.com/duanqn",
            "followers_url": "https://api.github.com/users/duanqn/followers",
            "following_url": "https://api.github.com/users/duanqn/following{/other_user}",
            "gists_url": "https://api.github.com/users/duanqn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/duanqn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/duanqn/subscriptions",
            "organizations_url": "https://api.github.com/users/duanqn/orgs",
            "repos_url": "https://api.github.com/users/duanqn/repos",
            "events_url": "https://api.github.com/users/duanqn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/duanqn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-16T09:58:10Z",
        "updated_at": "2023-05-16T10:03:15Z",
        "author_association": "NONE",
        "body": "@PhilippShemetov \r\nI would suggest you to collect more data using the following methods. Maybe this can provide more insights.\r\n1. Dump the optimized graph with `session_options.SetOptimizedModelFilePath`, as shown in [this doc](https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html). This will give you a chance to inspect the final model that is executed on your machine.\r\n2. Collect profiling data by setting `session_options.EnableProfiling`, as shown in [this doc](https://onnxruntime.ai/docs/performance/tune-performance/profiling-tools.html). You can then visualize the profiling data (a JSON file) with various tools, e.g. edge://tracing in the Edge browser. This will give you the exact execution duration of each operator. Note that the operators here match with the operators in the optimized graph, not the original model graph.\r\n\r\nIf I have to guess, the reason that Conv+MaxPool is faster is probably that the result tensor in your Conv+MaxPool model is much smaller than the Conv-only model. In fact it's only 1/4 as large, because you are using a `torch.nn.MaxPool2d` with kernel size 2x2. There is a hidden operation after your Conv+MaxPool because ONNXRuntime needs to convert the result tensor from NCHWc format back to the normal NCHW format. This memory layout conversion is faster in Conv+MaxPool model because it is operating on a smaller tensor. There is also a memory layout conversion before the first Conv operator, but this one is operating on the same tensor (the input data) in both models, so it does not contribute to the performance difference you observed.\r\n\r\nMy guess could be wrong as I don't have the optimized graph or the profiling data of your models. You can collect the additional data and verify it.\r\n\r\n**Disclaimer**: I am not a developer of ONNXRuntime.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1549360895/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]