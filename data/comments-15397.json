[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1499560651",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1499560651",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1499560651,
        "node_id": "IC_kwDOCVq1mM5ZYXrL",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-06T20:12:19Z",
        "updated_at": "2023-04-06T20:12:19Z",
        "author_association": "MEMBER",
        "body": "Cc: @skottmckay @edgchen1 ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1499560651/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500008321",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1500008321",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1500008321,
        "node_id": "IC_kwDOCVq1mM5ZaE-B",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-07T07:06:56Z",
        "updated_at": "2023-04-07T07:06:56Z",
        "author_association": "MEMBER",
        "body": "@adityagoel4512 Not quite following. We already have what you're asking for.\r\n\r\n> I would make the argument that aiming to support the entire standard and giving users optionality to build ORT with a smaller binary footprint strikes the right balance.\r\n\r\nOur default build supports the whole standard. We intentionally don't implement types that are not required for production scenarios at all. You're always welcome add those types if there's a real use case.\r\n\r\n> We currently cannot specify reduced type builds where we only include certain types supported by an operator\r\n\r\nHave you seen this? https://onnxruntime.ai/docs/reference/operators/reduced-operator-config-file.html",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500008321/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500299623",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1500299623",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1500299623,
        "node_id": "IC_kwDOCVq1mM5ZbMFn",
        "user": {
            "login": "adityagoel4512",
            "id": 48102515,
            "node_id": "MDQ6VXNlcjQ4MTAyNTE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/48102515?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adityagoel4512",
            "html_url": "https://github.com/adityagoel4512",
            "followers_url": "https://api.github.com/users/adityagoel4512/followers",
            "following_url": "https://api.github.com/users/adityagoel4512/following{/other_user}",
            "gists_url": "https://api.github.com/users/adityagoel4512/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adityagoel4512/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adityagoel4512/subscriptions",
            "organizations_url": "https://api.github.com/users/adityagoel4512/orgs",
            "repos_url": "https://api.github.com/users/adityagoel4512/repos",
            "events_url": "https://api.github.com/users/adityagoel4512/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adityagoel4512/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-07T13:41:48Z",
        "updated_at": "2023-04-07T13:54:35Z",
        "author_association": "CONTRIBUTOR",
        "body": "> @adityagoel4512 Not quite following. We already have what you're asking for.\r\n> \r\n> > I would make the argument that aiming to support the entire standard and giving users optionality to build ORT with a smaller binary footprint strikes the right balance.\r\n> \r\n> Our default build supports the whole standard. We intentionally don't implement types that are not required for production scenarios at all. You're always welcome add those types if there's a real use case.\r\n> \r\n> > We currently cannot specify reduced type builds where we only include certain types supported by an operator\r\n> \r\n> Have you seen this? https://onnxruntime.ai/docs/reference/operators/reduced-operator-config-file.html\r\n\r\nMy point was more to do with this decision to _**intentionally**_ not cover all the types until someone discovers a production scenario:\r\n\r\n> We intentionally don't implement types that are not required for production scenarios at all. You're always welcome add those types if there's a real use case.\r\n\r\nWhile the PR based model to add the types as and when production needs arise does certainly work in the long term, I wanted to know what the reason might be behind this - I imagine it's binary size? \r\n\r\nThe issue with this intentional decision on our end is that typically you figure out what types are needed for production scenarios when you want to ship something to production! To then patch in the missing type can take a significant amount of time which adds friction to the process of using onnxruntime and can lead to needing suboptimal, ad-hoc workarounds motivated by what the runtime supports at that moment and slower iteration speed.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1500299623/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1502516364",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1502516364",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1502516364,
        "node_id": "IC_kwDOCVq1mM5ZjpSM",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-11T00:30:30Z",
        "updated_at": "2023-04-11T00:30:30Z",
        "author_association": "MEMBER",
        "body": "Couple of reasons: \r\n1. We don't want our default binary size to grow unnecessarily. While users can always restrict ops and types in their custom builds it's not the most convenient experience and intended for only those users who are really constrained. It would be unfair to penalize our regular users by increasing the size without any bounds just to support the standard and impose artificial constraints on them forcing them to resort to custom builds.\r\n2. Adding support for certain types (e.g., complex types) is not only non-trivial taking resources away from higher priority work items but also adds to the complexity of the codebase and increases maintenance costs.\r\n\r\nHaving said that if there's a legitimate production use case we're more than happy to accept contributions or make the changes ourselves when time permits.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1502516364/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1502670656",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1502670656",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1502670656,
        "node_id": "IC_kwDOCVq1mM5ZkO9A",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-11T04:28:28Z",
        "updated_at": "2023-04-11T04:28:28Z",
        "author_association": "MEMBER",
        "body": "> I would make the argument that _aiming_ to support the entire standard and giving users optionality to build ORT with a smaller binary footprint strikes the right balance.\r\n\r\nA custom build involves a significant amount of time and effort, especially if you're deploying on multiple platforms and/or architectures. For example, if you're using the nuget package you have to assemble builds from all platforms in one place before creating the package, which is non-trivial. \r\n\r\nOur current pre-built binaries include the necessary types to handle known production scenarios. Occasionally a new unsupported scenario comes up and we add the required types to the necessary operators. Historically this has been infrequent. Wouldn't the development/maintenance/binary size cost to support all types in order to avoid these infrequent type expansions be optimizing for an edge case? \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1502670656/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1504922018",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1504922018",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1504922018,
        "node_id": "IC_kwDOCVq1mM5Zs0mi",
        "user": {
            "login": "cbourjau",
            "id": 3288058,
            "node_id": "MDQ6VXNlcjMyODgwNTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3288058?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbourjau",
            "html_url": "https://github.com/cbourjau",
            "followers_url": "https://api.github.com/users/cbourjau/followers",
            "following_url": "https://api.github.com/users/cbourjau/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbourjau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbourjau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbourjau/subscriptions",
            "organizations_url": "https://api.github.com/users/cbourjau/orgs",
            "repos_url": "https://api.github.com/users/cbourjau/repos",
            "events_url": "https://api.github.com/users/cbourjau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbourjau/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-12T09:05:34Z",
        "updated_at": "2023-04-12T09:05:34Z",
        "author_association": "CONTRIBUTOR",
        "body": "I feel as if there is a bit of ambiguity about which types and binary sizes/EPs are referred to here. Maybe it helps to be more explicit here?\r\n\r\nOur ( @adityagoel4512 and I are colleagues) primary use case at this point is expressing feature engineering pipelines in ONNX. We want to empower data scientists (on our side and on the client side) to express their business logic of that kind in ONNX. The pipelines have to be as close as possible to their numpy/pandas equivalent. We are exclusively running these models on the CPU execution provider. Numpy/Pandas defaults to `float64`, `int64`, and `object`/`string` making these two data types particularly important to us. To a lesser degree, we may also encounter `float32`, `int32` and `uint64` data types. \r\n\r\nIn summary, having good and predictable coverage of the standard for the already existing data types (`float64`, `int64`, `string`, `float32, `int32`, ...) on the CPU execution provider would be very helpful to us. Our use case currently does not call for expanding the coverage for other execution providers or introducing entirely new types (such as complex ones). \r\n\r\nThe binary size increase required to implement the above seems fairly marginal especially since it is  GPU rather than CPU releases that are pretty heavyweight in terms of size.\r\n\r\nGiven these clarifications of our use case, is there interest from the `onnxruntime` project side to accept PRs that expand the coverage for these types on the CPU EP proactively or do you consider our use case of expressing Numpy/Pandas feature engineering pipelines in ONNX too much of an edge case? Maybe the ORT could select a few \"blessed\" data types for which it strives to have complete coverage while non-blessed data types continue to be implemented on a per-use-case basis? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1504922018/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1506051539",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1506051539",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1506051539,
        "node_id": "IC_kwDOCVq1mM5ZxIXT",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-12T22:33:28Z",
        "updated_at": "2023-04-12T22:33:28Z",
        "author_association": "MEMBER",
        "body": "> The binary size increase required to implement the above seems fairly marginal especially since it is GPU rather than CPU releases that are pretty heavyweight in terms of size.\r\n\r\n'marginal' is relative. The impact of the binary size increase on mobile/edge devices could very well be significant.\r\n\r\nWhilst numpy/pandas might default to 64-bit numbers, producing models that use them is roughly twice as expensive in terms of model size and memory usage, and incurs the performance penalty of processing 2x the data vs a 32-bit version of the model. Unless the use-case requires 64-bit numbers, that is a high price to pay. e.g. I'd expect that roughly doubles the cost of training the model. \r\n\r\nAFAIK there should be complete coverage for the common types - e.g. float32 data/weights, uint8/int8 in a quantized model, and int64 when used for indices. We have added to individual operators the types required by all production scenarios that we are aware of over a number of years, so based on that I'd expect all common use cases should be supported. \r\n\r\nUsing unnecessarily large data types probably falls into an uncommon use case though given the high cost involved. \r\n\r\nIs there a reason not to convert to 32-bit as part of your pipeline? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1506051539/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1519610565",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15397#issuecomment-1519610565",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15397",
        "id": 1519610565,
        "node_id": "IC_kwDOCVq1mM5ak2rF",
        "user": {
            "login": "cbourjau",
            "id": 3288058,
            "node_id": "MDQ6VXNlcjMyODgwNTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3288058?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbourjau",
            "html_url": "https://github.com/cbourjau",
            "followers_url": "https://api.github.com/users/cbourjau/followers",
            "following_url": "https://api.github.com/users/cbourjau/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbourjau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbourjau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbourjau/subscriptions",
            "organizations_url": "https://api.github.com/users/cbourjau/orgs",
            "repos_url": "https://api.github.com/users/cbourjau/repos",
            "events_url": "https://api.github.com/users/cbourjau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbourjau/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-24T08:21:42Z",
        "updated_at": "2023-04-24T08:21:42Z",
        "author_association": "CONTRIBUTOR",
        "body": "I am aware of the benefits of of using `float32`. I think our use case is novel in the sense that we are really striving to express long and complex feature engineering steps completely in ONNX which have previously been expressed in Pandas/Numpy. This is probably the reason why we have run into missing `float64` implementations repeatedly. Would it be better to express the pipeline in `float32` even in Pandas/Numpy? Often times yes! But that is not how pandas works. Memory and speed is not the primary concern in many use cases and thus models end up being trained using `float64` precision. If we convert the models using `float32` we get discrepancies that need to be monitored and explained. This is especially important when using decision trees where a loss of precision can lead to ending up in a completely different branch. This may sound unlikely but it happens in reality. For instance, LightGBM's algorithm for determining split values can lead to splits coinciding *precisely* with values seen in the training data in some scenarios. This is very unfortunate but the reality. Using `float32` for the feature engineering at inference time will lead to completely different outputs. \r\n\r\n**tl;dr**:\r\n- Pandas/Numpy defaults to `float64`. This behavior is hard to control and leads to (legacy) models being trained with that precision.\r\n- Supporting `float64` makes the introduction of ONNX into an organization much easier because it removes any discussions in the review due to numerical discrepancies. Some use cases absolutely require `float64` in the feature engineering pipeline.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1519610565/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]