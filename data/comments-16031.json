[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1556468593",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1556468593",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1556468593,
        "node_id": "IC_kwDOCVq1mM5cxdNx",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-22T03:30:30Z",
        "updated_at": "2023-05-22T03:30:30Z",
        "author_association": "MEMBER",
        "body": "We have looked at adding this support but haven't had the resources available to do so. Do you have a production scenario you require this for? \r\n\r\nWhilst the base64 encode/decode overhead isn't great, typically model execution is the largest cost for a production model. \r\n\r\nI'm struggling to understand how base64 encode/decode could add up to multiple seconds in the comment you linked though. The buffer size can be pre-calculated, and it's a single iteration of the data to encode/decode. Reasonably trivial stuff. We don't do much when decoding either - convert from base64 using [buffer](https://github.com/feross/buffer#convert-arraybuffer-to-buffer) and put in a typed array. \r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/4dc4470cc7e178d9a8a134e6617e09394ce41d5a/js/react_native/lib/backend.ts#L149-L151",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1556468593/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1556527812",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1556527812",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1556527812,
        "node_id": "IC_kwDOCVq1mM5cxrrE",
        "user": {
            "login": "jhen0409",
            "id": 3001525,
            "node_id": "MDQ6VXNlcjMwMDE1MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3001525?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jhen0409",
            "html_url": "https://github.com/jhen0409",
            "followers_url": "https://api.github.com/users/jhen0409/followers",
            "following_url": "https://api.github.com/users/jhen0409/following{/other_user}",
            "gists_url": "https://api.github.com/users/jhen0409/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jhen0409/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jhen0409/subscriptions",
            "organizations_url": "https://api.github.com/users/jhen0409/orgs",
            "repos_url": "https://api.github.com/users/jhen0409/repos",
            "events_url": "https://api.github.com/users/jhen0409/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jhen0409/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-22T04:56:20Z",
        "updated_at": "2023-05-22T04:56:20Z",
        "author_association": "CONTRIBUTOR",
        "body": "In [the case](https://github.com/xenova/transformers.js/pull/118#issuecomment-1555426456) the model run just take ~500ms for each decode session run, but every decode run in JS (decodeReturnType) take ~3.7s with ~5250000 size buffer.\r\n\r\nI've plan to use onnxruntime for production in the second half of the year, this may be the current challenge. Will be great if we have resources/maintenance here.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1556527812/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1562425270",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1562425270",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1562425270,
        "node_id": "IC_kwDOCVq1mM5dILe2",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-25T07:37:40Z",
        "updated_at": "2023-05-25T07:37:40Z",
        "author_association": "MEMBER",
        "body": "We'll see if we can get it done in the next release. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1562425270/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575754617",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1575754617",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1575754617,
        "node_id": "IC_kwDOCVq1mM5d7Bt5",
        "user": {
            "login": "jhen0409",
            "id": 3001525,
            "node_id": "MDQ6VXNlcjMwMDE1MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3001525?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jhen0409",
            "html_url": "https://github.com/jhen0409",
            "followers_url": "https://api.github.com/users/jhen0409/followers",
            "following_url": "https://api.github.com/users/jhen0409/following{/other_user}",
            "gists_url": "https://api.github.com/users/jhen0409/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jhen0409/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jhen0409/subscriptions",
            "organizations_url": "https://api.github.com/users/jhen0409/orgs",
            "repos_url": "https://api.github.com/users/jhen0409/repos",
            "events_url": "https://api.github.com/users/jhen0409/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jhen0409/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-04T22:18:46Z",
        "updated_at": "2023-06-04T22:26:41Z",
        "author_association": "CONTRIBUTOR",
        "body": "For #16094 I've been testing for a while, and there are a few things I see that aren't perfect:\r\n\r\n- Delay on session run with native bridge\r\n  - Android: 20 ~ 30ms on Hermes / more on JSC (I reported a related issue [here](https://github.com/Kudo/react-native-v8/issues/179), although it only for V8 but JSC have the same issue)\r\n  - iOS: 3 ~ 4ms\r\n- resolveArrayBuffer\r\n  - Android: 1 ~ 5 ms\r\n  - iOS: 0.x ~ 1.x ms\r\n\r\nFor a task that requires multiple session runs (like whisper), such a delay may very large, it may take a few seconds. The best way still a full JSI migration, but currently the performance of PR #16094 is acceptable for me.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1575754617/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1581592628",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1581592628",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1581592628,
        "node_id": "IC_kwDOCVq1mM5eRTA0",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-07T22:23:46Z",
        "updated_at": "2023-06-07T22:23:46Z",
        "author_association": "MEMBER",
        "body": "Can you expand on what 'full JSI migration' would equate to? \r\n\r\nI have a very limited knowledge of JSI so I'm not sure what the cost/benefit of that would be. My understanding was the main reason for using JSI with ORT would be to avoid the base64 encode/decode when running the model (given that's typically the performance sensitive operation), and your much appreciated PR seems to cover that.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1581592628/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582101444",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1582101444",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1582101444,
        "node_id": "IC_kwDOCVq1mM5eTPPE",
        "user": {
            "login": "jhen0409",
            "id": 3001525,
            "node_id": "MDQ6VXNlcjMwMDE1MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3001525?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jhen0409",
            "html_url": "https://github.com/jhen0409",
            "followers_url": "https://api.github.com/users/jhen0409/followers",
            "following_url": "https://api.github.com/users/jhen0409/following{/other_user}",
            "gists_url": "https://api.github.com/users/jhen0409/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jhen0409/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jhen0409/subscriptions",
            "organizations_url": "https://api.github.com/users/jhen0409/orgs",
            "repos_url": "https://api.github.com/users/jhen0409/repos",
            "events_url": "https://api.github.com/users/jhen0409/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jhen0409/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-08T08:07:43Z",
        "updated_at": "2023-06-08T08:07:43Z",
        "author_association": "CONTRIBUTOR",
        "body": "The full JSI migration will need some refactor in my imagination, to rewrite `run` JSI function with C++ for `load` & `run` and consider threading (avoid blocking JS thread) & type convertation for tensor helper.\r\n\r\n- For iOS, it maybe easy because Objective C++\r\n- For Android, options:\r\n  1. Access existing Java native module though JNI, but it’s not clean and may a little bit slow\r\n  2. Recompile onnxruntime-c to use the API directly in C++, I like it but seems to be some other work to do\r\n\r\nIt may basically solve the delay of native bridge, especially the Android platform.\r\n\r\nThe base64 encode/decode is my main concern, the full implementation of JSI may not be urgent.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1582101444/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1583556928",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1583556928",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1583556928,
        "node_id": "IC_kwDOCVq1mM5eYylA",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-08T22:51:01Z",
        "updated_at": "2023-06-08T22:51:01Z",
        "author_association": "MEMBER",
        "body": "Thanks for the info. Is the native bridge delay on every `run` call or just the first? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1583556928/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1583857324",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16031#issuecomment-1583857324",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16031",
        "id": 1583857324,
        "node_id": "IC_kwDOCVq1mM5eZ76s",
        "user": {
            "login": "jhen0409",
            "id": 3001525,
            "node_id": "MDQ6VXNlcjMwMDE1MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3001525?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jhen0409",
            "html_url": "https://github.com/jhen0409",
            "followers_url": "https://api.github.com/users/jhen0409/followers",
            "following_url": "https://api.github.com/users/jhen0409/following{/other_user}",
            "gists_url": "https://api.github.com/users/jhen0409/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jhen0409/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jhen0409/subscriptions",
            "organizations_url": "https://api.github.com/users/jhen0409/orgs",
            "repos_url": "https://api.github.com/users/jhen0409/repos",
            "events_url": "https://api.github.com/users/jhen0409/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jhen0409/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-09T02:34:26Z",
        "updated_at": "2023-06-09T02:34:26Z",
        "author_association": "CONTRIBUTOR",
        "body": "> Thanks for the info. Is the native bridge delay on every `run` call or just the first?\r\n\r\nThis is result (use ASR task of [this example](https://github.com/hans00/react-native-transformers-example/tree/main), and patched https://github.com/microsoft/onnxruntime/pull/16094) to running whisper-tiny.en for a demo audio file\r\n\r\n- Monitor `inferenceSession.run` by `performance.now`\r\n- Monitor `run` native method by `System.currentTimeMillis`\r\n- Get the diff time\r\n\r\n<details>\r\n\r\nPlatform: Android\r\nDevice: Pixel 6\r\nReact Native version: 0.71\r\nJS engine: Hermes\r\n\r\n```logs\r\nFull infer time: 378.95 ms, native infer: 378 ms, diff: 0.95 ms\r\nFull infer time: 371.03 ms, native infer: 364 ms, diff: 7.03 ms\r\nFull infer time: 626.60 ms, native infer: 620 ms, diff: 6.60 ms\r\nFull infer time: 640.24 ms, native infer: 632 ms, diff: 8.24 ms\r\nFull infer time: 628.04 ms, native infer: 622 ms, diff: 6.04 ms\r\nFull infer time: 618.83 ms, native infer: 611 ms, diff: 7.83 ms\r\nFull infer time: 626.14 ms, native infer: 620 ms, diff: 6.14 ms\r\nFull infer time: 615.17 ms, native infer: 609 ms, diff: 6.17 ms\r\nFull infer time: 633.09 ms, native infer: 627 ms, diff: 6.09 ms\r\nFull infer time: 630.86 ms, native infer: 625 ms, diff: 5.86 ms\r\nFull infer time: 616.15 ms, native infer: 610 ms, diff: 6.15 ms\r\nFull infer time: 617.30 ms, native infer: 611 ms, diff: 6.30 ms\r\nFull infer time: 636.89 ms, native infer: 625 ms, diff: 11.89 ms\r\nFull infer time: 630.92 ms, native infer: 619 ms, diff: 11.92 ms\r\nFull infer time: 676.55 ms, native infer: 634 ms, diff: 42.55 ms\r\nFull infer time: 647.41 ms, native infer: 637 ms, diff: 10.41 ms\r\nFull infer time: 628.70 ms, native infer: 618 ms, diff: 10.70 ms\r\nFull infer time: 695.45 ms, native infer: 633 ms, diff: 62.45 ms\r\nFull infer time: 644.94 ms, native infer: 633 ms, diff: 11.94 ms\r\nFull infer time: 621.50 ms, native infer: 610 ms, diff: 11.50 ms\r\nFull infer time: 654.28 ms, native infer: 643 ms, diff: 11.28 ms\r\nFull infer time: 650.18 ms, native infer: 639 ms, diff: 11.18 ms\r\nFull infer time: 630.11 ms, native infer: 624 ms, diff: 6.11 ms\r\nFull infer time: 636.94 ms, native infer: 630 ms, diff: 6.94 ms\r\nFull infer time: 648.47 ms, native infer: 641 ms, diff: 7.47 ms\r\nFull infer time: 651.05 ms, native infer: 645 ms, diff: 6.05 ms\r\nFull infer time: 648.11 ms, native infer: 641 ms, diff: 7.11 ms\r\n```\r\n</details>\r\n\r\nNot sure if it might caused by some scheduling issue, so it could have a delay up to 60 ms.\r\n\r\nThe difference may be less noticeable by use [MNIST in the e2e project](https://github.com/microsoft/onnxruntime/tree/main/js/react_native/e2e).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1583857324/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]