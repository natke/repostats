[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10151",
        "id": 1090840434,
        "node_id": "I_kwDOCVq1mM5BBOdy",
        "number": 10151,
        "title": "FusedMatMul kernel does not support the double data type",
        "user": {
            "login": "wjj19950828",
            "id": 19977378,
            "node_id": "MDQ6VXNlcjE5OTc3Mzc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19977378?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wjj19950828",
            "html_url": "https://github.com/wjj19950828",
            "followers_url": "https://api.github.com/users/wjj19950828/followers",
            "following_url": "https://api.github.com/users/wjj19950828/following{/other_user}",
            "gists_url": "https://api.github.com/users/wjj19950828/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wjj19950828/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wjj19950828/subscriptions",
            "organizations_url": "https://api.github.com/users/wjj19950828/orgs",
            "repos_url": "https://api.github.com/users/wjj19950828/repos",
            "events_url": "https://api.github.com/users/wjj19950828/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wjj19950828/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:enhancement",
                "name": "type:enhancement",
                "color": "a2eeef",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-30T02:42:00Z",
        "updated_at": "2022-01-04T00:56:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen I run Transpose+MatMul, the following error will be reported\r\n![e2a886271cea1a51136c4fc513864e1f](https://user-images.githubusercontent.com/19977378/147716898-cd22f5c0-bfe8-43c8-8688-9d1bb6132333.png)\r\nIt seems that when onnxruntime encounters this situation, the [FusedMatMul kernel](https://github.com/microsoft/onnxruntime/blob/ceb17f82ffc9f72acb64f28629d7db93d98e5ba9/onnxruntime/core/optimizer/matmul_transpose_fusion.cc#L200) will be used, but the double type is not supported.\r\n\r\nIs this a known issue? When will it be scheduled for support?\r\n\r\n**Urgency**\r\nNow use cast op temporarily, switch to float type to execute\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- ONNX Runtime installed from (source or binary):pip install \r\n- ONNX Runtime version:1.10.0\r\n- Python version:3.6\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.2\r\n- GPU model and memory:16G",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10151/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10150",
        "id": 1090796760,
        "node_id": "PR_kwDOCVq1mM4wYcyo",
        "number": 10150,
        "title": "moving from torch nightly build to stable build",
        "user": {
            "login": "ajindal1",
            "id": 32752809,
            "node_id": "MDQ6VXNlcjMyNzUyODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/32752809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajindal1",
            "html_url": "https://github.com/ajindal1",
            "followers_url": "https://api.github.com/users/ajindal1/followers",
            "following_url": "https://api.github.com/users/ajindal1/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajindal1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajindal1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajindal1/subscriptions",
            "organizations_url": "https://api.github.com/users/ajindal1/orgs",
            "repos_url": "https://api.github.com/users/ajindal1/repos",
            "events_url": "https://api.github.com/users/ajindal1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajindal1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-29T23:36:58Z",
        "updated_at": "2021-12-30T03:35:11Z",
        "closed_at": "2021-12-30T03:35:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10150",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10150",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10150.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10150.patch",
            "merged_at": "2021-12-30T03:35:10Z"
        },
        "body": "**Description**: Describe your changes.\r\nRemoving the torch nightly build and moving to a stable build for pytorch\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10150/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10149",
        "id": 1090715047,
        "node_id": "PR_kwDOCVq1mM4wYMId",
        "number": 10149,
        "title": "Update EP Perf Pipeline",
        "user": {
            "login": "oliviajain",
            "id": 25233514,
            "node_id": "MDQ6VXNlcjI1MjMzNTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/25233514?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/oliviajain",
            "html_url": "https://github.com/oliviajain",
            "followers_url": "https://api.github.com/users/oliviajain/followers",
            "following_url": "https://api.github.com/users/oliviajain/following{/other_user}",
            "gists_url": "https://api.github.com/users/oliviajain/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/oliviajain/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/oliviajain/subscriptions",
            "organizations_url": "https://api.github.com/users/oliviajain/orgs",
            "repos_url": "https://api.github.com/users/oliviajain/repos",
            "events_url": "https://api.github.com/users/oliviajain/events{/privacy}",
            "received_events_url": "https://api.github.com/users/oliviajain/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-29T19:41:22Z",
        "updated_at": "2022-01-12T00:12:34Z",
        "closed_at": "2022-01-12T00:12:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10149",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10149",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10149.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10149.patch",
            "merged_at": "2022-01-12T00:12:33Z"
        },
        "body": "**Description**: \r\n\r\n- Migrate to 1ES Hosted Pool.\r\n- Migrate to Kusto database.\r\n- Refactor and organize ep names with ORT prefix.\r\n- Standardize TRT benchmarking with save/load engine, input binding, and workspace. \r\n- Add TRT 8.2 to ep perf pipeline.\r\n- Update model_list.json with full list onnx zoo models.\r\n- Update Anubis to 8.2 and add credentials. \r\n\r\n**Motivation and Context**\r\n- Forced to migrate to 1ES Hosted Pool. \r\n- Improving reliability of results.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10149/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10148",
        "id": 1090491562,
        "node_id": "I_kwDOCVq1mM5A_5Sq",
        "number": 10148,
        "title": "Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.",
        "user": {
            "login": "joao-alves97",
            "id": 80961411,
            "node_id": "MDQ6VXNlcjgwOTYxNDEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/80961411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/joao-alves97",
            "html_url": "https://github.com/joao-alves97",
            "followers_url": "https://api.github.com/users/joao-alves97/followers",
            "following_url": "https://api.github.com/users/joao-alves97/following{/other_user}",
            "gists_url": "https://api.github.com/users/joao-alves97/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/joao-alves97/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/joao-alves97/subscriptions",
            "organizations_url": "https://api.github.com/users/joao-alves97/orgs",
            "repos_url": "https://api.github.com/users/joao-alves97/repos",
            "events_url": "https://api.github.com/users/joao-alves97/events{/privacy}",
            "received_events_url": "https://api.github.com/users/joao-alves97/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-29T12:35:11Z",
        "updated_at": "2021-12-30T18:42:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I tried to replicate fastT5 for a different transformers model (EncoderDecoderModel) but I'm always facing this error:\r\n\r\n`onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running MatMul node. Name:'MatMul_155' Status Message: /onnxruntime_src/onnxruntime/core/framework/op_kernel.cc:44 OrtValue* onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape&, size_t) status.IsOK() was false. Shape mismatch attempting to re-use buffer. {1,1,768} != {1,133,768}. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.`\r\n\r\n**environment:**\r\nhuggingface-hub 0.0.8\r\nimportlib-metadata 4.10.0\r\nnumpy 1.21.5\r\nonnx 1.10.2\r\nonnxruntime 1.4.0\r\npackaging 21.3\r\npip 19.2.3\r\nprogress 1.6\r\nprotobuf 3.19.1\r\npsutil 5.8.0\r\npyparsing 3.0.6\r\nregex 2021.11.10\r\nrequests 2.26.0\r\nsacremoses 0.0.46\r\nsentencepiece 0.1.96\r\nsetuptools 41.2.0\r\nsix 1.16.0\r\ntokenizers 0.10.3\r\ntorch 1.10.1\r\ntqdm 4.62.3\r\ntransformers 4.4.2\r\n\r\nAnyone having a similar error? Any idea on how to solve it?\r\nThanks",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10148/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10147",
        "id": 1090402196,
        "node_id": "I_kwDOCVq1mM5A_jeU",
        "number": 10147,
        "title": "Using ORT in a custom class: the program unexpectedly finished using CUDA execution provider.",
        "user": {
            "login": "giaxxi",
            "id": 4654167,
            "node_id": "MDQ6VXNlcjQ2NTQxNjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4654167?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/giaxxi",
            "html_url": "https://github.com/giaxxi",
            "followers_url": "https://api.github.com/users/giaxxi/followers",
            "following_url": "https://api.github.com/users/giaxxi/following{/other_user}",
            "gists_url": "https://api.github.com/users/giaxxi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/giaxxi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/giaxxi/subscriptions",
            "organizations_url": "https://api.github.com/users/giaxxi/orgs",
            "repos_url": "https://api.github.com/users/giaxxi/repos",
            "events_url": "https://api.github.com/users/giaxxi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/giaxxi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-29T09:55:08Z",
        "updated_at": "2021-12-29T11:44:30Z",
        "closed_at": "2021-12-29T11:44:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI'm using ONNX Runtime in a custom class, following the issue https://github.com/microsoft/onnxruntime/issues/4131 I was able to make it work when the execution provider is CPU, **but fails using CUDA**.\r\n\r\n**I can run properly the program using CUDA as execution provider with no crashes when I'm not using it inside my custom class** (so, without using pointers for session and env)\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 11 Pro - 10.0.22000 Build 22000:\r\n- ONNX Runtime installed from [github.com/microsoft/onnxruntime/releases/tag/v1.9.0](https://github.com/microsoft/onnxruntime/releases/tag/v1.9.0):\r\n- ONNX Runtime version: 1.9.0\r\n- Visual Studio version (if applicable): using Qt, **Desktop_Qt_6_2_0_MSVC2019_64bit**\r\n- Program compiled with: Microsoft Visual C++ Compiler 16.10.31515.178 (amd64)\r\n- CUDA/cuDNN version:\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Sun_Aug_15_21:18:57_Pacific_Daylight_Time_2021\r\nCuda compilation tools, release 11.4, V11.4.120\r\nBuild cuda_11.4.r11.4/compiler.30300941_0\r\n```\r\n- GPU model and memory: Quadro T2000\r\n\r\n**To Reproduce**\r\nThis is what I have in the class header:\r\n```\r\n    //    https://github.com/microsoft/onnxruntime/issues/4131\r\n    std::unique_ptr<Ort::Session> session = nullptr;\r\n    std::unique_ptr<Ort::Env> env = nullptr;\r\n```\r\n\r\nAnd this is the implementation:\r\n```\r\n    Ort::SessionOptions session_options;\r\n    OrtCUDAProviderOptions cuda_options;\r\n    cuda_options.device_id = 0;\r\n    session_options.AppendExecutionProvider_CUDA(cuda_options);\r\n    session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_EXTENDED );\r\n\r\n    auto env_local = std::make_unique<Ort::Env>(ORT_LOGGING_LEVEL_WARNING, \"test\");\r\n    env = std::move(env_local);\r\n    auto session_local = std::make_unique<Ort::Session>(*env, model_filename, session_options);\r\n    session = move(session_local);\r\n```\r\n\r\nRunning the inference in this way:\r\n```\r\n    std::cout << \"Starting inference!\" << std::endl;\r\n    session->Run(Ort::RunOptions{ nullptr },\r\n                input_names.data(),  input_tensors.data(),  input_tensors.size(),\r\n                output_names.data(), output_tensors.data(), output_tensors.size());\r\n    std::cout << \"End inference!\" << std::endl;\r\n```\r\n\r\nWhen I run the inference with CUDA, the program outputs \"End inference!\" then hangs and is terminated (The process was ended forcefully.)\r\nI'm able to call `n` times in sequence the funcion that runs the inference and it outputs properly \"End inference!\" `n` times, but finally crashes in the same way.\r\n\r\nFor example:\r\n```\r\n    std::cout << \"first time\" << std::endl;\r\n    onnx_inference.RunTheInference(blob);\r\n    std::cout << \"second time\" << std::endl;\r\n    onnx_inference.RunTheInference(blob);\r\n    std::cout << \"third time\" << std::endl;\r\n    onnx_inference.RunTheInference(blob);\r\n```\r\n\r\nI'm also able to show the result of the inference using openCV GUI, but finally the program crashes with this message:\r\n\r\n> `[process exited with code 3221225477 (0xc0000005)]`\r\n\r\n\r\n**Expected behavior**\r\nThe program should `terminate with code 0`.\r\n\r\nThe program works fine commenting out this line:\r\n`session_options.AppendExecutionProvider_CUDA(cuda_options);`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10147/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10146",
        "id": 1090291625,
        "node_id": "I_kwDOCVq1mM5A_Iep",
        "number": 10146,
        "title": "current version seem can not run at net6.0-android",
        "user": {
            "login": "zhangzifang1",
            "id": 50613176,
            "node_id": "MDQ6VXNlcjUwNjEzMTc2",
            "avatar_url": "https://avatars.githubusercontent.com/u/50613176?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhangzifang1",
            "html_url": "https://github.com/zhangzifang1",
            "followers_url": "https://api.github.com/users/zhangzifang1/followers",
            "following_url": "https://api.github.com/users/zhangzifang1/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhangzifang1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhangzifang1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhangzifang1/subscriptions",
            "organizations_url": "https://api.github.com/users/zhangzifang1/orgs",
            "repos_url": "https://api.github.com/users/zhangzifang1/repos",
            "events_url": "https://api.github.com/users/zhangzifang1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhangzifang1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2314849695,
                "node_id": "MDU6TGFiZWwyMzE0ODQ5Njk1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:android",
                "name": "platform:android",
                "color": "d4ea72",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "skottmckay",
                "id": 979079,
                "node_id": "MDQ6VXNlcjk3OTA3OQ==",
                "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/skottmckay",
                "html_url": "https://github.com/skottmckay",
                "followers_url": "https://api.github.com/users/skottmckay/followers",
                "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
                "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
                "organizations_url": "https://api.github.com/users/skottmckay/orgs",
                "repos_url": "https://api.github.com/users/skottmckay/repos",
                "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
                "received_events_url": "https://api.github.com/users/skottmckay/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-29T06:07:10Z",
        "updated_at": "2021-12-30T06:59:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "current version seem can not run at net6.0-android, does any plan to add module for the platform?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10146/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10145",
        "id": 1090248829,
        "node_id": "I_kwDOCVq1mM5A--B9",
        "number": 10145,
        "title": "ONNXRTv1.10 Model Format v8, works on python and crash on C++ run. ",
        "user": {
            "login": "ibrahimsoliman97",
            "id": 30038478,
            "node_id": "MDQ6VXNlcjMwMDM4NDc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/30038478?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ibrahimsoliman97",
            "html_url": "https://github.com/ibrahimsoliman97",
            "followers_url": "https://api.github.com/users/ibrahimsoliman97/followers",
            "following_url": "https://api.github.com/users/ibrahimsoliman97/following{/other_user}",
            "gists_url": "https://api.github.com/users/ibrahimsoliman97/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ibrahimsoliman97/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ibrahimsoliman97/subscriptions",
            "organizations_url": "https://api.github.com/users/ibrahimsoliman97/orgs",
            "repos_url": "https://api.github.com/users/ibrahimsoliman97/repos",
            "events_url": "https://api.github.com/users/ibrahimsoliman97/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ibrahimsoliman97/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1395147764,
                "node_id": "MDU6TGFiZWwxMzk1MTQ3NzY0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:CC++",
                "name": "api:CC++",
                "color": "0e8a16",
                "default": false,
                "description": "related to the  public API(and ABI) for onnxruntime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-29T03:44:33Z",
        "updated_at": "2021-12-31T03:24:05Z",
        "closed_at": "2021-12-31T03:24:05Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI am using a ONNX Model with v8 format, it works using python, but it crash on Run() for C++ without showing any error message. I am using the latest ONNXRuntime v.1.10.0. I have attached the model for your reference. \r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable): 2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- [code.txt](https://github.com/microsoft/onnxruntime/files/7787198/code.txt)\r\n- [model](https://drive.google.com/file/d/149KO9WjhrkCnGYb9ag6C_8Jv7KD_vJSx/view?usp=sharing)\r\n- [Session VERBOSE log running ONNXRuntime](https://github.com/microsoft/onnxruntime/files/7787205/logs.txt)\r\n\r\n\r\n\r\n**Expected behavior**\r\nModel should work and run smoothly on C++ as well / **Show error message about the problem**.\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/30038478/147624636-86656905-d6ae-423b-8675-fbe7eddb1509.png)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10145/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10144",
        "id": 1090215823,
        "node_id": "I_kwDOCVq1mM5A-1-P",
        "number": 10144,
        "title": "Bug ld: error: undefined symbol: pthread_cancel  for android runtime AAR build",
        "user": {
            "login": "shichaog",
            "id": 7869827,
            "node_id": "MDQ6VXNlcjc4Njk4Mjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7869827?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shichaog",
            "html_url": "https://github.com/shichaog",
            "followers_url": "https://api.github.com/users/shichaog/followers",
            "following_url": "https://api.github.com/users/shichaog/following{/other_user}",
            "gists_url": "https://api.github.com/users/shichaog/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shichaog/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shichaog/subscriptions",
            "organizations_url": "https://api.github.com/users/shichaog/orgs",
            "repos_url": "https://api.github.com/users/shichaog/repos",
            "events_url": "https://api.github.com/users/shichaog/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shichaog/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            },
            {
                "id": 2314849695,
                "node_id": "MDU6TGFiZWwyMzE0ODQ5Njk1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:android",
                "name": "platform:android",
                "color": "d4ea72",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-29T01:44:14Z",
        "updated_at": "2021-12-30T06:40:05Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nBuild onnxruntime package for Android AAR\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from source\r\n- ONNX Runtime version: master branch\r\n- Python version:\r\nPython 3.9.9 (v3.9.9:ccb0e6a345)\r\n[Clang 6.0 (clang-600.0.57)] on darwin\r\n\r\n**To Reproduce**\r\n./build.sh --android --use_nnapi --build_java --android_sdk_path Android/sdk --android_ndk_path Android/sdk/ndk/23.1.7779620/ --android_abi arm64-v8a --android_api 27 --parallel\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/7869827/147619548-fcca4d3c-18d4-4e5a-ba53-7e5be204c964.png)\r\n![image](https://user-images.githubusercontent.com/7869827/147619581-ce6e0bdf-88fd-4d34-ab9a-a20e9f876eb6.png)\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10144/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10143",
        "id": 1089898129,
        "node_id": "I_kwDOCVq1mM5A9oaR",
        "number": 10143,
        "title": "test_qresize",
        "user": {
            "login": "www516717402",
            "id": 30460509,
            "node_id": "MDQ6VXNlcjMwNDYwNTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30460509?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/www516717402",
            "html_url": "https://github.com/www516717402",
            "followers_url": "https://api.github.com/users/www516717402/followers",
            "following_url": "https://api.github.com/users/www516717402/following{/other_user}",
            "gists_url": "https://api.github.com/users/www516717402/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/www516717402/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/www516717402/subscriptions",
            "organizations_url": "https://api.github.com/users/www516717402/orgs",
            "repos_url": "https://api.github.com/users/www516717402/repos",
            "events_url": "https://api.github.com/users/www516717402/events{/privacy}",
            "received_events_url": "https://api.github.com/users/www516717402/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-28T13:30:09Z",
        "updated_at": "2022-01-05T02:01:16Z",
        "closed_at": "2022-01-05T02:01:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "How to make node and graph for QResize OP like QLinearConv as [follows](https://github.com/onnx/onnx/blob/65974860e20b311d14b642ce22b5a56b8c176ca5/onnx/test/shape_inference_test.py?_pjax=%23js-repo-pjax-container%2C%20div%5Bitemtype%3D%22http%3A%2F%2Fschema.org%2FSoftwareSourceCode%22%5D%20main%2C%20%5Bdata-pjax-container%5D#L2322-L2334):\r\n``` python\r\ndef test_qlinearconv(self):  # type: () -> None\r\n        graph = self._make_graph(\r\n            [('x', TensorProto.UINT8, (3, 4, 5, 6, 7)),\r\n             ('x_scale', TensorProto.FLOAT, ()),\r\n             ('x_zero_point', TensorProto.UINT8, ()),\r\n             ('w', TensorProto.UINT8, (5, 4, 2, 4, 3)),\r\n             ('w_scale', TensorProto.FLOAT, ()),\r\n             ('w_zero_point', TensorProto.UINT8, ()),\r\n             ('y_scale', TensorProto.FLOAT, ()),\r\n             ('y_zero_point', TensorProto.UINT8, ())],\r\n            [make_node('QLinearConv', ['x', 'x_scale', 'x_zero_point', 'w', 'w_scale', 'w_zero_point', 'y_scale', 'y_zero_point'], 'y', pads=[0, 1, 1, 0, 0, 1], dilations=[1, 2, 2], strides=[1, 1, 2])],\r\n            [])\r\n        self._assert_inferred(graph, [make_tensor_value_info('y', TensorProto.UINT8, (3, 5, 4, 1, 3))])\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10143/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10142",
        "id": 1089788173,
        "node_id": "I_kwDOCVq1mM5A9NkN",
        "number": 10142,
        "title": "No Performance Benefit from OnnxRuntime.GPU in .NET",
        "user": {
            "login": "noumanqaiser",
            "id": 5542052,
            "node_id": "MDQ6VXNlcjU1NDIwNTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5542052?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noumanqaiser",
            "html_url": "https://github.com/noumanqaiser",
            "followers_url": "https://api.github.com/users/noumanqaiser/followers",
            "following_url": "https://api.github.com/users/noumanqaiser/following{/other_user}",
            "gists_url": "https://api.github.com/users/noumanqaiser/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noumanqaiser/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noumanqaiser/subscriptions",
            "organizations_url": "https://api.github.com/users/noumanqaiser/orgs",
            "repos_url": "https://api.github.com/users/noumanqaiser/repos",
            "events_url": "https://api.github.com/users/noumanqaiser/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noumanqaiser/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1758308176,
                "node_id": "MDU6TGFiZWwxNzU4MzA4MTc2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:CSharp",
                "name": "api:CSharp",
                "color": "0e8a16",
                "default": false,
                "description": "related to the C# API"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "michaelgsharp",
            "id": 51342856,
            "node_id": "MDQ6VXNlcjUxMzQyODU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/51342856?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/michaelgsharp",
            "html_url": "https://github.com/michaelgsharp",
            "followers_url": "https://api.github.com/users/michaelgsharp/followers",
            "following_url": "https://api.github.com/users/michaelgsharp/following{/other_user}",
            "gists_url": "https://api.github.com/users/michaelgsharp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/michaelgsharp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/michaelgsharp/subscriptions",
            "organizations_url": "https://api.github.com/users/michaelgsharp/orgs",
            "repos_url": "https://api.github.com/users/michaelgsharp/repos",
            "events_url": "https://api.github.com/users/michaelgsharp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/michaelgsharp/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "michaelgsharp",
                "id": 51342856,
                "node_id": "MDQ6VXNlcjUxMzQyODU2",
                "avatar_url": "https://avatars.githubusercontent.com/u/51342856?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/michaelgsharp",
                "html_url": "https://github.com/michaelgsharp",
                "followers_url": "https://api.github.com/users/michaelgsharp/followers",
                "following_url": "https://api.github.com/users/michaelgsharp/following{/other_user}",
                "gists_url": "https://api.github.com/users/michaelgsharp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/michaelgsharp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/michaelgsharp/subscriptions",
                "organizations_url": "https://api.github.com/users/michaelgsharp/orgs",
                "repos_url": "https://api.github.com/users/michaelgsharp/repos",
                "events_url": "https://api.github.com/users/michaelgsharp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/michaelgsharp/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 17,
        "created_at": "2021-12-28T10:46:28Z",
        "updated_at": "2022-02-05T13:45:57Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have an Image classification model that was trained using Microsoft CustomVision and exported as an ONNX model. I am able to run inferencing using this model with an average inference time of around 45ms. My computer is equipped with an NVIDIA GPU and I have been trying to reduce the inference time. \r\n\r\nMy application is a .NET console application written in C#. \r\n\r\nI tried utilizing the OnnxRuntime.GPU nuget package version 1.10 and followed in steps given on the link below to install the relevant CUDA Toolkit and Cudnn packages. (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements). Despite this, I have not seem any performance improvement when using OnnxRuntime or OnnxRuntime.GPU. The average inference time is similar and varies between 45 to 60ms.\r\n\r\n**Urgency**\r\nI have been trying various options to improve inference performance but none of them seem to be working. Urgent support would be appreciated.\r\n\r\n**System information**\r\nWindows 10 Home 21H1, Dell Inspiron 5406, Core i7 1165G7, 16GB RAM with Nvidia MX330 2GB GPU\r\nONNX Runtime installed from Nuget\r\nONNX Runtime version: 1.10.0\r\nProgram is written in C#, .NET 5, Console App\r\nVisual Studio 2019 v16.10.3\r\nCUDA/CudNN version: CUDA Tooklit 11.4.3 , CudNN 8.2.2.26 for Cuda 11.4\r\nGPU model and memory: Nvidia MX330 with 2GB Memory\r\n\r\n\r\n**To Reproduce**\r\nI use the following class to initiate an ONNX Scoring class:\r\n`public class OnnxModelScorer\r\n{\r\n\r\n    public class ImageInputData\r\n    {\r\n        [ImageType(300, 300)]\r\n        public Bitmap Image { get; set; }\r\n    }\r\n\r\n    public class ImagePrediction\r\n    {\r\n            \r\n        [ColumnName(\"model_output\")]\r\n        public float[] PredictedLabels;\r\n    }\r\n\r\n    PredictionEngine<ImageInputData, ImagePrediction> predictionEngine;\r\n    ModelMetadataPropertiesClass modelprops;\r\n    Dictionary<int, string> ModelLabels = new Dictionary<int, string>();\r\n\r\n    public void SetupPredictionEngine(string modelFolderPath, out string errors)\r\n    {\r\n        errors = \"\";\r\n        predictionEngine = null;\r\n        try\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n            modelprops = LoadProperties(modelFolderPath + \"metadata_properties.json\", out string error);\r\n\r\n            var pipeline = mlContext.Transforms\r\n                            .ResizeImages(\"image\", modelprops.CustomVisionPreprocessTargetWidth, modelprops.CustomVisionPreprocessTargetHeight, nameof(ImageInputData.Image), ImageResizingEstimator.ResizingKind.Fill)\r\n                            .Append(mlContext.Transforms.ExtractPixels(\"data\", \"image\"))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(\"model_output\", \"data\", modelFolderPath + @\"model.onnx\"));\r\n\r\n            var data = mlContext.Data.LoadFromEnumerable(new List<ImageInputData>());\r\n            var model = pipeline.Fit(data);\r\n\r\n            predictionEngine = mlContext.Model.CreatePredictionEngine<ImageInputData, ImagePrediction>(model);\r\n\r\n            string[] labels = File.ReadAllText(modelFolderPath + @\"labels.txt\").Split('\\n');\r\n\r\n            int i = 0;\r\n            foreach (var label in labels)\r\n            {\r\n                ModelLabels.Add(i, label);\r\n                i++;\r\n            }\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            errors = \"Model Loading Failed: \" + ex.ToString();\r\n        }\r\n            \r\n    }\r\n\r\n    public PredictionResultClass GetModelPrediction(Bitmap sample, out string error)\r\n    {\r\n        PredictionResultClass pr = new PredictionResultClass();\r\n        error = \"\";\r\n        if (predictionEngine != null)\r\n        {\r\n            var input = new ImageInputData { Image = sample };\r\n\r\n            var prediction = predictionEngine.Predict(input);\r\n            Dictionary<int, PredictionResultClass> predictionResults = new Dictionary<int, PredictionResultClass>();\r\n            int indexofMaxProb = -1;\r\n            float maxProbability = 0;\r\n            for (int i = 0; i < prediction.PredictedLabels.Count(); i++)\r\n            {\r\n                predictionResults.Add(i,new PredictionResultClass() { Label = ModelLabels[i], probability = prediction.PredictedLabels[i] });\r\n\r\n                if(prediction.PredictedLabels[i]>maxProbability)\r\n                {\r\n                    maxProbability = prediction.PredictedLabels[i];\r\n                    indexofMaxProb = i;\r\n                }\r\n            }\r\n\r\n            pr = predictionResults[indexofMaxProb];\r\n\r\n        }\r\n        else error = \"Prediction Engine Not initialized\";\r\n\r\n        return pr;\r\n    }\r\n    public class PredictionResultClass\r\n    {\r\n        public string Label = \"\";\r\n        public float probability = 0;\r\n    }\r\n\r\n    public void ModelMassTest(string samplesfolder)\r\n    {\r\n            \r\n        string[] inputfiles = Directory.GetFiles(samplesfolder);\r\n        List<double> analysistimes = new List<double>();\r\n        foreach (var fl in inputfiles)\r\n        {\r\n\r\n            //Emgu.CV.Image<Emgu.CV.Structure.Bgr, byte> Img = new Emgu.CV.Image<Emgu.CV.Structure.Bgr, byte>(fl);\r\n            // Img.ROI = JsonConvert.DeserializeObject<Rectangle>(\"\\\"450, 288, 420, 1478\\\"\");\r\n            // string savePath = @\"C:\\ImageMLProjects\\Tresseme200Ml Soiling Experiment\\Tresseme200MlImages\\ROIApplied\\Bad\\\" + Path.GetFileName(fl);\r\n            // Img.Save(savePath);\r\n\r\n            //Bitmap bitmap = Emgu.CV.BitmapExtension.ToBitmap(Img); // your source of a bitmap\r\n            Bitmap bitmap = new Bitmap(fl);\r\n            Stopwatch sw = new Stopwatch();\r\n            sw.Start();\r\n            var res =  GetModelPrediction(bitmap, out string error);\r\n\r\n            sw.Stop();\r\n            PrintResultsonConsole(res, Path.GetFileName(fl));\r\n\r\n\r\n\r\n\r\n            Console.WriteLine($\"Analysis Time(ms): {sw.ElapsedMilliseconds}\");\r\n            analysistimes.Add(sw.ElapsedMilliseconds);\r\n\r\n        }\r\n\r\n        if(analysistimes.Count()>0)\r\n            Console.WriteLine($\"Average Analysis Time(ms): {analysistimes.Average()}\");\r\n    }\r\n\r\n\r\n    public static ModelMetadataPropertiesClass LoadProperties(string MetadatePropertiesFilepath, out string error)\r\n    {\r\n        string propertiesText = File.ReadAllText(MetadatePropertiesFilepath);\r\n        error = \"\";\r\n        ModelMetadataPropertiesClass mtp = new ModelMetadataPropertiesClass();\r\n\r\n        try\r\n        {\r\n            mtp = JsonConvert.DeserializeObject<ModelMetadataPropertiesClass>(propertiesText);\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            error = ex.ToString();\r\n            mtp = null;\r\n        }\r\n\r\n        return mtp;\r\n    }\r\n    public class ModelMetadataPropertiesClass\r\n    {\r\n        [JsonProperty(\"CustomVision.Metadata.AdditionalModelInfo\")]\r\n        public string CustomVisionMetadataAdditionalModelInfo { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Metadata.Version\")]\r\n        public string CustomVisionMetadataVersion { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Method\")]\r\n        public string CustomVisionPostprocessMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Yolo.Biases\")]\r\n        public string CustomVisionPostprocessYoloBiases { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Postprocess.Yolo.NmsThreshold\")]\r\n        public string CustomVisionPostprocessYoloNmsThreshold { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropHeight\")]\r\n        public string CustomVisionPreprocessCropHeight { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropMethod\")]\r\n        public string CustomVisionPreprocessCropMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.CropWidth\")]\r\n        public string CustomVisionPreprocessCropWidth { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MaxDimension\")]\r\n        public string CustomVisionPreprocessMaxDimension { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MaxScale\")]\r\n        public string CustomVisionPreprocessMaxScale { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MinDimension\")]\r\n        public string CustomVisionPreprocessMinDimension { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.MinScale\")]\r\n        public string CustomVisionPreprocessMinScale { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.NormalizeMean\")]\r\n        public string CustomVisionPreprocessNormalizeMean { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.NormalizeStd\")]\r\n        public string CustomVisionPreprocessNormalizeStd { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.ResizeMethod\")]\r\n        public string CustomVisionPreprocessResizeMethod { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.TargetHeight\")]\r\n        public int CustomVisionPreprocessTargetHeight { get; set; }\r\n\r\n        [JsonProperty(\"CustomVision.Preprocess.TargetWidth\")]\r\n        public int CustomVisionPreprocessTargetWidth { get; set; }\r\n\r\n        [JsonProperty(\"Image.BitmapPixelFormat\")]\r\n        public string ImageBitmapPixelFormat { get; set; }\r\n\r\n        [JsonProperty(\"Image.ColorSpaceGamma\")]\r\n        public string ImageColorSpaceGamma { get; set; }\r\n\r\n        [JsonProperty(\"Image.NominalPixelRange\")]\r\n        public string ImageNominalPixelRange { get; set; }\r\n    }\r\n\r\n\r\n    public static void PrintResultsonConsole( PredictionResultClass pr,string  filePath)\r\n    {\r\n        var defaultForeground = Console.ForegroundColor;\r\n        var labelColor = ConsoleColor.Magenta;\r\n        var probColor = ConsoleColor.Blue;\r\n        var exactLabel = ConsoleColor.Green;\r\n        var failLabel = ConsoleColor.Red;\r\n\r\n        Console.Write(\"ImagePath: \");\r\n        Console.ForegroundColor = labelColor;\r\n        Console.Write($\"{Path.GetFileName(filePath)}\");\r\n        Console.ForegroundColor = defaultForeground;\r\n\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.Write(\" predicted as \");\r\n        Console.ForegroundColor = exactLabel;\r\n        Console.Write($\"{pr.Label}\");\r\n\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.Write(\" with probability \");\r\n        Console.ForegroundColor = probColor;\r\n        Console.Write(pr.probability);\r\n        Console.ForegroundColor = defaultForeground;\r\n        Console.WriteLine(\"\");\r\n    }\r\n}\r\n`\r\n\r\nTo execute inferencing, I then initiate the modelScorer and consume it.\r\n`static void Main(string[] args)\r\n{\r\n    var onnxModelScorer = new OnnxModelScorer();\r\n\r\n            onnxModelScorer.SetupPredictionEngine(@\"..\\..\\..\\OnnxModel\\\", out string error);\r\n            onnxModelScorer.ModelMassTest(@\"..\\..\\..\\SampleImages\\Bad\\\");\r\n            ConsoleHelpers.ConsolePressAnyKey();\r\n            onnxModelScorer.ModelMassTest(@\"..\\..\\..\\SampleImages\\Good\\\");\r\n\r\n\r\n            ConsoleHelpers.ConsolePressAnyKey();\r\n\r\n            \r\n    ConsoleHelpers.ConsolePressAnyKey();\r\n}\r\n`\r\n\r\nExpected behavior\r\nWhen utilizing the Onnxruntime package, the average inferencing time is ~40ms, with Onnxruntime.GPU I expected it to be less than 10ms\r\n\r\nScreenshots\r\nNA\r\n\r\nAdditional context\r\nThis is a performance oriented question, on how well Onnxruntime.GPU allows .NET developers to exploit benefits of faster inferencing using Nvidia GPUs.\r\n\r\nIf having the full project with OnnxModel and sample images would help you investigate better, please access the following link and request access:\r\nhttps://drive.google.com/drive/folders/1DqnUvTaU9xp2QLuV_X9jFCjkratckMYL?usp=sharing\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10142/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10141",
        "id": 1089473590,
        "node_id": "PR_kwDOCVq1mM4wUMxU",
        "number": 10141,
        "title": "update tensorrt multi gpu pipeline to tensorrt 8.2",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-27T21:08:38Z",
        "updated_at": "2021-12-27T23:43:28Z",
        "closed_at": "2021-12-27T23:43:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10141",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10141",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10141.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10141.patch",
            "merged_at": "2021-12-27T23:43:28Z"
        },
        "body": "update tensorrt multi gpu pipeline to tensorrt 8.2 - it uses nvidia ngc container , which only recently published 21.12 based on tensorrt 8.2",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10141/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10140",
        "id": 1089147203,
        "node_id": "I_kwDOCVq1mM5A6xFD",
        "number": 10140,
        "title": "onnxruntime-web build contains browser incompatible requires e.g. worker_threads, fs, os",
        "user": {
            "login": "lincolnneu",
            "id": 39422558,
            "node_id": "MDQ6VXNlcjM5NDIyNTU4",
            "avatar_url": "https://avatars.githubusercontent.com/u/39422558?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lincolnneu",
            "html_url": "https://github.com/lincolnneu",
            "followers_url": "https://api.github.com/users/lincolnneu/followers",
            "following_url": "https://api.github.com/users/lincolnneu/following{/other_user}",
            "gists_url": "https://api.github.com/users/lincolnneu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lincolnneu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lincolnneu/subscriptions",
            "organizations_url": "https://api.github.com/users/lincolnneu/orgs",
            "repos_url": "https://api.github.com/users/lincolnneu/repos",
            "events_url": "https://api.github.com/users/lincolnneu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lincolnneu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:webassembly",
                "name": "platform:webassembly",
                "color": "d4ea72",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-27T10:40:20Z",
        "updated_at": "2021-12-28T23:28:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThe onnxruntime-web npm package 1.10.0 contains node.js exclusive requires, such as\r\n```\r\nvar a=require(\"worker_threads\")\r\nvar r=require(\"fs\")\r\n...\r\n```\r\nin [onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js](https://cdn.jsdelivr.net/npm/onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js)\r\n\r\nThese requires make the onnxruntime-web not usable in browser environment.\r\n\r\n**Urgency**\r\nBlocker.\r\n\r\n**System information**\r\nThis is a universal issue for web users.\r\n\r\n**To Reproduce**\r\nGo to https://cdn.jsdelivr.net/npm/onnxruntime-web@1.10.0/dist/ort-wasm-threaded.worker.js search for a=require(\"worker_threads\")\r\n\r\n\r\n**Expected behavior**\r\nonnxruntime-web for browser should not contains node.js exclusive libraries.\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/39422558/147463652-5b013768-b9bd-486a-b70d-302156610bcc.png)\r\n\r\n\r\n**Additional context**\r\nSuggestion: instead of using require(\"worker_threads\"), use __non_webpack_require__(\"worker_threads\")  [Similar issue in stackoverflow](https://stackoverflow.com/questions/52581441/ignoring-specific-requires-in-webpack)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10140/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10139",
        "id": 1089110030,
        "node_id": "I_kwDOCVq1mM5A6oAO",
        "number": 10139,
        "title": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : BatchNormInternal",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3105448033,
                "node_id": "MDU6TGFiZWwzMTA1NDQ4MDMz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:orttrainer",
                "name": "component:orttrainer",
                "color": "303a93",
                "default": false,
                "description": "ORTTrainer PyTorch Frontend"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-27T09:38:56Z",
        "updated_at": "2021-12-27T19:52:49Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhile trying to use run the model, wrapped with ORTModule from torch_ort on inputs, it throws this error \r\n\r\n```\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for BatchNormInternal(1) node with name 'BatchNormalization_6_BatchNormInternal'\r\n```\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7 \r\n- ONNX Runtime installed from (source or binary): Source\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n- Install torch_ort\r\n- from torch_ort import ORTModule\r\n- Model : Pytorch\r\n```\r\n-  TorchFFNN(\r\n  (model_layers): ModuleDict(\r\n    (nn_layer_0): Linear(in_features=1000, out_features=256, bias=True)\r\n    (activation_layer_0): ReLU()\r\n    (dropout_layer_0): Dropout(p=0.2, inplace=False)\r\n    (bn_layer_0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n    (nn_layer_1): Linear(in_features=256, out_features=128, bias=True)\r\n    (activation_layer_1): ReLU()\r\n    (dropout_layer_1): Dropout(p=0.15, inplace=False)\r\n    (nn_layer_2): Linear(in_features=128, out_features=204, bias=True)\r\n  )\r\n)\r\n```\r\n\r\n**Expected behavior**\r\nTraining should run fine\r\n\r\n**Screenshots**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/nimmaturi.venkatadat/nagini/python/trainer/workflow_pipeline/workflow_pipeline/components/classifier.py\", line 266, in _train_ffnn_model\r\n    clf.train_minibatch(X_train, y_train, x_test=X_test, y_test=y_test, minibatch_size=512, balance=\"none\")\r\n  File \"/home/nimmaturi.venkatadat/nagini/python/trainer/workflow_pipeline/workflow_pipeline/components/model/classifier/feed_forward_neural_network_torch.py\", line 197, in train_minibatch\r\n    y_pred = self.model(x_batch)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/ortmodule.py\", line 81, in _forward\r\n    return self._torch_module.forward(*inputs, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_torch_module_ort.py\", line 32, in _forward\r\n    return self._execution_manager(self.is_training()).forward(*inputs, **kwargs)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 263, in forward\r\n    self._fallback_manager.handle_exception(exception=e,\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_fallback.py\", line 194, in handle_exception\r\n    raise exception\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 121, in forward\r\n    self._create_execution_agent()\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_training_manager.py\", line 301, in _create_execution_agent\r\n    self._execution_agent = TrainingAgent(self._onnx_models.optimized_model.SerializeToString(),\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/training/ortmodule/_execution_agent.py\", line 113, in __init__\r\n    self._inference_session = onnxruntime.InferenceSession(path_or_bytes, session_options,\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 324, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 369, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for BatchNormInternal(1) node with name 'BatchNormalization_6_BatchNormInternal'\r\n\r\n```\r\n[https://www.toptal.com/developers/hastebin/fodenuloqi.sql](https://www.toptal.com/developers/hastebin/fodenuloqi.sql)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10139/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10138",
        "id": 1089074977,
        "node_id": "I_kwDOCVq1mM5A6fch",
        "number": 10138,
        "title": "Do you have any plan to add 'Round' Operator for gradient builder registry for orttrainer?",
        "user": {
            "login": "jang0977",
            "id": 77316386,
            "node_id": "MDQ6VXNlcjc3MzE2Mzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/77316386?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jang0977",
            "html_url": "https://github.com/jang0977",
            "followers_url": "https://api.github.com/users/jang0977/followers",
            "following_url": "https://api.github.com/users/jang0977/following{/other_user}",
            "gists_url": "https://api.github.com/users/jang0977/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jang0977/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jang0977/subscriptions",
            "organizations_url": "https://api.github.com/users/jang0977/orgs",
            "repos_url": "https://api.github.com/users/jang0977/repos",
            "events_url": "https://api.github.com/users/jang0977/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jang0977/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3105448033,
                "node_id": "MDU6TGFiZWwzMTA1NDQ4MDMz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:orttrainer",
                "name": "component:orttrainer",
                "color": "303a93",
                "default": false,
                "description": "ORTTrainer PyTorch Frontend"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-27T08:44:58Z",
        "updated_at": "2021-12-27T19:49:15Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\nI want to train a model that must use round node for training process but orttrainer currently does not support such a operation for training session due to gradient registry issue.\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using): I am using onnxruntime 1.10.0 \r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\nHope you to add 'Round' node for gradient builder registry for training.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\nor add some detailed explanation about registering custom round function from pytorch or python to default domain.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n\r\n\r\nThank you.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10138/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10135",
        "id": 1089010019,
        "node_id": "I_kwDOCVq1mM5A6Plj",
        "number": 10135,
        "title": "onnxruntime int8 quant slower than pytorch ",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-27T06:48:51Z",
        "updated_at": "2022-01-05T02:01:44Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\nI have a onnxmodel which was exported from torch, and the fp32 model inference of onnxruntime is faster than pytorch script\r\nhowever, when I quantize the model both in torchscript and onnxruntime, the onnxruntime is slower than pytorch\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- ONNX Runtime installed from (source or binary): pip install and build from source all try\r\n- ONNX Runtime version:1.10.0\r\n- Python version:3.8\r\n- Visual Studio version (if applicable):no\r\n- GCC/Compiler version (if compiling from source):gcc 9.3.0\r\n- CUDA/cuDNN version:no\r\n- GPU model and memory:no\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\nthe pytorch model and quant \r\n```\r\n# model is origin pytorch model\r\nmodel.qconfig = torch.quantization.get_default_qconfig('fbgemm')\r\nquant_model = torch.quantization.quantize_dynamic(model, {FSMNMT, FSMNONLINEMT, FSMNOFF2ON, torch.nn.Linear})\r\n......\r\ntrace_model = torch.jit.trace(model, (inp1, length1, history1))   #torchscript fp32 model\r\ntrace_model_q = torch.jit.trace(quant_model, (inp, length, history))   #torchscript int8 model\r\n```\r\nonnxmodel and quant:\r\n```\r\ntorch.onnx.export(model,\r\n                 (inp1, length1, history1),\r\n                 \"model.onnx\",\r\n                 verbose=False,\r\n                 input_names=input_names,\r\n                 output_names=output_names,\r\n                 opset_version=13,\r\n                 do_constant_folding=True,\r\n                 #dynamic_axes={'input':[0],'length':[0],'pre_state':[0],'output':[0,1],'cur_state':[0]},\r\n                 custom_opsets={\"mydomain\": 2})\r\n\r\nquanttized_model = quantize_dynamic(onnxmodel, onnx_quantmodel, weight_type=QuantType.QUInt8)\r\n\r\n#and do inference with following parameters\r\n\r\nenviron[\"OMP_NUM_THREADS\"] = '1'\r\nenviron[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\r\nopts = ort.SessionOptions()\r\nopts.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nopts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\r\nopts.enable_profiling = True\r\nopts.inter_op_num_threads = 1\r\nopts.intra_op_num_threads = 1\r\n\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nonnxruntime fp32 and int8 all faster than pytorch\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n![](https://user-images.githubusercontent.com/41035013/147443218-c62c15a9-7157-46fe-a800-084e964f0a6a.png)\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10135/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10134",
        "id": 1088867772,
        "node_id": "I_kwDOCVq1mM5A5s28",
        "number": 10134,
        "title": "Large performance discrepancy between Chrome and Firefox onnxruntime-web WASM inference (unless Chrome profiler is enabled)",
        "user": {
            "login": "ziyadedher",
            "id": 16349988,
            "node_id": "MDQ6VXNlcjE2MzQ5OTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/16349988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ziyadedher",
            "html_url": "https://github.com/ziyadedher",
            "followers_url": "https://api.github.com/users/ziyadedher/followers",
            "following_url": "https://api.github.com/users/ziyadedher/following{/other_user}",
            "gists_url": "https://api.github.com/users/ziyadedher/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ziyadedher/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ziyadedher/subscriptions",
            "organizations_url": "https://api.github.com/users/ziyadedher/orgs",
            "repos_url": "https://api.github.com/users/ziyadedher/repos",
            "events_url": "https://api.github.com/users/ziyadedher/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ziyadedher/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:webassembly",
                "name": "platform:webassembly",
                "color": "d4ea72",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-27T00:00:23Z",
        "updated_at": "2021-12-27T23:22:39Z",
        "closed_at": "2021-12-27T22:42:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThere is a large discrepancy in execution speed of the attached model depending on whether it is running in Chrome or Firefox, being nearly twice as fast on Firefox. Both inference sessions are using the same WASM back-end. However, if we run the model with Chrome profiling enabled, the speeds are much closer.\r\n\r\nAll times are measured using `performance.now` calls. Running regularly on Chrome, model execution time is ~2600ms. Running regularly in Firefox, model execution time is ~1350ms. If we enable profiling on Chrome, model execution time is ~1200ms. I have no clue what is causing this, and I can't really profile it to figure it out :stuck_out_tongue: \r\n\r\n**Urgency**\r\nNone.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- ONNX Runtime installed from (source or binary): Binary\r\n- ONNX Runtime version: 1.10.0\r\n\r\n**Additional context**\r\nThe model is too large to attach to this GitHub Issue, you can download it [here](https://storage.ziyadedher.com/darkarts/models/onnx/stylegan2-ffhq-256x256.generator.onnx.pb).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10134/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10133",
        "id": 1088703093,
        "node_id": "PR_kwDOCVq1mM4wRxuA",
        "number": 10133,
        "title": "fix: clang compile",
        "user": {
            "login": "ganler",
            "id": 38074777,
            "node_id": "MDQ6VXNlcjM4MDc0Nzc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/38074777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ganler",
            "html_url": "https://github.com/ganler",
            "followers_url": "https://api.github.com/users/ganler/followers",
            "following_url": "https://api.github.com/users/ganler/following{/other_user}",
            "gists_url": "https://api.github.com/users/ganler/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ganler/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ganler/subscriptions",
            "organizations_url": "https://api.github.com/users/ganler/orgs",
            "repos_url": "https://api.github.com/users/ganler/repos",
            "events_url": "https://api.github.com/users/ganler/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ganler/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-26T05:35:49Z",
        "updated_at": "2021-12-31T02:47:13Z",
        "closed_at": "2021-12-31T02:47:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10133",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10133",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10133.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10133.patch",
            "merged_at": null
        },
        "body": "**Description**: cannot compile ORT-cuda with clang. \r\nIt says \"hides overloaded virtual function\" which is a common clang compile error (also see [here](https://stackoverflow.com/questions/18515183/c-overloaded-virtual-function-warning-by-clang)).\r\n\r\n**Motivation and Context**\r\n- Fix ORT-cuda compilation on clang (specifically, my platform: Manjaro; clang-13)\r\n\r\n![image](https://user-images.githubusercontent.com/38074777/147400364-63406fcc-9b35-410b-9da5-bbe3a4187f2f.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10133/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10132",
        "id": 1088616451,
        "node_id": "PR_kwDOCVq1mM4wRis1",
        "number": 10132,
        "title": "Add `.git` suffix to github URL.",
        "user": {
            "login": "xkszltl",
            "id": 5203025,
            "node_id": "MDQ6VXNlcjUyMDMwMjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5203025?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xkszltl",
            "html_url": "https://github.com/xkszltl",
            "followers_url": "https://api.github.com/users/xkszltl/followers",
            "following_url": "https://api.github.com/users/xkszltl/following{/other_user}",
            "gists_url": "https://api.github.com/users/xkszltl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xkszltl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xkszltl/subscriptions",
            "organizations_url": "https://api.github.com/users/xkszltl/orgs",
            "repos_url": "https://api.github.com/users/xkszltl/repos",
            "events_url": "https://api.github.com/users/xkszltl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xkszltl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-25T15:16:34Z",
        "updated_at": "2022-01-03T22:38:35Z",
        "closed_at": "2022-01-03T22:38:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10132",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10132",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10132.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10132.patch",
            "merged_at": "2022-01-03T22:38:35Z"
        },
        "body": "Although github works with both, this is more precise.\r\nHaving an extension also makes it easy to match with regex, when we want to inject code to reroute traffic to our own git mirror.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10132/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10131",
        "id": 1088582645,
        "node_id": "I_kwDOCVq1mM5A4nP1",
        "number": 10131,
        "title": "What's the most time-consuming process in python's `InferenceSession` class init?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-12-25T10:38:10Z",
        "updated_at": "2021-12-30T17:46:52Z",
        "closed_at": "2021-12-30T17:46:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "What's the most time-consuming process in python's `InferenceSession` class init?\r\nBy profiling using `cProfile`, I have noticed that the `_create_inference_session` which runs in `InferenceSession`'s init is the most time-consuming.\r\n\r\nI consulted with the great @xadupre which explained to me that the process of `InferenceSession` is generally as follows:\r\nModel Loading -> Graph Optimization -> Data Structure Modifications.\r\n\r\nXavier recommended that saving and using the optimized graph **may** save time. I've tried it, and even though a bit of time was saved, the change wasn't significant.\r\nYou can try it yourself in this Colab notebook: https://colab.research.google.com/drive/1KwtH90g2NPC8P_bmTT31GdytV2OlS8Y7?usp=sharing\r\n\r\nIf the Graph Optimization isn't the bottleneck, then I may assume that `Model Loading` or `Data Structure Modifications` is.\r\n\r\nI want to understand a bit more about the Model Loading process.\r\nIf for example, instead of passing a string (file path) to `InferenceSession`, I'd pass model bytes buffer, will there still be a Model Loading process? I assume No because the model is already loaded in the memory and the CPP code should just get the pointer to the memory location.\r\n\r\nAlso, I want to understand a bit better the Data Structure Modifying process.\r\nWhy is it needed and what's happening in the process?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10131/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10130",
        "id": 1088546330,
        "node_id": "PR_kwDOCVq1mM4wRWgL",
        "number": 10130,
        "title": "BugFix: quantization tools will throw a ValueError in HistogramCollector",
        "user": {
            "login": "xusworld",
            "id": 13519244,
            "node_id": "MDQ6VXNlcjEzNTE5MjQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13519244?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xusworld",
            "html_url": "https://github.com/xusworld",
            "followers_url": "https://api.github.com/users/xusworld/followers",
            "following_url": "https://api.github.com/users/xusworld/following{/other_user}",
            "gists_url": "https://api.github.com/users/xusworld/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xusworld/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xusworld/subscriptions",
            "organizations_url": "https://api.github.com/users/xusworld/orgs",
            "repos_url": "https://api.github.com/users/xusworld/repos",
            "events_url": "https://api.github.com/users/xusworld/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xusworld/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "chilo-ms",
                "id": 54722500,
                "node_id": "MDQ6VXNlcjU0NzIyNTAw",
                "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/chilo-ms",
                "html_url": "https://github.com/chilo-ms",
                "followers_url": "https://api.github.com/users/chilo-ms/followers",
                "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
                "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
                "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
                "repos_url": "https://api.github.com/users/chilo-ms/repos",
                "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
                "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-12-25T04:51:52Z",
        "updated_at": "2022-01-15T02:57:55Z",
        "closed_at": "2022-01-15T02:57:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10130",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10130",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10130.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10130.patch",
            "merged_at": null
        },
        "body": "Fix bug and spelling errors.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10130/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10129",
        "id": 1088517508,
        "node_id": "PR_kwDOCVq1mM4wRRij",
        "number": 10129,
        "title": "Update test script to work with python 3.8+ on Windows",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-24T23:59:20Z",
        "updated_at": "2021-12-28T06:10:28Z",
        "closed_at": "2021-12-28T06:10:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10129",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10129",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10129.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10129.patch",
            "merged_at": "2021-12-28T06:10:26Z"
        },
        "body": "**Description**: \r\nOn Windows for Python 3.8+ you need to explicitly add the current directory for libraries to be loaded from it. Update onnxruntime_test_python.py to do that.\r\n\r\n**Motivation and Context**\r\nFix build break if build.py is run on Windows with python 3.8+",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10129/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10128",
        "id": 1088479826,
        "node_id": "I_kwDOCVq1mM5A4OJS",
        "number": 10128,
        "title": "BatchNorm fails on CUDA EP with zero length sequences",
        "user": {
            "login": "david-macleod",
            "id": 17232877,
            "node_id": "MDQ6VXNlcjE3MjMyODc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/17232877?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david-macleod",
            "html_url": "https://github.com/david-macleod",
            "followers_url": "https://api.github.com/users/david-macleod/followers",
            "following_url": "https://api.github.com/users/david-macleod/following{/other_user}",
            "gists_url": "https://api.github.com/users/david-macleod/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david-macleod/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david-macleod/subscriptions",
            "organizations_url": "https://api.github.com/users/david-macleod/orgs",
            "repos_url": "https://api.github.com/users/david-macleod/repos",
            "events_url": "https://api.github.com/users/david-macleod/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david-macleod/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2114490130,
                "node_id": "MDU6TGFiZWwyMTE0NDkwMTMw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:operator",
                "name": "component:operator",
                "color": "303a93",
                "default": false,
                "description": "related to specific ONNX operator support"
            },
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to CUDA EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-24T19:09:47Z",
        "updated_at": "2021-12-28T22:50:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen passing tensors with a dimension of zero size e.g. (8, 1024, 0) to BatchNorm1d we hit the following error\r\n```\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node. Name:'BatchNormalization_0' Status Message: CUDNN error executing cudnnSetTensorNdDescriptor(tensor_, dataType, static_cast<int>(rank), dims.data(), strides.data())\r\n```\r\nThis is not an issue for the CPU EP and should be supported according to the ONNX spec\r\n\r\nThank you\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 11.2/8.1.1\r\n- GPU model and memory: Titan RTX 2080 Ti (11 GB)\r\n\r\n**To Reproduce**\r\n```py\r\nimport torch\r\nimport onnxruntime as ort\r\nimport tempfile\r\n\r\nclass Model(torch.nn.Module):\r\n\r\n    def __init__(self) -> None:\r\n        super().__init__()\r\n        self.bnorm = torch.nn.BatchNorm1d(2048)\r\n\r\n    def forward(self, x):\r\n        x = self.bnorm(x)\r\n        return x\r\n\r\nx =  torch.randn(1, 2048, 0)\r\nmodel = torch.jit.script(Model())\r\nmodel.eval()\r\n\r\nwith tempfile.TemporaryDirectory() as temp_dir:\r\n    temp_onnx = temp_dir + \"tmp.onnx\"\r\n    torch.onnx.export(model, x, temp_onnx, opset_version=14, input_names=[\"x\"], dynamic_axes={\"x\":[2]}, example_outputs=x)\r\n\r\n    options = ort.SessionOptions()\r\n    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n\r\n    for providers in (['CPUExecutionProvider'], [\"CUDAExecutionProvider\"]):\r\n        session = ort.InferenceSession(temp_onnx, options, providers=providers)\r\n        print(\"EPs\", session.get_providers())\r\n        output = session.run(None, input_feed={\"x\": x.numpy()})[0]\r\n        print(\"Output\", output.shape)\r\n```\r\n\r\n**Expected behavior**\r\nA successful inference pass, as demonstrated with the CPU EP\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10128/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10127",
        "id": 1088311406,
        "node_id": "I_kwDOCVq1mM5A3lBu",
        "number": 10127,
        "title": "ORTModule import error : with onnxruntime",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2732589361,
                "node_id": "MDU6TGFiZWwyNzMyNTg5MzYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:ortmodule",
                "name": "component:ortmodule",
                "color": "303a93",
                "default": false,
                "description": "related to ortmodule"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-24T10:48:45Z",
        "updated_at": "2021-12-25T05:04:46Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen both onnxruntime and onnxruntime-training are installed and ORTModule is imported\r\n `from torch_ort import ORTModule` it throws an error.\r\nWhen I uninstall onnxruntime, the same import works fine.\r\n\r\n```\r\nImportError: cannot import name 'TrainingParameters' from 'onnxruntime.capi._pybind_state' (/home/nimmaturi.venkatadat/.cache/pypoetry/virtualenvs/mltrainer-nagini-COPLqCiN-py3.9/lib/python3.9/site-packages/onnxruntime/capi/_pybind_state.py)\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- ONNX Runtime installed from (source or binary): Binary\r\n- ONNX Runtime version:  1.9.0 and 1.10.0\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\n- install [torch_ort](https://github.com/pytorch/ort) package.\r\n- do ` from torch_ort import ORTModule`\r\n- install onnxruntime (1.9.0 or 1.10.0)\r\n- do ` from torch_ort import ORTModule`. This fails\r\n\r\n**Expected behavior**\r\nImport should happen successfully\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/39181234/147346360-352be3f8-225f-483f-b9c8-4c65f98ce148.png)\r\n![image](https://user-images.githubusercontent.com/39181234/147346382-4b96f686-d84c-4e8c-a17a-89b7c4ccf8d8.png)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10127/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10126",
        "id": 1088215721,
        "node_id": "I_kwDOCVq1mM5A3Nqp",
        "number": 10126,
        "title": "Why I met Type 'seq(tensor(int64))' of operator (MemcpyFromHost) is invalid when using onnxruntime.InferenceSession() in GPU, and How to resolve it?  On emergency holdthanks!",
        "user": {
            "login": "yuanhuachao",
            "id": 13781668,
            "node_id": "MDQ6VXNlcjEzNzgxNjY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/13781668?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuanhuachao",
            "html_url": "https://github.com/yuanhuachao",
            "followers_url": "https://api.github.com/users/yuanhuachao/followers",
            "following_url": "https://api.github.com/users/yuanhuachao/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuanhuachao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuanhuachao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuanhuachao/subscriptions",
            "organizations_url": "https://api.github.com/users/yuanhuachao/orgs",
            "repos_url": "https://api.github.com/users/yuanhuachao/repos",
            "events_url": "https://api.github.com/users/yuanhuachao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuanhuachao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-24T07:43:48Z",
        "updated_at": "2021-12-28T02:56:41Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nwhen I run exported onnx model of transformers (BARTBeamSearchGenerator model) on GPU. I met this. Who knows how can resolve it?\r\n`Traceback (most recent call last):\r\n  File \"run_onnx_exporter.py\", line 262, in <module>\r\n    main()\r\n  File \"run_onnx_exporter.py\", line 258, in main\r\n    export_and_validate_model(model, tokenizer, output_name, num_beams, max_length, device)\r\n  File \"run_onnx_exporter.py\", line 177, in export_and_validate_model\r\n    ort_sess = onnxruntime.InferenceSession(new_onnx_file_path, providers=['CUDAExecutionProvider'])\r\n  File \"/home/venv/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 283, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/venv/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 321, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. Type Error: Type 'seq(tensor(int64))' of input parameter (best.1) of operator (MemcpyFromHost) in node (Memcpy_token_30) is invalid.`\r\n\r\n**Urgency**\r\nIs very Urgent\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- ONNX Runtime version: 1.8.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CUDA11.2\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10126/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10125",
        "id": 1088050175,
        "node_id": "I_kwDOCVq1mM5A2lP_",
        "number": 10125,
        "title": "Error of building onnxruntime from source",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1805781160,
                "node_id": "MDU6TGFiZWwxODA1NzgxMTYw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Java",
                "name": "api:Java",
                "color": "0e8a16",
                "default": false,
                "description": "related to the Java API"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to TensorRT EP"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-23T23:59:55Z",
        "updated_at": "2021-12-28T16:22:07Z",
        "closed_at": "2021-12-28T16:22:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi, I was trying to build the onnxruntime from source (with no changes), but it results in the following error when the building was 56%:\r\n\"/home/xx/docker_container/onnxruntime/cmake/external/onnx-tensorrt/onnx2trt_utils.hpp:377:117: error: **nvinfer1::ScatterMode has not been declared**\r\n  377 |     IImporterContext* ctx, const ::ONNX_NAMESPACE::NodeProto& node, std::vector<TensorOrWeights>& inputs, nvinfer1::ScatterMode mode, int32_t axis = 0);\r\n      |                                                                                                                     ^~~~~~~~~~~\r\nmake[2]: *** [external/onnx-tensorrt/CMakeFiles/nvonnxparser_static.dir/build.make:76: external/onnx-tensorrt/CMakeFiles/nvonnxparser_static.dir/NvOnnxParser.cpp.o] Error 1\"\r\n\r\nCan you help take a look at what causes this?\r\nI was trying to build an OnnxRuntime with tensorrt, with java bindings inside a nvidia container. I put the details in the \"Reproduce\" section.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: latest master (the last commit is [this](https://github.com/microsoft/onnxruntime/pull/10105))\r\n- Python version: 3.8.10\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): cmake 3.22\r\n- CUDA/cuDNN version:  11.4\r\n- GPU model and memory: V100, 16G\r\n\r\n**To Reproduce**\r\nStart a nvidia tensorrt container 21.10-py3\r\nInstall the cmake cmake-3.22.1-linux-x86_64.sh (from [here](https://cmake.org/download/))\r\nGit clone the onnxruntime repo. The last commit is [this](https://github.com/microsoft/onnxruntime/pull/10105)\r\nRun \"./build.sh --cudnn_home /usr/lib/x86_64-linux-gnu --cuda_home /usr/local/cuda --use_tensorrt --tensorrt_home /opt/tensorrt --build_java\"\r\n\r\n**Expected behavior**\r\nBuild success\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10125/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10124",
        "id": 1087990728,
        "node_id": "PR_kwDOCVq1mM4wPn0J",
        "number": 10124,
        "title": "Fix props file overwriting AdditionalIncludeDirectories",
        "user": {
            "login": "CarlPoirier",
            "id": 5577772,
            "node_id": "MDQ6VXNlcjU1Nzc3NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5577772?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CarlPoirier",
            "html_url": "https://github.com/CarlPoirier",
            "followers_url": "https://api.github.com/users/CarlPoirier/followers",
            "following_url": "https://api.github.com/users/CarlPoirier/following{/other_user}",
            "gists_url": "https://api.github.com/users/CarlPoirier/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CarlPoirier/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CarlPoirier/subscriptions",
            "organizations_url": "https://api.github.com/users/CarlPoirier/orgs",
            "repos_url": "https://api.github.com/users/CarlPoirier/repos",
            "events_url": "https://api.github.com/users/CarlPoirier/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CarlPoirier/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-23T21:04:01Z",
        "updated_at": "2022-01-12T07:30:42Z",
        "closed_at": "2022-01-12T07:30:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10124",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10124",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10124.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10124.patch",
            "merged_at": "2022-01-12T07:30:41Z"
        },
        "body": "**Description**: In .props file, prepend to AdditionalIncludeDirectories variable instead of overwriting it.\r\n\r\n**Motivation and Context**\r\n- Fixes #9646\r\n- Fixes #9924\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10124/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10123",
        "id": 1087917991,
        "node_id": "PR_kwDOCVq1mM4wPYk4",
        "number": 10123,
        "title": "Correctly set thread affinity on Windows",
        "user": {
            "login": "chausner-audeering",
            "id": 64791786,
            "node_id": "MDQ6VXNlcjY0NzkxNzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64791786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner-audeering",
            "html_url": "https://github.com/chausner-audeering",
            "followers_url": "https://api.github.com/users/chausner-audeering/followers",
            "following_url": "https://api.github.com/users/chausner-audeering/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner-audeering/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner-audeering/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner-audeering/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner-audeering/orgs",
            "repos_url": "https://api.github.com/users/chausner-audeering/repos",
            "events_url": "https://api.github.com/users/chausner-audeering/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner-audeering/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-23T18:25:08Z",
        "updated_at": "2021-12-23T23:47:39Z",
        "closed_at": "2021-12-23T23:47:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10123",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10123",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10123.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10123.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\nThis fixes an issue with how thread affinity was set on Windows. `SetThreadAffinityMask` requires a bit vector for the mask, see https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-setthreadaffinitymask and https://stackoverflow.com/questions/5919699/proper-usage-of-setthreadaffinitymask.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10123/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10122",
        "id": 1087884945,
        "node_id": "PR_kwDOCVq1mM4wPRm7",
        "number": 10122,
        "title": "Check size of ThreadOptions.affinity vector",
        "user": {
            "login": "chausner-audeering",
            "id": 64791786,
            "node_id": "MDQ6VXNlcjY0NzkxNzg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64791786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner-audeering",
            "html_url": "https://github.com/chausner-audeering",
            "followers_url": "https://api.github.com/users/chausner-audeering/followers",
            "following_url": "https://api.github.com/users/chausner-audeering/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner-audeering/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner-audeering/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner-audeering/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner-audeering/orgs",
            "repos_url": "https://api.github.com/users/chausner-audeering/repos",
            "events_url": "https://api.github.com/users/chausner-audeering/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner-audeering/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "pranavsharma",
                "id": 2732907,
                "node_id": "MDQ6VXNlcjI3MzI5MDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pranavsharma",
                "html_url": "https://github.com/pranavsharma",
                "followers_url": "https://api.github.com/users/pranavsharma/followers",
                "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
                "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
                "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
                "repos_url": "https://api.github.com/users/pranavsharma/repos",
                "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-23T17:23:36Z",
        "updated_at": "2022-01-21T23:54:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10122",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10122",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10122.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10122.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\nThis checks the size of the `ThreadOptions.affinity` vector to be either zero or match the number of threads in the thread pool. The thread pool implementations in `onnxruntime/core/platform/windows/env.cc` and `onnxruntime/core/platform/posix/env.cc` depend on the correct size:\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/05d20343ee04990a7082ccb162faab9dd9a8305c/onnxruntime/core/platform/windows/env.cc#L103\r\n\r\nand \r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/05d20343ee04990a7082ccb162faab9dd9a8305c/onnxruntime/core/platform/posix/env.cc#L179\r\n\r\n**Motivation and Context**\r\nMight fix https://github.com/microsoft/onnxruntime/issues/10113.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10122/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10119",
        "id": 1087659809,
        "node_id": "I_kwDOCVq1mM5A1F8h",
        "number": 10119,
        "title": "onnxruntime_test_all fails at Gemm, Conv, Pool and Concat tests",
        "user": {
            "login": "ghost",
            "id": 10137,
            "node_id": "MDQ6VXNlcjEwMTM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ghost",
            "html_url": "https://github.com/ghost",
            "followers_url": "https://api.github.com/users/ghost/followers",
            "following_url": "https://api.github.com/users/ghost/following{/other_user}",
            "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
            "organizations_url": "https://api.github.com/users/ghost/orgs",
            "repos_url": "https://api.github.com/users/ghost/repos",
            "events_url": "https://api.github.com/users/ghost/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ghost/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            },
            {
                "id": 2682135653,
                "node_id": "MDU6TGFiZWwyNjgyMTM1NjUz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:ArmNN",
                "name": "ep:ArmNN",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to Arm NN EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-23T12:10:25Z",
        "updated_at": "2021-12-24T10:01:49Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Building successfully onnxruntime to use armnn as a provider onnxruntime_test_all fails. Using the library into my own app it crashes when doing a Conv operation.\r\n\r\nTo reproduce the error just build onnxruntime with the following options and run onnxruntime_test_all\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux xilinx-k26-starterkit-2021_1 5.10.0-xilinx-v2021.1 SMP Tue Aug 24 05:53:21 UTC 2021 aarch64 aarch64 aarch64 GNU/Linux (petalinux)\r\n- ONNX Runtime version: 1.11.0\r\n- Python version: N/A, using C/C++ api\r\n- GCC/Compiler version (if compiling from source): 10.2.0\r\n- ARM version: arm64v8-a\r\n\r\n**To Reproduce**\r\n\r\nBuild:\r\n\r\nComputeLibrary:\r\nscons Werror=1 debug=0 neon=1 opencl=0 embed_kernels=0 os=linux arch=arm64-v8a build=native extra_cxx_flags=-fPIC benchmark_tests=1 validation_tests=1\r\n\r\narmnn:\r\ncmake \\\r\n-DARMCOMPUTE_ROOT=/home/manu/ComputeLibrary \\\r\n-DARMCOMPUTE_BUILD_DIR=/home/manu/ComputeLibrary/build \\\r\n-DARMCOMPUTENEON=1 \\\r\n..\r\n\r\nmake -j4\r\n\r\nonnxruntime:\r\n\r\n./build.sh \\\r\n--config Release \\\r\n--update \\\r\n--build \\\r\n--parallel \\\r\n--build_shared_lib \\\r\n--use_armnn \\\r\n--armnn_home /home/manu/armnn \\\r\n--armnn_libs /home/manu/armnn/build \\\r\n--acl_home /home/manu/ComputeLibrary \\\r\n--acl_libs /home/manu/ComputeLibrary/build \\\r\n1>build.log 2>&1\r\n\r\nrun onnxruntime_test_all\r\n\r\n**Expected behavior**\r\nonnxruntime_test_all output:\r\n[  FAILED  ] 38 tests, listed below:\r\n[  FAILED  ] GemmOpTest.GemmNoTrans_float\r\n[  FAILED  ] GemmOpTest.GemmBroadcast\r\n[  FAILED  ] GemmOpTest.GemmTransB\r\n[  FAILED  ] GemmOpTest.GemmTransB_1\r\n[  FAILED  ] GemmOpTest.GemmNaN\r\n[  FAILED  ] GemmOpTest.GemmScalarBroadcast\r\n[  FAILED  ] GemmOpTest.Gemm2DBroadcast_1\r\n[  FAILED  ] GemmOpTest.Gemm2DBroadcast_2\r\n[  FAILED  ] GemmOpTest.GemmFalseBroadcast\r\n[  FAILED  ] GemmOpTest.GemmEmptyTensor\r\n[  FAILED  ] GemmOpTest.GemmNoBiasOpset11\r\n[  FAILED  ] ConvTest.Conv2D_1\r\n[  FAILED  ] ConvTest.Conv2D_Bias_1\r\n[  FAILED  ] ConvTest.Conv2D_Bias_2\r\n[  FAILED  ] ConvTest.Conv2D_AutoPad1\r\n[  FAILED  ] ConvTest.Conv2D_AutoPad2\r\n[  FAILED  ] ConvTest.Conv_AutoPad_with_non_default_strides\r\n[  FAILED  ] PoolTest.MaxPool\r\n[  FAILED  ] PoolTest.GlobalMaxPool\r\n[  FAILED  ] PoolTest.AveragePool\r\n[  FAILED  ] PoolTest.AveragePool_IncludePadPixel\r\n[  FAILED  ] PoolTest.AveragePool_10_ceil1_2d\r\n[  FAILED  ] PoolTest.GlobalAveragePool\r\n[  FAILED  ] ConcatOpTest.Concat1D_1\r\n[  FAILED  ] ConcatOpTest.Concat1D_2\r\n[  FAILED  ] ConcatOpTest.Concat2D_1\r\n[  FAILED  ] ConcatOpTest.Concat2D_2\r\n[  FAILED  ] ConcatOpTest.Concat2D_3\r\n[  FAILED  ] ConcatOpTest.Concat2D_4\r\n[  FAILED  ] ConcatOpTest.Concat3D_1\r\n[  FAILED  ] ConcatOpTest.Concat3D_1_negative_axis\r\n[  FAILED  ] ConcatOpTest.Concat3D_2\r\n[  FAILED  ] ConcatOpTest.Concat3D_3\r\n[  FAILED  ] ConcatOpTest.Concat3D_4\r\n[  FAILED  ] ConcatOpTest.Concat3D_5\r\n[  FAILED  ] ConcatOpTest.Concat4D_1\r\n[  FAILED  ] ConcatOpTest.Concat4D_1_negative_axis\r\n[  FAILED  ] ConcatOpTest.Concat4D_2\r\n\r\nexpected no failed test.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10119/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10118",
        "id": 1087492548,
        "node_id": "PR_kwDOCVq1mM4wN-X9",
        "number": 10118,
        "title": "update",
        "user": {
            "login": "xusworld",
            "id": 13519244,
            "node_id": "MDQ6VXNlcjEzNTE5MjQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13519244?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xusworld",
            "html_url": "https://github.com/xusworld",
            "followers_url": "https://api.github.com/users/xusworld/followers",
            "following_url": "https://api.github.com/users/xusworld/following{/other_user}",
            "gists_url": "https://api.github.com/users/xusworld/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xusworld/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xusworld/subscriptions",
            "organizations_url": "https://api.github.com/users/xusworld/orgs",
            "repos_url": "https://api.github.com/users/xusworld/repos",
            "events_url": "https://api.github.com/users/xusworld/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xusworld/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-23T08:32:24Z",
        "updated_at": "2021-12-23T08:32:35Z",
        "closed_at": "2021-12-23T08:32:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10118",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10118",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10118.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10118.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10118/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10117",
        "id": 1087340869,
        "node_id": "I_kwDOCVq1mM5Az4FF",
        "number": 10117,
        "title": "AssignNodesToEpsFromHashesImpl Failed to find kernel def hash (14280390279553192696) in kernel registries for Einsum(12) node with name 'Einsum_382'.",
        "user": {
            "login": "piekey1994",
            "id": 9911201,
            "node_id": "MDQ6VXNlcjk5MTEyMDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9911201?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/piekey1994",
            "html_url": "https://github.com/piekey1994",
            "followers_url": "https://api.github.com/users/piekey1994/followers",
            "following_url": "https://api.github.com/users/piekey1994/following{/other_user}",
            "gists_url": "https://api.github.com/users/piekey1994/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/piekey1994/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/piekey1994/subscriptions",
            "organizations_url": "https://api.github.com/users/piekey1994/orgs",
            "repos_url": "https://api.github.com/users/piekey1994/repos",
            "events_url": "https://api.github.com/users/piekey1994/events{/privacy}",
            "received_events_url": "https://api.github.com/users/piekey1994/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2314849695,
                "node_id": "MDU6TGFiZWwyMzE0ODQ5Njk1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:android",
                "name": "platform:android",
                "color": "d4ea72",
                "default": false,
                "description": ""
            },
            {
                "id": 2385898474,
                "node_id": "MDU6TGFiZWwyMzg1ODk4NDc0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:%20mobile",
                "name": "feature: mobile",
                "color": "0052cc",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-23T03:24:26Z",
        "updated_at": "2022-01-03T20:38:02Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI exported the onnx file with pytorch 1.10 on PC. Then I convert the file to ORT format through onnxruntime 1.10. This is the config file:\r\nai.onnx;1;LayerNormalization\r\nai.onnx;9;ConstantOfShape,Where\r\nai.onnx;12;Einsum\r\nai.onnx;13;ArgMax,Cast,Concat,Gather,Log,LogSoftmax,Pad,Shape,Slice,Softmax,Transpose,Unsqueeze\r\nai.onnx;14;Add,Div,Mul,Relu,Reshape,Trilu\r\ncom.microsoft;1;DynamicQuantizeMatMul\r\n\r\nOn x86pc, I can load ort file and run it normally with the x86java version of onnxruntime.\r\n\r\nBut error encountered when loading ort model in Android.\r\nai.onnxruntime.OrtException: Error code - ORT_FAIL - message: inference_session.cc:1194 AssignNodesToEpsFromHashesImpl Failed to find kernel def hash (14280390279553192696) in kernel registries for Einsum(12) node with name 'Einsum_382'.\r\n\r\n\r\n**System information**\r\nOS Platform and Distribution: windows 64bit\r\nandroid studio version : android studio 4.1.1\r\nused android device : emulator(android api level 28 x86)\r\nONNX Runtime version: 'com.microsoft.onnxruntime:onnxruntime-mobile:1.10.0'\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10117/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10116",
        "id": 1087321712,
        "node_id": "PR_kwDOCVq1mM4wNa8E",
        "number": 10116,
        "title": "Automate Python API docs generation ",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:documentation",
                "name": "component:documentation",
                "color": "303a93",
                "default": false,
                "description": "related to documentation"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-23T02:34:34Z",
        "updated_at": "2022-01-04T02:22:23Z",
        "closed_at": "2022-01-04T02:22:23Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10116",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10116",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10116.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10116.patch",
            "merged_at": "2022-01-04T02:22:22Z"
        },
        "body": "PR created by this workflow staged here: https://github.com/natke/onnxruntime/pull/17 \r\n\r\nStaged here: https://natke.github.io/onnxruntime/docs/api/python/api_summary.html",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10116/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10115",
        "id": 1087286962,
        "node_id": "PR_kwDOCVq1mM4wNUCi",
        "number": 10115,
        "title": "Fix the default provider related issue",
        "user": {
            "login": "feihugis",
            "id": 5057740,
            "node_id": "MDQ6VXNlcjUwNTc3NDA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5057740?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/feihugis",
            "html_url": "https://github.com/feihugis",
            "followers_url": "https://api.github.com/users/feihugis/followers",
            "following_url": "https://api.github.com/users/feihugis/following{/other_user}",
            "gists_url": "https://api.github.com/users/feihugis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/feihugis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/feihugis/subscriptions",
            "organizations_url": "https://api.github.com/users/feihugis/orgs",
            "repos_url": "https://api.github.com/users/feihugis/repos",
            "events_url": "https://api.github.com/users/feihugis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/feihugis/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "RyanUnderhill",
                "id": 38674843,
                "node_id": "MDQ6VXNlcjM4Njc0ODQz",
                "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/RyanUnderhill",
                "html_url": "https://github.com/RyanUnderhill",
                "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
                "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
                "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
                "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
                "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
                "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
                "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-23T00:58:20Z",
        "updated_at": "2022-01-28T18:32:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10115",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10115",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10115.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10115.patch",
            "merged_at": null
        },
        "body": "**Description**: If setting `providers` be be `None` for InferenceSession, will get the below message. This PR will make the behavior work as the doc `if not provided, then all available providers are used with the default precedence.`.\r\n\r\n```\r\nEP Error using None\r\nFalling back to ['CPUExecutionProvider'] and retrying.\r\n```\r\n\r\nAlso a related issue in the optimizer.py is fixed.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10115/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10114",
        "id": 1087179944,
        "node_id": "PR_kwDOCVq1mM4wM-CR",
        "number": 10114,
        "title": "Builds onnxruntime + eager mode with the same value for _GLIBCXX_USE_CXX11_ABI as pytorch ",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-core",
                "name": "component:training-core",
                "color": "303a93",
                "default": false,
                "description": "related to training core"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-22T20:48:20Z",
        "updated_at": "2022-01-25T10:25:32Z",
        "closed_at": "2022-01-25T10:25:31Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10114",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10114",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10114.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10114.patch",
            "merged_at": "2022-01-25T10:25:31Z"
        },
        "body": "**Description**:\r\n\r\nEager mode does not work on Linux because _GLIBCXX_USE_CXX11_ABI=1 by default and pytorch build is released with _GLIBCXX_USE_CXX11_ABI=0.\r\n\r\n**Motivation and Context**\r\n\r\npytorch does not have to be recompiled before compiling onnxruntime.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10114/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10113",
        "id": 1086721155,
        "node_id": "I_kwDOCVq1mM5AxgyD",
        "number": 10113,
        "title": "onnxruntime latest version segment fault",
        "user": {
            "login": "henrywu2019",
            "id": 47995124,
            "node_id": "MDQ6VXNlcjQ3OTk1MTI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/47995124?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/henrywu2019",
            "html_url": "https://github.com/henrywu2019",
            "followers_url": "https://api.github.com/users/henrywu2019/followers",
            "following_url": "https://api.github.com/users/henrywu2019/following{/other_user}",
            "gists_url": "https://api.github.com/users/henrywu2019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/henrywu2019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/henrywu2019/subscriptions",
            "organizations_url": "https://api.github.com/users/henrywu2019/orgs",
            "repos_url": "https://api.github.com/users/henrywu2019/repos",
            "events_url": "https://api.github.com/users/henrywu2019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/henrywu2019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 11,
        "created_at": "2021-12-22T11:18:38Z",
        "updated_at": "2022-01-18T01:40:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nin docker, when cpu-sets are specified, onnxruntime will get segment fault.\r\n\r\n**Urgency**\r\naffect production\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- ONNX Runtime installed from (source or binary): pypi\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: CPU intel/AMD\r\n\r\n** Error **\r\n\r\n```\r\nRuntimeError: /onnxruntime_src/onnxruntime/core/platform/posix/env.cc:183 \r\nonnxruntime::{anonymous}::PosixThread::PosixThread(const char*, int, \r\nunsigned int (*)(int, Eigen::ThreadPoolInterface*), Eigen::ThreadPoolInterface*,\r\nconst onnxruntime::ThreadOptions&) pthread_setaffinity_np failed, error code: 0 error msg:\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10113/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10112",
        "id": 1086658671,
        "node_id": "I_kwDOCVq1mM5AxRhv",
        "number": 10112,
        "title": "What's the fastest way to view my implemented changes?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-22T10:05:05Z",
        "updated_at": "2021-12-28T13:49:01Z",
        "closed_at": "2021-12-23T20:57:51Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm implementing some modifications to the python module, which includes modifying `CPP`, `header`, and `python` files.\r\n\r\nCurrently, when I modify files, I run `.\\build.bat --build_wheel --parallel` to generate a `wheel` file to install.\r\nThis process is pretty slow.\r\n\r\nIs there any other way, so that I'll be able to work fast on it? :)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10112/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10111",
        "id": 1086519060,
        "node_id": "I_kwDOCVq1mM5AwvcU",
        "number": 10111,
        "title": "is batch inference supported in dynamic quantization?",
        "user": {
            "login": "rohanshingade",
            "id": 18469762,
            "node_id": "MDQ6VXNlcjE4NDY5NzYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/18469762?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rohanshingade",
            "html_url": "https://github.com/rohanshingade",
            "followers_url": "https://api.github.com/users/rohanshingade/followers",
            "following_url": "https://api.github.com/users/rohanshingade/following{/other_user}",
            "gists_url": "https://api.github.com/users/rohanshingade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rohanshingade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rohanshingade/subscriptions",
            "organizations_url": "https://api.github.com/users/rohanshingade/orgs",
            "repos_url": "https://api.github.com/users/rohanshingade/repos",
            "events_url": "https://api.github.com/users/rohanshingade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rohanshingade/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-22T07:07:14Z",
        "updated_at": "2022-01-03T17:42:35Z",
        "closed_at": "2022-01-03T17:42:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI used dynamic quantization to quanitze the model. However running with different batch size, give inconsistent model prediction.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04.5 LTS\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.\r\n- Python version: 1.8.0\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Expected behavior**\r\nModel prediction should not change as batch size changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10111/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10110",
        "id": 1086458077,
        "node_id": "I_kwDOCVq1mM5Awgjd",
        "number": 10110,
        "title": "Using tensorrt execution provider is significantly slower than cuda execution provider",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1273765791,
                "node_id": "MDU6TGFiZWwxMjczNzY1Nzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:performance",
                "name": "type:performance",
                "color": "a2eeef",
                "default": false,
                "description": "performance related issues and questions"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to TensorRT EP"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-22T05:13:54Z",
        "updated_at": "2021-12-22T19:42:56Z",
        "closed_at": "2021-12-22T19:42:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI was using both TensorrtExecutionProvider and the CudaExecutionProvider in Python to test the inference speed of the same model, however the TensorrtExecutionProvider is siginifantly slower.  I was using Tensorrt container 21.10 and ONNX Runtime version 1.10, on a V100 GPU. Using CUDA provider, the inference only takes 26ms, but using Tensorrt provider the inference takes > 3,000 ms with cache enabled. Can anyone help take a look at what's wrong with my setup?\r\n\r\nI turn on the verbose logging of the inference session and it shows \"\r\n [V:onnxruntime:, inference_session.cc:153 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n [V:onnxruntime:, inference_session.cc:155 VerifyEachNodeIsAssignedToAnEp] All nodes have been placed on [TensorrtExecutionProvider].\" Not sure if this is expected. I posted more detailed verbose logging in the additional context, and the profiling (screenshot below) doesn't show any single operations, just a whole \"TensorrtExecutionProvider_TRTKernel_graph_torch-jit-export\".\r\n\r\n**System information**\r\n(Using Tensorrt container 21.10)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  Cuda 11.4/CuDNN8.2.2\r\n- GPU model and memory: V100, 16G\r\n\r\n**To Reproduce**\r\nMy code was below. The ONNX model is an encoder model of a seq2seq model exported by torch.onnx.export. When we switch to cuda setting we only change providers to `EP_list_cuda` when creating the session.\r\n```\r\nEP_list_tensorrt = [('TensorrtExecutionProvider', {'trt_max_workspace_size':22147483648, 'trt_fp16_enable':True,'trt_engine_cache_enable':True,'trt_engine_cache_path':'./trt_cache'}), ('CUDAExecutionProvider', {'device_id':0})]\r\n\r\nEP_list_cuda = ['CUDAExecutionProvider']\r\n\r\nsess_options = ort.SessionOptions()\r\nsess_options.intra_op_num_threads = 4\r\nsess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nsess_options.log_severity_level = 0\r\nsess_options.log_verbosity_level = 1\r\nsess_options.enable_profiling = True\r\n\r\nencoder_session = ort.InferenceSession(args.onnx_model_path, sess_options, providers=EP_list_tensorrt)\r\n\r\nstart = time.perf_counter()\r\n\r\nencoder_result = encoder_session.run(None,{\"input_ids\":test_input[\"input_ids\"].cpu().numpy()})\r\n\r\nend = time.perf_counter()\r\n\r\nprint(f'Encoder takes time: {(end-start)*1000} ms')\r\n\r\nencoder_prof_file = encoder_session.end_profiling()\r\n```\r\n\r\n**Expected behavior**\r\nUsing TensorRTProvider shouldn't be this slow.\r\n\r\n**Screenshots**\r\nThe profiling file screenshot: https://paste.pics/FF0HX\r\n\r\n**Additional context**\r\nVerbose logging:\r\n2021-12-22 05:06:19.413336217 [I:onnxruntime:, inference_session.cc:273 operator()] Flush-to-zero and denormal-as-zero are off\r\n2021-12-22 05:06:19.413367427 [I:onnxruntime:, inference_session.cc:280 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n2021-12-22 05:06:22.279321986 [I:onnxruntime:, inference_session.cc:1228 Initialize] Initializing session.\r\n2021-12-22 05:06:22.279363097 [I:onnxruntime:, inference_session.cc:1265 Initialize] Adding default CPU execution provider.\r\n2021-12-22 05:06:22.279400158 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:Cuda id:0 OrtMemType:0 OrtAllocatorType:1 Device:[DeviceType:1 MemoryType:0 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.279424173 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:CudaPinned id:0 OrtMemType:-1 OrtAllocatorType:1 Device:[DeviceType:0 MemoryType:1 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.279448197 [I:onnxruntime:, session_state.cc:32 SetupAllocators] Allocator already registered for OrtMemoryInfo:[name:CUDA_CPU id:0 OrtMemType:-2 OrtAllocatorType:1 Device:[DeviceType:0 MemoryType:0 DeviceId:0]]. Ignoring allocator from CUDAExecutionProvider\r\n2021-12-22 05:06:22.297476062 [I:onnxruntime:, graph.cc:3529 CleanUnusedInitializersAndNodeArgs] Removing initializer '274'. It is no longer used by any node.\r\n2021-12-22 05:06:22.312514583 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:22.320686565 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:25.039880040 [W:onnxruntime:Default, tensorrt_execution_provider.h:53 log] [2021-12-22 05:06:25 WARNING] /onnxruntime_src/cmake/external/onnx-tensorrt/onnx2trt_utils.cpp:362: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n2021-12-22 05:06:31.481898183 [I:onnxruntime:, reshape_fusion.cc:42 ApplyImpl] Total fused reshape node count: 0\r\n2021-12-22 05:06:31.482785481 [V:onnxruntime:, inference_session.cc:153 VerifyEachNodeIsAssignedToAnEp] Node placements\r\n2021-12-22 05:06:31.482809857 [V:onnxruntime:, inference_session.cc:155 VerifyEachNodeIsAssignedToAnEp] All nodes have been placed on [TensorrtExecutionProvider].\r\n2021-12-22 05:06:31.484109031 [V:onnxruntime:, session_state.cc:67 CreateGraphInfo] SaveMLValueNameIndexMapping\r\n2021-12-22 05:06:31.484509663 [V:onnxruntime:, session_state.cc:113 CreateGraphInfo] Done saving OrtValue mappings.\r\n2021-12-22 05:06:31.485508500 [I:onnxruntime:, session_state_utils.cc:140 SaveInitializedTensors] Saving initialized tensors.\r\n2021-12-22 05:06:32.105186738 [I:onnxruntime:, session_state_utils.cc:266 SaveInitializedTensors] Done saving initialized tensors\r\n2021-12-22 05:06:32.106737739 [I:onnxruntime:, inference_session.cc:1437 Initialize] Session successfully initialized.\r\n2021-12-22 05:06:33.212640872 [I:onnxruntime:, sequential_executor.cc:155 Execute] Begin execution\r\nEncoder takes time: 3581.6109420266002 ms\r\n2021-12-22 05:06:35.879273667 [I:onnxruntime:, profiler.cc:115 EndProfiling] Writing profiler data to file onnxruntime_profile__2021-12-22_05-06-19.json\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10110/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10109",
        "id": 1086421043,
        "node_id": "PR_kwDOCVq1mM4wKdu7",
        "number": 10109,
        "title": "ConcatGrad for OpSet13",
        "user": {
            "login": "iK1D",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iK1D",
            "html_url": "https://github.com/iK1D",
            "followers_url": "https://api.github.com/users/iK1D/followers",
            "following_url": "https://api.github.com/users/iK1D/following{/other_user}",
            "gists_url": "https://api.github.com/users/iK1D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iK1D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iK1D/subscriptions",
            "organizations_url": "https://api.github.com/users/iK1D/orgs",
            "repos_url": "https://api.github.com/users/iK1D/repos",
            "events_url": "https://api.github.com/users/iK1D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iK1D/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-core",
                "name": "component:training-core",
                "color": "303a93",
                "default": false,
                "description": "related to training core"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-22T03:47:51Z",
        "updated_at": "2021-12-24T02:02:53Z",
        "closed_at": "2021-12-24T02:02:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10109",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10109",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10109.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10109.patch",
            "merged_at": "2021-12-24T02:02:53Z"
        },
        "body": "Concat's grad uses Split Op, Split Op moves \"split\" from attribute to input since OpSet13. This PR is to support both cases for building gradient of Concat/ConcatTraning.\r\n\r\nThis is required to run ULR model when ORTModule uses OpSet14 by default.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10109/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10108",
        "id": 1086383471,
        "node_id": "I_kwDOCVq1mM5AwOVv",
        "number": 10108,
        "title": "How to create writable build-in buffers during inference?",
        "user": {
            "login": "lawlict",
            "id": 35951198,
            "node_id": "MDQ6VXNlcjM1OTUxMTk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/35951198?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lawlict",
            "html_url": "https://github.com/lawlict",
            "followers_url": "https://api.github.com/users/lawlict/followers",
            "following_url": "https://api.github.com/users/lawlict/following{/other_user}",
            "gists_url": "https://api.github.com/users/lawlict/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lawlict/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lawlict/subscriptions",
            "organizations_url": "https://api.github.com/users/lawlict/orgs",
            "repos_url": "https://api.github.com/users/lawlict/repos",
            "events_url": "https://api.github.com/users/lawlict/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lawlict/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1273765791,
                "node_id": "MDU6TGFiZWwxMjczNzY1Nzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:performance",
                "name": "type:performance",
                "color": "a2eeef",
                "default": false,
                "description": "performance related issues and questions"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            },
            {
                "id": 2847143198,
                "node_id": "MDU6TGFiZWwyODQ3MTQzMTk4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:converter-pytorch",
                "name": "component:converter-pytorch",
                "color": "303a93",
                "default": false,
                "description": "related to pytorch exporter. Please post these to the PyTorch issues page: https://github.com/pytor."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-22T02:18:54Z",
        "updated_at": "2022-01-27T23:37:18Z",
        "closed_at": "2022-01-27T23:37:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi, I try to create a first-in-first-out queue as a pytorch model, export it to onnx and infer with onnxruntime. The queue, with a limited size, updates every time when a new input comes, and returns the updated queue. Codes are very simple:\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass WavBuffer(nn.Module):\r\n    def __init__(self, size=10):\r\n        super().__init__()\r\n        self.size = size\r\n        wavbuf = torch.zeros(size)\r\n        self.register_buffer('wavbuf', wavbuf)\r\n\r\n    def forward(self, x):\r\n        self.wavbuf = torch.cat([self.wavbuf, x])[-self.size:]\r\n        return self.wavbuf\r\n\r\nmodel = WavBuffer(10)\r\nx = torch.ones(5)\r\nfor i in range(2):\r\n    wavbuf = model(x)\r\n    print(wavbuf)\r\n```\r\nAs expected, the outputs are:\r\n```\r\ntensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\r\ntensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\r\n```\r\nThen I export the model to onnx format and infer with onnxruntime:\r\n```\r\ntorch.onnx.export(\r\n    model, torch.zeros(5), 'model.onnx', verbose=False, input_names=['wav'],\r\n    output_names=['wavbuf'], opset_version=11\r\n)\r\n\r\nimport numpy as np\r\nimport onnxruntime\r\n\r\nmodel = onnxruntime.InferenceSession('model.onnx')\r\nx = np.ones(5, dtype=np.float32)\r\ninputs = {model.get_inputs()[0].name: x}\r\nfor i in range(2):\r\n    outputs = model.run(None, inputs)\r\n    wavbuf = outputs[0]\r\n    print(wavbuf)\r\n```\r\nHowever, now the outputs are:\r\n```\r\n[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\r\n[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\r\n```\r\nI guess that weights in onnx models are not changeable, but is there any solution to create writable build-in buffers during model design and change the buffers in onnx inference? An available example is LSTM, where the hidden states update for each time step. However, it is too difficult for me to its implementation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10108/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10106",
        "id": 1086300199,
        "node_id": "PR_kwDOCVq1mM4wKErB",
        "number": 10106,
        "title": "Add support for FusedAdam to be mathematically equivalent to pytorch/AdamW",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-core",
                "name": "component:training-core",
                "color": "303a93",
                "default": false,
                "description": "related to training core"
            },
            {
                "id": 2087204672,
                "node_id": "MDU6TGFiZWwyMDg3MjA0Njcy",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-frontend",
                "name": "component:training-frontend",
                "color": "303a93",
                "default": false,
                "description": "related to training frontend"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T23:12:10Z",
        "updated_at": "2022-01-21T21:38:00Z",
        "closed_at": "2022-01-21T21:37:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10106",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10106",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10106.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10106.patch",
            "merged_at": "2022-01-21T21:37:59Z"
        },
        "body": "ORT's `FusedAdam` is currently mathematically equivalent to `transformers/AdamW`. Users wanting to work with `pytorch/AdamW` mathematical implementation would see convergence disparity because of the subtle differences.\r\n\r\nThis pull request introduces a way for users to select the implementation they want so that they can get the performance gains, as well as aligned convergence.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10106/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10105",
        "id": 1086288345,
        "node_id": "PR_kwDOCVq1mM4wKCLj",
        "number": 10105,
        "title": "Remove duplicated constant initializer copies for TensorRT nodes",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T22:46:47Z",
        "updated_at": "2021-12-22T20:19:57Z",
        "closed_at": "2021-12-22T20:19:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10105",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10105",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10105.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10105.patch",
            "merged_at": "2021-12-22T20:19:57Z"
        },
        "body": "When a subgraph is assigned to TensorRT EP, both ORT and TRT maintain a copy of the subgraph's constant initializers. This PR removes the ORT copy to save memory.\r\n1. add constant_initializers field in MetaDef in order to differentiate constant initializers and overridable initializers in the (sub)graph input.\r\n2. remove constant initializers from MetaDef input for TRT nodes, so that ORT can clean the constant initializers memory after partitioning.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10105/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10104",
        "id": 1086287203,
        "node_id": "I_kwDOCVq1mM5Av21j",
        "number": 10104,
        "title": "Thread affinity mask does not seem to have any effect, leading to inconsistent performance",
        "user": {
            "login": "chausner",
            "id": 15180557,
            "node_id": "MDQ6VXNlcjE1MTgwNTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/15180557?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chausner",
            "html_url": "https://github.com/chausner",
            "followers_url": "https://api.github.com/users/chausner/followers",
            "following_url": "https://api.github.com/users/chausner/following{/other_user}",
            "gists_url": "https://api.github.com/users/chausner/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chausner/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chausner/subscriptions",
            "organizations_url": "https://api.github.com/users/chausner/orgs",
            "repos_url": "https://api.github.com/users/chausner/repos",
            "events_url": "https://api.github.com/users/chausner/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chausner/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1273765791,
                "node_id": "MDU6TGFiZWwxMjczNzY1Nzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:performance",
                "name": "type:performance",
                "color": "a2eeef",
                "default": false,
                "description": "performance related issues and questions"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-21T22:44:24Z",
        "updated_at": "2021-12-23T23:56:34Z",
        "closed_at": "2021-12-23T23:56:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI am seeing inconsistent performance when benchmarking a CNN model. I have been able to trace the variation in performance to different assignment of threads to processor cores by the OS scheduler. Even though onnxruntime [should automatically set](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/session/inference_session.cc#L292) the processor affinity mask to restrict threads to the first half of logical cores, it apparently does not have an effect. If I do the same via `numactl`, I do see consistent performance but not when onnxruntime sets the affinity mask. I have checked with a debugger that onnxruntime is indeed setting the affinity mask for all 4 thread pool threads by setting a breakpoint on `pthread_setaffinity_np`.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): Official Python pip package\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- CPU: Intel Core i7-7700HQ (4 physical cores, 8 logical cores)\r\n\r\n**To Reproduce**\r\nRun the following benchmark multiple times:\r\n```python\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nimport time\r\nsession = ort.InferenceSession('model.onnx')\r\ninput = np.array(shape=(1, 60000), dtype=np.float32)\r\nfor i in range(100):\r\n    start = time.time()\r\n    outputs = session.run(['output'], {'input': input})\r\n    print(f'Iteration: {it}, Elapsed: {time.time() - start}')\r\n```\r\nIt will show different elapsed times between runs, e.g. sometimes\r\n```\r\nIteration: 0, Elapsed: 0.223\r\nIteration: 1, Elapsed: 0.231\r\nIteration: 2, Elapsed: 0.230\r\n...\r\nIteration: 99: Elapsed: 0.219\r\n```\r\nand sometimes:\r\n```\r\nIteration: 0, Elapsed: 0.147\r\nIteration: 1, Elapsed: 0.145\r\nIteration: 2, Elapsed: 0.152\r\n...\r\nIteration: 99: Elapsed: 0.148\r\n```\r\n\r\nIf running long enough and initial thread assignment is suboptimal, it appears the OS scheduler after some time reassigns affinity to the faster configuration automatically which can be seen as e.g.:\r\n```\r\nIteration: 1, Elapsed: 0.226\r\n...\r\nIteration: 73, Elapsed: 0.224\r\nIteration: 74, Elapsed: 0.178\r\nIteration: 75, Elapsed: 0.152\r\nIteration: 76, Elapsed: 0.151\r\n...\r\nIteration: 99: Elapsed: 0.149\r\n```\r\n\r\nThe performance is consistently good (around 0.15s) when running\r\n```\r\nnumactl --physcpubind=0,1,2,3 python3 test.py\r\n```\r\nand consistently bad (around 0.23s) when running\r\n```\r\nnumactl --physcpubind=0,2,4,6 python3 test.py\r\n```\r\n\r\nIt appears as if the Ubuntu scheduler does not honor what applications set via `pthread_setaffinity_np` but it does honor the affinity set by `numactl`.\r\n\r\n**Expected behavior**\r\nWhen running the benchmark without `numactl`, I would expect the results to always match the fast case because onnxruntime should itself set the thread affinity mask appropriately to 0,1,2,3 (half of logical cores).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10104/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10103",
        "id": 1086226314,
        "node_id": "I_kwDOCVq1mM5Avn-K",
        "number": 10103,
        "title": "ORT gpu io binding output buffers corrupted over multiple inferences with resizing",
        "user": {
            "login": "viboga",
            "id": 44417868,
            "node_id": "MDQ6VXNlcjQ0NDE3ODY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/44417868?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viboga",
            "html_url": "https://github.com/viboga",
            "followers_url": "https://api.github.com/users/viboga/followers",
            "following_url": "https://api.github.com/users/viboga/following{/other_user}",
            "gists_url": "https://api.github.com/users/viboga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viboga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viboga/subscriptions",
            "organizations_url": "https://api.github.com/users/viboga/orgs",
            "repos_url": "https://api.github.com/users/viboga/repos",
            "events_url": "https://api.github.com/users/viboga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viboga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T20:59:44Z",
        "updated_at": "2021-12-21T23:07:20Z",
        "closed_at": "2021-12-21T21:01:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nOnnx inference on GPU provides performance boost with io binding. The buffers for outputs of a model are pre-allocated. They can be used over multiple iterations. However, repeated usage with varying shapes leads to corruption of the order or corruption of memory itself. The buffers are created on GPU with torch.zeros().\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2016 DataCenter\r\n- ONNX Runtime installed from (source or binary): source \r\n- ONNX Runtime version: 1.10 (latest as of 12/15/2021)\r\n- Python version: python 8\r\n- Visual Studio version (if applicable): VS 2019\r\n- GCC/Compiler version (if compiling from source): build from source, VS compiler\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: V100, 32GB\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior:\r\nIn order to fetch multiple outputs from multiple inferences, have a pre-allocated buffer of larger size than any of the intended outputs. \r\n1. For each iteration\r\nFetch the outputs from buffer using reshape logic as follows:\r\nbuffer.view(-1)[:target_size].view(target_shape)\r\n2. Change output sizes from iteration to iteration and the expected output is different from the run without io binding.\r\n3. It happens after first resize/reuse on my setup.\r\n\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation\r\nIssue was first seen/reproduced on modified GPT2 with BxSx50297 logits size.\r\n\r\n**Expected behavior**\r\nThe outputs are same with and without io binding.\r\n\r\n**Additional context**:\r\nI am describing the exact steps I used for a modified GPT2:\r\nlogits size of Batch_size x Sequence_length x 50297 (vocab) for input size of Batch_size x Sequence_length. There are other inputs attention_mask(bxs) (lower triangle of 1's)\r\nposition_ids(bxs) (ascending index from 0 - [0,1,2,..s-1]\r\nand past_state(2xbx32xsx128) - first iteration NA, from second iterations outputs from previous run.\r\n\r\n1. Allocate buffer for logits with size 4 (batch_size) x 1024 (sequence_length) x 50297.\r\n2. For the first iteration let b = 4 and s = 10 (4 batches are replicas of just one). After inference fetch the logits using\r\ntarget_size = [4,10,50297]\r\nresult = logits_buffer.view(-1)[:np.prod(target_size)].view(target_size)\r\n\r\n3. For the second iteration let the batch_size be 4, sequence_length be 1. Same as step 2, its a replica\r\nFetch the logits using \r\ntarget_size = [4, 1, 50297]\r\nresult = logits_buffer.view(-1)[:np.prod(target_size)].view(target_size)\r\n\r\nExpected output is all four batches are similar in second iteration: [0,1,50297] == [1,1,50297] == [2,1,50297] == [3,1,50297]\r\nbut this is not the case.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10103/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10102",
        "id": 1086071822,
        "node_id": "PR_kwDOCVq1mM4wJTn4",
        "number": 10102,
        "title": "[ROCm] update hipify-perl location",
        "user": {
            "login": "jeffdaily",
            "id": 904248,
            "node_id": "MDQ6VXNlcjkwNDI0OA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/904248?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeffdaily",
            "html_url": "https://github.com/jeffdaily",
            "followers_url": "https://api.github.com/users/jeffdaily/followers",
            "following_url": "https://api.github.com/users/jeffdaily/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeffdaily/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeffdaily/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeffdaily/subscriptions",
            "organizations_url": "https://api.github.com/users/jeffdaily/orgs",
            "repos_url": "https://api.github.com/users/jeffdaily/repos",
            "events_url": "https://api.github.com/users/jeffdaily/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeffdaily/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 33,
        "created_at": "2021-12-21T17:45:29Z",
        "updated_at": "2022-01-07T01:21:03Z",
        "closed_at": "2022-01-07T01:21:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10102",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10102",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10102.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10102.patch",
            "merged_at": "2022-01-07T01:21:03Z"
        },
        "body": "Depending on the ROCm version installed, hipify-perl might not always\r\nlive in the hard-coded path of /opt/rocm/bin. Use python 3.3's\r\nshutil.which to locate the script.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10102/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10101",
        "id": 1086062317,
        "node_id": "I_kwDOCVq1mM5Au_7t",
        "number": 10101,
        "title": "RandomNormal with integer output seems ill-specified",
        "user": {
            "login": "ArchRobison",
            "id": 2983330,
            "node_id": "MDQ6VXNlcjI5ODMzMzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2983330?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ArchRobison",
            "html_url": "https://github.com/ArchRobison",
            "followers_url": "https://api.github.com/users/ArchRobison/followers",
            "following_url": "https://api.github.com/users/ArchRobison/following{/other_user}",
            "gists_url": "https://api.github.com/users/ArchRobison/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ArchRobison/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ArchRobison/subscriptions",
            "organizations_url": "https://api.github.com/users/ArchRobison/orgs",
            "repos_url": "https://api.github.com/users/ArchRobison/repos",
            "events_url": "https://api.github.com/users/ArchRobison/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ArchRobison/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2235309445,
                "node_id": "MDU6TGFiZWwyMjM1MzA5NDQ1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:onnx",
                "name": "component:onnx",
                "color": "303a93",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T17:32:33Z",
        "updated_at": "2021-12-22T01:08:38Z",
        "closed_at": "2021-12-22T01:08:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "The specification https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormal seems to allow `RandomNormal` to have integer output. It's not clear to me if the implementation is correct, or even how to write a correct implementation.\r\n\r\nFor example, suppose the output has type `int32`, the mean is 1, and the scale is 1.0.  Simply generating a set of floating-point values with that mean and scale, and then converting to `int32` biases the mean towards zero and shrinks standard deviation. The net effect is a mean of about 0.66 and standard deviation of 0.83.  I have not yet run this example with the ONNX runtime, but looking over the code I didn't see compensation for these effects.\r\n\r\nWhat does the ONNX runtime do, and what _should_ it do for int32 output?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10101/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10100",
        "id": 1086025334,
        "node_id": "I_kwDOCVq1mM5Au252",
        "number": 10100,
        "title": "Can't Use INT8 Input Data on Quantized Model",
        "user": {
            "login": "Hamptonjc",
            "id": 41594631,
            "node_id": "MDQ6VXNlcjQxNTk0NjMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/41594631?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Hamptonjc",
            "html_url": "https://github.com/Hamptonjc",
            "followers_url": "https://api.github.com/users/Hamptonjc/followers",
            "following_url": "https://api.github.com/users/Hamptonjc/following{/other_user}",
            "gists_url": "https://api.github.com/users/Hamptonjc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Hamptonjc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Hamptonjc/subscriptions",
            "organizations_url": "https://api.github.com/users/Hamptonjc/orgs",
            "repos_url": "https://api.github.com/users/Hamptonjc/repos",
            "events_url": "https://api.github.com/users/Hamptonjc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Hamptonjc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-21T16:48:26Z",
        "updated_at": "2021-12-28T22:22:23Z",
        "closed_at": "2021-12-28T22:22:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I am currently trying to export a LSTM from PyTorch and quantize it. However I would like for it to accept INT8 data instead of FP32. When trying to use static quantization with an INT8 calibration data, I get the error: \"InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(int8)) , expected: (tensor(float))\". \r\n\r\nBelow is my process:\r\n\r\n```python\r\n# Imports\r\nimport torch\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nfrom onnxruntime.quantization import quantize_static, CalibrationDataReader\r\n\r\n# Create Torch module\r\nclass MyLSTM(torch.nn.Module):\r\n\r\n  def __init__(self):\r\n    super().__init__()\r\n    self.model = torch.nn.LSTM(input_size=512, hidden_size=128, batch_first=True)\r\n\r\n  def forward(self, input, hx, cx):\r\n    return self.model(input, (hx, cx))\r\n\r\n# Instantiate\r\nm = MyLSTM()\r\n\r\n# Create samples/names for exporter\r\ninput_sample = torch.randn((1,1,512))\r\nhidden_sample = torch.randn((1,1,128))\r\ncs_sample = torch.randn((1,1,128))\r\ninput_names = [\"input\", \"hidden_0\", \"cell_st_0\"]\r\noutput_names = [\"output\", \"hidden_1\", \"cell_st_1\"]\r\n\r\n# Export to ONNX\r\ntorch.onnx.export(m, (input_sample, hidden_sample, cs_sample),\r\n                  \"./LSTM.float.onnx\", input_names=input_names, \r\n                  output_names=output_names)\r\n\r\n\r\n# fake data for onnx quantizer to calibrate on\r\nclass PsuedoData(CalibrationDataReader):\r\n\r\n    def __init__(self, size):\r\n        super().__init__()\r\n        self.size = size\r\n        self.it = 0\r\n\r\n        \r\n    def get_next(self):\r\n        self.it += 1\r\n        if self.it == self.size:\r\n            return None\r\n        else:          \r\n            return {'input':np.random.random((1,1,512)).astype(np.int8),\r\n                    'hidden_0':np.random.random((1,1,128)).astype(np.int8),\r\n                    'cell_st_0':np.random.random((1,1,128)).astype(np.int8)\r\n                   }\r\n\r\n# Instantiate\r\ncali_data = PsuedoData(size=1000)\r\n\r\n# Quantize\r\nquantize_static(\"./LSTM.float.onnx\", \"/LSTM.quant.onnx\", cali_data)\r\n```\r\n\r\nI have also used float32 data in the calibration dataset. The model successfully quantizes. However I still get the error when I try to use INT8 data on the quantized model. Any suggestions?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10100/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10099",
        "id": 1086021536,
        "node_id": "I_kwDOCVq1mM5Au1-g",
        "number": 10099,
        "title": "ReduceMean consumes an unreasonable amount of VRAM",
        "user": {
            "login": "ponbaton",
            "id": 17086180,
            "node_id": "MDQ6VXNlcjE3MDg2MTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/17086180?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ponbaton",
            "html_url": "https://github.com/ponbaton",
            "followers_url": "https://api.github.com/users/ponbaton/followers",
            "following_url": "https://api.github.com/users/ponbaton/following{/other_user}",
            "gists_url": "https://api.github.com/users/ponbaton/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ponbaton/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ponbaton/subscriptions",
            "organizations_url": "https://api.github.com/users/ponbaton/orgs",
            "repos_url": "https://api.github.com/users/ponbaton/repos",
            "events_url": "https://api.github.com/users/ponbaton/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ponbaton/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T16:44:00Z",
        "updated_at": "2021-12-21T18:36:50Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nReduceMean allocates 4x the amount of memory of the input size.\r\n\r\nExample: (4, 128, 1024, 1024) float32 tensor with reduction along axes 0, 2, 3 should require memory for 128 floats.\r\n\r\nInstead it tries to allocate 8GB of space (which is 4x the input size) and fails with the following error:\r\n\r\n```\r\n[E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running ReduceMean node. Name:'op' Status Message: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:331 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool) Failed to allocate memory for requested buffer of size 8589934592\r\n```\r\n\r\n**Urgency**\r\n\r\nUrgent. This breaks testing several models with the required batch size.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.7\r\n- Visual Studio version (if applicable): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: GTX 1080Ti, 11GB\r\n\r\n**To Reproduce**\r\n\r\nRun the following code\r\n\r\n```python\r\nimport numpy as np\r\nimport onnx\r\nimport onnxruntime as ort\r\n\r\n\r\nFEATURE_MAP_SHAPE = (128, 1024, 1024)\r\n\r\n\r\ndef create_onnx_model():\r\n    # Size is (batch_size / 2) GB\r\n    input_proto = onnx.helper.make_tensor_value_info('x', onnx.TensorProto.FLOAT, [None, *FEATURE_MAP_SHAPE])\r\n    output_proto = onnx.helper.make_tensor_value_info('y', onnx.TensorProto.FLOAT, [1, FEATURE_MAP_SHAPE[0], 1, 1])\r\n\r\n    node_def = onnx.helper.make_node(\r\n        'ReduceMean',\r\n        inputs=[input_proto.name],\r\n        outputs=[output_proto.name],\r\n        name='op',\r\n        axes=(0, 2, 3),\r\n    )\r\n\r\n    graph_def = onnx.helper.make_graph(\r\n        nodes=[node_def],\r\n        name='test-model',\r\n        inputs=[input_proto],\r\n        outputs=[output_proto],\r\n    )\r\n\r\n    model_def = onnx.helper.make_model(graph_def, producer_name='onnx-example')\r\n    model_def.ir_version = 4\r\n    model_def.opset_import[0].version = 11\r\n\r\n    onnx.checker.check_model(model_def, full_check=True)\r\n\r\n    onnx.save_model(model_def, 'test.onnx')\r\n\r\n    return ort.InferenceSession('test.onnx', providers=['CUDAExecutionProvider'])\r\n\r\n\r\nmodel = create_onnx_model()\r\nbatch_size = 4\r\nx = np.zeros((batch_size, *FEATURE_MAP_SHAPE), np.float32)\r\nmodel.run(None, {'x': x})[0].shape\r\n```\r\n\r\nSee the attached Jupyter notebook for a complete runnable example: [reducemean_demo.zip](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)\r\n\r\n**Expected behavior**\r\n\r\nIn the attached example `batch_size` close to 20 should be possible, as in PyTorch (see [the same notebook](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)).\r\n\r\nI. e. ReduceMean should only require the same amount of memory as its output for operation.\r\n\r\n**Screenshots**\r\nNone\r\n\r\n**Additional context**\r\nA runnable example: [reducemean_demo.zip](https://github.com/microsoft/onnxruntime/files/7756795/reducemean_demo.zip)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10099/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10098",
        "id": 1085930215,
        "node_id": "I_kwDOCVq1mM5Aufrn",
        "number": 10098,
        "title": "Problem loading Scikit-Learn Pipeline With DictVectorizer",
        "user": {
            "login": "dafajon",
            "id": 25409216,
            "node_id": "MDQ6VXNlcjI1NDA5MjE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/25409216?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dafajon",
            "html_url": "https://github.com/dafajon",
            "followers_url": "https://api.github.com/users/dafajon/followers",
            "following_url": "https://api.github.com/users/dafajon/following{/other_user}",
            "gists_url": "https://api.github.com/users/dafajon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dafajon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dafajon/subscriptions",
            "organizations_url": "https://api.github.com/users/dafajon/orgs",
            "repos_url": "https://api.github.com/users/dafajon/repos",
            "events_url": "https://api.github.com/users/dafajon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dafajon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1220611565,
                "node_id": "MDU6TGFiZWwxMjIwNjExNTY1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:converter",
                "name": "component:converter",
                "color": "303a93",
                "default": false,
                "description": "related to ONNX converters"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "xadupre",
                "id": 22452781,
                "node_id": "MDQ6VXNlcjIyNDUyNzgx",
                "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xadupre",
                "html_url": "https://github.com/xadupre",
                "followers_url": "https://api.github.com/users/xadupre/followers",
                "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
                "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
                "organizations_url": "https://api.github.com/users/xadupre/orgs",
                "repos_url": "https://api.github.com/users/xadupre/repos",
                "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xadupre/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 10,
        "created_at": "2021-12-21T15:07:13Z",
        "updated_at": "2022-01-19T19:21:58Z",
        "closed_at": "2022-01-19T19:21:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have a pipeline serialized via `skl2onnx` converter.\r\n```python\r\npipeline = Pipeline([('feat', DictVectorizer(sparse=False)), ('dt', RandomForestClassifier())])\r\n```\r\n\r\nWhich ingests span based features to work as a sentence boundary detection model as follows:\r\n```python\r\n [{'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, {'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, {'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}, ... ,{'PREV_ALL_LOWER': True, 'ALL_LOWER': True, 'NEXT_ALL_LOWER': True}]\r\n```\r\n\r\nKeys are of type `string` and values are `bool`.\r\n\r\nThe model is serialized with `skl2onnx` as follows.\r\n\r\n```python\r\ninitial_type = [('boolean_input', DictionaryType(StringTensorType([1]), BooleanTensorType([1])))]\r\nonx = convert_sklearn(pipeline, initial_types=initial_type)\r\n```\r\n\r\nUpon loading, I have the following error:\r\n\r\n```bash\r\nInvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from /Users/dorukhanafacan/sadedegel/sadedegel/ml/model/sbd.onnx failed:This is an invalid model. Type Error: Type 'map(string,tensor(bool))' of input parameter (boolean_input) of operator (DictVectorizer) in node (DictVectorizer) is invalid.\r\n```\r\n\r\nI tried again also with `StringType` for key but had the same issue. Loading models with `DictionaryType` initilalized with other key, value types returned different issues since they are not compatible with the input type the model is trained on. However `InvalidGraph` is not encountered with them.\r\n\r\n**Urgency**\r\nDelaying the next release of our [library](https://github.com/GlobalMaksimum/sadedegel)\r\n\r\n**System information**\r\n- OS Platform and Distribution: MacOS 10.14.2\r\n- ONNX Runtime installed from (source or binary): PyPI 1.10.0\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.12\r\n- Visual Studio version (if applicable): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10098/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10097",
        "id": 1085768792,
        "node_id": "I_kwDOCVq1mM5At4RY",
        "number": 10097,
        "title": "Why it is not possible to `pickle` an `InferenceSession` object?",
        "user": {
            "login": "igaloly",
            "id": 38460810,
            "node_id": "MDQ6VXNlcjM4NDYwODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/38460810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/igaloly",
            "html_url": "https://github.com/igaloly",
            "followers_url": "https://api.github.com/users/igaloly/followers",
            "following_url": "https://api.github.com/users/igaloly/following{/other_user}",
            "gists_url": "https://api.github.com/users/igaloly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/igaloly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/igaloly/subscriptions",
            "organizations_url": "https://api.github.com/users/igaloly/orgs",
            "repos_url": "https://api.github.com/users/igaloly/repos",
            "events_url": "https://api.github.com/users/igaloly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/igaloly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:enhancement",
                "name": "type:enhancement",
                "color": "a2eeef",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T12:12:46Z",
        "updated_at": "2021-12-28T05:40:52Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Why it is not possible to `pickle` an `InferenceSession` object?\r\nAs I understand, this is because it's a CPP binding. Why it is a challenge? What will make it possible?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10097/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10096",
        "id": 1085638486,
        "node_id": "I_kwDOCVq1mM5AtYdW",
        "number": 10096,
        "title": "segmentation fault when get subgraph in tensorrt provider",
        "user": {
            "login": "RELOAD22",
            "id": 37140865,
            "node_id": "MDQ6VXNlcjM3MTQwODY1",
            "avatar_url": "https://avatars.githubusercontent.com/u/37140865?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RELOAD22",
            "html_url": "https://github.com/RELOAD22",
            "followers_url": "https://api.github.com/users/RELOAD22/followers",
            "following_url": "https://api.github.com/users/RELOAD22/following{/other_user}",
            "gists_url": "https://api.github.com/users/RELOAD22/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RELOAD22/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RELOAD22/subscriptions",
            "organizations_url": "https://api.github.com/users/RELOAD22/orgs",
            "repos_url": "https://api.github.com/users/RELOAD22/repos",
            "events_url": "https://api.github.com/users/RELOAD22/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RELOAD22/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to TensorRT EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T09:49:55Z",
        "updated_at": "2021-12-23T05:33:54Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nsegmentation fault when get subgraph in tensorrt provider. \r\nThis error occurs when i process a onnx model with multiple graphs. This model has a node called 'IF_312' which connects the other two graphs. \r\nNode 'IF_312': input(name: 436 type: boolean[1]), output(name: 437 type: float32[64,64])\r\nNode 'Add_299': output(name: 420 type: float32[1,64,64])\r\nThe following part of the code will have a bug when processing node 'Add_299':\r\nhttps://github.com/microsoft/onnxruntime/blob/7a1bdc2052bca1b4073229fee71123976731b866/onnxruntime/core/providers/tensorrt/tensorrt_execution_provider.cc#L748-L751\r\nAdd_299's output(420) is the input of the node in the subgraph connected by IF_312.    [torch-jit-export1 is then/else branch of Node 'IF_312'. torch-jit-export1 has Node 'Squeeze_313', which has input(name: 420).]\r\nWhen processing Node Add_299, one of it->GetNode() is IF_312.  it->GetDstArgIndex() is out of range, because Node 'IF_312' has no corresponding InputDefs. However, it->GetNode().ImplicitInputDefs() has the input def of 420.\r\n\r\nI use the following code to replace L751, and then this function can work(no error)\r\n`int inputdef_size = (int)((it->GetNode()).InputDefs().size());`\r\n`const auto& output = (it->GetDstArgIndex() < inputdef_size)?((it->GetNode()).InputDefs()[it->GetDstArgIndex()]) : (it->GetNode().ImplicitInputDefs()[it->GetDstArgIndex() - inputdef_size]);`\r\nhttps://github.com/microsoft/onnxruntime/blob/7a1bdc2052bca1b4073229fee71123976731b866/onnxruntime/core/providers/tensorrt/tensorrt_execution_provider.cc#L751\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n[model.onnx.zip](https://github.com/microsoft/onnxruntime/files/7751296/model.onnx.zip)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10096/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10095",
        "id": 1085558755,
        "node_id": "I_kwDOCVq1mM5AtE_j",
        "number": 10095,
        "title": "Memory leak",
        "user": {
            "login": "se7enXF",
            "id": 33513042,
            "node_id": "MDQ6VXNlcjMzNTEzMDQy",
            "avatar_url": "https://avatars.githubusercontent.com/u/33513042?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/se7enXF",
            "html_url": "https://github.com/se7enXF",
            "followers_url": "https://api.github.com/users/se7enXF/followers",
            "following_url": "https://api.github.com/users/se7enXF/following{/other_user}",
            "gists_url": "https://api.github.com/users/se7enXF/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/se7enXF/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/se7enXF/subscriptions",
            "organizations_url": "https://api.github.com/users/se7enXF/orgs",
            "repos_url": "https://api.github.com/users/se7enXF/repos",
            "events_url": "https://api.github.com/users/se7enXF/events{/privacy}",
            "received_events_url": "https://api.github.com/users/se7enXF/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-21T08:19:39Z",
        "updated_at": "2021-12-24T06:29:15Z",
        "closed_at": "2021-12-24T06:29:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\nLoop to run session.run cause memory leak  \r\n```python\r\ninput_info = self.preprocess(img_rgb)\r\noutput_res = self.session.run([self.output_name], input_info)[0]\r\n# output_res = np.array([[2, 0.98, 0, 0, 400, 400]])\r\nouts = self.parse_det_results(output_res, threshold, max_det_results)\r\n```\r\ncode likes upper, commont 'np.array' line, run 'session.run' will get memory leak. uncomment 'np.array' line and comment\r\n'self.session.run' line  will process normal.  'self.session' is init at script start by 'onnxruntime.InferenceSession'. \r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary):pip install \r\n- ONNX Runtime version: gpu-1.10.0\r\n- Python version:python3.8\r\n- CUDA/cuDNN version:cuda11/cudnn8.0\r\n- GPU model and memory:Tesla T4 6G\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10095/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10094",
        "id": 1085385095,
        "node_id": "I_kwDOCVq1mM5AsamH",
        "number": 10094,
        "title": "error: nodiscard : onnxruntime DNNL/1DNN",
        "user": {
            "login": "Datta0",
            "id": 39181234,
            "node_id": "MDQ6VXNlcjM5MTgxMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/39181234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Datta0",
            "html_url": "https://github.com/Datta0",
            "followers_url": "https://api.github.com/users/Datta0/followers",
            "following_url": "https://api.github.com/users/Datta0/following{/other_user}",
            "gists_url": "https://api.github.com/users/Datta0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Datta0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Datta0/subscriptions",
            "organizations_url": "https://api.github.com/users/Datta0/orgs",
            "repos_url": "https://api.github.com/users/Datta0/repos",
            "events_url": "https://api.github.com/users/Datta0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Datta0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1630303001,
                "node_id": "MDU6TGFiZWwxNjMwMzAzMDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:DNNL",
                "name": "ep:DNNL",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to DNNL EP"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T03:01:10Z",
        "updated_at": "2022-01-03T04:27:01Z",
        "closed_at": "2022-01-03T04:27:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhile trying to build onnxruntime for oneDNN for source using the command `./build.sh --enable_training --use_dnnl` , it throws the error.\r\n\r\n**System information**\r\n- OS Platform and Distribution : CentOS 7\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: N/A\r\n- Python version: 3.9.5\r\n- Visual Studio version (if applicable):N/A\r\n- GCC/Compiler version (if compiling from source): 9.2.0\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: No GPU\r\n\r\n**To Reproduce**\r\n- Clone the repo https://github.com/microsoft/onnxruntime\r\n- Run `./build.sh --enable_training --use_dnnl`\r\n\r\n\r\n**Console output**\r\n```\r\n > $ which gcc\r\n~/GCC-9.2.0/bin/gcc\r\n > $ which g++\r\n~/GCC-9.2.0/bin/g++\r\n > $ g++ --version\r\ng++ (GCC) 9.2.0\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n > $ ./build.sh --enable_training --use_dnnl\r\n2021-12-20 18:52:55,408 tools_python_utils [INFO] - flatbuffers module is not installed. parse_config will not be available\r\n2021-12-20 18:52:55,409 build [DEBUG] - Command line arguments:\r\n  --build_dir /home/nimmaturi.venkatadat/onnxruntime/build/Linux --enable_training --use_dnnl\r\n2021-12-20 18:52:55,416 build [DEBUG] - Defaulting to running update, build [and test for native builds].\r\n2021-12-20 18:52:55,416 build [INFO] - Build started\r\n2021-12-20 18:52:55,416 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  git submodule sync --recursive\r\nSynchronizing submodule url for 'cmake/external/SafeInt/safeint'\r\nSynchronizing submodule url for 'cmake/external/coremltools'\r\nSynchronizing submodule url for 'cmake/external/cub'\r\nSynchronizing submodule url for 'cmake/external/cxxopts'\r\nSynchronizing submodule url for 'cmake/external/date'\r\nSynchronizing submodule url for 'cmake/external/dlpack'\r\nSynchronizing submodule url for 'cmake/external/eigen'\r\nSynchronizing submodule url for 'cmake/external/emsdk'\r\nSynchronizing submodule url for 'cmake/external/flatbuffers'\r\nSynchronizing submodule url for 'cmake/external/googlebenchmark'\r\nSynchronizing submodule url for 'cmake/external/googletest'\r\nSynchronizing submodule url for 'cmake/external/json'\r\nSynchronizing submodule url for 'cmake/external/libprotobuf-mutator'\r\nSynchronizing submodule url for 'cmake/external/mimalloc'\r\nSynchronizing submodule url for 'cmake/external/mp11'\r\nSynchronizing submodule url for 'cmake/external/nsync'\r\nSynchronizing submodule url for 'cmake/external/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnxruntime-extensions'\r\nSynchronizing submodule url for 'cmake/external/protobuf'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/googletest'\r\nSynchronizing submodule url for 'cmake/external/pytorch_cpuinfo'\r\nSynchronizing submodule url for 'cmake/external/re2'\r\nSynchronizing submodule url for 'cmake/external/tensorboard'\r\nSynchronizing submodule url for 'cmake/external/tvm'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/HalideIR'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dlpack'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dmlc-core'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/rang'\r\nSynchronizing submodule url for 'cmake/external/tvm_update'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/cutlass'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/dlpack'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/dmlc-core'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/libbacktrace'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/rang'\r\nSynchronizing submodule url for 'cmake/external/tvm_update/3rdparty/vta-hw'\r\nSynchronizing submodule url for 'cmake/external/wil'\r\nSynchronizing submodule url for 'server/external/spdlog'\r\n2021-12-20 18:52:57,413 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:52:57,414 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  git submodule update --init --recursive\r\n2021-12-20 18:53:00,243 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:53:00,243 build [INFO] - Generating CMake build tree\r\n2021-12-20 18:53:00,244 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug'\r\n  /usr/local/bin/cmake /home/nimmaturi.venkatadat/onnxruntime/cmake -Donnxruntime_RUN_ONNX_TESTS=OFF -Donnxruntime_BUILD_WINML_TESTS=ON -Donnxruntime_GENERATE_TEST_REPORTS=ON -DPython_EXECUTABLE=/home/nimmaturi.venkatadat/anaconda3/bin/python3 -DPYTHON_EXECUTABLE=/home/nimmaturi.venkatadat/anaconda3/bin/python3 -Donnxruntime_ROCM_VERSION= -Donnxruntime_USE_MIMALLOC=OFF -Donnxruntime_ENABLE_PYTHON=OFF -Donnxruntime_BUILD_CSHARP=OFF -Donnxruntime_BUILD_JAVA=OFF -Donnxruntime_BUILD_NODEJS=OFF -Donnxruntime_BUILD_OBJC=OFF -Donnxruntime_BUILD_SHARED_LIB=OFF -Donnxruntime_BUILD_APPLE_FRAMEWORK=OFF -Donnxruntime_USE_DNNL=ON -Donnxruntime_DNNL_GPU_RUNTIME= -Donnxruntime_DNNL_OPENCL_ROOT= -Donnxruntime_USE_NNAPI_BUILTIN=OFF -Donnxruntime_USE_RKNPU=OFF -Donnxruntime_USE_OPENMP=OFF -Donnxruntime_USE_TVM=OFF -Donnxruntime_USE_LLVM=OFF -Donnxruntime_ENABLE_MICROSOFT_INTERNAL=OFF -Donnxruntime_USE_VITISAI=OFF -Donnxruntime_USE_NUPHAR=OFF -Donnxruntime_USE_TENSORRT=OFF -Donnxruntime_TENSORRT_HOME= -Donnxruntime_USE_STVM=OFF -Donnxruntime_STVM_HOME=/home/nimmaturi.venkatadat/onnxruntime/cmake/external/tvm_update -Donnxruntime_USE_MIGRAPHX=OFF -Donnxruntime_MIGRAPHX_HOME= -Donnxruntime_CROSS_COMPILING=OFF -Donnxruntime_DISABLE_CONTRIB_OPS=OFF -Donnxruntime_DISABLE_ML_OPS=OFF -Donnxruntime_DISABLE_RTTI=OFF -Donnxruntime_DISABLE_EXCEPTIONS=OFF -Donnxruntime_MINIMAL_BUILD=OFF -Donnxruntime_EXTENDED_MINIMAL_BUILD=OFF -Donnxruntime_MINIMAL_BUILD_CUSTOM_OPS=OFF -Donnxruntime_REDUCED_OPS_BUILD=OFF -Donnxruntime_REDUCED_OP_TYPE_SUPPORT=OFF -Donnxruntime_ENABLE_LANGUAGE_INTEROP_OPS=OFF -Donnxruntime_USE_DML=OFF -Donnxruntime_USE_WINML=OFF -Donnxruntime_BUILD_MS_EXPERIMENTAL_OPS=OFF -Donnxruntime_USE_TELEMETRY=OFF -Donnxruntime_ENABLE_LTO=OFF -Donnxruntime_ENABLE_TRANSFORMERS_TOOL_TEST=OFF -Donnxruntime_USE_ACL=OFF -Donnxruntime_USE_ACL_1902=OFF -Donnxruntime_USE_ACL_1905=OFF -Donnxruntime_USE_ACL_1908=OFF -Donnxruntime_USE_ACL_2002=OFF -Donnxruntime_USE_ARMNN=OFF -Donnxruntime_ARMNN_RELU_USE_CPU=ON -Donnxruntime_ARMNN_BN_USE_CPU=ON -Donnxruntime_ENABLE_NVTX_PROFILE=OFF -Donnxruntime_ENABLE_TRAINING=ON -Donnxruntime_ENABLE_TRAINING_OPS=OFF -Donnxruntime_ENABLE_TRAINING_TORCH_INTEROP=OFF -Donnxruntime_ENABLE_CPU_FP16_OPS=ON -Donnxruntime_USE_NCCL=ON -Donnxruntime_BUILD_BENCHMARKS=OFF -Donnxruntime_USE_ROCM=OFF -Donnxruntime_ROCM_HOME= -DOnnxruntime_GCOV_COVERAGE=OFF -Donnxruntime_USE_MPI=ON -Donnxruntime_ENABLE_MEMORY_PROFILE=OFF -Donnxruntime_ENABLE_CUDA_LINE_NUMBER_INFO=OFF -Donnxruntime_BUILD_WEBASSEMBLY=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_SIMD=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_EXCEPTION_CATCHING=ON -Donnxruntime_ENABLE_WEBASSEMBLY_EXCEPTION_THROWING=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_THREADS=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_DEBUG_INFO=OFF -Donnxruntime_ENABLE_WEBASSEMBLY_PROFILING=OFF -Donnxruntime_WEBASSEMBLY_MALLOC=dlmalloc -Donnxruntime_ENABLE_EAGER_MODE=OFF -Donnxruntime_ENABLE_EXTERNAL_CUSTOM_OP_SCHEMAS=OFF -Donnxruntime_NVCC_THREADS=1 -Donnxruntime_ENABLE_CUDA_PROFILING=OFF -Donnxruntime_DEV_MODE=ON -Donnxruntime_PYBIND_EXPORT_OPSCHEMA=OFF -Donnxruntime_ENABLE_MEMLEAK_CHECKER=ON -DCMAKE_BUILD_TYPE=Debug\r\nBuilding ONNX Runtime for x86_64\r\nUse gtest from submodule\r\n-- Found Python: /home/nimmaturi.venkatadat/anaconda3/bin/python3 (found version \"3.9.7\") found components: Interpreter\r\nUse protobuf from submodule\r\n--\r\n-- 3.16.0.0\r\n-- Using the single-header code from /home/nimmaturi.venkatadat/onnxruntime/cmake/external/json/single_include/\r\nNVCC_ERROR =\r\nNVCC_OUT = No such file or directory\r\n-- Found PythonInterp: /home/nimmaturi.venkatadat/anaconda3/bin/python3 (found version \"3.9.7\")\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\nGenerated: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\n--\r\n-- ******** Summary ********\r\n--   CMake version             : 3.22.1\r\n--   CMake command             : /usr/local/bin/cmake\r\n--   System                    : Linux\r\n--   C++ compiler              : /usr/bin/c++\r\n--   C++ compiler version      : 4.8.5\r\n--   CXX flags                 :  -ffunction-sections -fdata-sections -DCPUINFO_SUPPORTED -Wnon-virtual-dtor\r\n--   Build type                : Debug\r\n--   Compile definitions       : EIGEN_MPL2_ONLY;ENABLE_CPU_FP16_TRAINING_OPS;PLATFORM_POSIX;__STDC_FORMAT_MACROS\r\n--   CMAKE_PREFIX_PATH         :\r\n--   CMAKE_INSTALL_PREFIX      : /usr/local\r\n--   CMAKE_MODULE_PATH         : /home/nimmaturi.venkatadat/onnxruntime/cmake/external\r\n--\r\n--   ONNX version              : 1.10.1\r\n--   ONNX NAMESPACE            : onnx\r\n--   ONNX_USE_LITE_PROTO       : ON\r\n--   USE_PROTOBUF_SHARED_LIBS  : OFF\r\n--   Protobuf_USE_STATIC_LIBS  : ON\r\n--   ONNX_DISABLE_EXCEPTIONS   : OFF\r\n--   ONNX_WERROR               : OFF\r\n--   ONNX_BUILD_TESTS          : OFF\r\n--   ONNX_BUILD_BENCHMARKS     : OFF\r\n--   ONNXIFI_DUMMY_BACKEND     : OFF\r\n--   ONNXIFI_ENABLE_EXT        : OFF\r\n--\r\n--   Protobuf compiler         :\r\n--   Protobuf includes         :\r\n--   Protobuf libraries        :\r\n--   BUILD_ONNX_PYTHON         : OFF\r\n-- Found MPI_C: /home/nimmaturi.venkatadat/anaconda3/lib/libmpi.so (found version \"3.1\")\r\n-- Could NOT find MPI_CXX (missing: MPI_CXX_WORKS)\r\n-- Could NOT find MPI (missing: MPI_CXX_FOUND) (found version \"3.1\")\r\nCMake Warning at CMakeLists.txt:1723 (message):\r\n  MPI is not found.  Please define onnxruntime_MPI_HOME to specify the path\r\n  of MPI.  Otherwise, NCCL will be disabled.\r\n\r\n\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug\r\n2021-12-20 18:53:02,321 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-12-20 18:53:02,322 build [INFO] - Building targets for Debug configuration\r\n2021-12-20 18:53:02,322 util.run [INFO] - Running subprocess in '/home/nimmaturi.venkatadat/onnxruntime'\r\n  /usr/local/bin/cmake --build /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug --config Debug\r\n[  0%] Performing update step for 'project_dnnl'\r\n[  0%] No patch step for 'project_dnnl'\r\n[  0%] Performing configure step for 'project_dnnl'\r\n-- DNNL_LIBRARY_NAME: dnnl\r\n-- Could NOT find Doxyrest (missing: DOXYREST_EXECUTABLE)\r\n-- Enabled workload: TRAINING\r\n-- Enabled primitives: ALL\r\n-- Primitive cache is enabled\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/src/project_dnnl-build\r\n[  1%] Performing build step for 'project_dnnl'\r\nConsolidate compiler generated dependencies of target dnnl_cpu_x64\r\n[ 59%] Built target dnnl_cpu_x64\r\nConsolidate compiler generated dependencies of target dnnl_common\r\n[ 72%] Built target dnnl_common\r\nConsolidate compiler generated dependencies of target dnnl_cpu\r\n[ 98%] Built target dnnl_cpu\r\n[100%] Built target dnnl\r\n[100%] Built target compat_libs\r\n[100%] Built target compat_libs.2\r\n[100%] Built target compat_libs.2.4\r\n[  1%] Performing install step for 'project_dnnl'\r\n[ 59%] Built target dnnl_cpu_x64\r\n[ 72%] Built target dnnl_common\r\n[ 98%] Built target dnnl_cpu\r\n[100%] Built target dnnl\r\n[100%] Built target compat_libs\r\n[100%] Built target compat_libs.2\r\n[100%] Built target compat_libs.2.4\r\nInstall the project...\r\n-- Install configuration: \"Debug\"\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_dnnl_programming_flow.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_programming_model.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_dnnl_object_snapshot.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/conf.py\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_padded_blk.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_singlescalar.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_training_inference_scope.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_img2.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_bf16_diagram.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/strides.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_depthwise_fusion.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_blk.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_diagram.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/unrolled_stack_rnn.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_multiscalar.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_overview_flow.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/mem_fmt_img1.png\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/rst/img_inference_scope.jpg\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/reference/html\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so.2.4\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so.2\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libdnnl.so\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_ocl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_ocl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_sycl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_threadpool_iface.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/dnnl_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_dnnl_mangling.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/mkldnn_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_debug.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_ocl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_sycl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_threadpool_iface.hpp\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_types.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_config.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/include/oneapi/dnnl/dnnl_version.h\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-config.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-config-version.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-targets.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/cmake/dnnl/dnnl-targets-debug.cmake\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so.2\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/lib64/libmkldnn.so.2.4\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/LICENSE\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/THIRD-PARTY-PROGRAMS\r\n-- Up-to-date: /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/dnnl/install/share/doc/dnnl/README\r\n[  1%] Completed 'project_dnnl'\r\n[  1%] Built target project_dnnl\r\nConsolidate compiler generated dependencies of target flatbuffers\r\n[  1%] Built target flatbuffers\r\nConsolidate compiler generated dependencies of target clog\r\n[  1%] Built target clog\r\nConsolidate compiler generated dependencies of target cpuinfo\r\n[  2%] Built target cpuinfo\r\nConsolidate compiler generated dependencies of target libprotobuf\r\n[  8%] Built target libprotobuf\r\nConsolidate compiler generated dependencies of target libprotoc\r\n[ 14%] Built target libprotoc\r\nConsolidate compiler generated dependencies of target protoc\r\n[ 14%] Built target protoc\r\n[ 14%] Running gen_proto.py on onnx/onnx.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_pb.py\r\n[ 14%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-ml.proto\r\n[ 14%] Built target gen_onnx_proto\r\n[ 14%] Running gen_proto.py on onnx/onnx-data.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx-data.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_data_pb.py\r\n[ 14%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-data.proto\r\n[ 14%] Built target gen_onnx_data_proto\r\nConsolidate compiler generated dependencies of target libprotobuf-lite\r\n[ 16%] Built target libprotobuf-lite\r\n[ 16%] Running gen_proto.py on onnx/onnx-operators.in.proto\r\nProcessing /home/nimmaturi.venkatadat/onnxruntime/cmake/external/onnx/onnx/onnx-operators.in.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\nWriting /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto3\r\ngenerating /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx_operators_pb.py\r\n[ 16%] Running C++ protocol buffer compiler on /home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug/external/onnx/onnx/onnx-operators-ml.proto\r\n[ 16%] Built target gen_onnx_operators_proto\r\nConsolidate compiler generated dependencies of target onnx_proto\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-ml.pb.cc.o\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-operators-ml.pb.cc.o\r\n[ 16%] Building CXX object external/onnx/CMakeFiles/onnx_proto.dir/onnx/onnx-data.pb.cc.o\r\n[ 16%] Linking CXX static library libonnx_proto.a\r\n[ 16%] Built target onnx_proto\r\n[ 16%] Building CXX object CMakeFiles/onnxruntime_common.dir/home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc.o\r\nIn file included from /home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/common.h:37:0,\r\n                 from /home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.h:6,\r\n                 from /home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc:22:\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h: In function constexpr const char* onnxruntime::common::StatusCodeToString(onnxruntime::common::StatusCode):\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h:79:1: error: body of constexpr function constexpr const char* onnxruntime::common::StatusCodeToString(onnxruntime::common::StatusCode) not a return-statement\r\n }\r\n ^\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h: At global scope:\r\n/home/nimmaturi.venkatadat/onnxruntime/include/onnxruntime/core/common/status.h:114:21: error: nodiscard attribute directive ignored [-Werror=attributes]\r\n class [[nodiscard]] Status {\r\n                     ^\r\ncc1plus: all warnings being treated as errors\r\ngmake[2]: *** [CMakeFiles/onnxruntime_common.dir/home/nimmaturi.venkatadat/onnxruntime/onnxruntime/core/common/cpuid_info.cc.o] Error 1\r\ngmake[1]: *** [CMakeFiles/onnxruntime_common.dir/all] Error 2\r\ngmake: *** [all] Error 2\r\nTraceback (most recent call last):\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 2391, in <module>\r\n    sys.exit(main())\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 2309, in main\r\n    build_targets(args, cmake_path, build_dir, configs, num_parallel_jobs, args.target)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 1192, in build_targets\r\n    run_subprocess(cmd_args, env=env)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/ci_build/build.py\", line 653, in run_subprocess\r\n    return run(*args, cwd=cwd, capture_stdout=capture_stdout, shell=shell, env=my_env)\r\n  File \"/home/nimmaturi.venkatadat/onnxruntime/tools/python/util/run.py\", line 42, in run\r\n    completed_process = subprocess.run(\r\n  File \"/home/nimmaturi.venkatadat/anaconda3/lib/python3.9/subprocess.py\", line 528, in run\r\n    raise CalledProcessError(retcode, process.args,\r\nsubprocess.CalledProcessError: Command '['/usr/local/bin/cmake', '--build', '/home/nimmaturi.venkatadat/onnxruntime/build/Linux/Debug', '--config', 'Debug']' returned non-zero exit status 2.\r\n\r\n> $\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10094/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10093",
        "id": 1085379904,
        "node_id": "PR_kwDOCVq1mM4wHAwb",
        "number": 10093,
        "title": "Update C/C++ API docs automation to create a PR (instead of push to publish branch)",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:documentation",
                "name": "component:documentation",
                "color": "303a93",
                "default": false,
                "description": "related to documentation"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-21T02:48:16Z",
        "updated_at": "2022-01-08T00:16:47Z",
        "closed_at": "2022-01-08T00:16:47Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10093",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10093",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10093.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10093.patch",
            "merged_at": "2022-01-08T00:16:47Z"
        },
        "body": "See staged PR here: https://github.com/natke/onnxruntime/pull/15\r\n\r\nThis action creates a (or adds to an existing) PR to update the C/C++ API docs to the latest master. \r\n\r\nThe original action failed because it is trying to commit to a protected branch (https://github.com/microsoft/onnxruntime/actions/runs/1565902647)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10093/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10092",
        "id": 1085333319,
        "node_id": "PR_kwDOCVq1mM4wG3dC",
        "number": 10092,
        "title": "Add build output directory to gitignore",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T01:02:34Z",
        "updated_at": "2021-12-30T19:27:35Z",
        "closed_at": "2021-12-30T19:27:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10092",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10092",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10092.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10092.patch",
            "merged_at": "2021-12-30T19:27:35Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10092/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10091",
        "id": 1085327713,
        "node_id": "PR_kwDOCVq1mM4wG2T1",
        "number": 10091,
        "title": "[website] Update customer quote section",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-21T00:48:58Z",
        "updated_at": "2022-01-03T21:42:47Z",
        "closed_at": "2022-01-03T21:42:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10091",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10091",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10091.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10091.patch",
            "merged_at": "2022-01-03T21:42:43Z"
        },
        "body": "Staged here for preview: https://faxu.github.io/onnxruntime/\r\n\r\nChanges:\r\n- update logo assets for sizing/spacing\r\n- update main page logo section to just icons\r\n- new page for quotes",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10091/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10090",
        "id": 1085299965,
        "node_id": "PR_kwDOCVq1mM4wGwgg",
        "number": 10090,
        "title": "Fix DecoderAttention's shape inference when input cache has dynamic shape",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T23:48:19Z",
        "updated_at": "2021-12-21T05:19:30Z",
        "closed_at": "2021-12-21T05:19:29Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10090",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10090",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10090.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10090.patch",
            "merged_at": "2021-12-21T05:19:29Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\nhttps://github.com/microsoft/onnxruntime/issues/10087 \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10090/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10089",
        "id": 1085260324,
        "node_id": "I_kwDOCVq1mM5Ar8Ik",
        "number": 10089,
        "title": "Python bindings give RuntimeError on multi input models",
        "user": {
            "login": "thomasahle",
            "id": 946355,
            "node_id": "MDQ6VXNlcjk0NjM1NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/946355?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thomasahle",
            "html_url": "https://github.com/thomasahle",
            "followers_url": "https://api.github.com/users/thomasahle/followers",
            "following_url": "https://api.github.com/users/thomasahle/following{/other_user}",
            "gists_url": "https://api.github.com/users/thomasahle/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thomasahle/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thomasahle/subscriptions",
            "organizations_url": "https://api.github.com/users/thomasahle/orgs",
            "repos_url": "https://api.github.com/users/thomasahle/repos",
            "events_url": "https://api.github.com/users/thomasahle/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thomasahle/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1195353125,
                "node_id": "MDU6TGFiZWwxMTk1MzUzMTI1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Python",
                "name": "api:Python",
                "color": "0e8a16",
                "default": false,
                "description": "related to the Python API"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-20T22:31:14Z",
        "updated_at": "2021-12-21T16:40:55Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nMy model takes two inputs\r\n\r\n    >>> print([o.name for o in ort_sess.get_inputs()])\r\n    ['priv', 'pub']\r\n\r\nWhen I run the model\r\n\r\n    >>> ort_sess.run(['value'], {'priv': priv, 'pub': pub})\r\n\r\nI get the stacktrace\r\n\r\n    File \"/Users/.../homebrew/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 192, in run\r\n        return self._sess.run(output_names, input_feed, run_options)\r\n    RuntimeError: Input must be a list of dictionaries or a single numpy array for input 'priv'.\r\n\r\nIt seems that the python bindings for onnxruntime doesn't support multi-input models?\r\n\r\nI also use the javascript bindings which work fine like this:\r\n\r\n       ... = await session.run({ priv: priv, pub: state });\r\n\r\n**Urgency**\r\nThis is completely blocking me from using my model in python.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Monterey 12.0.1\r\n- ONNX Runtime installed from (source or binary): homebrew\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.9",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10089/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10088",
        "id": 1085237751,
        "node_id": "PR_kwDOCVq1mM4wGjYM",
        "number": 10088,
        "title": "Generate native resources for all supported MacOS versions, not just 10.14",
        "user": {
            "login": "baronfel",
            "id": 573979,
            "node_id": "MDQ6VXNlcjU3Mzk3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/573979?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baronfel",
            "html_url": "https://github.com/baronfel",
            "followers_url": "https://api.github.com/users/baronfel/followers",
            "following_url": "https://api.github.com/users/baronfel/following{/other_user}",
            "gists_url": "https://api.github.com/users/baronfel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baronfel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baronfel/subscriptions",
            "organizations_url": "https://api.github.com/users/baronfel/orgs",
            "repos_url": "https://api.github.com/users/baronfel/repos",
            "events_url": "https://api.github.com/users/baronfel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baronfel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-12-20T21:58:24Z",
        "updated_at": "2022-01-07T22:00:08Z",
        "closed_at": "2022-01-07T21:42:49Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10088",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10088",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10088.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10088.patch",
            "merged_at": null
        },
        "body": "**Description**:\r\n\r\nThis changes the generated path for MacOS assets in the nuget package from `runtimes/osx.10.14-<arch>` to `/runtimes/osx-<arch>`, which allows users on more versions of MacOS to use the library. This brings the library back to parity with the layout of 1.8.1. This should fix #9707.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n  - this change is required because the current package layout doesn't support as many MacOS versions as it used to. I'm unsure if this is by design or by accident. Without this change, MacOS consumers on versions other than 10.14 experience runtime errors instead of compile-time errors.\r\n- If it fixes an open issue, please link to the issue here.\r\n  - the fixed issue would be #9707.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/reactions",
            "total_count": 2,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10088/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10087",
        "id": 1084864463,
        "node_id": "I_kwDOCVq1mM5AqbfP",
        "number": 10087,
        "title": "DecoderAttention kernel Shape Inference bug on dynamic axes",
        "user": {
            "login": "rom1K",
            "id": 91061498,
            "node_id": "MDQ6VXNlcjkxMDYxNDk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/91061498?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rom1K",
            "html_url": "https://github.com/rom1K",
            "followers_url": "https://api.github.com/users/rom1K/followers",
            "following_url": "https://api.github.com/users/rom1K/following{/other_user}",
            "gists_url": "https://api.github.com/users/rom1K/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rom1K/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rom1K/subscriptions",
            "organizations_url": "https://api.github.com/users/rom1K/orgs",
            "repos_url": "https://api.github.com/users/rom1K/repos",
            "events_url": "https://api.github.com/users/rom1K/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rom1K/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "wangyems",
                "id": 52801275,
                "node_id": "MDQ6VXNlcjUyODAxMjc1",
                "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wangyems",
                "html_url": "https://github.com/wangyems",
                "followers_url": "https://api.github.com/users/wangyems/followers",
                "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
                "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
                "organizations_url": "https://api.github.com/users/wangyems/orgs",
                "repos_url": "https://api.github.com/users/wangyems/repos",
                "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wangyems/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-20T14:37:01Z",
        "updated_at": "2021-12-21T23:10:09Z",
        "closed_at": "2021-12-21T23:10:09Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen specifying the past key and value in a `DecoderAttention` node, the shape inference fails if the batch size and sequence length are dynamic.\r\n\r\n\r\n**Urgency**\r\nDue to this bug the kernel is basically unusable, since you either must fix the batch size and sequence length, or not use the last key / value feature - which is the main feature of the kernel.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): binary (wheel)\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.9.9\r\n- Visual Studio version (if applicable): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: GeForce RTX 2060, 6GB\r\n\r\n**To Reproduce**\r\nI've created this GIST to exhibit the error\r\n-  [link](https://gist.github.com/rom1K/b9a1dbb313ce8cb1d53a188b170ed0cc)\r\n\r\n**Expected behavior**\r\nI expected dynamic shapes to be usable with the kernel, as is the case with the regular self-attention kernel.\r\n\r\n\r\n**Additional context**\r\nThe line raising the error is [here](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/graph/contrib_ops/contrib_defs.cc#L557). As we can see from this [line](https://github.com/microsoft/onnxruntime/blob/4e9e01cb3c008335a2471c27dbdf7dd5d12e4224/onnxruntime/core/graph/contrib_ops/contrib_defs.cc#L518) a bit above, which does the shape inference check for the older attention kernel, the check is done only on non-dynamic axis (number of heads and head size). \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/reactions",
            "total_count": 5,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10087/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10086",
        "id": 1084567022,
        "node_id": "I_kwDOCVq1mM5ApS3u",
        "number": 10086,
        "title": "Same Pad_Head value in ORT for SAME_UPPER/SAME_LOWER if get negative odd pad value",
        "user": {
            "login": "RunnerZhong",
            "id": 30307463,
            "node_id": "MDQ6VXNlcjMwMzA3NDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30307463?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RunnerZhong",
            "html_url": "https://github.com/RunnerZhong",
            "followers_url": "https://api.github.com/users/RunnerZhong/followers",
            "following_url": "https://api.github.com/users/RunnerZhong/following{/other_user}",
            "gists_url": "https://api.github.com/users/RunnerZhong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RunnerZhong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RunnerZhong/subscriptions",
            "organizations_url": "https://api.github.com/users/RunnerZhong/orgs",
            "repos_url": "https://api.github.com/users/RunnerZhong/repos",
            "events_url": "https://api.github.com/users/RunnerZhong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RunnerZhong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-12-20T09:37:59Z",
        "updated_at": "2021-12-21T02:41:35Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nImplementation code in ORT is as below:\r\n![image](https://user-images.githubusercontent.com/30307463/146745972-dcaac56f-e653-4015-bd21-623ee6acf8d0.png)\r\n\r\nFor below case, Input_shape = [1,3,500, 224], kernel=[5, 6], stride=[10,2], auto_pad = same_upper/lower\r\nAccording to ONNX op SPEC,\r\n\r\n> SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\r\n\r\n> pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\r\n\r\nwe got pad_h_value = -5.\r\n\r\nSo, \r\n*pad_head = (pad_needed + 1) / 2;    # pad_head = -2\r\n  \r\n*pad_head = pad_needed / 2;   # pad_head = -2 too\r\n\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10086/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10085",
        "id": 1084490640,
        "node_id": "PR_kwDOCVq1mM4wEHhN",
        "number": 10085,
        "title": "CUDA BFloat16 Refactor",
        "user": {
            "login": "iK1D",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iK1D",
            "html_url": "https://github.com/iK1D",
            "followers_url": "https://api.github.com/users/iK1D/followers",
            "following_url": "https://api.github.com/users/iK1D/following{/other_user}",
            "gists_url": "https://api.github.com/users/iK1D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iK1D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iK1D/subscriptions",
            "organizations_url": "https://api.github.com/users/iK1D/orgs",
            "repos_url": "https://api.github.com/users/iK1D/repos",
            "events_url": "https://api.github.com/users/iK1D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iK1D/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-core",
                "name": "component:training-core",
                "color": "303a93",
                "default": false,
                "description": "related to training core"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T08:19:02Z",
        "updated_at": "2022-01-14T11:38:57Z",
        "closed_at": "2022-01-14T11:38:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10085",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10085",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10085.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10085.patch",
            "merged_at": "2022-01-14T11:38:57Z"
        },
        "body": "Previous code casted BFloat16 to CUDA's nv_bfloat16 type for calculation, which required A100 to run because nv_bfloat16's calculation can run on A100 only. PyTorch uses its own type c10::BFloat16 for calculation. This PR is to refactor our code to follow the same idea to use our own onnxruntime::BFloat16 for calculation. The general implemtation is to cast BFloat16 to float for calculation, and use nv_bfloat16 on A100 using macro __CUDA_ARCH__ >= 800.\r\n\r\nWith this implementation, we can support BFloat16 on most of the Nvidia devices besides A100.\r\n\r\nTested the code using ORTModule in two ways (need latest nightly PyTorch and ONNX for some BFloat16 support):\r\n- Add cast to torch.bfloat16 in the Module, this can run on both V100 and A100, and can get same calculation results\r\n- Use torch.autocast. PyTorch supports BFloat16 autocast on A100 only. I tested both PyTorch and ORT using torch.autocast on A100 to run the BERT model from transformers. We can get the same result (ignoring the margin of error), and ORT's perf is better than PyTorch (same as autocast of Float16).\r\n\r\nNote that PyTorch also uses its own type c10::Float16 type for float16 calculation in CUDA, but ORT casts to CUDA's half type. This is OK as half is supported by most of the Nvidia devices. This PR doesn't torch any logic related to the float16 case.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10085/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10084",
        "id": 1084434667,
        "node_id": "PR_kwDOCVq1mM4wD78r",
        "number": 10084,
        "title": "aten add_ op supports bf16",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-20T07:05:44Z",
        "updated_at": "2022-01-05T17:33:29Z",
        "closed_at": "2022-01-05T17:33:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10084",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10084",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10084.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10084.patch",
            "merged_at": "2022-01-05T17:33:29Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\nUpdates the `aten::add_.Tensor` op to support `BFloat16` tensors.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\nThis is required to run bf16 models on the ORT eager device.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10084/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10083",
        "id": 1084317840,
        "node_id": "I_kwDOCVq1mM5AoWCQ",
        "number": 10083,
        "title": "MaxPool shape inference is NOT matched with ONNX OP SPEC ",
        "user": {
            "login": "RunnerZhong",
            "id": 30307463,
            "node_id": "MDQ6VXNlcjMwMzA3NDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/30307463?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RunnerZhong",
            "html_url": "https://github.com/RunnerZhong",
            "followers_url": "https://api.github.com/users/RunnerZhong/followers",
            "following_url": "https://api.github.com/users/RunnerZhong/following{/other_user}",
            "gists_url": "https://api.github.com/users/RunnerZhong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RunnerZhong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RunnerZhong/subscriptions",
            "organizations_url": "https://api.github.com/users/RunnerZhong/orgs",
            "repos_url": "https://api.github.com/users/RunnerZhong/repos",
            "events_url": "https://api.github.com/users/RunnerZhong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RunnerZhong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2235309445,
                "node_id": "MDU6TGFiZWwyMjM1MzA5NDQ1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:onnx",
                "name": "component:onnx",
                "color": "303a93",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-20T03:27:45Z",
        "updated_at": "2021-12-20T18:30:09Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nFrom ONNX OP specif I used auto_pad = Valid, the output shape is inferred as below:\r\n`VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\r\nSAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\r\n`\r\nAbove inference is not effected whether ceil_mode if set.\r\nBut from ONNXRUNTIME, I found the inference is different if ceil_mode is set or not.\r\n\r\n`int64_t ComputeOutputSize(int64_t in_size,\r\n                            int64_t stride,\r\n                            int64_t kernel,\r\n                            int64_t pad_needed,\r\n                            int64_t dilation) const {\r\n    if (ceil_mode == 0) {\r\n      return static_cast<int64_t>(static_cast<float>(in_size + pad_needed - dilation * (kernel - 1) - 1) / stride + 1);\r\n    }\r\n    return static_cast<int64_t>(\r\n        std::ceil(static_cast<float>(in_size + pad_needed - dilation * (kernel - 1) - 1) / stride + 1));\r\n  }`\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:\r\n- Python version:\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nClear And Matched behavior between ONNX op SPEC and ONNX Run Time\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10083/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10082",
        "id": 1084302042,
        "node_id": "I_kwDOCVq1mM5AoSLa",
        "number": 10082,
        "title": "how to use dynamic_quant to quantize an onnx model with custom op",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-20T03:01:53Z",
        "updated_at": "2021-12-21T01:57:26Z",
        "closed_at": "2021-12-21T01:57:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\nHi, I have a custom op, and i have register the op in onnxruntime.\r\nnow, I can use the api `opts.register_custom_ops_library(_lib_path(\"my_custom_op.so\"))` to load the .so file, and do inference on the model with this custom op.\r\nbut, when I try to quant the model with this custom op, I git an error:\r\n`onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from dfsmn_online.onnx failed:Fatal error: fsmn_forward is not a registered function/op`\r\nI am confused that how to add the build .so file to onnxruntime.quantization and quant the model\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n- 1.10.0\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\nquant the model with custom op \r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10082/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10081",
        "id": 1083857872,
        "node_id": "I_kwDOCVq1mM5AmlvQ",
        "number": 10081,
        "title": "Do threading settings have any effect on GPU EPs",
        "user": {
            "login": "admayber",
            "id": 44822281,
            "node_id": "MDQ6VXNlcjQ0ODIyMjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/44822281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/admayber",
            "html_url": "https://github.com/admayber",
            "followers_url": "https://api.github.com/users/admayber/followers",
            "following_url": "https://api.github.com/users/admayber/following{/other_user}",
            "gists_url": "https://api.github.com/users/admayber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/admayber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/admayber/subscriptions",
            "organizations_url": "https://api.github.com/users/admayber/orgs",
            "repos_url": "https://api.github.com/users/admayber/repos",
            "events_url": "https://api.github.com/users/admayber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/admayber/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-18T15:43:25Z",
        "updated_at": "2021-12-20T22:33:11Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm having trouble understanding the relationship between the ORT top-level thread settings - IntraOpNumThreads, InterOpNumThreads, ExecutionMode - and the GPU EPs (cuda and trt).\r\n\r\nI would normally assume those settings have no impact if running on GPU. However, they aren't attached as options on the CPU execution provider, they're top-level settings in the SessionOptions class in the cpp api, which implies to me that they're relevant regardless of EP (e.g., maybe they still have impact on the runtime orchestration when running cuda / trt). Is that true at all, or is it safe to ignore them if running in GPU?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10081/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10080",
        "id": 1083723150,
        "node_id": "PR_kwDOCVq1mM4wBwbP",
        "number": 10080,
        "title": "Coding style fix.",
        "user": {
            "login": "satyajandhyala",
            "id": 26722914,
            "node_id": "MDQ6VXNlcjI2NzIyOTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26722914?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/satyajandhyala",
            "html_url": "https://github.com/satyajandhyala",
            "followers_url": "https://api.github.com/users/satyajandhyala/followers",
            "following_url": "https://api.github.com/users/satyajandhyala/following{/other_user}",
            "gists_url": "https://api.github.com/users/satyajandhyala/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/satyajandhyala/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/satyajandhyala/subscriptions",
            "organizations_url": "https://api.github.com/users/satyajandhyala/orgs",
            "repos_url": "https://api.github.com/users/satyajandhyala/repos",
            "events_url": "https://api.github.com/users/satyajandhyala/events{/privacy}",
            "received_events_url": "https://api.github.com/users/satyajandhyala/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-18T02:13:57Z",
        "updated_at": "2021-12-18T20:05:49Z",
        "closed_at": "2021-12-18T20:05:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10080",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10080",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10080.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10080.patch",
            "merged_at": "2021-12-18T20:05:49Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10080/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10079",
        "id": 1083698366,
        "node_id": "I_kwDOCVq1mM5Al-y-",
        "number": 10079,
        "title": "[fp16] InstanceNorm generate totally wrong result on fp16",
        "user": {
            "login": "yetingqiaqia",
            "id": 6299908,
            "node_id": "MDQ6VXNlcjYyOTk5MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6299908?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yetingqiaqia",
            "html_url": "https://github.com/yetingqiaqia",
            "followers_url": "https://api.github.com/users/yetingqiaqia/followers",
            "following_url": "https://api.github.com/users/yetingqiaqia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yetingqiaqia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yetingqiaqia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yetingqiaqia/subscriptions",
            "organizations_url": "https://api.github.com/users/yetingqiaqia/orgs",
            "repos_url": "https://api.github.com/users/yetingqiaqia/repos",
            "events_url": "https://api.github.com/users/yetingqiaqia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yetingqiaqia/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-18T00:21:25Z",
        "updated_at": "2022-01-03T18:55:19Z",
        "closed_at": "2022-01-03T18:55:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi, I found InstanceNorm generates totally wrong result on fp16, while both fp32 model and partial fp16 model (i.e., InstanceNorm is fp32) generate correct result. See below: \r\n\r\n | Fp32 model | Partial fp16 model | Full fp16 model\r\n-- | -- | -- | --\r\nResult | [[ 6.0549564 -3.183563 -2.8680713]   [   6.1917925 -3.354034 -2.8344436]   [   6.169338 -3.3007898 -2.8652153]   [   6.1567574 -3.3921351 -2.7612722]   [   6.079842 -3.1844094 -2.8921494]   [   6.04279 -3.3625133 -2.6769447]] | [[ 6.0546875 -3.1835938 -2.8671875]   [   6.1914062 -3.3535156 -2.8339844]   [   6.1679688 -3.3007812 -2.8632812]   [   6.15625 -3.390625 -2.7617188]   [   6.078125 -3.1835938 -2.890625 ]   [   6.0429688 -3.3613281 -2.6757812]] | **[[   3.953125 -1.5253906 -2.4238281]   [ 3.953125   -1.5253906 -2.4238281]   [ 3.953125   -1.5253906 -2.4238281]   [ 3.953125   -1.5253906 -2.4238281]   [ 3.953125   -1.5253906 -2.4238281]   [ 3.953125   -1.5253906 -2.4238281]]**\r\n\r\nCould you help check if there anything wrong for InstanceNorm on fp16? \r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10\r\n- Python version: 3.6\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 11.5, CuDNN 8.3.1\r\n- GPU model and memory: V100, 16GB\r\n\r\n**To Reproduce**\r\n- Test code: \r\n```python\r\nimport numpy as np\r\nimport onnxruntime as ort\r\n\r\nsess_options = ort.SessionOptions()\r\nsess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\nsess_options.enable_mem_pattern=False\r\n\r\n#Full fp16 model\r\nsess = ort.InferenceSession(\"graph_opset12_optimized_fp16_keep_io_True_unblockInstanceNormalization.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\n#Partial fp16 model (every other ops are fp16 except InstanceNormalization)\r\n#sess = ort.InferenceSession(\"graph_opset12_optimized_fp16_keep_io_True.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\n#Full fp32 model\r\n#sess = ort.InferenceSession(\"graph_opset12_optimized.onnx\", sess_options, providers=[\"CUDAExecutionProvider\"])\r\n\r\ninput_name = sess.get_inputs()[0].name\r\nlabel_name = sess.get_outputs()[0].name\r\n\r\n#warm-up run\r\nnp.random.seed(123)\r\nbatch_size=6\r\ninput = np.random.rand(batch_size, 3, 480, 480)*256\r\ninput = np.floor(input).astype(np.float32)\r\npred = sess.run([label_name], {input_name: input})[0]\r\nprint(pred)\r\n```\r\n\r\n- Test models:\r\n  Full fp16 model: https://drive.google.com/file/d/1lvoLHigqiWaB3eFPoStQ22L5Avh316h8/view?usp=sharing\r\n  Partial fp16 model: https://drive.google.com/file/d/1Z2lrFbQ61mqZOapz4GQUUINn4aFCgvRH/view?usp=sharing\r\n  Full fp32 model: https://drive.google.com/file/d/1LIFFxD8O39VITABQuH0H0Zx4kT3Wk-xd/view?usp=sharing\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10079/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10078",
        "id": 1083628706,
        "node_id": "PR_kwDOCVq1mM4wBdGn",
        "number": 10078,
        "title": "Check kMSDomain already exists before registering it",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T21:31:19Z",
        "updated_at": "2021-12-18T01:55:16Z",
        "closed_at": "2021-12-18T01:55:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10078",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10078",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10078.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10078.patch",
            "merged_at": "2021-12-18T01:55:16Z"
        },
        "body": "**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\n External execution providers may register custom ops into the `kMSDomain`, which may cause a redundant registration of `kMSDomain` during `Environment::Initialize` or `RegisterOrtOpSchemas` and thereby an [assertion failure](https://github.com/onnx/onnx/blob/c9f53d00932ab60e381a71789a85db0463a8d9e0/onnx/defs/schema.h#L982). \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10078/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10077",
        "id": 1083484538,
        "node_id": "PR_kwDOCVq1mM4wA-dt",
        "number": 10077,
        "title": "add qdq support for LeakyRelu",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T17:47:47Z",
        "updated_at": "2022-01-03T22:48:50Z",
        "closed_at": "2022-01-03T22:48:50Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10077",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10077",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10077.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10077.patch",
            "merged_at": "2022-01-03T22:48:50Z"
        },
        "body": "1. add qdq fusion for LeakyRelu.\r\n2. support both int8 and uint8 for UnaryOperator.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10077/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10076",
        "id": 1083440205,
        "node_id": "PR_kwDOCVq1mM4wA1Nu",
        "number": 10076,
        "title": "Fix Microsoft.AI.MachineLearning NuGet App failure with multiple binaries copied to same destination",
        "user": {
            "login": "smk2007",
            "id": 6754002,
            "node_id": "MDQ6VXNlcjY3NTQwMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6754002?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smk2007",
            "html_url": "https://github.com/smk2007",
            "followers_url": "https://api.github.com/users/smk2007/followers",
            "following_url": "https://api.github.com/users/smk2007/following{/other_user}",
            "gists_url": "https://api.github.com/users/smk2007/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smk2007/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smk2007/subscriptions",
            "organizations_url": "https://api.github.com/users/smk2007/orgs",
            "repos_url": "https://api.github.com/users/smk2007/repos",
            "events_url": "https://api.github.com/users/smk2007/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smk2007/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T16:48:10Z",
        "updated_at": "2021-12-21T20:34:04Z",
        "closed_at": "2021-12-21T20:34:04Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10076",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10076",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10076.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10076.patch",
            "merged_at": "2021-12-21T20:34:04Z"
        },
        "body": "Fix Microsoft.AI.MachineLearning NuGet App failure with multiple binaries copied to same destination\r\n\r\nIssue: This was regressed in 1.10 by changes that were beginning to remove references to the UWP built versions of the binaries. These are no longer needed. However, in this state the .NuGet package began to reference both the native and UWP versions concurrently. This is because the NuGet package will forcibly copy anything in the lib/uap10.0 folder in the UWP context, causing multiple binaries to be copied into the destination.\r\n\r\nFix: Completely remove the UWP built binaries from the package and add a build test to make sure that this does not happen again.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10076/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10075",
        "id": 1083342392,
        "node_id": "I_kwDOCVq1mM5Akn44",
        "number": 10075,
        "title": "Model local functions not recognized by onnxruntime",
        "user": {
            "login": "jantonguirao",
            "id": 3891217,
            "node_id": "MDQ6VXNlcjM4OTEyMTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3891217?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jantonguirao",
            "html_url": "https://github.com/jantonguirao",
            "followers_url": "https://api.github.com/users/jantonguirao/followers",
            "following_url": "https://api.github.com/users/jantonguirao/following{/other_user}",
            "gists_url": "https://api.github.com/users/jantonguirao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jantonguirao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jantonguirao/subscriptions",
            "organizations_url": "https://api.github.com/users/jantonguirao/orgs",
            "repos_url": "https://api.github.com/users/jantonguirao/repos",
            "events_url": "https://api.github.com/users/jantonguirao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jantonguirao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2235309445,
                "node_id": "MDU6TGFiZWwyMjM1MzA5NDQ1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:onnx",
                "name": "component:onnx",
                "color": "303a93",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T14:59:49Z",
        "updated_at": "2022-01-11T16:18:16Z",
        "closed_at": "2022-01-11T16:18:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nModel local functions seem to be not recognized by onnxruntime. Attempting to use a model that uses a model local function (copy-pasted from ONNX's function_verify_test.cc) results in an error: `foo is not a registered function/op`\r\n\r\n**Urgency**\r\nThis slows down the progress of the experiments regarding the ONNX preprocessing working group.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.3 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: Python 3.8.10\r\n- Visual Studio version (if applicable): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**To Reproduce**\r\n```\r\nimport onnx\r\nimport onnxruntime\r\nimport numpy as np\r\nfrom onnx import parser\r\nm = parser.parse_model(\r\n'''\r\n<\r\n  ir_version: 8,\r\n  opset_import: [ \"\" : 13, \"custom_domain\" : 1],\r\n  producer_name: \"FunctionProtoTest\",\r\n  producer_version: \"1.0\",\r\n  model_version: 1,\r\n  doc_string: \"A test model for model local functions.\"\r\n>\r\nagraph (float[N] x) => (float[N] w)\r\n{\r\n    y = custom_domain.foo(x)\r\n    w = Identity(y)\r\n}\r\n\r\n<\r\n  domain: \"custom_domain\",\r\n  opset_import: [ \"\" : 13],\r\n  doc_string: \"Test function proto\"\r\n>\r\nfoo (x) => (y) {\r\n      Q_Min = Constant <value = float[1] {0.0}> ()\r\n      Q_Max = Constant <value = float[1] {255.0}> ()\r\n      X_Min = ReduceMin <keepdims = 0> (x)\r\n      X_Max = ReduceMax <keepdims = 0> (x)\r\n      X_Range = Sub (X_Max, X_Min)\r\n      Scale = Div (X_Range, Q_Max)\r\n      ZeroPoint_FP = Sub (Q_Min, Scale)\r\n      Zeropoint = Cast <to = 2> (ZeroPoint_FP)\r\n      y = QuantizeLinear (x, Scale, Zeropoint)\r\n}\r\n'''\r\n)\r\n\r\nonnx.save(m, \"test.onnx\")\r\nsession = onnxruntime.InferenceSession(\"test.onnx\", None)\r\nresult = session.run([], {'x' : np.array([1, 2, 3])})\r\n```\r\nresults in \r\n```\r\nFail: [ONNXRuntimeError] : 1 : FAIL : Load model from test.onnx failed:Fatal error: foo is not a registered function/op\r\n```\r\n\r\n**Expected behavior**\r\nsession.run executes, including the local function.\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nN/A",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10075/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10074",
        "id": 1083254139,
        "node_id": "I_kwDOCVq1mM5AkSV7",
        "number": 10074,
        "title": "when my models input size is 3808, then i forward with yolov5, the memry is break.",
        "user": {
            "login": "xinsuinizhuan",
            "id": 40679769,
            "node_id": "MDQ6VXNlcjQwNjc5NzY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/40679769?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinsuinizhuan",
            "html_url": "https://github.com/xinsuinizhuan",
            "followers_url": "https://api.github.com/users/xinsuinizhuan/followers",
            "following_url": "https://api.github.com/users/xinsuinizhuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinsuinizhuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinsuinizhuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinsuinizhuan/subscriptions",
            "organizations_url": "https://api.github.com/users/xinsuinizhuan/orgs",
            "repos_url": "https://api.github.com/users/xinsuinizhuan/repos",
            "events_url": "https://api.github.com/users/xinsuinizhuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinsuinizhuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/status:more-info-needed",
                "name": "status:more-info-needed",
                "color": "45b2d3",
                "default": false,
                "description": "more information is requested to continue investigation"
            },
            {
                "id": 2233102485,
                "node_id": "MDU6TGFiZWwyMjMzMTAyNDg1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:windows",
                "name": "platform:windows",
                "color": "d4ea72",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T13:20:04Z",
        "updated_at": "2021-12-19T02:58:47Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\n**System information**\r\n- OS Platform and Distribution: win10\r\n- ONNX Runtime installed from (source or binary):binary\r\n- ONNX Runtime version:1.10\r\n- Python version:\r\n- Visual Studio version (if applicable):vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 2060\r\n- GPU model and memory:\r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C9670 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeException 0x000000B2687C95C0 \r\n0x00007FFBEB5F4F69 ( ewb_single.exe ): Microsoft C++ : onnxruntime::OnnxRuntimeExceptio\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10074/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10071",
        "id": 1083099446,
        "node_id": "I_kwDOCVq1mM5Ajsk2",
        "number": 10071,
        "title": "how to forward with a batch images, oncetime?",
        "user": {
            "login": "xinsuinizhuan",
            "id": 40679769,
            "node_id": "MDQ6VXNlcjQwNjc5NzY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/40679769?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinsuinizhuan",
            "html_url": "https://github.com/xinsuinizhuan",
            "followers_url": "https://api.github.com/users/xinsuinizhuan/followers",
            "following_url": "https://api.github.com/users/xinsuinizhuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinsuinizhuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinsuinizhuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinsuinizhuan/subscriptions",
            "organizations_url": "https://api.github.com/users/xinsuinizhuan/orgs",
            "repos_url": "https://api.github.com/users/xinsuinizhuan/repos",
            "events_url": "https://api.github.com/users/xinsuinizhuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinsuinizhuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/status:more-info-needed",
                "name": "status:more-info-needed",
                "color": "45b2d3",
                "default": false,
                "description": "more information is requested to continue investigation"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T10:15:33Z",
        "updated_at": "2021-12-19T02:55:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I want to foward with multi images once time with yolov5, to to do?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10071/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10070",
        "id": 1083039474,
        "node_id": "I_kwDOCVq1mM5Ajd7y",
        "number": 10070,
        "title": "How to use ep TensorrtExecutionProvider_fp16",
        "user": {
            "login": "QuantumLiu",
            "id": 21980268,
            "node_id": "MDQ6VXNlcjIxOTgwMjY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21980268?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/QuantumLiu",
            "html_url": "https://github.com/QuantumLiu",
            "followers_url": "https://api.github.com/users/QuantumLiu/followers",
            "following_url": "https://api.github.com/users/QuantumLiu/following{/other_user}",
            "gists_url": "https://api.github.com/users/QuantumLiu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/QuantumLiu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/QuantumLiu/subscriptions",
            "organizations_url": "https://api.github.com/users/QuantumLiu/orgs",
            "repos_url": "https://api.github.com/users/QuantumLiu/repos",
            "events_url": "https://api.github.com/users/QuantumLiu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/QuantumLiu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to TensorRT EP"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T09:10:56Z",
        "updated_at": "2021-12-18T04:24:28Z",
        "closed_at": "2021-12-18T04:24:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI' m using `TensorrtExecutionProvider `which build by command:\r\n`./build.sh --cudnn_home \"/usr/local/cuda\" --cuda_home \"/usr/local/cuda\" --use_tensorrt --tensorrt_home \"/home/tianqing/Downloads/TensorRT-7.2.3.4\" --skip_submodule_sync --build_wheel --parallel --skip_tests --use_openvino --config Release`\r\nIt use `TensorrtExecutionProvider ` perfectly, but I can't using TensorrtExecutionProvider_fp16.  \r\nI tried to build and run with \r\n`export ORT_TENSORRT_FP16_ENABLE=1\r\n`\r\nhttps://github.com/microsoft/onnxruntime/issues/2967\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):\r\n```\r\n# packages in environment at /home/tianqing/anaconda3/envs/infer:\r\n#\r\n# Name                    Version                   Build  Channel\r\nonnx                      1.10.1                   pypi_0    pypi\r\nonnx-simplifier           0.3.6                    pypi_0    pypi\r\nonnx2keras                0.0.24                   pypi_0    pypi\r\nonnxconverter-common      1.8.1                    pypi_0    pypi\r\nonnxmltools               1.10.0                   pypi_0    pypi\r\nonnxoptimizer             0.2.6                    pypi_0    pypi\r\nonnxruntime-gpu-tensorrt  1.8.1                    pypi_0    pypi\r\nskl2onnx                  1.10.0                   pypi_0    pypi\r\n```\r\n**Describe the solution you'd like**\r\nAn option to build TensorrtExecutionProvider_fp16 ep.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\n`session.get_providers()\r\n`\r\ngot:\r\n`['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'OpenVINOExecutionProvider', 'CPUExecutionProvider']`",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10070/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10069",
        "id": 1082937340,
        "node_id": "I_kwDOCVq1mM5AjE_8",
        "number": 10069,
        "title": "GRU runtime error. ",
        "user": {
            "login": "bigbigzxl",
            "id": 25808190,
            "node_id": "MDQ6VXNlcjI1ODA4MTkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/25808190?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bigbigzxl",
            "html_url": "https://github.com/bigbigzxl",
            "followers_url": "https://api.github.com/users/bigbigzxl/followers",
            "following_url": "https://api.github.com/users/bigbigzxl/following{/other_user}",
            "gists_url": "https://api.github.com/users/bigbigzxl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bigbigzxl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bigbigzxl/subscriptions",
            "organizations_url": "https://api.github.com/users/bigbigzxl/orgs",
            "repos_url": "https://api.github.com/users/bigbigzxl/repos",
            "events_url": "https://api.github.com/users/bigbigzxl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bigbigzxl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:coreruntime",
                "name": "component:coreruntime",
                "color": "303a93",
                "default": false,
                "description": "related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-17T06:41:02Z",
        "updated_at": "2021-12-19T21:55:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nin GRU casewith the same parameters and inputs, the output of ONNX is inconstant with Tensorflow.\r\n\r\n**Urgency**\r\n none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04)   (Red Hat 4.8.5-16)] on linux\r\n- ONNX Runtime installed from (source or binary):  binary\r\n- ONNX Runtime version: onnx.__version__='1.6.0'\r\n- Python version: python3.65\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): GCC 4.8.5 20150623\r\n- CUDA/cuDNN version:  \r\n                                        torch.__version__ - 1.7.1+cu101\r\n                                        torch.version.cuda10.2\r\n                                        torch.backends.cudnn.version()7603\r\n\r\n- GPU model and memory: Tesla V100 64GB\r\n\r\n**To Reproduce**\r\njust single gru case.\r\n\r\n**Expected behavior**\r\nthe output of onnx is equal with the output of tensorflow.\r\n\r\n**Screenshots**\r\n\r\n![image](https://user-images.githubusercontent.com/25808190/146499217-25902f3e-0d69-47e1-8e92-1e2fa92334bd.png)\r\n\r\n\r\n![tf output](https://user-images.githubusercontent.com/25808190/146498805-faf47d8d-e211-4645-bc7d-c6e5778d40ae.png)\r\n\r\n![onnx runtime output](https://user-images.githubusercontent.com/25808190/146498784-7cdb6e53-3293-4b20-aa79-8c984baa61de.png)\r\n**Additional context**\r\nGRU params:\r\nBatch = 3\r\ntime step: T = 28\r\noutput size: H = 5\r\ninput size: X = 10\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10069/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10068",
        "id": 1082932882,
        "node_id": "I_kwDOCVq1mM5AjD6S",
        "number": 10068,
        "title": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ArgMax_1094:ArgMax(11)",
        "user": {
            "login": "yumulinfeng1",
            "id": 50360389,
            "node_id": "MDQ6VXNlcjUwMzYwMzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/50360389?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yumulinfeng1",
            "html_url": "https://github.com/yumulinfeng1",
            "followers_url": "https://api.github.com/users/yumulinfeng1/followers",
            "following_url": "https://api.github.com/users/yumulinfeng1/following{/other_user}",
            "gists_url": "https://api.github.com/users/yumulinfeng1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yumulinfeng1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yumulinfeng1/subscriptions",
            "organizations_url": "https://api.github.com/users/yumulinfeng1/orgs",
            "repos_url": "https://api.github.com/users/yumulinfeng1/repos",
            "events_url": "https://api.github.com/users/yumulinfeng1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yumulinfeng1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2114490130,
                "node_id": "MDU6TGFiZWwyMTE0NDkwMTMw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:operator",
                "name": "component:operator",
                "color": "303a93",
                "default": false,
                "description": "related to specific ONNX operator support"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-17T06:32:05Z",
        "updated_at": "2021-12-23T09:15:18Z",
        "closed_at": "2021-12-23T09:15:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\nhi i run\r\n`onnx_session1 = onnxruntime.InferenceSession(\"./pretrained/textmodel.onnx\")`\r\nand generate error as below:\r\n\r\n**File \"D:\\anaconda3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 312, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ArgMax_1094:ArgMax(11)**\r\n\r\nONNX - 1.7.0\r\nonnxruntime - 1.7.0\r\n\r\n\r\ncould you help me to solve this problem?\r\n\r\nand the onnx model i transfered here\r\n\r\n\r\n![_16397227177148](https://user-images.githubusercontent.com/50360389/146499754-a24ac96f-cd16-41ce-9006-5cf1030adc37.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10068/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10067",
        "id": 1082854420,
        "node_id": "PR_kwDOCVq1mM4v-5fW",
        "number": 10067,
        "title": "add int8_t for Resize",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-17T03:44:15Z",
        "updated_at": "2021-12-17T23:36:10Z",
        "closed_at": "2021-12-17T23:36:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10067",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10067",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10067.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10067.patch",
            "merged_at": "2021-12-17T23:36:09Z"
        },
        "body": "As we support quantization for format s8s8, we need Resize to support int8_t.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10067/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10064",
        "id": 1082743107,
        "node_id": "PR_kwDOCVq1mM4v-iz-",
        "number": 10064,
        "title": "Add STVM to website installation matrix",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-12-16T23:59:39Z",
        "updated_at": "2021-12-17T00:35:08Z",
        "closed_at": "2021-12-17T00:35:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10064",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10064",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10064.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10064.patch",
            "merged_at": "2021-12-17T00:35:08Z"
        },
        "body": "Staged here: https://natke.github.io/onnxruntime/\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10064/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10063",
        "id": 1082742406,
        "node_id": "I_kwDOCVq1mM5AiVaG",
        "number": 10063,
        "title": "Linking custom library to onnxruntime fails on Linux",
        "user": {
            "login": "bkaruman",
            "id": 65257187,
            "node_id": "MDQ6VXNlcjY1MjU3MTg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/65257187?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bkaruman",
            "html_url": "https://github.com/bkaruman",
            "followers_url": "https://api.github.com/users/bkaruman/followers",
            "following_url": "https://api.github.com/users/bkaruman/following{/other_user}",
            "gists_url": "https://api.github.com/users/bkaruman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bkaruman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bkaruman/subscriptions",
            "organizations_url": "https://api.github.com/users/bkaruman/orgs",
            "repos_url": "https://api.github.com/users/bkaruman/repos",
            "events_url": "https://api.github.com/users/bkaruman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bkaruman/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:build",
                "name": "component:build",
                "color": "303a93",
                "default": false,
                "description": "related to builds"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T23:57:51Z",
        "updated_at": "2021-12-17T00:49:37Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHello, I am trying to link a .so file  to onnxruntime for profiling experiments on Linux and observed that build fails. Not sure if I am doing it right.\r\n\r\n**Urgency**\r\nThis is blocking our efforts to run profiling experiments on ONNX RT.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version:v1.10.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\nI have modified the CMakeLists.txt to include paths \r\nif (NOT WIN32)\r\n  set(MYAPP_INCLUDE_DIR \"/home/path/to/app/include\")\r\n  set(MYAPP_LIB \"/home/path/to/app/lib64/runtime\")\r\n  include_directories(${MYAPP_INCLUDE_DIR})\r\n  list(APPEND onnxruntime_EXTERNAL_LIBRARIES ${MYAPP_LIB}/myapp.so)\r\nendif() \r\n\r\n\r\nCan someone share guidelines on modifying cmake to link custom libraries?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10063/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10062",
        "id": 1082734320,
        "node_id": "PR_kwDOCVq1mM4v-g_B",
        "number": 10062,
        "title": "adding definition of concat operator for mapping it to onnx",
        "user": {
            "login": "ajindal1",
            "id": 32752809,
            "node_id": "MDQ6VXNlcjMyNzUyODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/32752809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajindal1",
            "html_url": "https://github.com/ajindal1",
            "followers_url": "https://api.github.com/users/ajindal1/followers",
            "following_url": "https://api.github.com/users/ajindal1/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajindal1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajindal1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajindal1/subscriptions",
            "organizations_url": "https://api.github.com/users/ajindal1/orgs",
            "repos_url": "https://api.github.com/users/ajindal1/repos",
            "events_url": "https://api.github.com/users/ajindal1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajindal1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T23:38:22Z",
        "updated_at": "2022-01-06T22:56:37Z",
        "closed_at": "2022-01-06T22:56:36Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10062",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10062",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10062.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10062.patch",
            "merged_at": "2022-01-06T22:56:36Z"
        },
        "body": "**Description**: Describe your changes.\r\nImplementing concat operator mapping to onnx, and defined required create ort value funciton. Unable to use the opgen script output because the TensorList is passed, which does have device and other options as generated by the opgen script.\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10062/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10061",
        "id": 1082645715,
        "node_id": "PR_kwDOCVq1mM4v-OPo",
        "number": 10061,
        "title": "Add citation file",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T21:11:17Z",
        "updated_at": "2021-12-17T03:56:23Z",
        "closed_at": "2021-12-17T03:56:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10061",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10061",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10061.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10061.patch",
            "merged_at": "2021-12-17T03:56:22Z"
        },
        "body": "Add citation file to repo\r\n\r\nRef: https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10061/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10060",
        "id": 1082607404,
        "node_id": "PR_kwDOCVq1mM4v-GKA",
        "number": 10060,
        "title": "Convert com.microsoft::ATen into org.pytorch.aten::ATen onnx op",
        "user": {
            "login": "thiagocrepaldi",
            "id": 5469809,
            "node_id": "MDQ6VXNlcjU0Njk4MDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5469809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thiagocrepaldi",
            "html_url": "https://github.com/thiagocrepaldi",
            "followers_url": "https://api.github.com/users/thiagocrepaldi/followers",
            "following_url": "https://api.github.com/users/thiagocrepaldi/following{/other_user}",
            "gists_url": "https://api.github.com/users/thiagocrepaldi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thiagocrepaldi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thiagocrepaldi/subscriptions",
            "organizations_url": "https://api.github.com/users/thiagocrepaldi/orgs",
            "repos_url": "https://api.github.com/users/thiagocrepaldi/repos",
            "events_url": "https://api.github.com/users/thiagocrepaldi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thiagocrepaldi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:training-core",
                "name": "component:training-core",
                "color": "303a93",
                "default": false,
                "description": "related to training core"
            },
            {
                "id": 2114490130,
                "node_id": "MDU6TGFiZWwyMTE0NDkwMTMw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:operator",
                "name": "component:operator",
                "color": "303a93",
                "default": false,
                "description": "related to specific ONNX operator support"
            },
            {
                "id": 2235309445,
                "node_id": "MDU6TGFiZWwyMjM1MzA5NDQ1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:onnx",
                "name": "component:onnx",
                "color": "303a93",
                "default": false,
                "description": ""
            },
            {
                "id": 2732589361,
                "node_id": "MDU6TGFiZWwyNzMyNTg5MzYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:ortmodule",
                "name": "component:ortmodule",
                "color": "303a93",
                "default": false,
                "description": "related to ortmodule"
            },
            {
                "id": 3865252115,
                "node_id": "LA_kwDOCVq1mM7mYxET",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/release:1.11",
                "name": "release:1.11",
                "color": "C97364",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 12,
        "created_at": "2021-12-16T20:16:13Z",
        "updated_at": "2022-02-25T14:05:49Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10060",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10060",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10060.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10060.patch",
            "merged_at": null
        },
        "body": "Pytorch ONNX exporter now emits org.pytorch.aten::ATen nodes with operator_name and overload_name attribute\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10060/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10059",
        "id": 1082287984,
        "node_id": "PR_kwDOCVq1mM4v9BvD",
        "number": 10059,
        "title": "[DOC] add STVM EP docs",
        "user": {
            "login": "vvchernov",
            "id": 28704584,
            "node_id": "MDQ6VXNlcjI4NzA0NTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/28704584?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vvchernov",
            "html_url": "https://github.com/vvchernov",
            "followers_url": "https://api.github.com/users/vvchernov/followers",
            "following_url": "https://api.github.com/users/vvchernov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vvchernov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vvchernov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vvchernov/subscriptions",
            "organizations_url": "https://api.github.com/users/vvchernov/orgs",
            "repos_url": "https://api.github.com/users/vvchernov/repos",
            "events_url": "https://api.github.com/users/vvchernov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vvchernov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T14:52:17Z",
        "updated_at": "2021-12-16T22:59:44Z",
        "closed_at": "2021-12-16T22:59:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10059",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10059",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10059.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10059.patch",
            "merged_at": "2021-12-16T22:59:44Z"
        },
        "body": "Add docs for new execution provider: Standalone TVM (STVM) EP\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10059/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10058",
        "id": 1082101141,
        "node_id": "I_kwDOCVq1mM5Af42V",
        "number": 10058,
        "title": "Unexpected numerical differences between batch and single row predictions",
        "user": {
            "login": "cbourjau",
            "id": 3288058,
            "node_id": "MDQ6VXNlcjMyODgwNTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3288058?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbourjau",
            "html_url": "https://github.com/cbourjau",
            "followers_url": "https://api.github.com/users/cbourjau/followers",
            "following_url": "https://api.github.com/users/cbourjau/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbourjau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbourjau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbourjau/subscriptions",
            "organizations_url": "https://api.github.com/users/cbourjau/orgs",
            "repos_url": "https://api.github.com/users/cbourjau/repos",
            "events_url": "https://api.github.com/users/cbourjau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbourjau/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-16T11:49:49Z",
        "updated_at": "2022-01-07T21:20:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n`onnxruntime` version `1.10.0` (Python bindings) produces slightly different results in batch mode with four or more rows than when performing single-row predictions for float32 input of the `Log` node. ~Other node types such as `Exp` do not exhibit this behavior.~ Turns out at least `Exp` is also affected. I updated the test case below. \r\n\r\n**Urgency**\r\nOur production use case requires reproducible predictions regardless if they were submitted as a single row (or batch of less then 4 rows) or within a larger batch. We are currently forced to fall back to single-row predictions which naturally causes a large performance hit.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux  5.4.0-1060-aws #63~18.04.1-Ubuntu SMP x86_64 x86_64 x86_64 GNU/Linux`\r\n- ONNX Runtime installed from (source or binary): binary from [conda-forge](https://github.com/conda-forge/onnxruntime-feedstock)\r\n- ONNX Runtime version: `1.10.0`\r\n- Python version: `3.9.7`\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**To Reproduce**\r\nThe following test case reproduces the issue reliably in the above described environment:\r\n```python\r\nfrom onnx import helper, checker, TensorProto, version\r\nimport onnxruntime as rt\r\nimport numpy as np\r\n\r\n\r\ndef test_minimal_log():\r\n    assert rt.__version__ == \"1.10.0\"\r\n    assert version.version == \"1.10.2\"  # ONNX version\r\n    node = helper.make_node(\"Log\", inputs=[\"input\"], outputs=[\"output\"])\r\n    inputs = [helper.make_tensor_value_info(\"input\", TensorProto.FLOAT, [None])]\r\n    outputs = [helper.make_tensor_value_info(\"output\", TensorProto.FLOAT, [None])]\r\n    g = helper.make_graph([node], \"log_batch_issue\", inputs, outputs)\r\n    model = helper.make_model(g)\r\n    checker.check_model(model, full_check=True)\r\n    sess = rt.InferenceSession(model.SerializeToString())\r\n    # Issue only occurs for certain values. For example, `42.42` works\r\n    # as expected.\r\n    input_vals = np.array([1.06023156] * 4, dtype=\"float32\")\r\n    first_row_batch = sess.run([\"output\"], {\"input\": input_vals})[0][0]\r\n    first_row_single = sess.run([\"output\"], {\"input\": input_vals[:1]})[0][0]\r\n    assert first_row_batch == first_row_single\r\n    \r\ndef test_minimal_exp():\r\n    assert rt.__version__ == \"1.10.0\"\r\n    assert version.version == \"1.10.2\"\r\n    node = helper.make_node(\"Exp\", inputs=[\"input\"], outputs=[\"output\"])\r\n    inputs = [helper.make_tensor_value_info(\"input\", TensorProto.DOUBLE, [None])]\r\n    outputs = [helper.make_tensor_value_info(\"output\", TensorProto.DOUBLE, [None])]\r\n    g = helper.make_graph([node], \"log_batch_issue\", inputs, outputs)\r\n    model = helper.make_model(g)\r\n    checker.check_model(model, full_check=True)\r\n    sess = rt.InferenceSession(model.SerializeToString())\r\n    # Issue only occurs for certain values. For example, `42.42` works\r\n    # as expected.\r\n    input_vals = np.array([-0.26606467366] * 4, dtype=\"float64\")  # For Exp\r\n    first_row_batch = sess.run([\"output\"], {\"input\": input_vals})[0][0]\r\n    first_row_single = sess.run([\"output\"], {\"input\": input_vals[:1]})[0][0]\r\n    assert first_row_batch == first_row_single\r\n```\r\n\r\n**Expected behavior**\r\nI expect the results of each row to be independent of the batch size in which they were submitted. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10058/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10057",
        "id": 1081743889,
        "node_id": "PR_kwDOCVq1mM4v7PKY",
        "number": 10057,
        "title": "Revert a bad change in bfc_arena.cc",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-16T03:59:35Z",
        "updated_at": "2021-12-16T07:38:47Z",
        "closed_at": "2021-12-16T07:38:46Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10057",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10057",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10057.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10057.patch",
            "merged_at": "2021-12-16T07:38:46Z"
        },
        "body": "**Description**: \r\n\r\nRevert a bad change in bfc_arena.cc which was introduced in #10033 by me. It is causing failures in AMD GPU pipeline.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10057/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10056",
        "id": 1081660365,
        "node_id": "PR_kwDOCVq1mM4v6-Kr",
        "number": 10056,
        "title": "Reduce ops for DNNL ep",
        "user": {
            "login": "georgen117",
            "id": 16688936,
            "node_id": "MDQ6VXNlcjE2Njg4OTM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16688936?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/georgen117",
            "html_url": "https://github.com/georgen117",
            "followers_url": "https://api.github.com/users/georgen117/followers",
            "following_url": "https://api.github.com/users/georgen117/following{/other_user}",
            "gists_url": "https://api.github.com/users/georgen117/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/georgen117/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/georgen117/subscriptions",
            "organizations_url": "https://api.github.com/users/georgen117/orgs",
            "repos_url": "https://api.github.com/users/georgen117/repos",
            "events_url": "https://api.github.com/users/georgen117/events{/privacy}",
            "received_events_url": "https://api.github.com/users/georgen117/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-12-16T01:03:07Z",
        "updated_at": "2021-12-16T15:31:17Z",
        "closed_at": "2021-12-16T15:31:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10056",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10056",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10056.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10056.patch",
            "merged_at": "2021-12-16T15:31:17Z"
        },
        "body": "**Description**: Describe your changes.\r\nThis adds all of the ONNX specified Reduce ops to the DNNL execution provider\r\nThe ops added are  ReduceL1, ReduceL2, ReduceLogSum, ReduceLogSumExp, ReduceMax, ReduceMin, ReduceProd, ReduceSum, ReduceSumSquare.\r\n\r\nThis is a modification of the already existing ReduceMean code.\r\n\r\nThe code can now handle the keepdims attribute. Previous code  would only accept ReduceMean if the keepdims == 1.\r\n\r\nCommit also contains a documentation fix for the recently commtied DNNL QAttention op. The in code documentaiton, some how had a bunch of new lines added that made reading more difficult.  The extra newlines were cleaned up.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nThis change expands the model coverage of the DNNL execution provider. By adding all the Reduction Operators.\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10056/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10055",
        "id": 1081613145,
        "node_id": "PR_kwDOCVq1mM4v60JS",
        "number": 10055,
        "title": "Abjindal/clean eager backend",
        "user": {
            "login": "ajindal1",
            "id": 32752809,
            "node_id": "MDQ6VXNlcjMyNzUyODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/32752809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajindal1",
            "html_url": "https://github.com/ajindal1",
            "followers_url": "https://api.github.com/users/ajindal1/followers",
            "following_url": "https://api.github.com/users/ajindal1/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajindal1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajindal1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajindal1/subscriptions",
            "organizations_url": "https://api.github.com/users/ajindal1/orgs",
            "repos_url": "https://api.github.com/users/ajindal1/repos",
            "events_url": "https://api.github.com/users/ajindal1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajindal1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T23:36:32Z",
        "updated_at": "2022-01-19T22:20:10Z",
        "closed_at": "2022-01-19T22:20:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10055",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10055",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10055.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10055.patch",
            "merged_at": "2022-01-19T22:20:10Z"
        },
        "body": "**Description**: Describe your changes.\r\nReleasing the backends manager for eager mode when python interpreter exit.\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10055/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10052",
        "id": 1081570197,
        "node_id": "PR_kwDOCVq1mM4v6q_D",
        "number": 10052,
        "title": "[QDQ] Add shared NodeUnit class",
        "user": {
            "login": "gwang-msft",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gwang-msft",
            "html_url": "https://github.com/gwang-msft",
            "followers_url": "https://api.github.com/users/gwang-msft/followers",
            "following_url": "https://api.github.com/users/gwang-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/gwang-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gwang-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gwang-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/gwang-msft/orgs",
            "repos_url": "https://api.github.com/users/gwang-msft/repos",
            "events_url": "https://api.github.com/users/gwang-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gwang-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T22:23:59Z",
        "updated_at": "2022-01-06T01:32:12Z",
        "closed_at": "2021-12-17T01:37:52Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10052",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10052",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10052.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10052.patch",
            "merged_at": "2021-12-17T01:37:52Z"
        },
        "body": "**Description**: Add NodeUnit class\r\n\r\n**Motivation and Context**\r\n- To avoid excessively large PR, the NNAPI QDQ integration is splitted into the following small tasks\r\n- [x] 1. Add shared NodeUnit class (this PR)\r\n- [ ] 2. Move NNAPI EP to use NodeUnit IODef for non-QDQ ops\r\n- [ ] 3. Add shared QDQ selectors\r\n- [ ] 4. Hookup NNAPI GetCapability/Compile with shared QDQ selectors\r\n- [ ] 5. Enable QDQ for ops with QLinear version (QLinear[Conv/Matmul/Pool/...])\r\n- [ ] 6. Enable QDQ for ops without QLinear Version\r\n\r\n- This is step 1 of the tasks, we add the shared NodeUnit and move NNAPI builder interface to take NodeUnit, the NNAPI builders still work as before, we have not yet converted the quantized input of some QLinear ops to quant_params, which will be covered in step 2 (there are some code (later removed from `onnxruntime/core/providers/shared/node_unit/node_unit.cc`) in this [commit](https://github.com/microsoft/onnxruntime/pull/10052/commits/ceb60bf8c762206deaf72d4602a5016580f213b6) of the PR)\r\n- The shared NodeUnit class will be shared between a single Node or a QDQ group, which will both be treated as a unit with necessary functions, the main difference between a Node interface and a NodeUnit interface is the IODef which embed the input with its quantization params (scale and ZP), which defines a consistent way to retrieve quantization information for input and output\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10052/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10051",
        "id": 1081540447,
        "node_id": "PR_kwDOCVq1mM4v6kqK",
        "number": 10051,
        "title": "Optimization Convolution op when using dnnl ep",
        "user": {
            "login": "georgen117",
            "id": 16688936,
            "node_id": "MDQ6VXNlcjE2Njg4OTM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16688936?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/georgen117",
            "html_url": "https://github.com/georgen117",
            "followers_url": "https://api.github.com/users/georgen117/followers",
            "following_url": "https://api.github.com/users/georgen117/following{/other_user}",
            "gists_url": "https://api.github.com/users/georgen117/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/georgen117/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/georgen117/subscriptions",
            "organizations_url": "https://api.github.com/users/georgen117/orgs",
            "repos_url": "https://api.github.com/users/georgen117/repos",
            "events_url": "https://api.github.com/users/georgen117/events{/privacy}",
            "received_events_url": "https://api.github.com/users/georgen117/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-12-15T21:42:50Z",
        "updated_at": "2021-12-16T04:28:35Z",
        "closed_at": "2021-12-16T04:28:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10051",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10051",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10051.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10051.patch",
            "merged_at": "2021-12-16T04:28:34Z"
        },
        "body": "**Description**: \r\nIf Group attr = 1 allow the OneDNN library to optimize the memory\r\nlayout for the device the Convolution operator is being run on.\r\n\r\nWithout this optimization, the default NCHW memory layout is used\r\non CPUs, the NCHW memory layout can result in a significant performance\r\ndecrease.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\nUsing the default NCHW memory layout on CPU resulted in poor performance when running convolution models on CPU.\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10051/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10050",
        "id": 1081514003,
        "node_id": "PR_kwDOCVq1mM4v6fDM",
        "number": 10050,
        "title": "fix aten view op",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-15T21:06:36Z",
        "updated_at": "2022-01-04T16:29:31Z",
        "closed_at": "2022-01-04T16:29:30Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10050",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10050",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10050.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10050.patch",
            "merged_at": "2022-01-04T16:29:30Z"
        },
        "body": "**Description**: The view operator in eager mode doesn't use the aten infer size correctly. actually we don't need to invoke that.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10050/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10049",
        "id": 1081390344,
        "node_id": "PR_kwDOCVq1mM4v6H5-",
        "number": 10049,
        "title": "Disable ROCm C++ BERT batch and performance tests",
        "user": {
            "login": "suffiank",
            "id": 4366369,
            "node_id": "MDQ6VXNlcjQzNjYzNjk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4366369?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suffiank",
            "html_url": "https://github.com/suffiank",
            "followers_url": "https://api.github.com/users/suffiank/followers",
            "following_url": "https://api.github.com/users/suffiank/following{/other_user}",
            "gists_url": "https://api.github.com/users/suffiank/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suffiank/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suffiank/subscriptions",
            "organizations_url": "https://api.github.com/users/suffiank/orgs",
            "repos_url": "https://api.github.com/users/suffiank/repos",
            "events_url": "https://api.github.com/users/suffiank/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suffiank/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T19:01:28Z",
        "updated_at": "2021-12-16T23:24:57Z",
        "closed_at": "2021-12-16T23:24:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10049",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10049",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10049.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10049.patch",
            "merged_at": null
        },
        "body": "Making CI pipeline flaky. Disable for now.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10049/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10048",
        "id": 1081325117,
        "node_id": "I_kwDOCVq1mM5Ac7Y9",
        "number": 10048,
        "title": "System.MissingMethodException: Method not found: System.Memory'1<!0> Microsoft.ML.OnnxRuntime.Tensors.DenseTensor'1.get_Buffer() on iOS",
        "user": {
            "login": "juwens",
            "id": 11560817,
            "node_id": "MDQ6VXNlcjExNTYwODE3",
            "avatar_url": "https://avatars.githubusercontent.com/u/11560817?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juwens",
            "html_url": "https://github.com/juwens",
            "followers_url": "https://api.github.com/users/juwens/followers",
            "following_url": "https://api.github.com/users/juwens/following{/other_user}",
            "gists_url": "https://api.github.com/users/juwens/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juwens/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juwens/subscriptions",
            "organizations_url": "https://api.github.com/users/juwens/orgs",
            "repos_url": "https://api.github.com/users/juwens/repos",
            "events_url": "https://api.github.com/users/juwens/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juwens/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1758308176,
                "node_id": "MDU6TGFiZWwxNzU4MzA4MTc2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:CSharp",
                "name": "api:CSharp",
                "color": "0e8a16",
                "default": false,
                "description": "related to the C# API"
            },
            {
                "id": 2380867869,
                "node_id": "MDU6TGFiZWwyMzgwODY3ODY5",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:iOS",
                "name": "platform:iOS",
                "color": "d4ea72",
                "default": false,
                "description": ""
            },
            {
                "id": 2385898474,
                "node_id": "MDU6TGFiZWwyMzg1ODk4NDc0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:%20mobile",
                "name": "feature: mobile",
                "color": "0052cc",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2021-12-15T17:57:20Z",
        "updated_at": "2021-12-17T00:18:41Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nRuntime exception when predicting data with our onnx model on iOS.\r\nWorks fine on android.\r\n\r\n```\r\nSystem.MissingMethodException: Method not found: System.Memory`1<!0> Microsoft.ML.OnnxRuntime.Tensors.DenseTensor`1.get_Buffer()\r\n\r\n  at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase+<>c__DisplayClass8_0`1[TRow,TDst].<CreateDirectVBufferSetter>b__0 (TRow row) [0x0001d] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.Data.TypedCursorable`1+TypedRowBase[TRow].FillValues (TRow row) [0x0000f] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.Data.TypedCursorable`1+RowImplementation[TRow].FillValues (TRow row) [0x00000] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngineBase`2[TSrc,TDst].FillValues (TDst prediction) [0x00000] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngine`2[TSrc,TDst].Predict (TSrc example, TDst& prediction) [0x0002a] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at Microsoft.ML.PredictionEngineBase`2[TSrc,TDst].Predict (TSrc example) [0x00006] in <2bd131dbe89f4bb18c578a3340570234>:0\r\n  at OnnxLib.OnnxAlgorithm.Predict (System.String onnxPath, System.Single[] inputData) [0x0005e] in /Users/jjaehrig/repo/foobar_ml/src/OnnxLib/OnnxAlgorithm.cs:26\r\n  at XamarinApp.MainPage.OnAppearing () [0x00015] in /Users/jjaehrig/repo/foobar_ml/src/XamarinApp/XamarinApp/MainPage.xaml.cs:23\r\n  at Xamarin.Forms.Page.SendAppearing () [0x00045] in D:\\a\\1\\s\\Xamarin.Forms.Core\\Page.cs:452\r\n  at Xamarin.Forms.Platform.iOS.PageRenderer.ViewDidAppear (System.Boolean animated) [0x0004d] in D:\\a\\1\\s\\Xamarin.Forms.Platform.iOS\\Renderers\\PageRenderer.cs:215\r\n  at at (wrapper managed-to-native) UIKit.UIApplication.UIApplicationMain(int,string[],intptr,intptr)\r\n  at UIKit.UIApplication.Main (System.String[] args, System.Type principalClass, System.Type delegateClass) [0x00047] in /Users/builder/azdo/_work/1/s/xamarin-macios/src/UIKit/UIApplication.cs:79\r\n  at XamarinApp.iOS.Application.Main (System.String[] args) [0x00001] in /Users/jjaehrig/repo/foobar_ml/src/XamarinApp/XamarinApp.iOS/Main.cs:17\r\n```\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS 15\r\n- ONNX Runtime installed from (source or binary): 1.10\r\n- ONNX Runtime version: 1.10\r\n- Python version: n/a\r\n- Visual Studio version (if applicable): VS Mac 8.10.15\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**To Reproduce**\r\n- create a bare minimal engine, run it -> crash\r\n- i can't provide our onnx because of intellectual property, but i can try to create a similar one.\r\n- but essentially its this:\r\n```\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.Diagnostics;\r\nusing System.Numerics;\r\n\r\nnamespace FooLib\r\n{\r\n    public static class FooAlgorithm\r\n    {\r\n        public static Vector3 Predict(string onnxPath, float[] inputData)\r\n        {\r\n            if (inputData.Length != FooInput.InputLength) throw new ArgumentException($\"array must be of length {FooInput.InputLength}\");\r\n\r\n            var mlContext = new MLContext();\r\n\r\n            var onnxPredictionPipeline = GetPredictionPipeline(mlContext, onnxPath);\r\n            var onnxPredictionEngine = mlContext.Model.CreatePredictionEngine<FooInput, FooOutput>(onnxPredictionPipeline);\r\n\r\n\r\n            var input = new FooInput()\r\n            {\r\n                sequenceinput = inputData,\r\n            };\r\n\r\n            var prediction = onnxPredictionEngine.Predict(input);\r\n\r\n            var sm = prediction.softmax;\r\n            Debug.WriteLine($\"Prediction: {sm[0]}; {sm[1]}; {sm[2]}\");\r\n            return new Vector3(sm[0], sm[1], sm[2]);\r\n        }\r\n\r\n        private static ITransformer GetPredictionPipeline(MLContext mlContext, string onnxPath)\r\n        {\r\n            var inputColumns = new string[]\r\n            {\r\n                \"sequenceinput\"\r\n            };\r\n\r\n            var outputColumns = new string[] { \"softmax\" };\r\n\r\n            var onnxPredictionPipeline =\r\n                mlContext\r\n                    .Transforms\r\n                    .ApplyOnnxModel(\r\n                        outputColumnNames: outputColumns,\r\n                        inputColumnNames: inputColumns,\r\n                        onnxPath);\r\n\r\n            var emptyDv = mlContext.Data.LoadFromEnumerable(new FooInput[] { });\r\n\r\n            return onnxPredictionPipeline.Fit(emptyDv);\r\n        }\r\n    }\r\n\r\n    class FooInput\r\n    {\r\n        public const int InputLength = 72;\r\n\r\n        private float[] _sequenceinput;\r\n\r\n        public FooInput()\r\n        {\r\n            sequenceinput = new float[InputLength];\r\n        }\r\n\r\n        [ColumnName(\"sequenceinput\"), VectorType(InputLength)]\r\n        public float[] sequenceinput\r\n        {\r\n            get => _sequenceinput;\r\n            set\r\n            {\r\n                if (value.Length != InputLength) throw new ArgumentException($\"array must be of length {InputLength}\");\r\n                _sequenceinput = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    class FooOutput\r\n    {\r\n        [ColumnName(\"softmax\"), VectorType(3)]\r\n        public float[] softmax { get; set; }\r\n    }\r\n}\r\n```\r\n**Expected behavior**\r\nno MissingMethodException \r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nTried to apply https://devblogs.microsoft.com/xamarin/machine-learning-in-xamarin-forms-with-onnx-runtime/ to our onnx scenario",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10048/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10047",
        "id": 1081163603,
        "node_id": "I_kwDOCVq1mM5AcT9T",
        "number": 10047,
        "title": "CUDA Cross-attention kernel",
        "user": {
            "login": "rom1K",
            "id": 91061498,
            "node_id": "MDQ6VXNlcjkxMDYxNDk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/91061498?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rom1K",
            "html_url": "https://github.com/rom1K",
            "followers_url": "https://api.github.com/users/rom1K/followers",
            "following_url": "https://api.github.com/users/rom1K/following{/other_user}",
            "gists_url": "https://api.github.com/users/rom1K/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rom1K/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rom1K/subscriptions",
            "organizations_url": "https://api.github.com/users/rom1K/orgs",
            "repos_url": "https://api.github.com/users/rom1K/repos",
            "events_url": "https://api.github.com/users/rom1K/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rom1K/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:enhancement",
                "name": "type:enhancement",
                "color": "a2eeef",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:documentation",
                "name": "component:documentation",
                "color": "303a93",
                "default": false,
                "description": "related to documentation"
            },
            {
                "id": 2114490130,
                "node_id": "MDU6TGFiZWwyMTE0NDkwMTMw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:operator",
                "name": "component:operator",
                "color": "303a93",
                "default": false,
                "description": "related to specific ONNX operator support"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-12-15T15:17:08Z",
        "updated_at": "2021-12-17T20:51:58Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm able to use the `onnxruntime.transformers` codebase to optimize Tranformer-based model using self-attention, however it's not possible to use the self-attention kernel for cross-attention.\r\n\r\n**System information**\r\n\r\n- ONNX Runtime version (you are using): 1.10.0\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would like to know if the implementation of a CUDA kernel for cross-attention is something you've considered adding to ONNXRuntime - or simply a modification of the current self-attention kernel to take in one input for queries and one input for keys and values.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFor generative models I think the self-attention kernel can be used after a first pass, as we can simply reuse past keys and values. However that is not the case more generally, when you only perform one inference on a given pair of input.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10047/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10046",
        "id": 1080714617,
        "node_id": "I_kwDOCVq1mM5AamV5",
        "number": 10046,
        "title": "[BUG] Registered type of RoiAlign  does not work ",
        "user": {
            "login": "zhibai-269",
            "id": 56142653,
            "node_id": "MDQ6VXNlcjU2MTQyNjUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/56142653?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhibai-269",
            "html_url": "https://github.com/zhibai-269",
            "followers_url": "https://api.github.com/users/zhibai-269/followers",
            "following_url": "https://api.github.com/users/zhibai-269/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhibai-269/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhibai-269/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhibai-269/subscriptions",
            "organizations_url": "https://api.github.com/users/zhibai-269/orgs",
            "repos_url": "https://api.github.com/users/zhibai-269/repos",
            "events_url": "https://api.github.com/users/zhibai-269/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhibai-269/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2021-12-15T08:15:10Z",
        "updated_at": "2022-02-08T08:34:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI register three type(MLFloat16floatdouble ) for Roialign to compute for onnx model.When I put  MLFloat16 in the front in .cc file,I can run float16 models successfully, but float double  with errors.But When I put float in the front ,I can run float models successfully, others with errors.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos 7.2 \r\n- ONNX Runtime installed from (source or binary):source\r\n- ONNX Runtime version: 1.7\r\n- Python version: 3.7.3\r\n- GCC/Compiler version (if compiling from source):gcc 5.4\r\n- CUDA/cuDNN version: CUDA 11.1CUDA 10.1etc.\r\n- GPU model and memory: NVIDIA GeForce 3090T4 etc.\r\n\r\n\r\n**To Reproduce**\r\nHere are the models.\r\n[roi_align.zip](https://github.com/microsoft/onnxruntime/files/7717431/roi_align.zip)\r\n\r\n\r\n\r\n\r\n**Screenshots**\r\n***As you can see ,I registered three Type in cuda_execution_provider.cc***\r\n![TH~6BNVZKLIB9 H@938870T](https://user-images.githubusercontent.com/56142653/146135303-5713a871-dab8-4991-84b4-829798d3daec.png)\r\nThen I run a test.py ,with a float16 ONNX model,and   got a right answer .However,when I run a same test.py with a float32 ONNX model(any other files hasn't been changed), I got the error blow.\r\n\r\n![F$_ 9)$~`C7GQAX3%MT7 JA](https://user-images.githubusercontent.com/56142653/146136514-b72939c0-6ff6-488a-8471-edf77378479c.jpg)\r\n\r\n***After that I moved the float Type in front of MLFloat16 in cuda_execution_provider.cc.***\r\n![G8 E1SYZ(1 5K%Q(QQ{I8M](https://user-images.githubusercontent.com/56142653/146136829-68d81fe4-d984-4c94-b0b8-3cb73a7ac998.png)\r\n***This time I can run the test.py with float32 model succesffly.When we run this test script with float16 model ,the same error occurs.***\r\n![UPO6THQ7SO~`@~4FSTSI1H](https://user-images.githubusercontent.com/56142653/146138247-ba7e264a-dbd9-4378-800b-a5fb6ae88c11.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n**Additional context**\r\nI tried test.py  whith duoble type models ,and got error all times.NEED HELP !@snnn !\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10046/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10045",
        "id": 1080687549,
        "node_id": "I_kwDOCVq1mM5Aafu9",
        "number": 10045,
        "title": "I can not run the tensorrt example \"quantized BERT model example\"",
        "user": {
            "login": "fangd123",
            "id": 3364985,
            "node_id": "MDQ6VXNlcjMzNjQ5ODU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3364985?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fangd123",
            "html_url": "https://github.com/fangd123",
            "followers_url": "https://api.github.com/users/fangd123/followers",
            "following_url": "https://api.github.com/users/fangd123/following{/other_user}",
            "gists_url": "https://api.github.com/users/fangd123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fangd123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fangd123/subscriptions",
            "organizations_url": "https://api.github.com/users/fangd123/orgs",
            "repos_url": "https://api.github.com/users/fangd123/repos",
            "events_url": "https://api.github.com/users/fangd123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fangd123/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature:quantization",
                "name": "feature:quantization",
                "color": "0052cc",
                "default": false,
                "description": "related to quantization of models or running quantized models"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "bfdadc",
                "default": false,
                "description": "questions/issues related to TensorRT EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-12-15T07:44:38Z",
        "updated_at": "2021-12-18T01:25:04Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I ran the exmaple file [quantized BERT model example](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/nlp/bert/trt) \r\n\r\nIt said error\r\n\r\n```bash\r\n [E:onnxruntime:Default, tensorrt_execution_provider.h:51 log] [2021-12-15 07:23:33   ERROR] 1: [codeGenerator.cpp::compileGraph::476] Error Code 1: Myelin (Quantize op 1886_QuantizeLinear_quantize_scale_node{ForeignNode[1798...Add_1257]} has mis-matched Scale shape and dimension at axis)\r\n[1]    2881918 segmentation fault (core dumped)  python e2e_tensorrt_bert_example.py\r\n```\r\n\r\nI used the model from the huggingface transformers which named \"bert-base-uncased\" and converted it into onnx file\r\n\r\n**System information**\r\n- OS Platform and Distribution Linux Ubuntu 20.04:\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.4.2\r\n- GPU model and memory: RTX3090\r\n- Tensorrt: 8.0.3.4",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10045/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10044",
        "id": 1080635000,
        "node_id": "I_kwDOCVq1mM5AaS54",
        "number": 10044,
        "title": "Segmentation fault : onnxruntime infer all outputs include all nodes with python API",
        "user": {
            "login": "wangxudong-cq",
            "id": 76459010,
            "node_id": "MDQ6VXNlcjc2NDU5MDEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/76459010?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangxudong-cq",
            "html_url": "https://github.com/wangxudong-cq",
            "followers_url": "https://api.github.com/users/wangxudong-cq/followers",
            "following_url": "https://api.github.com/users/wangxudong-cq/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangxudong-cq/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangxudong-cq/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangxudong-cq/subscriptions",
            "organizations_url": "https://api.github.com/users/wangxudong-cq/orgs",
            "repos_url": "https://api.github.com/users/wangxudong-cq/repos",
            "events_url": "https://api.github.com/users/wangxudong-cq/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangxudong-cq/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/type:enhancement",
                "name": "type:enhancement",
                "color": "a2eeef",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 1195353125,
                "node_id": "MDU6TGFiZWwxMTk1MzUzMTI1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Python",
                "name": "api:Python",
                "color": "0e8a16",
                "default": false,
                "description": "related to the Python API"
            },
            {
                "id": 2235309445,
                "node_id": "MDU6TGFiZWwyMjM1MzA5NDQ1",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/component:onnx",
                "name": "component:onnx",
                "color": "303a93",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2021-12-15T06:45:08Z",
        "updated_at": "2022-02-09T01:20:36Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nSegmentation fault (core dumped)\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04.5 LTS\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: Version: 1.6.0\r\n- Python version: Python 3.8.10\r\n\r\n**To Reproduce**\r\nmodel:https://github.com/onnx/models/blob/master/vision/classification/inception_and_googlenet/inception_v1/model/inception-v1-9.onnx\r\n\r\n#test.py\r\n```\r\n  import onnx\r\n  import onnx.numpy_helper\r\n  import onnxruntime as ort\r\n  from collections import OrderedDict\r\n  \r\n  \r\n  def readArrayFromPB(file):\r\n      tensor = onnx.TensorProto()\r\n      with open(file, \"rb\") as f:\r\n          tensor.ParseFromString(f.read())\r\n      array = onnx.numpy_helper.to_array(tensor)\r\n      return array\r\n  \r\n  def writeArrayToPB(file, array):\r\n      tensor = onnx.numpy_helper.from_array(array)\r\n      with open(file, \"wb\") as f:\r\n          f.write(tensor.SerializeToString())\r\n  \r\n  if __name__==\"__main__\":\r\n      model = onnx.load_model(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_nodes/inception-v1-9/inception-v1-9.onnx\")\r\n  \r\n      OutputNameLists = []\r\n      for i in range(len(model.graph.node)):\r\n          OutputNameLists.extend(model.graph.node[i].output)    \r\n  \r\n      OutputNameList = []\r\n      for i in range(len(model.graph.output)):\r\n          OutputNameList.append(model.graph.output[i].name)\r\n  \r\n      all_outs = list(set(OutputNameLists) - set(OutputNameList))\r\n      all_outs = [onnx.ValueInfoProto(name=x) for x in all_outs]\r\n      print(\"all_outs:{0}\".format(all_outs))\r\n  \r\n      model.graph.output.extend(all_outs)\r\n  \r\n      ort_session = ort.InferenceSession(model.SerializeToString())\r\n  \r\n      ort_ins = {}\r\n      ort_ins.update({\"data_0\":readArrayFromPB(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_nodes/inception-v1-9/test_data_set_0/input_0.pb\")})\r\n      \r\n      # ort_outnames = [\"prob_1\"]\r\n      ort_outnames = [x.name for x in ort_session.get_outputs()]\r\n      print(\"ort_outnames:{0}\".format(ort_outnames))\r\n      \r\n      ort_array = ort_session.run(ort_outnames, ort_ins)\r\n  \r\n      ort_outs = OrderedDict(zip(ort_outnames, ort_array))\r\n      ort_outshapes = {}\r\n      for k,v in ort_outs.items():\r\n          writeArrayToPB(\"/home/wang/wangxudong/RPP_iTest/netmodel/save_model_all_outs/inception-v1-9/prob_1.pb\",v)\r\n          ort_outshapes.update({k:v.shape})\r\n      print(ort_outshapes)\r\n```\r\n\r\n**Expected behavior**\r\nonnxruntime infer success\r\n\r\n**Screenshots**\r\n(ubuntu) wang@VM-1-159-ubuntu:~/wangxudong/RPP_iTest/netmodel$ python3 test.py\r\nall_outs:[name: \"loss3_classifier_1\"\r\n, name: \"conv1_7x7_s2_1\"\r\n, name: \"inception_4b_5x5_reduce_2\"\r\n, name: \"inception_4b_5x5_1\"\r\n, name: \"inception_4c_1x1_2\"\r\n, name: \"inception_4c_3x3_reduce_2\"\r\n, name: \"pool3_3x3_s2_1\"\r\n, name: \"inception_5b_pool_proj_2\"\r\n, name: \"inception_5a_5x5_2\"\r\n, name: \"inception_4c_5x5_2\"\r\n, name: \"inception_3a_pool_1\"\r\n, name: \"pool1_norm1_1\"\r\n, name: \"inception_4c_3x3_1\"\r\n, name: \"inception_3a_3x3_reduce_2\"\r\n, name: \"inception_4d_pool_proj_2\"\r\n, name: \"inception_4e_pool_1\"\r\n, name: \"_pool5/7x7_s1_mask_1\"\r\n, name: \"inception_4b_3x3_reduce_2\"\r\n, name: \"pool5_7x7_s1_1\"\r\n, name: \"inception_4a_5x5_1\"\r\n, name: \"inception_3a_5x5_1\"\r\n, name: \"inception_4d_5x5_reduce_1\"\r\n, name: \"inception_5b_5x5_2\"\r\n, name: \"inception_4d_5x5_reduce_2\"\r\n, name: \"inception_3b_5x5_reduce_2\"\r\n, name: \"inception_4b_1x1_2\"\r\n, name: \"inception_4a_1x1_1\"\r\n, name: \"inception_4b_3x3_1\"\r\n, name: \"inception_3a_1x1_1\"\r\n, name: \"inception_4d_3x3_1\"\r\n, name: \"pool1_3x3_s2_1\"\r\n, name: \"inception_5b_output_1\"\r\n, name: \"inception_5a_5x5_reduce_2\"\r\n, name: \"inception_4d_1x1_1\"\r\n, name: \"inception_4e_5x5_1\"\r\n, name: \"conv2_3x3_1\"\r\n, name: \"inception_4e_1x1_2\"\r\n, name: \"inception_4d_3x3_reduce_1\"\r\n, name: \"inception_3b_5x5_2\"\r\n, name: \"inception_4d_3x3_reduce_2\"\r\n, name: \"inception_4c_pool_1\"\r\n, name: \"inception_5b_1x1_1\"\r\n, name: \"inception_5a_3x3_reduce_2\"\r\n, name: \"inception_5a_output_1\"\r\n, name: \"inception_4a_3x3_2\"\r\n, name: \"inception_5a_pool_proj_1\"\r\n, name: \"inception_3a_5x5_reduce_2\"\r\n, name: \"inception_3a_pool_proj_1\"\r\n, name: \"inception_5a_pool_1\"\r\n, name: \"inception_4e_pool_proj_1\"\r\n, name: \"conv2_3x3_reduce_1\"\r\n, name: \"inception_4c_pool_proj_1\"\r\n, name: \"inception_4d_3x3_2\"\r\n, name: \"inception_3b_3x3_reduce_2\"\r\n, name: \"inception_4a_5x5_reduce_1\"\r\n, name: \"inception_4a_3x3_1\"\r\n, name: \"inception_4c_output_1\"\r\n, name: \"pool2_3x3_s2_1\"\r\n, name: \"inception_4e_3x3_1\"\r\n, name: \"inception_4e_pool_proj_2\"\r\n, name: \"conv2_3x3_2\"\r\n, name: \"inception_3b_pool_1\"\r\n, name: \"conv2_norm2_1\"\r\n, name: \"inception_5b_3x3_reduce_2\"\r\n, name: \"inception_4a_3x3_reduce_1\"\r\n, name: \"inception_5a_pool_proj_2\"\r\n, name: \"conv1_7x7_s2_2\"\r\n, name: \"inception_3a_pool_proj_2\"\r\n, name: \"inception_3a_3x3_1\"\r\n, name: \"inception_5b_5x5_reduce_2\"\r\n, name: \"inception_4b_5x5_2\"\r\n, name: \"inception_4e_5x5_reduce_1\"\r\n, name: \"inception_4b_pool_proj_1\"\r\n, name: \"inception_4c_3x3_reduce_1\"\r\n, name: \"inception_5a_5x5_1\"\r\n, name: \"inception_4a_pool_proj_1\"\r\n, name: \"inception_4a_5x5_reduce_2\"\r\n, name: \"inception_4a_1x1_2\"\r\n, name: \"inception_5a_3x3_reduce_1\"\r\n, name: \"inception_5b_1x1_2\"\r\n, name: \"inception_4c_5x5_reduce_2\"\r\n, name: \"inception_4c_3x3_2\"\r\n, name: \"inception_4e_3x3_reduce_2\"\r\n, name: \"inception_5b_pool_proj_1\"\r\n, name: \"inception_3a_5x5_reduce_1\"\r\n, name: \"inception_3a_5x5_2\"\r\n, name: \"inception_3b_pool_proj_1\"\r\n, name: \"inception_3b_pool_proj_2\"\r\n, name: \"OC2_DUMMY_0\"\r\n, name: \"inception_4e_output_1\"\r\n, name: \"inception_4b_pool_proj_2\"\r\n, name: \"inception_3b_output_1\"\r\n, name: \"inception_4b_3x3_2\"\r\n, name: \"inception_4a_3x3_reduce_2\"\r\n, name: \"inception_4a_5x5_2\"\r\n, name: \"inception_4e_1x1_1\"\r\n, name: \"inception_3b_5x5_reduce_1\"\r\n, name: \"inception_4e_5x5_reduce_2\"\r\n, name: \"inception_3b_5x5_1\"\r\n, name: \"inception_5b_pool_1\"\r\n, name: \"inception_3a_3x3_2\"\r\n, name: \"inception_3a_3x3_reduce_1\"\r\n, name: \"inception_5b_5x5_reduce_1\"\r\n, name: \"inception_4d_5x5_1\"\r\n, name: \"inception_5b_3x3_1\"\r\n, name: \"inception_4d_pool_proj_1\"\r\n, name: \"inception_4b_1x1_1\"\r\n, name: \"inception_3a_output_1\"\r\n, name: \"inception_4b_3x3_reduce_1\"\r\n, name: \"inception_3b_3x3_2\"\r\n, name: \"inception_5a_1x1_1\"\r\n, name: \"inception_4d_1x1_2\"\r\n, name: \"inception_3b_1x1_2\"\r\n, name: \"inception_4c_5x5_1\"\r\n, name: \"inception_5b_3x3_reduce_1\"\r\n, name: \"inception_3b_3x3_reduce_1\"\r\n, name: \"inception_4b_output_1\"\r\n, name: \"inception_5a_3x3_2\"\r\n, name: \"inception_4d_pool_1\"\r\n, name: \"inception_4d_output_1\"\r\n, name: \"inception_4e_3x3_reduce_1\"\r\n, name: \"OC2_DUMMY_2\"\r\n, name: \"inception_4a_pool_1\"\r\n, name: \"inception_4c_5x5_reduce_1\"\r\n, name: \"inception_4a_output_1\"\r\n, name: \"inception_4c_1x1_1\"\r\n, name: \"pool4_3x3_s2_1\"\r\n, name: \"inception_3a_1x1_2\"\r\n, name: \"inception_4b_5x5_reduce_1\"\r\n, name: \"inception_4d_5x5_2\"\r\n, name: \"inception_4a_pool_proj_2\"\r\n, name: \"conv2_3x3_reduce_2\"\r\n, name: \"inception_5a_1x1_2\"\r\n, name: \"inception_5b_3x3_2\"\r\n, name: \"inception_3b_1x1_1\"\r\n, name: \"inception_5a_5x5_reduce_1\"\r\n, name: \"pool5_7x7_s1_2\"\r\n, name: \"inception_5a_3x3_1\"\r\n, name: \"inception_4e_5x5_2\"\r\n, name: \"inception_3b_3x3_1\"\r\n, name: \"inception_5b_5x5_1\"\r\n, name: \"inception_4c_pool_proj_2\"\r\n, name: \"inception_4b_pool_1\"\r\n, name: \"inception_4e_3x3_2\"\r\n]\r\nort_outnames:['prob_1', 'loss3_classifier_1', 'conv1_7x7_s2_1', 'inception_4b_5x5_reduce_2', 'inception_4b_5x5_1', 'inception_4c_1x1_2', 'inception_4c_3x3_reduce_2', 'pool3_3x3_s2_1', 'inception_5b_pool_proj_2', 'inception_5a_5x5_2', 'inception_4c_5x5_2', 'inception_3a_pool_1', 'pool1_norm1_1', 'inception_4c_3x3_1', 'inception_3a_3x3_reduce_2', 'inception_4d_pool_proj_2', 'inception_4e_pool_1', '_pool5/7x7_s1_mask_1', 'inception_4b_3x3_reduce_2', 'pool5_7x7_s1_1', 'inception_4a_5x5_1', 'inception_3a_5x5_1', 'inception_4d_5x5_reduce_1', 'inception_5b_5x5_2', 'inception_4d_5x5_reduce_2', 'inception_3b_5x5_reduce_2', 'inception_4b_1x1_2', 'inception_4a_1x1_1', 'inception_4b_3x3_1', 'inception_3a_1x1_1', 'inception_4d_3x3_1', 'pool1_3x3_s2_1', 'inception_5b_output_1', 'inception_5a_5x5_reduce_2', 'inception_4d_1x1_1', 'inception_4e_5x5_1', 'conv2_3x3_1', 'inception_4e_1x1_2', 'inception_4d_3x3_reduce_1', 'inception_3b_5x5_2', 'inception_4d_3x3_reduce_2', 'inception_4c_pool_1', 'inception_5b_1x1_1', 'inception_5a_3x3_reduce_2', 'inception_5a_output_1', 'inception_4a_3x3_2', 'inception_5a_pool_proj_1', 'inception_3a_5x5_reduce_2', 'inception_3a_pool_proj_1', 'inception_5a_pool_1', 'inception_4e_pool_proj_1', 'conv2_3x3_reduce_1', 'inception_4c_pool_proj_1', 'inception_4d_3x3_2', 'inception_3b_3x3_reduce_2', 'inception_4a_5x5_reduce_1', 'inception_4a_3x3_1', 'inception_4c_output_1', 'pool2_3x3_s2_1', 'inception_4e_3x3_1', 'inception_4e_pool_proj_2', 'conv2_3x3_2', 'inception_3b_pool_1', 'conv2_norm2_1', 'inception_5b_3x3_reduce_2', 'inception_4a_3x3_reduce_1', 'inception_5a_pool_proj_2', 'conv1_7x7_s2_2', 'inception_3a_pool_proj_2', 'inception_3a_3x3_1', 'inception_5b_5x5_reduce_2', 'inception_4b_5x5_2', 'inception_4e_5x5_reduce_1', 'inception_4b_pool_proj_1', 'inception_4c_3x3_reduce_1', 'inception_5a_5x5_1', 'inception_4a_pool_proj_1', 'inception_4a_5x5_reduce_2', 'inception_4a_1x1_2', 'inception_5a_3x3_reduce_1', 'inception_5b_1x1_2', 'inception_4c_5x5_reduce_2', 'inception_4c_3x3_2', 'inception_4e_3x3_reduce_2', 'inception_5b_pool_proj_1', 'inception_3a_5x5_reduce_1', 'inception_3a_5x5_2', 'inception_3b_pool_proj_1', 'inception_3b_pool_proj_2', 'OC2_DUMMY_0', 'inception_4e_output_1', 'inception_4b_pool_proj_2', 'inception_3b_output_1', 'inception_4b_3x3_2', 'inception_4a_3x3_reduce_2', 'inception_4a_5x5_2', 'inception_4e_1x1_1', 'inception_3b_5x5_reduce_1', 'inception_4e_5x5_reduce_2', 'inception_3b_5x5_1', 'inception_5b_pool_1', 'inception_3a_3x3_2', 'inception_3a_3x3_reduce_1', 'inception_5b_5x5_reduce_1', 'inception_4d_5x5_1', 'inception_5b_3x3_1', 'inception_4d_pool_proj_1', 'inception_4b_1x1_1', 'inception_3a_output_1', 'inception_4b_3x3_reduce_1', 'inception_3b_3x3_2', 'inception_5a_1x1_1', 'inception_4d_1x1_2', 'inception_3b_1x1_2', 'inception_4c_5x5_1', 'inception_5b_3x3_reduce_1', 'inception_3b_3x3_reduce_1', 'inception_4b_output_1', 'inception_5a_3x3_2', 'inception_4d_pool_1', 'inception_4d_output_1', 'inception_4e_3x3_reduce_1', 'OC2_DUMMY_2', 'inception_4a_pool_1', 'inception_4c_5x5_reduce_1', 'inception_4a_output_1', 'inception_4c_1x1_1', 'pool4_3x3_s2_1', 'inception_3a_1x1_2', 'inception_4b_5x5_reduce_1', 'inception_4d_5x5_2', 'inception_4a_pool_proj_2', 'conv2_3x3_reduce_2', 'inception_5a_1x1_2', 'inception_5b_3x3_2', 'inception_3b_1x1_1', 'inception_5a_5x5_reduce_1', 'pool5_7x7_s1_2', 'inception_5a_3x3_1', 'inception_4e_5x5_2', 'inception_3b_3x3_1', 'inception_5b_5x5_1', 'inception_4c_pool_proj_2', 'inception_4b_pool_1', 'inception_4e_3x3_2']\r\nSegmentation fault (core dumped)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10044/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10043",
        "id": 1080559175,
        "node_id": "I_kwDOCVq1mM5AaAZH",
        "number": 10043,
        "title": "How to config the developing ide?",
        "user": {
            "login": "ZinuoCai",
            "id": 42794964,
            "node_id": "MDQ6VXNlcjQyNzk0OTY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/42794964?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ZinuoCai",
            "html_url": "https://github.com/ZinuoCai",
            "followers_url": "https://api.github.com/users/ZinuoCai/followers",
            "following_url": "https://api.github.com/users/ZinuoCai/following{/other_user}",
            "gists_url": "https://api.github.com/users/ZinuoCai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ZinuoCai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ZinuoCai/subscriptions",
            "organizations_url": "https://api.github.com/users/ZinuoCai/orgs",
            "repos_url": "https://api.github.com/users/ZinuoCai/repos",
            "events_url": "https://api.github.com/users/ZinuoCai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ZinuoCai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T04:42:21Z",
        "updated_at": "2021-12-15T05:25:04Z",
        "closed_at": "2021-12-15T05:19:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I am new to onnxruntime, and I wonder how to config the ide to code. Both vscode and clion are all right.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10043/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10042",
        "id": 1080501366,
        "node_id": "PR_kwDOCVq1mM4v3MmS",
        "number": 10042,
        "title": "A small fix to allocators",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-12-15T02:48:24Z",
        "updated_at": "2021-12-15T05:21:09Z",
        "closed_at": "2021-12-15T05:21:08Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10042",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10042",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10042.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10042.patch",
            "merged_at": "2021-12-15T05:21:08Z"
        },
        "body": "**Description**: \r\n\r\nCalcMemSizeForArray is a static function, it should be access from the class name, not pointers.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\nFix a VC++ warning:\r\n\r\nwarning C6031: return value ignored: called-function could return unexpected value\r\n\r\n\r\n\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10042/timeline",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/10041",
        "id": 1080451345,
        "node_id": "PR_kwDOCVq1mM4v3CYY",
        "number": 10041,
        "title": "Conv node bug, cached state was incoherent",
        "user": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-12-15T01:10:41Z",
        "updated_at": "2021-12-17T20:36:21Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10041",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/10041",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/10041.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/10041.patch",
            "merged_at": null
        },
        "body": "**Description**: When a zero sized shape passes through the Conv node we early exit during the computation, unfortunately this skips the setting of one of our cached state values. If we move the setting before the early exit, the cached state stays coherent.\r\n\r\nFixes: https://github.com/microsoft/onnxruntime/issues/10020\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10041/timeline",
        "performed_via_github_app": null
    }
]