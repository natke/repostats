[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1662881197",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16619#issuecomment-1662881197",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16619",
        "id": 1662881197,
        "node_id": "IC_kwDOCVq1mM5jHY2t",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-02T19:50:30Z",
        "updated_at": "2023-08-02T19:50:30Z",
        "author_association": "MEMBER",
        "body": "Please attach a repro model.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1662881197/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1663308030",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16619#issuecomment-1663308030",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16619",
        "id": 1663308030,
        "node_id": "IC_kwDOCVq1mM5jJBD-",
        "user": {
            "login": "justinchuby",
            "id": 11205048,
            "node_id": "MDQ6VXNlcjExMjA1MDQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11205048?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/justinchuby",
            "html_url": "https://github.com/justinchuby",
            "followers_url": "https://api.github.com/users/justinchuby/followers",
            "following_url": "https://api.github.com/users/justinchuby/following{/other_user}",
            "gists_url": "https://api.github.com/users/justinchuby/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/justinchuby/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/justinchuby/subscriptions",
            "organizations_url": "https://api.github.com/users/justinchuby/orgs",
            "repos_url": "https://api.github.com/users/justinchuby/repos",
            "events_url": "https://api.github.com/users/justinchuby/events{/privacy}",
            "received_events_url": "https://api.github.com/users/justinchuby/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-03T05:20:43Z",
        "updated_at": "2023-08-04T02:42:01Z",
        "author_association": "MEMBER",
        "body": "\r\n### Summary\r\n\r\nONNX Runtime raises `` when executing test `ops_test.TestOutputConsistencyFullGraphCPU.test_output_match_opinfo__concat_cpu_float32` in ONNX Script `TorchLib`.\r\n\r\nTo recreate this report, use\r\n\r\n```bash\r\nCREATE_REPRODUCTION_REPORT=1 python -m pytest onnxscript/tests/function_libs/torch_lib/ops_test.py -k test_output_match_opinfo__concat_cpu_float32\r\n```\r\n\r\n### To reproduce\r\n\r\n```python\r\nimport google.protobuf.text_format\r\nimport numpy as np\r\nfrom numpy import array, float16, float32, float64, int32, int64\r\nimport onnx\r\nimport onnxruntime as ort\r\n\r\n# Run n times\r\nN = 1\r\n\r\nonnx_model_text = \"\"\"\r\nir_version: 8\r\nproducer_name: \"pytorch\"\r\nproducer_version: \"2.1.0\"\r\ngraph {\r\n  node {\r\n    input: \"input_0_0\"\r\n    input: \"input_0_1\"\r\n    output: \"2\"\r\n    name: \"SequenceConstruct_0\"\r\n    op_type: \"SequenceConstruct\"\r\n    doc_string: \"\"\r\n  }\r\n  node {\r\n    input: \"2\"\r\n    output: \"_val_3\"\r\n    name: \"aten_concat_1\"\r\n    op_type: \"aten_concat\"\r\n    attribute {\r\n      name: \"dim\"\r\n      i: 1\r\n      type: INT\r\n    }\r\n    doc_string: \"\"\r\n    domain: \"pkg.onnxscript.torch_lib\"\r\n  }\r\n  name: \"torch_jit\"\r\n  input {\r\n    name: \"input_0_0\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: 1\r\n        shape {\r\n          dim {\r\n            dim_value: 0\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  input {\r\n    name: \"input_0_1\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: 1\r\n        shape {\r\n          dim {\r\n            dim_value: 5\r\n          }\r\n          dim {\r\n            dim_value: 5\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  output {\r\n    name: \"_val_3\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: 1\r\n        shape {\r\n          dim {\r\n            dim_value: 5\r\n          }\r\n          dim {\r\n            dim_value: 5\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  value_info {\r\n    name: \"2\"\r\n    type {\r\n      sequence_type {\r\n        elem_type {\r\n          tensor_type {\r\n            elem_type: 1\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nopset_import {\r\n  domain: \"pkg.onnxscript.torch_lib\"\r\n  version: 1\r\n}\r\nopset_import {\r\n  domain: \"\"\r\n  version: 18\r\n}\r\nfunctions {\r\n  name: \"aten_concat\"\r\n  input: \"tensors\"\r\n  output: \"return_val\"\r\n  node {\r\n    input: \"tensors\"\r\n    output: \"return_val\"\r\n    name: \"n0\"\r\n    op_type: \"ConcatFromSequence\"\r\n    attribute {\r\n      name: \"axis\"\r\n      type: INT\r\n      ref_attr_name: \"dim\"\r\n    }\r\n    domain: \"\"\r\n  }\r\n  doc_string: \"concat(Tensor[] tensors, int dim=0) -> Tensor\"\r\n  opset_import {\r\n    domain: \"\"\r\n    version: 18\r\n  }\r\n  domain: \"pkg.onnxscript.torch_lib\"\r\n  attribute_proto {\r\n    name: \"dim\"\r\n    i: 0\r\n    type: INT\r\n  }\r\n}\r\n\r\n\"\"\"\r\n\r\nort_inputs = {'input_0_0': array([], dtype=float32), 'input_0_1': array([[-1.5814927 , -2.3832114 ,  0.9628283 , -1.5898869 , -2.6820095 ],\r\n       [ 5.752862  ,  7.7345963 , -0.8909762 , -2.0150719 ,  0.13133061],\r\n       [-0.53737414,  2.1637015 ,  2.5221026 , -8.174311  , -3.3213396 ],\r\n       [ 7.5791655 ,  3.5059948 , -0.44763815, -5.4261518 , -5.5062456 ],\r\n       [-8.061902  , -2.933662  ,  3.0393376 ,  5.738595  ,  4.1552763 ]],\r\n      dtype=float32)}\r\n\r\n# Set up the inference session\r\nsession_options = ort.SessionOptions()\r\nsession_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\r\nonnx_model = onnx.ModelProto()\r\ngoogle.protobuf.text_format.Parse(onnx_model_text, onnx_model)\r\n\r\n# Uncomment this line to save the model to a file for examination\r\n# onnx.save_model(onnx_model, \"test_output_match_opinfo__concat_cpu_float32.onnx\")\r\n\r\nonnx.checker.check_model(onnx_model)\r\nsession = ort.InferenceSession(onnx_model.SerializeToString(), session_options, providers=(\"CPUExecutionProvider\",))\r\n\r\n# Run the model\r\nfor _ in range(N):\r\n    ort_outputs = session.run(None, ort_inputs)\r\n\r\n```\r\n\r\n### Full error stack\r\n\r\n```\r\n\r\n  File \"/home/justinchu/dev/onnx-script/onnxscript/tests/function_libs/torch_lib/ops_test_common.py\", line 533, in _capture_graph_and_evaluate_torch_script_evaluator\r\n    return _safe_ort_session_run(onnx_model.SerializeToString(), ort_inputs)\r\n  File \"/home/justinchu/dev/onnx-script/onnxscript/tests/function_libs/torch_lib/ops_test_common.py\", line 347, in _safe_ort_session_run\r\n    raise OrtAbortedError()\r\n\r\n```\r\n\r\n### Environment\r\n\r\n```\r\nOS: Linux-5.15.0-1042-azure-x86_64-with-glibc2.35\r\nPython version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]\r\nonnx==1.15.0.dev20230731\r\nonnxruntime==1.15.1\r\nnumpy==1.25.1\r\ntorch==2.1.0.dev20230622+cpu\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1663308030/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]