[
    {
        "id": 6254897091,
        "node_id": "LE_lADOCVq1mM5F0JyDzwAAAAF00ifD",
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events/6254897091",
        "actor": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "event": "labeled",
        "commit_id": null,
        "commit_url": null,
        "created_at": "2022-03-17T00:59:10Z",
        "label": {
            "name": "ep:CUDA",
            "color": "bfdadc"
        },
        "performed_via_github_app": null
    },
    {
        "actor": {
            "login": "L-Reichardt",
            "id": 72140033,
            "node_id": "MDQ6VXNlcjcyMTQwMDMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/72140033?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/L-Reichardt",
            "html_url": "https://github.com/L-Reichardt",
            "followers_url": "https://api.github.com/users/L-Reichardt/followers",
            "following_url": "https://api.github.com/users/L-Reichardt/following{/other_user}",
            "gists_url": "https://api.github.com/users/L-Reichardt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/L-Reichardt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/L-Reichardt/subscriptions",
            "organizations_url": "https://api.github.com/users/L-Reichardt/orgs",
            "repos_url": "https://api.github.com/users/L-Reichardt/repos",
            "events_url": "https://api.github.com/users/L-Reichardt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/L-Reichardt/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T14:00:48Z",
        "updated_at": "2022-03-17T14:00:48Z",
        "source": {
            "type": "issue",
            "issue": {
                "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914",
                "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
                "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914/labels{/name}",
                "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914/comments",
                "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914/events",
                "html_url": "https://github.com/microsoft/onnxruntime/issues/10914",
                "id": 1172425109,
                "node_id": "I_kwDOCVq1mM5F4cmV",
                "number": 10914,
                "title": "TensorRT Execution [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization",
                "user": {
                    "login": "L-Reichardt",
                    "id": 72140033,
                    "node_id": "MDQ6VXNlcjcyMTQwMDMz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/72140033?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/L-Reichardt",
                    "html_url": "https://github.com/L-Reichardt",
                    "followers_url": "https://api.github.com/users/L-Reichardt/followers",
                    "following_url": "https://api.github.com/users/L-Reichardt/following{/other_user}",
                    "gists_url": "https://api.github.com/users/L-Reichardt/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/L-Reichardt/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/L-Reichardt/subscriptions",
                    "organizations_url": "https://api.github.com/users/L-Reichardt/orgs",
                    "repos_url": "https://api.github.com/users/L-Reichardt/repos",
                    "events_url": "https://api.github.com/users/L-Reichardt/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/L-Reichardt/received_events",
                    "type": "User",
                    "site_admin": false
                },
                "labels": [
                    {
                        "id": 2204061391,
                        "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                        "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                        "name": "ep:TensorRT",
                        "color": "0052CC",
                        "default": false,
                        "description": "issues related to TensorRT execution provider"
                    }
                ],
                "state": "open",
                "locked": false,
                "assignee": null,
                "assignees": [],
                "milestone": null,
                "comments": 0,
                "created_at": "2022-03-17T14:00:48Z",
                "updated_at": "2022-03-17T17:20:09Z",
                "closed_at": null,
                "author_association": "NONE",
                "active_lock_reason": null,
                "repository": {
                    "id": 156939672,
                    "node_id": "MDEwOlJlcG9zaXRvcnkxNTY5Mzk2NzI=",
                    "name": "onnxruntime",
                    "full_name": "microsoft/onnxruntime",
                    "private": false,
                    "owner": {
                        "login": "microsoft",
                        "id": 6154722,
                        "node_id": "MDEyOk9yZ2FuaXphdGlvbjYxNTQ3MjI=",
                        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4",
                        "gravatar_id": "",
                        "url": "https://api.github.com/users/microsoft",
                        "html_url": "https://github.com/microsoft",
                        "followers_url": "https://api.github.com/users/microsoft/followers",
                        "following_url": "https://api.github.com/users/microsoft/following{/other_user}",
                        "gists_url": "https://api.github.com/users/microsoft/gists{/gist_id}",
                        "starred_url": "https://api.github.com/users/microsoft/starred{/owner}{/repo}",
                        "subscriptions_url": "https://api.github.com/users/microsoft/subscriptions",
                        "organizations_url": "https://api.github.com/users/microsoft/orgs",
                        "repos_url": "https://api.github.com/users/microsoft/repos",
                        "events_url": "https://api.github.com/users/microsoft/events{/privacy}",
                        "received_events_url": "https://api.github.com/users/microsoft/received_events",
                        "type": "Organization",
                        "site_admin": false
                    },
                    "html_url": "https://github.com/microsoft/onnxruntime",
                    "description": "ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator",
                    "fork": false,
                    "url": "https://api.github.com/repos/microsoft/onnxruntime",
                    "forks_url": "https://api.github.com/repos/microsoft/onnxruntime/forks",
                    "keys_url": "https://api.github.com/repos/microsoft/onnxruntime/keys{/key_id}",
                    "collaborators_url": "https://api.github.com/repos/microsoft/onnxruntime/collaborators{/collaborator}",
                    "teams_url": "https://api.github.com/repos/microsoft/onnxruntime/teams",
                    "hooks_url": "https://api.github.com/repos/microsoft/onnxruntime/hooks",
                    "issue_events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events{/number}",
                    "events_url": "https://api.github.com/repos/microsoft/onnxruntime/events",
                    "assignees_url": "https://api.github.com/repos/microsoft/onnxruntime/assignees{/user}",
                    "branches_url": "https://api.github.com/repos/microsoft/onnxruntime/branches{/branch}",
                    "tags_url": "https://api.github.com/repos/microsoft/onnxruntime/tags",
                    "blobs_url": "https://api.github.com/repos/microsoft/onnxruntime/git/blobs{/sha}",
                    "git_tags_url": "https://api.github.com/repos/microsoft/onnxruntime/git/tags{/sha}",
                    "git_refs_url": "https://api.github.com/repos/microsoft/onnxruntime/git/refs{/sha}",
                    "trees_url": "https://api.github.com/repos/microsoft/onnxruntime/git/trees{/sha}",
                    "statuses_url": "https://api.github.com/repos/microsoft/onnxruntime/statuses/{sha}",
                    "languages_url": "https://api.github.com/repos/microsoft/onnxruntime/languages",
                    "stargazers_url": "https://api.github.com/repos/microsoft/onnxruntime/stargazers",
                    "contributors_url": "https://api.github.com/repos/microsoft/onnxruntime/contributors",
                    "subscribers_url": "https://api.github.com/repos/microsoft/onnxruntime/subscribers",
                    "subscription_url": "https://api.github.com/repos/microsoft/onnxruntime/subscription",
                    "commits_url": "https://api.github.com/repos/microsoft/onnxruntime/commits{/sha}",
                    "git_commits_url": "https://api.github.com/repos/microsoft/onnxruntime/git/commits{/sha}",
                    "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/comments{/number}",
                    "issue_comment_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments{/number}",
                    "contents_url": "https://api.github.com/repos/microsoft/onnxruntime/contents/{+path}",
                    "compare_url": "https://api.github.com/repos/microsoft/onnxruntime/compare/{base}...{head}",
                    "merges_url": "https://api.github.com/repos/microsoft/onnxruntime/merges",
                    "archive_url": "https://api.github.com/repos/microsoft/onnxruntime/{archive_format}{/ref}",
                    "downloads_url": "https://api.github.com/repos/microsoft/onnxruntime/downloads",
                    "issues_url": "https://api.github.com/repos/microsoft/onnxruntime/issues{/number}",
                    "pulls_url": "https://api.github.com/repos/microsoft/onnxruntime/pulls{/number}",
                    "milestones_url": "https://api.github.com/repos/microsoft/onnxruntime/milestones{/number}",
                    "notifications_url": "https://api.github.com/repos/microsoft/onnxruntime/notifications{?since,all,participating}",
                    "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/labels{/name}",
                    "releases_url": "https://api.github.com/repos/microsoft/onnxruntime/releases{/id}",
                    "deployments_url": "https://api.github.com/repos/microsoft/onnxruntime/deployments",
                    "created_at": "2018-11-10T02:22:53Z",
                    "updated_at": "2022-12-20T19:02:34Z",
                    "pushed_at": "2022-12-20T19:09:41Z",
                    "git_url": "git://github.com/microsoft/onnxruntime.git",
                    "ssh_url": "git@github.com:microsoft/onnxruntime.git",
                    "clone_url": "https://github.com/microsoft/onnxruntime.git",
                    "svn_url": "https://github.com/microsoft/onnxruntime",
                    "homepage": "https://www.onnxruntime.ai",
                    "size": 1018648,
                    "stargazers_count": 7949,
                    "watchers_count": 7949,
                    "language": "C++",
                    "has_issues": true,
                    "has_projects": true,
                    "has_downloads": true,
                    "has_wiki": true,
                    "has_pages": true,
                    "has_discussions": true,
                    "forks_count": 1862,
                    "mirror_url": null,
                    "archived": false,
                    "disabled": false,
                    "open_issues_count": 1452,
                    "license": {
                        "key": "mit",
                        "name": "MIT License",
                        "spdx_id": "MIT",
                        "url": "https://api.github.com/licenses/mit",
                        "node_id": "MDc6TGljZW5zZTEz"
                    },
                    "allow_forking": true,
                    "is_template": false,
                    "web_commit_signoff_required": false,
                    "topics": [
                        "ai-framework",
                        "deep-learning",
                        "hacktoberfest",
                        "hardware-acceleration",
                        "machine-learning",
                        "neural-networks",
                        "onnx",
                        "pytorch",
                        "scikit-learn",
                        "tensorflow"
                    ],
                    "visibility": "public",
                    "forks": 1862,
                    "open_issues": 1452,
                    "watchers": 7949,
                    "default_branch": "main",
                    "permissions": {
                        "admin": false,
                        "maintain": true,
                        "push": true,
                        "triage": true,
                        "pull": true
                    }
                },
                "body": "**Describe the bug**\r\nMy Tensorflow -> ONNX converted model runs on CPU, but not executing through TensorRT or CUDA (CUDA separate issue #10894 ). Tensorflow model itself works fine on GPU. Found no related Issue or solution related to this Issue.\r\nModels and logs found here [Google Drive](https://drive.google.com/drive/folders/1cIoRX7tYtX1Ze0Dx_0roT4IA3pUZjjlp?usp=sharing) (file format blocked by github)\r\n\r\n**Urgency**\r\nUrgent: by Monday 21.03.2022\r\n\r\n**System Information**\r\n- Linux Ubuntu 20.04\r\n- ONNX Runtime installed from binary:\r\n- ONNX Runtime version: gpu 1.10.0\r\n- Python version: 3.8.10\r\n- Visual Studio version (if applicable): n.a.\r\n- GCC/Compiler version (if compiling from source): n.a.\r\n- CUDA/cuDNN version: 10.04, 8.2.4\r\n- TensorRT Version: 8.2.1, also tested with all newer versions\r\n- GPU model and memory: RTX3060 12 GB\r\n\r\n**To Reproduce**\r\n- Attached Tensorflow model converted to attached ONNX Model\r\n- Conversion with Opset 13\r\n\r\n**Expected behavior**\r\n- Failure to run model through ONNX runtime with TensorRT execution\r\n\r\n**Screenshots**\r\n\r\n**Additional context**\r\n",
                "reactions": {
                    "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914/reactions",
                    "total_count": 0,
                    "+1": 0,
                    "-1": 0,
                    "laugh": 0,
                    "hooray": 0,
                    "confused": 0,
                    "heart": 0,
                    "rocket": 0,
                    "eyes": 0
                },
                "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10914/timeline",
                "performed_via_github_app": null,
                "state_reason": null
            }
        },
        "event": "cross-referenced"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1110915026",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10894#issuecomment-1110915026",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10894",
        "id": 1110915026,
        "node_id": "IC_kwDOCVq1mM5CNzfS",
        "user": {
            "login": "ephr4321",
            "id": 23211899,
            "node_id": "MDQ6VXNlcjIzMjExODk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/23211899?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ephr4321",
            "html_url": "https://github.com/ephr4321",
            "followers_url": "https://api.github.com/users/ephr4321/followers",
            "following_url": "https://api.github.com/users/ephr4321/following{/other_user}",
            "gists_url": "https://api.github.com/users/ephr4321/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ephr4321/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ephr4321/subscriptions",
            "organizations_url": "https://api.github.com/users/ephr4321/orgs",
            "repos_url": "https://api.github.com/users/ephr4321/repos",
            "events_url": "https://api.github.com/users/ephr4321/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ephr4321/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-27T11:59:57Z",
        "updated_at": "2022-04-27T11:59:57Z",
        "author_association": "NONE",
        "body": "I had a similar problem when running about 12 different models. I got the error only at the 8th model, and saw I'm actually out of GPU memory...\r\nI see you have 12GB of Memory, but maybe...",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1110915026/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "ephr4321",
            "id": 23211899,
            "node_id": "MDQ6VXNlcjIzMjExODk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/23211899?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ephr4321",
            "html_url": "https://github.com/ephr4321",
            "followers_url": "https://api.github.com/users/ephr4321/followers",
            "following_url": "https://api.github.com/users/ephr4321/following{/other_user}",
            "gists_url": "https://api.github.com/users/ephr4321/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ephr4321/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ephr4321/subscriptions",
            "organizations_url": "https://api.github.com/users/ephr4321/orgs",
            "repos_url": "https://api.github.com/users/ephr4321/repos",
            "events_url": "https://api.github.com/users/ephr4321/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ephr4321/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1202060015",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10894#issuecomment-1202060015",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10894",
        "id": 1202060015,
        "node_id": "IC_kwDOCVq1mM5Hpfrv",
        "user": {
            "login": "tall-josh",
            "id": 18511395,
            "node_id": "MDQ6VXNlcjE4NTExMzk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/18511395?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tall-josh",
            "html_url": "https://github.com/tall-josh",
            "followers_url": "https://api.github.com/users/tall-josh/followers",
            "following_url": "https://api.github.com/users/tall-josh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tall-josh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tall-josh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tall-josh/subscriptions",
            "organizations_url": "https://api.github.com/users/tall-josh/orgs",
            "repos_url": "https://api.github.com/users/tall-josh/repos",
            "events_url": "https://api.github.com/users/tall-josh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tall-josh/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-02T06:11:32Z",
        "updated_at": "2022-08-31T01:18:05Z",
        "author_association": "NONE",
        "body": "I got a similar error:\r\n\r\n```console\r\nRuntimeError: Error in execution: Non-zero status code returned while running FusedConv node. Name:'Conv_0' Status Message: /onnxruntime_src/include/onnxruntime/core/framework/op_kernel_context.h:40 const T* onnxruntime::OpKernelContext::Input(int) const [with T = onnxruntime::Tensor] Missing Input: input\r\n```\r\n\r\nTurns out I was checking for Cuda availability before setting `io_binding` for my input. I only set the binding if Cuda was available but used `sess.run_with_iobinding(self.io_binding)` in both Cuda and CPU cases. The fix was to remove the conditional around the `bind_cpu_input`. ie:\r\n\r\n```python\r\n#### BAD ####\r\nif ort.get_device() == \"GPU\":\r\n    self.io_binding.bind_cpu_input(\"input\", preproc_crops)\r\nself.sess.run_with_iobinding(self.io_binding)\r\nort_outputs = self.io_binding.copy_outputs_to_cpu()\r\n#############\r\n\r\n#### GOOD ####\r\nself.io_binding.bind_cpu_input(\"input\", preproc_crops)\r\nself.sess.run_with_iobinding(self.io_binding)\r\nort_outputs = self.io_binding.copy_outputs_to_cpu()\r\n#############\r\n```\r\n\r\nIn the [docs](https://onnxruntime.ai/docs/api/python/api_summary.html#data-on-device) _that I only read as a last resort_ :-p it says `io_binding.bind_cpu_input('input', X)` will \"_copy the data over to the CUDA device **if** 'input' is consumed by nodes on the CUDA device_\". So if 'input' is not consumed by nodes of the CUDA device it will not do the copy, but 'input' will still be passed to the CPU. \r\n\r\nThe error in my original thinking was that the bind was only required **if** GPU was available but that meant the 'input' was not bound to any device in the case where GPU was not available.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1202060015/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "tall-josh",
            "id": 18511395,
            "node_id": "MDQ6VXNlcjE4NTExMzk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/18511395?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tall-josh",
            "html_url": "https://github.com/tall-josh",
            "followers_url": "https://api.github.com/users/tall-josh/followers",
            "following_url": "https://api.github.com/users/tall-josh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tall-josh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tall-josh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tall-josh/subscriptions",
            "organizations_url": "https://api.github.com/users/tall-josh/orgs",
            "repos_url": "https://api.github.com/users/tall-josh/repos",
            "events_url": "https://api.github.com/users/tall-josh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tall-josh/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "actor": {
            "login": "rmccorm4",
            "id": 21284872,
            "node_id": "MDQ6VXNlcjIxMjg0ODcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/21284872?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rmccorm4",
            "html_url": "https://github.com/rmccorm4",
            "followers_url": "https://api.github.com/users/rmccorm4/followers",
            "following_url": "https://api.github.com/users/rmccorm4/following{/other_user}",
            "gists_url": "https://api.github.com/users/rmccorm4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rmccorm4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rmccorm4/subscriptions",
            "organizations_url": "https://api.github.com/users/rmccorm4/orgs",
            "repos_url": "https://api.github.com/users/rmccorm4/repos",
            "events_url": "https://api.github.com/users/rmccorm4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rmccorm4/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-15T21:50:17Z",
        "updated_at": "2022-08-15T21:50:17Z",
        "source": {
            "type": "issue",
            "issue": {
                "url": "https://api.github.com/repos/triton-inference-server/server/issues/4766",
                "repository_url": "https://api.github.com/repos/triton-inference-server/server",
                "labels_url": "https://api.github.com/repos/triton-inference-server/server/issues/4766/labels{/name}",
                "comments_url": "https://api.github.com/repos/triton-inference-server/server/issues/4766/comments",
                "events_url": "https://api.github.com/repos/triton-inference-server/server/issues/4766/events",
                "html_url": "https://github.com/triton-inference-server/server/issues/4766",
                "id": 1338479148,
                "node_id": "I_kwDOCQnI4s5Px5Is",
                "number": 4766,
                "title": "CUDNN_STATUS_EXECUTION_FAILED when Triton server is running",
                "user": {
                    "login": "heibaidaolx123",
                    "id": 19296609,
                    "node_id": "MDQ6VXNlcjE5Mjk2NjA5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/19296609?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/heibaidaolx123",
                    "html_url": "https://github.com/heibaidaolx123",
                    "followers_url": "https://api.github.com/users/heibaidaolx123/followers",
                    "following_url": "https://api.github.com/users/heibaidaolx123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/heibaidaolx123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/heibaidaolx123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/heibaidaolx123/subscriptions",
                    "organizations_url": "https://api.github.com/users/heibaidaolx123/orgs",
                    "repos_url": "https://api.github.com/users/heibaidaolx123/repos",
                    "events_url": "https://api.github.com/users/heibaidaolx123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/heibaidaolx123/received_events",
                    "type": "User",
                    "site_admin": false
                },
                "labels": [
                    {
                        "id": 1079803568,
                        "node_id": "MDU6TGFiZWwxMDc5ODAzNTY4",
                        "url": "https://api.github.com/repos/triton-inference-server/server/labels/bug",
                        "name": "bug",
                        "color": "d73a4a",
                        "default": true,
                        "description": "Something isn't working"
                    }
                ],
                "state": "open",
                "locked": false,
                "assignee": null,
                "assignees": [],
                "milestone": null,
                "comments": 3,
                "created_at": "2022-08-15T03:10:25Z",
                "updated_at": "2022-09-01T00:34:30Z",
                "closed_at": null,
                "author_association": "NONE",
                "active_lock_reason": null,
                "repository": {
                    "id": 151636194,
                    "node_id": "MDEwOlJlcG9zaXRvcnkxNTE2MzYxOTQ=",
                    "name": "server",
                    "full_name": "triton-inference-server/server",
                    "private": false,
                    "owner": {
                        "login": "triton-inference-server",
                        "id": 68086070,
                        "node_id": "MDEyOk9yZ2FuaXphdGlvbjY4MDg2MDcw",
                        "avatar_url": "https://avatars.githubusercontent.com/u/68086070?v=4",
                        "gravatar_id": "",
                        "url": "https://api.github.com/users/triton-inference-server",
                        "html_url": "https://github.com/triton-inference-server",
                        "followers_url": "https://api.github.com/users/triton-inference-server/followers",
                        "following_url": "https://api.github.com/users/triton-inference-server/following{/other_user}",
                        "gists_url": "https://api.github.com/users/triton-inference-server/gists{/gist_id}",
                        "starred_url": "https://api.github.com/users/triton-inference-server/starred{/owner}{/repo}",
                        "subscriptions_url": "https://api.github.com/users/triton-inference-server/subscriptions",
                        "organizations_url": "https://api.github.com/users/triton-inference-server/orgs",
                        "repos_url": "https://api.github.com/users/triton-inference-server/repos",
                        "events_url": "https://api.github.com/users/triton-inference-server/events{/privacy}",
                        "received_events_url": "https://api.github.com/users/triton-inference-server/received_events",
                        "type": "Organization",
                        "site_admin": false
                    },
                    "html_url": "https://github.com/triton-inference-server/server",
                    "description": "The Triton Inference Server provides an optimized cloud and edge inferencing solution. ",
                    "fork": false,
                    "url": "https://api.github.com/repos/triton-inference-server/server",
                    "forks_url": "https://api.github.com/repos/triton-inference-server/server/forks",
                    "keys_url": "https://api.github.com/repos/triton-inference-server/server/keys{/key_id}",
                    "collaborators_url": "https://api.github.com/repos/triton-inference-server/server/collaborators{/collaborator}",
                    "teams_url": "https://api.github.com/repos/triton-inference-server/server/teams",
                    "hooks_url": "https://api.github.com/repos/triton-inference-server/server/hooks",
                    "issue_events_url": "https://api.github.com/repos/triton-inference-server/server/issues/events{/number}",
                    "events_url": "https://api.github.com/repos/triton-inference-server/server/events",
                    "assignees_url": "https://api.github.com/repos/triton-inference-server/server/assignees{/user}",
                    "branches_url": "https://api.github.com/repos/triton-inference-server/server/branches{/branch}",
                    "tags_url": "https://api.github.com/repos/triton-inference-server/server/tags",
                    "blobs_url": "https://api.github.com/repos/triton-inference-server/server/git/blobs{/sha}",
                    "git_tags_url": "https://api.github.com/repos/triton-inference-server/server/git/tags{/sha}",
                    "git_refs_url": "https://api.github.com/repos/triton-inference-server/server/git/refs{/sha}",
                    "trees_url": "https://api.github.com/repos/triton-inference-server/server/git/trees{/sha}",
                    "statuses_url": "https://api.github.com/repos/triton-inference-server/server/statuses/{sha}",
                    "languages_url": "https://api.github.com/repos/triton-inference-server/server/languages",
                    "stargazers_url": "https://api.github.com/repos/triton-inference-server/server/stargazers",
                    "contributors_url": "https://api.github.com/repos/triton-inference-server/server/contributors",
                    "subscribers_url": "https://api.github.com/repos/triton-inference-server/server/subscribers",
                    "subscription_url": "https://api.github.com/repos/triton-inference-server/server/subscription",
                    "commits_url": "https://api.github.com/repos/triton-inference-server/server/commits{/sha}",
                    "git_commits_url": "https://api.github.com/repos/triton-inference-server/server/git/commits{/sha}",
                    "comments_url": "https://api.github.com/repos/triton-inference-server/server/comments{/number}",
                    "issue_comment_url": "https://api.github.com/repos/triton-inference-server/server/issues/comments{/number}",
                    "contents_url": "https://api.github.com/repos/triton-inference-server/server/contents/{+path}",
                    "compare_url": "https://api.github.com/repos/triton-inference-server/server/compare/{base}...{head}",
                    "merges_url": "https://api.github.com/repos/triton-inference-server/server/merges",
                    "archive_url": "https://api.github.com/repos/triton-inference-server/server/{archive_format}{/ref}",
                    "downloads_url": "https://api.github.com/repos/triton-inference-server/server/downloads",
                    "issues_url": "https://api.github.com/repos/triton-inference-server/server/issues{/number}",
                    "pulls_url": "https://api.github.com/repos/triton-inference-server/server/pulls{/number}",
                    "milestones_url": "https://api.github.com/repos/triton-inference-server/server/milestones{/number}",
                    "notifications_url": "https://api.github.com/repos/triton-inference-server/server/notifications{?since,all,participating}",
                    "labels_url": "https://api.github.com/repos/triton-inference-server/server/labels{/name}",
                    "releases_url": "https://api.github.com/repos/triton-inference-server/server/releases{/id}",
                    "deployments_url": "https://api.github.com/repos/triton-inference-server/server/deployments",
                    "created_at": "2018-10-04T21:10:30Z",
                    "updated_at": "2022-12-20T15:52:44Z",
                    "pushed_at": "2022-12-19T22:35:37Z",
                    "git_url": "git://github.com/triton-inference-server/server.git",
                    "ssh_url": "git@github.com:triton-inference-server/server.git",
                    "clone_url": "https://github.com/triton-inference-server/server.git",
                    "svn_url": "https://github.com/triton-inference-server/server",
                    "homepage": "https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html",
                    "size": 28881,
                    "stargazers_count": 4535,
                    "watchers_count": 4535,
                    "language": "Python",
                    "has_issues": true,
                    "has_projects": false,
                    "has_downloads": true,
                    "has_wiki": false,
                    "has_pages": false,
                    "has_discussions": false,
                    "forks_count": 1055,
                    "mirror_url": null,
                    "archived": false,
                    "disabled": false,
                    "open_issues_count": 205,
                    "license": {
                        "key": "bsd-3-clause",
                        "name": "BSD 3-Clause \"New\" or \"Revised\" License",
                        "spdx_id": "BSD-3-Clause",
                        "url": "https://api.github.com/licenses/bsd-3-clause",
                        "node_id": "MDc6TGljZW5zZTU="
                    },
                    "allow_forking": true,
                    "is_template": false,
                    "web_commit_signoff_required": false,
                    "topics": [
                        "cloud",
                        "datacenter",
                        "deep-learning",
                        "edge",
                        "gpu",
                        "inference",
                        "machine-learning"
                    ],
                    "visibility": "public",
                    "forks": 1055,
                    "open_issues": 205,
                    "watchers": 4535,
                    "default_branch": "main",
                    "permissions": {
                        "admin": false,
                        "maintain": false,
                        "push": false,
                        "triage": false,
                        "pull": true
                    }
                },
                "body": "Hi, \r\nI deployed a ensemble model with Triton server. After serving successfully for 5 days, the server crashed with a CUDNN error **CUDNN_STATUS_EXECUTION_FAILED** .\r\nThe docker image we use is nvcr.io/nvidia/tritonserver:22.05-py3, and runs on an A40 GPU, the dirver verion  is 470.57.02.\r\nThe log printed is as blow:\r\n```\r\n2022-08-13 11:42:42.261057647 [E:onnxruntime:log, cuda_call.cc:118 CudaCall] CUDNN failure 8: CUDNN_STATUS_EXECUTION_FAILED ; GPU=0 ; hostname=asr5.jd.163.org ; expr=cudnnConvolutionForward(s_.handle, &alpha, s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.algo, workspace.get(), s_.workspace_bytes, &beta, s_.y_tensor, s_.y_data);\r\n2022-08-13 11:42:42.261148370 [E:onnxruntime:, sequential_executor.cc:368 Execute] Non-zero status code returned while running Conv node. Name:'Conv_35' Status Message: CUDNN error executing cudnnConvolutionForward(s_.handle, &alpha, s_.x_tensor, s_.x_data, s_.w_desc, s_.w_data, s_.conv_desc, s_.algo, workspace.get(), s_.workspace_bytes, &beta, s_.y_tensor, s_.y_data)\r\n```\r\n\r\nAnd the stack trace printed:\r\n```\r\n0# 0x0000558E7C9FB1B9 in tritonserver\r\n 1# 0x00007F14038C00C0 in /usr/lib/x86_64-linux-gnu/libc.so.6\r\n 2# cask_cudnn::ft::naryNode<cask_cudnn::sasskr::ft_sass_level>::hasBranchOrLeaf(unsigned int) const in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 3# cask_cudnn::ft::subTree<cask_cudnn::sasskr::ft_sass_level, cask_cudnn::Convolution, cask_cudnn::ConvShader, cask_cudnn::ShaderList<cask_cudnn::ConvShader, cask_cudnn::Convolution> >::search(cask_cudnn::kr::search_t<42ul, 32ul> const*, cask_cudnn::Convolution const&, cask_cudnn::kernel_record_t**, cask_cudnn::kernel_record_t const*) const in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 4# cask_cudnn::ft::subTree<cask_cudnn::sasskr::ft_sass_level, cask_cudnn::Convolution, cask_cudnn::ConvShader, cask_cudnn::ShaderList<cask_cudnn::ConvShader, cask_cudnn::Convolution> >::functionalSearch(cask_cudnn::kr::search_t<42ul, 32ul> const*, cask_cudnn::Convolution const&, cask_cudnn::kernel_record_t**, cask_cudnn::kernel_record_t const*, int) const in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 5# cask_cudnn::SafeEnum<cask_cudnn::ErrorEnum> cask_cudnn::ft::convSearch<cask_cudnn::Convolution, (cask_cudnn::record_type_t)0>(cask_cudnn::ft::convTreeHandle*, cask_cudnn::ft::convTreeHandle::thsch_t*, cask_cudnn::Convolution const&, cask_cudnn::kernel_record_t**, cask_cudnn::kernel_record_t const*, int) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 6# cudnn::InternalStatus_t cudnn::cnn::infer::searchTree<cask_cudnn::ShaderList<cask_cudnn::ConvShader, cask_cudnn::Convolution>, cask_cudnn::Convolution, (cudnn::cnn::infer::subtree_t)0>(int, cask_cudnn::ft::convTreeHandle&, cudnn::cnn::infer::SASSEngineHelper*, cask_cudnn::ft::convSearchOptions&, cask_cudnn::Convolution&) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 7# cudnn::cnn::infer::CaskMixIn<cask_cudnn::Convolution, cask_cudnn::ShaderList<cask_cudnn::ConvShader, cask_cudnn::Convolution>, cask_cudnn::ConvShader, (cudnn::cnn::infer::subtree_t)0>::searchTree(int) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 8# cudnn::cnn::infer::SASS4dInferSubEngine<true, (cudnnTensorFormat_t)0, (cudnnTensorFormat_t)0, (cudnnTensorFormat_t)0, (cudnnDataType_t)0, (cudnn::cnn::infer::ipg_infer_choice_t)1, false, 80, (cudnn::cnn::infer::subtree_t)0>::initSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n 9# cudnn::cnn::EngineInterface::isSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n10# cudnn::cnn::EngineContainer<(cudnnBackendEngineName_t)34, 113664ul>::initSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n11# cudnn::cnn::EngineInterface::isSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n12# cudnn::cnn::GeneralizedConvolutionEngine<cudnn::cnn::EngineContainer<(cudnnBackendEngineName_t)34, 113664ul> >::initSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n13# cudnn::cnn::EngineInterface::isSupported() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n14# cudnn::backend::ExecutionPlan::finalize_internal() in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n15# 0x00007F0A8E01939F in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n16# cudnn::backend::get_plan_for_legacy_algo(cudnnContext*, cudnn::backend::OperationSet const&, cudnn::backend::array_t<cudnnBackendEngineName_t const> const&, cudnnMathType_t, unsigned long, bool, cudnn::backend::ExecutionPlan&, unsigned long&, std::function<cudnn::backend::analyze_result_t (cudnn::backend::ExecutionPlan const&)> const&) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n17# cudnn::InternalStatus_t cudnn::backend::make_convolution_plan<cudnn::backend::ConvolutionForwardOperation, cudnnConvolutionFwdAlgo_t, cudnn::backend::EnginesAlgoMap<cudnnConvolutionFwdAlgo_t, 8> >(cudnnContext*, cudnnTensorStruct const*, cudnnFilterStruct const*, cudnnConvolutionStruct const*, cudnnTensorStruct const*, cudnnConvolutionFwdAlgo_t, void const*, void const*, cudnn::backend::OperationSet&, cudnn::backend::ExecutionPlan&, unsigned long&, bool) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n18# cudnn::backend::convolutionForward(cudnnContext*, void const*, cudnnTensorStruct const*, void const*, cudnnFilterStruct const*, void const*, cudnnConvolutionStruct const*, cudnnConvolutionFwdAlgo_t, void*, unsigned long, bool, void const*, void const*, void const*, cudnnActivationStruct const*, cudnnTensorStruct const*, void*) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n19# cudnn::cnn::convolutionForward(cudnnContext*, void const*, cudnnTensorStruct const*, void const*, cudnnFilterStruct const*, void const*, cudnnConvolutionStruct const*, cudnnConvolutionFwdAlgo_t, void*, unsigned long, void const*, cudnnTensorStruct const*, void*) in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n20# cudnnConvolutionForward in /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8\r\n21# 0x00007F0E10999E1D in /opt/tritonserver/backends/onnxruntime/libonnxruntime_providers_cuda.so\r\n22# 0x00007F0E108B5B06 in /opt/tritonserver/backends/onnxruntime/libonnxruntime_providers_cuda.so\r\n23# 0x00007F13F14F857F in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n24# 0x00007F13F14E1199 in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n25# 0x00007F13F14E326C in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n26# 0x00007F13F0EBF06D in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n27# 0x00007F13F0EBF2E8 in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n28# 0x00007F13F0E649CD in /opt/tritonserver/backends/onnxruntime/libonnxruntime.so\r\n29# 0x00007F13F1AE2BBD in /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so\r\n30# 0x00007F13F1AF85F3 in /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so\r\n31# TRITONBACKEND_ModelInstanceExecute in /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so\r\n32# 0x00007F140417173A in /opt/tritonserver/bin/../lib/libtritonserver.so\r\n33# 0x00007F14041720F7 in /opt/tritonserver/bin/../lib/libtritonserver.so\r\n34# 0x00007F140422F411 in /opt/tritonserver/bin/../lib/libtritonserver.so\r\n35# 0x00007F140416B5C7 in /opt/tritonserver/bin/../lib/libtritonserver.so\r\n36# 0x00007F1403CB1DE4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n37# 0x00007F1404EBF609 in /usr/lib/x86_64-linux-gnu/libpthread.so.0\r\n38# clone in /usr/lib/x86_64-linux-gnu/libc.so.6\r\n```\r\n\r\nAny idea?",
                "reactions": {
                    "url": "https://api.github.com/repos/triton-inference-server/server/issues/4766/reactions",
                    "total_count": 0,
                    "+1": 0,
                    "-1": 0,
                    "laugh": 0,
                    "hooray": 0,
                    "confused": 0,
                    "heart": 0,
                    "rocket": 0,
                    "eyes": 0
                },
                "timeline_url": "https://api.github.com/repos/triton-inference-server/server/issues/4766/timeline",
                "performed_via_github_app": null,
                "state_reason": null
            }
        },
        "event": "cross-referenced"
    }
]