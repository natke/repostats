[
    {
        "id": 5015319020,
        "node_id": "MDEyOkxhYmVsZWRFdmVudDUwMTUzMTkwMjA=",
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events/5015319020",
        "actor": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "event": "labeled",
        "commit_id": null,
        "commit_url": null,
        "created_at": "2021-07-13T17:27:09Z",
        "label": {
            "name": "ep:TensorRT",
            "color": "bfdadc"
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879269664",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879269664",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879269664,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTI2OTY2NA==",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-13T17:28:52Z",
        "updated_at": "2021-07-13T17:28:52Z",
        "author_association": "MEMBER",
        "body": "Seems that one of the binaries that should be loaded (and there are many of them) got corrupted. I see that you `--skip_tests`. Running tests would be a good indicator.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879269664/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879270738",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879270738",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879270738,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTI3MDczOA==",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-13T17:30:49Z",
        "updated_at": "2021-07-13T17:30:49Z",
        "author_association": "MEMBER",
        "body": "+@chilo-ms for assistance ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879270738/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "id": 5015336296,
        "node_id": "MDE0Ok1lbnRpb25lZEV2ZW50NTAxNTMzNjI5Ng==",
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events/5015336296",
        "actor": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "event": "mentioned",
        "commit_id": null,
        "commit_url": null,
        "created_at": "2021-07-13T17:30:50Z",
        "performed_via_github_app": null
    },
    {
        "id": 5015336300,
        "node_id": "MDE1OlN1YnNjcmliZWRFdmVudDUwMTUzMzYzMDA=",
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events/5015336300",
        "actor": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "event": "subscribed",
        "commit_id": null,
        "commit_url": null,
        "created_at": "2021-07-13T17:30:50Z",
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879511506",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879511506",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879511506,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTUxMTUwNg==",
        "user": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-14T01:28:25Z",
        "updated_at": "2021-07-14T01:28:25Z",
        "author_association": "NONE",
        "body": "> Seems that one of the binaries that should be loaded (and there are many of them) got corrupted. I see that you `--skip_tests`. Running tests would be a good indicator.\r\n\r\nrunning tests will occured error, part of the error information as follows:\r\n\r\n...\r\n1: [       OK ] QLinearConvTest.Conv2D_U8S8_Depthwise (39 ms)\r\n1: [ RUN      ] QLinearConvTest.Conv2D_U8U8_Depthwise\r\n1: [       OK ] QLinearConvTest.Conv2D_U8U8_Depthwise (26 ms)\r\n1: [ RUN      ] QLinearConvTest.Conv2D_U8S8_DepthwisePointwise\r\n1: Unsupported ONNX data type: UINT8 (2)\r\n...\r\n1: 2021-07-13 16:08:44.1796449 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.1796770 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 9 to type 16\r\n1: 2021-07-13 16:08:44.2260703 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.2261029 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 1 to type 16\r\n1: 2021-07-13 16:08:44.2724958 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.2725291 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 11 to type 16\r\n1: 2021-07-13 16:08:44.3219217 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.3219555 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 2 to type 16\r\n1: 2021-07-13 16:08:44.3708832 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.3709187 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 4 to type 16\r\n1: 2021-07-13 16:08:44.4200131 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.4200466 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 12 to type 16\r\n1: 2021-07-13 16:08:44.4695704 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.4696016 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 13 to type 16\r\n1: 2021-07-13 16:08:44.5172230 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.5172555 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 3 to type 16\r\n1: 2021-07-13 16:08:44.5647969 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.5648288 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 5 to type 16\r\n1: 2021-07-13 16:08:44.6134344 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.6134671 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 6 to type 16\r\n1: 2021-07-13 16:08:44.6615399 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.6615729 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 7 to type 16\r\n1: 2021-07-13 16:08:44.7100515 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7100838 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 10 to type 16\r\n1: 2021-07-13 16:08:44.7140533 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7140807 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 9\r\n1: 2021-07-13 16:08:44.7180226 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7180493 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 1\r\n1: 2021-07-13 16:08:44.7219374 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7219652 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 11\r\n1: 2021-07-13 16:08:44.7258168 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7258443 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 2\r\n1: 2021-07-13 16:08:44.7296677 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7296939 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 4\r\n1: 2021-07-13 16:08:44.7340322 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7340663 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 12\r\n1: 2021-07-13 16:08:44.7386099 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7386398 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 13\r\n1: 2021-07-13 16:08:44.7425801 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7426070 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 3\r\n1: 2021-07-13 16:08:44.7464513 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7464777 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 5\r\n1: 2021-07-13 16:08:44.7505031 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7505341 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 6\r\n1: 2021-07-13 16:08:44.7547622 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7547909 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 7\r\n1: 2021-07-13 16:08:44.7587389 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7587655 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 10\r\n1: 2021-07-13 16:08:44.7626171 [E:onnxruntime:Cast:Cast, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:44.7626430 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running Cast node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Google Test trace:\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\cpu\\tensor\\cast_op_test.cc(99): Cast from type 16 to type 16\r\n1: [  FAILED  ] CastOpTest.NonStringTypes (632 ms)\r\n1: [ RUN      ] CastOpTest.FromString\r\n1: [       OK ] CastOpTest.FromString (1 ms)\r\n1: [ RUN      ] CastOpTest.ToString\r\n1: [       OK ] CastOpTest.ToString (1 ms)\r\n1: [----------] 3 tests from CastOpTest (635 ms total)\r\n...\r\n1: [ RUN      ] ConcatOpTest.Concat3D_3\r\n1: [       OK ] ConcatOpTest.Concat3D_3 (173 ms)\r\n1: [ RUN      ] ConcatOpTest.Concat4D_1\r\n1: [       OK ] ConcatOpTest.Concat4D_1 (238 ms)\r\n1: [ RUN      ] ConcatOpTest.Concat4D_1_negative_axis\r\n1: [       OK ] ConcatOpTest.Concat4D_1_negative_axis (237 ms)\r\n1: [ RUN      ] ConcatOpTest.Concat4D_2\r\n1: [       OK ] ConcatOpTest.Concat4D_2 (238 ms)\r\n1: [----------] 16 tests from ConcatOpTest (2784 ms total)\r\n1:\r\n1: [       OK ] GatherNDOpTest.float (10 ms)\r\n1: [ RUN      ] GatherNDOpTest.double\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6587210 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: 2021-07-13 16:08:49.6619009 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.6619514 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6628557 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6634515 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6640736 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: 2021-07-13 16:08:49.6670119 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.6670679 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6680455 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.6686941 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [  FAILED  ] GatherNDOpTest.double (10 ms)\r\n1: [ RUN      ] GatherNDOpTest.int8_t\r\n1: 2021-07-13 16:08:49.6694056 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:08:48   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin GatherND version 1\r\n...\r\n1: [ RUN      ] GatherNDOpTest.GatherND_negative_slice_float_batch_dims_two\r\n1: 2021-07-13 16:08:49.7105507 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:08:48   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin GatherND version 1\r\n1: 2021-07-13 16:08:49.7105963 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] GatherNDOpTest.GatherND_negative_slice_float_batch_dims_two (3 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_1\r\n1: 2021-07-13 16:08:49.7135315 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.7135830 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.7145460 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_1 (3 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_slice_double_default_batch_dims\r\n1: 2021-07-13 16:08:49.7175404 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.7175887 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.7185019 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_default_batch_dims (3 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_2\r\n1: 2021-07-13 16:08:49.7214099 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.7214609 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: Unsupported ONNX data type: DOUBLE (11)\r\n1: 2021-07-13 16:08:49.7223700 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_2 (3 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_slice_half\r\n1: 2021-07-13 16:08:49.7252292 [E:onnxruntime:GatherND:GatherND, sequential_executor.cc:339 onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.7252776 [E:onnxruntime:Default, provider_test_utils.cc:667 onnxruntime::test::OpTester::ExecuteModel] Run failed with status: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: E:\\onnxruntime1.81_TensorRT\\onnxruntime\\test\\providers\\provider_test_utils.cc(669): error: Value of: status.IsOK()\r\n1:   Actual: false\r\n1: Expected: true\r\n1: Non-zero status code returned while running GatherND node. Name:'node1' Status Message: CUDA error cudaErrorInvalidDeviceFunction:invalid device function\r\n1: 2021-07-13 16:08:49.7261580 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:08:48   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin GatherND version 1\r\n1: 2021-07-13 16:08:49.7262025 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_half (3 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_batch_dims_of_2\r\n1: 2021-07-13 16:08:49.7268600 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:08:48   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin GatherND version 1\r\n1: 2021-07-13 16:08:49.7269038 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] GatherNDOpTest.GatherND_batch_dims_of_2 (0 ms)\r\n1: [ RUN      ] GatherNDOpTest.GatherND_slice_int64_t\r\n1: 2021-07-13 16:08:49.7305967 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:08:48   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin GatherND version 1\r\n1: 2021-07-13 16:08:49.7306459 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] GatherNDOpTest.GatherND_slice_int64_t (3 ms)\r\n1: [----------] 23 tests from GatherNDOpTest (133 ms total)\r\n...\r\n1: [----------] 8 tests from InternalTestingEP\r\n1: [ RUN      ] InternalTestingEP.TestSortResultsInSinglePartition\r\n1: [       OK ] InternalTestingEP.TestSortResultsInSinglePartition (9 ms)\r\n1: [ RUN      ] InternalTestingEP.TestDependenciesCorrectlyHandled\r\n1: [       OK ] InternalTestingEP.TestDependenciesCorrectlyHandled (2 ms)\r\n1: [ RUN      ] InternalTestingEP.TestSaveAndLoadOrtModel\r\n1: 2021-07-13 16:09:14.3100491 [W:onnxruntime:, inference_session.cc:1303 onnxruntime::InferenceSession::Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\r\n1: [       OK ] InternalTestingEP.TestSaveAndLoadOrtModel (12 ms)\r\n1: [ RUN      ] InternalTestingEP.PreventSaveOfModelWithCompiledOps\r\n1: [       OK ] InternalTestingEP.PreventSaveOfModelWithCompiledOps (7 ms)\r\n1: [ RUN      ] InternalTestingEP.TestLoadOrtModel\r\n1: [       OK ] InternalTestingEP.TestLoadOrtModel (1 ms)\r\n1: [ RUN      ] InternalTestingEP.TestLoadOrtModelWithReducedOpCoverage\r\n1: [       OK ] InternalTestingEP.TestLoadOrtModelWithReducedOpCoverage (1 ms)\r\n1: [ RUN      ] InternalTestingEP.TestModelWithSubgraph\r\n1: [       OK ] InternalTestingEP.TestModelWithSubgraph (33 ms)\r\n1: [ RUN      ] InternalTestingEP.TestOrtModelWithCompileFailure\r\n1: 2021-07-13 16:09:14.4713613 [E:onnxruntime:Default, graph_partitioner.cc:459 onnxruntime::PartitionOrtFormatModelImpl] EP: InternalTestingExecutionProvider has Compile error: CompileFailureTestExecutionProvider::Compile failed for node: gemm\r\n1: [       OK ] InternalTestingEP.TestOrtModelWithCompileFailure (108 ms)\r\n1: [----------] 8 tests from InternalTestingEP (175 ms total)\r\n1:\r\n1: [----------] 3 tests from RandomTest\r\n1: [ RUN      ] RandomTest.RandomSeedTest\r\n1: [       OK ] RandomTest.RandomSeedTest (0 ms)\r\n1: [ RUN      ] RandomTest.RandomGeneratorTest\r\n1: [       OK ] RandomTest.RandomGeneratorTest (0 ms)\r\n1: [ RUN      ] RandomTest.PhiloxGeneratorTest\r\n1: [       OK ] RandomTest.PhiloxGeneratorTest (0 ms)\r\n1: [----------] 3 tests from RandomTest (0 ms total)\r\n1:\r\n1: [----------] 18 tests from ActivationOpTest\r\n1: [ RUN      ] ActivationOpTest.ThresholdedRelu_version_1_to_9\r\n1: 2021-07-13 16:09:14.4751557 [W:onnxruntime:ThresholdedRelu, model.cc:139 onnxruntime::Model::Model] ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 1 model may run depending upon legacy support of some older opset version operators.\r\n...\r\n1: [       OK ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/4 (0 ms)\r\n1: [ RUN      ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/5\r\n1: 2021-07-13 16:09:58.2537134 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:09:56   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin LinearRegressor version 1\r\n1: 2021-07-13 16:09:58.2537549 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/5 (0 ms)\r\n1: [ RUN      ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/6\r\n1: 2021-07-13 16:09:58.2543503 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:09:56   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin LinearRegressor version 1\r\n1: 2021-07-13 16:09:58.2543917 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/6 (0 ms)\r\n1: [ RUN      ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/7\r\n1: 2021-07-13 16:09:58.2550071 [E:onnxruntime:Default, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-13 08:09:56   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin LinearRegressor version 1\r\n1: 2021-07-13 16:09:58.2550501 [W:onnxruntime:Default, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n1: [       OK ] LinearRegressorTest/LinearRegressorTest.LinearRegressorUniTarget/7 (0 ms)\r\n1: [----------] 8 tests from LinearRegressorTest/LinearRegressorTest (5 ms total)\r\n1:\r\n1: [----------] Global test environment tear-down\r\n1: [==========] 2846 tests from 215 test suites ran. (247002 ms total)\r\n1: [  PASSED  ] 2826 tests.\r\n1: [  SKIPPED ] 10 tests, listed below:\r\n1: [  SKIPPED ] InferenceSessionTests.TestLenientShapeInferencing\r\n1: [  SKIPPED ] SoftmaxOperator.InvalidAxis_opset13\r\n1: [  SKIPPED ] SoftmaxOperator.DimWithZero\r\n1: [  SKIPPED ] ConvTest.Conv1D_Invalid_Input_Shape\r\n1: [  SKIPPED ] ConvTest.Conv2D_Invalid_Input_Shape\r\n1: [  SKIPPED ] TfIdfVectorizerTest.Int32_TF_onlyBigrams_Skip0_Empty_Dim1Fail\r\n1: [  SKIPPED ] TfIdfVectorizerTest.Int32_TF_onlyBigrams_Skip0_Empty_Dim2\r\n1: [  SKIPPED ] TfIdfVectorizerTest.Int32_TF_onlyBigrams_Skip01_Empty_Dim2\r\n1: [  SKIPPED ] TensorOpTest.Unsqueeze_Duplicate\r\n1: [  SKIPPED ] TensorOpTest.Unsqueeze_OutOfRange\r\n1: [  FAILED  ] 10 tests, listed below:\r\n1: [  FAILED  ] EmbedLayerNormTest.EmbedLayerNormBatch1_Float16\r\n1: [  FAILED  ] FastGeluTest.FastGeluWithBiasFloat16\r\n1: [  FAILED  ] FastGeluTest.FastGeluWithoutBiasFloat16\r\n1: [  FAILED  ] SkipLayerNormTest.SkipLayerNormBatch1_Float16\r\n1: [  FAILED  ] CastOpTest.NonStringTypes\r\n1: [  FAILED  ] GatherNDOpTest.double\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_1\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_default_batch_dims\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_double_batch_dims_one_2\r\n1: [  FAILED  ] GatherNDOpTest.GatherND_slice_half\r\n1:\r\n1: 10 FAILED TESTS\r\n1:   YOU HAVE 7 DISABLED TESTS\r\n1:\r\n1/6 Test #1: onnxruntime_test_all ...................***Failed  247.95 sec\r\ntest 2\r\n    Start 2: onnx_test_pytorch_converted\r\n\r\n2: Test command: E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnx_test_runner.exe \"E:/onnxruntime1.81_TensorRT/cmake/external/onnx/onnx/backend/test/data/pytorch-converted\"\r\n2: Test timeout computed to be: 7200\r\n2: 2021-07-13 16:09:57.5911526 [E:onnxruntime:Default, testcase_driver.cc:39 onnxruntime::test::TestCaseDriver::RunParallel] Running tests in parallel: at most 8 models at any time\r\n2: 2021-07-13 16:09:57.7096358 [E:onnxruntime:Default, testcase_driver.cc:61 onnxruntime::test::TestCaseDriver::RunModelsAsync] Running tests finished. Generating report\r\n2: result:\r\n2:      Models: 59\r\n2:      Total test cases: 59\r\n2:              Succeeded: 59\r\n2:              Not implemented: 0\r\n2:              Failed: 0\r\n2:      Stats by Operator type:\r\n2:              Not implemented(0):\r\n2:              Failed:\r\n2: Failed Test Cases:\r\n2/6 Test #2: onnx_test_pytorch_converted ............   Passed    0.19 sec\r\ntest 3\r\n    Start 3: onnx_test_pytorch_operator\r\n\r\n3: Test command: E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnx_test_runner.exe \"E:/onnxruntime1.81_TensorRT/cmake/external/onnx/onnx/backend/test/data/pytorch-operator\"\r\n3: Test timeout computed to be: 7200\r\n3: 2021-07-13 16:09:57.7505446 [E:onnxruntime:Default, testcase_driver.cc:39 onnxruntime::test::TestCaseDriver::RunParallel] Running tests in parallel: at most 8 models at any time\r\n3: 2021-07-13 16:09:57.8387637 [E:onnxruntime:Default, testcase_driver.cc:61 onnxruntime::test::TestCaseDriver::RunModelsAsync] Running tests finished. Generating report\r\n3: result:\r\n3:      Models: 24\r\n3:      Total test cases: 24\r\n3:              Succeeded: 24\r\n3:              Not implemented: 0\r\n3:              Failed: 0\r\n3:      Stats by Operator type:\r\n3:              Not implemented(0):\r\n3:              Failed:\r\n3: Failed Test Cases:\r\n3/6 Test #3: onnx_test_pytorch_operator .............   Passed    0.13 sec\r\ntest 4\r\n    Start 4: onnxruntime_shared_lib_test\r\n\r\n4: Test command: E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_shared_lib_test.exe \"--gtest_output=xml:E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_shared_lib_test.exe.Release.results.xml\"\r\n4: Test timeout computed to be: 7200\r\n4: [==========] Running 49 tests from 3 test suites.\r\n4: [----------] Global test environment set-up.\r\n4: [----------] 43 tests from CApiTest\r\n4: [ RUN      ] CApiTest.session_options_graph_optimization_level\r\n4: [       OK ] CApiTest.session_options_graph_optimization_level (0 ms)\r\n4: [ RUN      ] CApiTest.run_options\r\n4: [       OK ] CApiTest.run_options (0 ms)\r\n4: [ RUN      ] CApiTest.allocation_info\r\n4: [       OK ] CApiTest.allocation_info (0 ms)\r\n4: [ RUN      ] CApiTest.DefaultAllocator\r\n4: [       OK ] CApiTest.DefaultAllocator (0 ms)\r\n4: [ RUN      ] CApiTest.CreateGetVectorOfMapsInt64Float\r\n4: [       OK ] CApiTest.CreateGetVectorOfMapsInt64Float (0 ms)\r\n4: [ RUN      ] CApiTest.CreateGetVectorOfMapsStringFloat\r\n4: [       OK ] CApiTest.CreateGetVectorOfMapsStringFloat (0 ms)\r\n4: [ RUN      ] CApiTest.TypeInfoMap\r\n4: [       OK ] CApiTest.TypeInfoMap (0 ms)\r\n4: [ RUN      ] CApiTest.CreateGetSeqTensors\r\n4: [       OK ] CApiTest.CreateGetSeqTensors (0 ms)\r\n4: [ RUN      ] CApiTest.CreateGetSeqStringTensors\r\n4: [       OK ] CApiTest.CreateGetSeqStringTensors (0 ms)\r\n4: [ RUN      ] CApiTest.TypeInfoSequence\r\n4: [       OK ] CApiTest.TypeInfoSequence (0 ms)\r\n4: [ RUN      ] CApiTest.model_from_array\r\n4: [       OK ] CApiTest.model_from_array (1417 ms)\r\n4: [ RUN      ] CApiTest.dim_param\r\n4: [       OK ] CApiTest.dim_param (5 ms)\r\n4: [ RUN      ] CApiTest.custom_op_handler\r\n4: Running custom op inference\r\n4: Running simple inference with cuda provider\r\n4: [       OK ] CApiTest.custom_op_handler (5 ms)\r\n4: [ RUN      ] CApiTest.varied_input_custom_op_handler\r\n4: Running simple inference with cuda provider\r\n4: [       OK ] CApiTest.varied_input_custom_op_handler (6 ms)\r\n4: [ RUN      ] CApiTest.multiple_varied_input_custom_op_handler\r\n4: [       OK ] CApiTest.multiple_varied_input_custom_op_handler (8 ms)\r\n4: [ RUN      ] CApiTest.optional_input_output_custom_op_handler\r\n4: [       OK ] CApiTest.optional_input_output_custom_op_handler (6 ms)\r\n4: [ RUN      ] CApiTest.custom_op_with_attributes_handler\r\n4: [       OK ] CApiTest.custom_op_with_attributes_handler (1 ms)\r\n4: [ RUN      ] CApiTest.RegisterCustomOpForCPUAndCUDA\r\n4: Tests registration of a custom op of the same name for both CPU and CUDA EPs\r\n4: Running simple inference with cuda provider\r\n4: 2021-07-13 16:09:59.4242993 [W:onnxruntime:Default, schema_registry.cc:78 onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSchemaInternal] Trying to register schema with name Foo (domain:  version: 1) from file custom op registered at runtime line 0, but it is already registered from file custom op registered at runtime line 0\r\n4:\r\n4: [       OK ] CApiTest.RegisterCustomOpForCPUAndCUDA (4 ms)\r\n4: [ RUN      ] CApiTest.test_custom_op_library\r\n4: Running inference using custom op shared library\r\n4: Running simple inference with default provider\r\n4: [       OK ] CApiTest.test_custom_op_library (5 ms)\r\n4: [ RUN      ] CApiTest.get_allocator_cpu\r\n4: [       OK ] CApiTest.get_allocator_cpu (1 ms)\r\n4: [ RUN      ] CApiTest.get_allocator_cuda\r\n4: [       OK ] CApiTest.get_allocator_cuda (4 ms)\r\n4: [ RUN      ] CApiTest.io_binding\r\n4: [       OK ] CApiTest.io_binding (1 ms)\r\n4: [ RUN      ] CApiTest.io_binding_cuda\r\n4: [       OK ] CApiTest.io_binding_cuda (525 ms)\r\n4: [ RUN      ] CApiTest.create_tensor\r\n4: [       OK ] CApiTest.create_tensor (0 ms)\r\n4: [ RUN      ] CApiTest.fill_string_tensor\r\n4: [       OK ] CApiTest.fill_string_tensor (0 ms)\r\n4: [ RUN      ] CApiTest.get_string_tensor_element\r\n4: [       OK ] CApiTest.get_string_tensor_element (0 ms)\r\n4: [ RUN      ] CApiTest.create_tensor_with_data\r\n4: [       OK ] CApiTest.create_tensor_with_data (0 ms)\r\n4: [ RUN      ] CApiTest.create_tensor_with_data_float16\r\n4: [       OK ] CApiTest.create_tensor_with_data_float16 (0 ms)\r\n4: [ RUN      ] CApiTest.create_tensor_with_data_bfloat16\r\n4: [       OK ] CApiTest.create_tensor_with_data_bfloat16 (0 ms)\r\n4: [ RUN      ] CApiTest.access_tensor_data_elements\r\n4: [       OK ] CApiTest.access_tensor_data_elements (0 ms)\r\n4: [ RUN      ] CApiTest.override_initializer\r\n4: 2021-07-13 16:09:59.9722955 [W:onnxruntime:, graph.cc:1077 onnxruntime::Graph::Graph] Initializer F1 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n4: [       OK ] CApiTest.override_initializer (5 ms)\r\n4: [ RUN      ] CApiTest.end_profiling\r\n4: [       OK ] CApiTest.end_profiling (2 ms)\r\n4: [ RUN      ] CApiTest.get_profiling_start_time\r\n4: [       OK ] CApiTest.get_profiling_start_time (2 ms)\r\n4: [ RUN      ] CApiTest.model_metadata\r\n4: [       OK ] CApiTest.model_metadata (2 ms)\r\n4: [ RUN      ] CApiTest.get_available_providers\r\n4: [       OK ] CApiTest.get_available_providers (0 ms)\r\n4: [ RUN      ] CApiTest.get_available_providers_cpp\r\n4: [       OK ] CApiTest.get_available_providers_cpp (0 ms)\r\n4: [ RUN      ] CApiTest.TestSharedAllocatorUsingCreateAndRegisterAllocator\r\n4: [       OK ] CApiTest.TestSharedAllocatorUsingCreateAndRegisterAllocator (2 ms)\r\n4: [ RUN      ] CApiTest.TestSharingOfInitializerAndItsPrepackedVersion\r\n4: [       OK ] CApiTest.TestSharingOfInitializerAndItsPrepackedVersion (2 ms)\r\n4: [ RUN      ] CApiTest.TestIncorrectInputTypeToModel_Tensors\r\n4: [       OK ] CApiTest.TestIncorrectInputTypeToModel_Tensors (1 ms)\r\n4: [ RUN      ] CApiTest.TestIncorrectInputTypeToModel_SequenceTensors\r\n4: [       OK ] CApiTest.TestIncorrectInputTypeToModel_SequenceTensors (4 ms)\r\n4: [ RUN      ] CApiTest.AllocateInitializersFromNonArenaMemory\r\n4: [       OK ] CApiTest.AllocateInitializersFromNonArenaMemory (5 ms)\r\n4: [ RUN      ] CApiTest.ConfigureCudaArenaAndDemonstrateMemoryArenaShrinkage\r\n4: [       OK ] CApiTest.ConfigureCudaArenaAndDemonstrateMemoryArenaShrinkage (4 ms)\r\n4: [ RUN      ] CApiTest.TestConfigureTensorRTProviderOptions\r\n4: [       OK ] CApiTest.TestConfigureTensorRTProviderOptions (285 ms)\r\n4: [----------] 43 tests from CApiTest (2316 ms total)\r\n4:\r\n4: [----------] 1 test from OrtFormatCustomOpTests\r\n4: [ RUN      ] OrtFormatCustomOpTests.ConvertOnnxModelToOrt\r\n4: 2021-07-13 16:10:00.2918838 [W:onnxruntime:CustomOp, inference_session.cc:1303 onnxruntime::InferenceSession::Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\r\n4: [       OK ] OrtFormatCustomOpTests.ConvertOnnxModelToOrt (11 ms)\r\n4: [----------] 1 test from OrtFormatCustomOpTests (11 ms total)\r\n4:\r\n4: [----------] 5 tests from CApiTestWithProviders/CApiTestWithProvider\r\n4: [ RUN      ] CApiTestWithProviders/CApiTestWithProvider.simple/0\r\n4: Running simple inference with default provider\r\n4: [       OK ] CApiTestWithProviders/CApiTestWithProvider.simple/0 (1 ms)\r\n4: [ RUN      ] CApiTestWithProviders/CApiTestWithProvider.simple/1\r\n4: Running simple inference with cuda provider\r\n4: [       OK ] CApiTestWithProviders/CApiTestWithProvider.simple/1 (4 ms)\r\n4: [ RUN      ] CApiTestWithProviders/CApiTestWithProvider.simple/2\r\n4: [       OK ] CApiTestWithProviders/CApiTestWithProvider.simple/2 (0 ms)\r\n4: [ RUN      ] CApiTestWithProviders/CApiTestWithProvider.simple/3\r\n4: [       OK ] CApiTestWithProviders/CApiTestWithProvider.simple/3 (0 ms)\r\n4: [ RUN      ] CApiTestWithProviders/CApiTestWithProvider.simple/4\r\n4: Running simple inference with default provider\r\n4: [       OK ] CApiTestWithProviders/CApiTestWithProvider.simple/4 (1 ms)\r\n4: [----------] 5 tests from CApiTestWithProviders/CApiTestWithProvider (7 ms total)\r\n4:\r\n4: [----------] Global test environment tear-down\r\n4: [==========] 49 tests from 3 test suites ran. (2335 ms total)\r\n4: [  PASSED  ] 49 tests.\r\n4/6 Test #4: onnxruntime_shared_lib_test ............   Passed    2.84 sec\r\ntest 5\r\n    Start 5: onnxruntime_global_thread_pools_test\r\n\r\n5: Test command: E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_global_thread_pools_test.exe \"--gtest_output=xml:E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_global_thread_pools_test.exe.Release.results.xml\"\r\n5: Test timeout computed to be: 7200\r\n5: [==========] Running 15 tests from 1 test suite.\r\n5: [----------] Global test environment set-up.\r\n5: [----------] 15 tests from CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/0\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/0 (27 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/1\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/1 (2032 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/2\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/2 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/3\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/3 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple/4\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/0 (40 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/1\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/1 (95 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/2\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/2 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/3\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/3 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/4\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple2/4 (35 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/0\r\n5: Running simple inference with default provider\r\n5: Running simple inference with default provider\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/0 (39 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/1\r\n5: Running simple inference with cuda provider\r\n5: Running simple inference with cuda provider\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/1 (94 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/2\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/2 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/3\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/3 (0 ms)\r\n5: [ RUN      ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/4\r\n5: Running simple inference with default provider\r\n5: [       OK ] CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider.simple3/4 (34 ms)\r\n5: [----------] 15 tests from CApiTestGlobalThreadPoolsWithProviders/CApiTestGlobalThreadPoolsWithProvider (2422 ms total)\r\n5: [----------] Global test environment tear-down\r\n5: [==========] 15 tests from 1 test suite ran. (2422 ms total)\r\n5: [  PASSED  ] 15 tests.\r\n5/6 Test #5: onnxruntime_global_thread_pools_test ...   Passed    3.22 sec\r\ntest 6\r\n    Start 6: onnxruntime_api_tests_without_env\r\n\r\n6: Test command: E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_api_tests_without_env.exe \"--gtest_output=xml:E:\\onnxruntime1.81_TensorRT\\build\\Windows\\Release\\Release\\onnxruntime_api_tests_without_env.exe.Release.results.xml\"\r\n6: Test timeout computed to be: 7200\r\n6: [==========] Running 1 test from 1 test suite.\r\n6: [----------] Global test environment set-up.\r\n6: [----------] 1 test from TestSessionOptions\r\n6: [ RUN      ] TestSessionOptions.SetIntraOpNumThreadsWithoutEnv\r\n6: [       OK ] TestSessionOptions.SetIntraOpNumThreadsWithoutEnv (0 ms)\r\n6: [----------] 1 test from TestSessionOptions (0 ms total)\r\n6:\r\n6: [----------] Global test environment tear-down\r\n6: [==========] 1 test from 1 test suite ran. (0 ms total)\r\n6: [  PASSED  ] 1 test.\r\n6/6 Test #6: onnxruntime_api_tests_without_env ......   Passed    0.01 sec\r\n\r\n83% tests passed, 1 tests failed out of 6\r\n\r\nTotal Test time (real) = 254.36 sec\r\n\r\nThe following tests FAILED:\r\n          1 - onnxruntime_test_all (Failed)\r\nErrors while running CTest\r\nOutput from these tests are in: E:/onnxruntime1.81_TensorRT/build/Windows/Release/Testing/Temporary/LastTest.log\r\nUse \"--rerun-failed --output-on-failure\" to re-run the failed cases verbosely.\r\nTraceback (most recent call last):\r\n  File \"E:\\onnxruntime1.81_TensorRT\\\\tools\\ci_build\\build.py\", line 2199, in <module>\r\n    sys.exit(main())\r\n  File \"E:\\onnxruntime1.81_TensorRT\\\\tools\\ci_build\\build.py\", line 2126, in main\r\n    run_onnxruntime_tests(args, source_dir, ctest_path, build_dir, configs)\r\n  File \"E:\\onnxruntime1.81_TensorRT\\\\tools\\ci_build\\build.py\", line 1475, in run_onnxruntime_tests\r\n    run_subprocess(ctest_cmd, cwd=cwd, dll_path=dll_path)\r\n  File \"E:\\onnxruntime1.81_TensorRT\\\\tools\\ci_build\\build.py\", line 593, in run_subprocess\r\n    return run(*args, cwd=cwd, capture_stdout=capture_stdout, shell=shell, env=my_env)\r\n  File \"E:\\onnxruntime1.81_TensorRT\\tools\\python\\util\\run.py\", line 44, in run\r\n    env=env, shell=shell)\r\n  File \"C:\\Program Files\\Python\\Python36\\lib\\subprocess.py\", line 438, in run\r\n    output=stdout, stderr=stderr)\r\nsubprocess.CalledProcessError: Command '['C:\\\\Program Files\\\\CMake\\\\bin\\\\ctest.EXE', '--build-config', 'Release', '--verbose', '--timeout', '7200']' returned non-zero exit status 8.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879511506/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879685883",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879685883",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879685883,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTY4NTg4Mw==",
        "user": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-14T08:05:44Z",
        "updated_at": "2021-07-14T08:05:44Z",
        "author_association": "MEMBER",
        "body": "Could you make sure that both nuget (DLLs) and your application were built for the same architecture? for example, both should be 64-bits or 32-bits.\r\n\r\nI would suggest using 64-bits as well as changing to vs2019 since we have tested it under this system environment.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879685883/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879728472",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879728472",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879728472,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTcyODQ3Mg==",
        "user": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-14T09:09:20Z",
        "updated_at": "2021-07-14T09:09:20Z",
        "author_association": "NONE",
        "body": "> Could you make sure that both nuget (DLLs) and your application were built for the same architecture? for example, both should be 64-bits or 32-bits.\r\n> \r\n> I would suggest using 64-bits as well as changing to vs2019 since we have tested it under this system environment.\r\n\r\nThank you for your suggestion, I set the architecture of my application  to 64-bits, the above error disappear，but another error occured as below:\r\n\r\n2021-07-14 16:57:28.0429351 [E:onnxruntime:CSharpOnnxRuntime, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-14 08:57:28   ERROR] INVALID_ARGUMENT: getPluginCreator could not find plugin ScatterND version 1\r\n\r\nUnhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions.ReleaseHandle()\r\n   at System.Runtime.InteropServices.SafeHandle.InternalFinalize()\r\n   at System.Runtime.InteropServices.SafeHandle.Finalize()",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879728472/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879782401",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-879782401",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 879782401,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg3OTc4MjQwMQ==",
        "user": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-14T10:33:13Z",
        "updated_at": "2021-07-14T10:33:13Z",
        "author_association": "MEMBER",
        "body": "From [this ](https://github.com/NVIDIA/TensorRT/issues/805)discussion, it seems TensorRT doesn't support ScatterND yet.\r\nIf possible, could you share the model so that we can take a closer look.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/879782401/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/880299239",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-880299239",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 880299239,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg4MDI5OTIzOQ==",
        "user": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-07-15T00:34:25Z",
        "updated_at": "2021-07-15T03:08:55Z",
        "author_association": "NONE",
        "body": "> From [this ](https://github.com/NVIDIA/TensorRT/issues/805)discussion, it seems TensorRT doesn't support ScatterND yet.\r\n> If possible, could you share the model so that we can take a closer look.\r\n\r\nthanks, I use this model exported from yolov5s:\r\n[https://raw.githubusercontent.com/mrljwlm/hellow-world/master/yolov5s.rar](url)\r\n\r\n\r\nUPDATE:\r\nI try another model, an instance segment model called yolact,  I run the model through symbolic_shape_infer.py with --auto-merge and I get a different error like these:\r\n\r\n2021-07-15 10:30:19.4742416 [E:onnxruntime:CSharpOnnxRuntime, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-15 02:30:19   ERROR] E:\\onnxruntime1.81_TensorRT\\cmake\\external\\onnx-tensorrt\\onnx2trt_utils.cpp:475: Found unsupported datatype (11) when importing initializer: 1029\r\n2021-07-15 10:30:19.4750506 [E:onnxruntime:CSharpOnnxRuntime, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-15 02:30:19   ERROR] E:\\onnxruntime1.81_TensorRT\\cmake\\external\\onnx-tensorrt\\onnx2trt_utils.cpp:475: Found unsupported datatype (11) when importing initializer: 1029\r\n2021-07-15 10:30:19.4759539 [E:onnxruntime:CSharpOnnxRuntime, tensorrt_execution_provider.h:51 onnxruntime::TensorrtLogger::log] [2021-07-15 02:30:19   ERROR] E:\\onnxruntime1.81_TensorRT\\cmake\\external\\onnx-tensorrt\\onnx2trt_utils.cpp:475: Found unsupported datatype (11) when importing initializer: 1029\r\n2021-07-15 10:30:19.8297725 [W:onnxruntime:CSharpOnnxRuntime, tensorrt_execution_provider.cc:1082 onnxruntime::TensorrtExecutionProvider::GetCapability] [TensorRT EP] No graph will run on TensorRT exeuction provider\r\n\r\nUnhandled Exception: System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\r\n   at Microsoft.ML.OnnxRuntime.SessionOptions.ReleaseHandle()\r\n   at System.Runtime.InteropServices.SafeHandle.InternalFinalize()\r\n   at System.Runtime.InteropServices.SafeHandle.Finalize()\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/880299239/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "mrljwlm",
            "id": 23266835,
            "node_id": "MDQ6VXNlcjIzMjY2ODM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23266835?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrljwlm",
            "html_url": "https://github.com/mrljwlm",
            "followers_url": "https://api.github.com/users/mrljwlm/followers",
            "following_url": "https://api.github.com/users/mrljwlm/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrljwlm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrljwlm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrljwlm/subscriptions",
            "organizations_url": "https://api.github.com/users/mrljwlm/orgs",
            "repos_url": "https://api.github.com/users/mrljwlm/repos",
            "events_url": "https://api.github.com/users/mrljwlm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrljwlm/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "actor": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-04T23:01:52Z",
        "updated_at": "2022-03-04T23:01:52Z",
        "source": {
            "type": "issue",
            "issue": {
                "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775",
                "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
                "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775/labels{/name}",
                "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775/comments",
                "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775/events",
                "html_url": "https://github.com/microsoft/onnxruntime/pull/10775",
                "id": 1160120362,
                "node_id": "PR_kwDOCVq1mM4z-sbR",
                "number": 10775,
                "title": "Disable some tests",
                "user": {
                    "login": "snnn",
                    "id": 856316,
                    "node_id": "MDQ6VXNlcjg1NjMxNg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/snnn",
                    "html_url": "https://github.com/snnn",
                    "followers_url": "https://api.github.com/users/snnn/followers",
                    "following_url": "https://api.github.com/users/snnn/following{/other_user}",
                    "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
                    "organizations_url": "https://api.github.com/users/snnn/orgs",
                    "repos_url": "https://api.github.com/users/snnn/repos",
                    "events_url": "https://api.github.com/users/snnn/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/snnn/received_events",
                    "type": "User",
                    "site_admin": false
                },
                "labels": [],
                "state": "closed",
                "locked": false,
                "assignee": null,
                "assignees": [],
                "milestone": null,
                "comments": 1,
                "created_at": "2022-03-04T23:01:52Z",
                "updated_at": "2022-03-05T18:16:13Z",
                "closed_at": "2022-03-04T23:08:16Z",
                "author_association": "MEMBER",
                "active_lock_reason": null,
                "draft": false,
                "repository": {
                    "id": 156939672,
                    "node_id": "MDEwOlJlcG9zaXRvcnkxNTY5Mzk2NzI=",
                    "name": "onnxruntime",
                    "full_name": "microsoft/onnxruntime",
                    "private": false,
                    "owner": {
                        "login": "microsoft",
                        "id": 6154722,
                        "node_id": "MDEyOk9yZ2FuaXphdGlvbjYxNTQ3MjI=",
                        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4",
                        "gravatar_id": "",
                        "url": "https://api.github.com/users/microsoft",
                        "html_url": "https://github.com/microsoft",
                        "followers_url": "https://api.github.com/users/microsoft/followers",
                        "following_url": "https://api.github.com/users/microsoft/following{/other_user}",
                        "gists_url": "https://api.github.com/users/microsoft/gists{/gist_id}",
                        "starred_url": "https://api.github.com/users/microsoft/starred{/owner}{/repo}",
                        "subscriptions_url": "https://api.github.com/users/microsoft/subscriptions",
                        "organizations_url": "https://api.github.com/users/microsoft/orgs",
                        "repos_url": "https://api.github.com/users/microsoft/repos",
                        "events_url": "https://api.github.com/users/microsoft/events{/privacy}",
                        "received_events_url": "https://api.github.com/users/microsoft/received_events",
                        "type": "Organization",
                        "site_admin": false
                    },
                    "html_url": "https://github.com/microsoft/onnxruntime",
                    "description": "ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator",
                    "fork": false,
                    "url": "https://api.github.com/repos/microsoft/onnxruntime",
                    "forks_url": "https://api.github.com/repos/microsoft/onnxruntime/forks",
                    "keys_url": "https://api.github.com/repos/microsoft/onnxruntime/keys{/key_id}",
                    "collaborators_url": "https://api.github.com/repos/microsoft/onnxruntime/collaborators{/collaborator}",
                    "teams_url": "https://api.github.com/repos/microsoft/onnxruntime/teams",
                    "hooks_url": "https://api.github.com/repos/microsoft/onnxruntime/hooks",
                    "issue_events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/events{/number}",
                    "events_url": "https://api.github.com/repos/microsoft/onnxruntime/events",
                    "assignees_url": "https://api.github.com/repos/microsoft/onnxruntime/assignees{/user}",
                    "branches_url": "https://api.github.com/repos/microsoft/onnxruntime/branches{/branch}",
                    "tags_url": "https://api.github.com/repos/microsoft/onnxruntime/tags",
                    "blobs_url": "https://api.github.com/repos/microsoft/onnxruntime/git/blobs{/sha}",
                    "git_tags_url": "https://api.github.com/repos/microsoft/onnxruntime/git/tags{/sha}",
                    "git_refs_url": "https://api.github.com/repos/microsoft/onnxruntime/git/refs{/sha}",
                    "trees_url": "https://api.github.com/repos/microsoft/onnxruntime/git/trees{/sha}",
                    "statuses_url": "https://api.github.com/repos/microsoft/onnxruntime/statuses/{sha}",
                    "languages_url": "https://api.github.com/repos/microsoft/onnxruntime/languages",
                    "stargazers_url": "https://api.github.com/repos/microsoft/onnxruntime/stargazers",
                    "contributors_url": "https://api.github.com/repos/microsoft/onnxruntime/contributors",
                    "subscribers_url": "https://api.github.com/repos/microsoft/onnxruntime/subscribers",
                    "subscription_url": "https://api.github.com/repos/microsoft/onnxruntime/subscription",
                    "commits_url": "https://api.github.com/repos/microsoft/onnxruntime/commits{/sha}",
                    "git_commits_url": "https://api.github.com/repos/microsoft/onnxruntime/git/commits{/sha}",
                    "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/comments{/number}",
                    "issue_comment_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments{/number}",
                    "contents_url": "https://api.github.com/repos/microsoft/onnxruntime/contents/{+path}",
                    "compare_url": "https://api.github.com/repos/microsoft/onnxruntime/compare/{base}...{head}",
                    "merges_url": "https://api.github.com/repos/microsoft/onnxruntime/merges",
                    "archive_url": "https://api.github.com/repos/microsoft/onnxruntime/{archive_format}{/ref}",
                    "downloads_url": "https://api.github.com/repos/microsoft/onnxruntime/downloads",
                    "issues_url": "https://api.github.com/repos/microsoft/onnxruntime/issues{/number}",
                    "pulls_url": "https://api.github.com/repos/microsoft/onnxruntime/pulls{/number}",
                    "milestones_url": "https://api.github.com/repos/microsoft/onnxruntime/milestones{/number}",
                    "notifications_url": "https://api.github.com/repos/microsoft/onnxruntime/notifications{?since,all,participating}",
                    "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/labels{/name}",
                    "releases_url": "https://api.github.com/repos/microsoft/onnxruntime/releases{/id}",
                    "deployments_url": "https://api.github.com/repos/microsoft/onnxruntime/deployments",
                    "created_at": "2018-11-10T02:22:53Z",
                    "updated_at": "2022-12-20T19:02:34Z",
                    "pushed_at": "2022-12-20T19:26:57Z",
                    "git_url": "git://github.com/microsoft/onnxruntime.git",
                    "ssh_url": "git@github.com:microsoft/onnxruntime.git",
                    "clone_url": "https://github.com/microsoft/onnxruntime.git",
                    "svn_url": "https://github.com/microsoft/onnxruntime",
                    "homepage": "https://www.onnxruntime.ai",
                    "size": 1018648,
                    "stargazers_count": 7949,
                    "watchers_count": 7949,
                    "language": "C++",
                    "has_issues": true,
                    "has_projects": true,
                    "has_downloads": true,
                    "has_wiki": true,
                    "has_pages": true,
                    "has_discussions": true,
                    "forks_count": 1862,
                    "mirror_url": null,
                    "archived": false,
                    "disabled": false,
                    "open_issues_count": 1453,
                    "license": {
                        "key": "mit",
                        "name": "MIT License",
                        "spdx_id": "MIT",
                        "url": "https://api.github.com/licenses/mit",
                        "node_id": "MDc6TGljZW5zZTEz"
                    },
                    "allow_forking": true,
                    "is_template": false,
                    "web_commit_signoff_required": false,
                    "topics": [
                        "ai-framework",
                        "deep-learning",
                        "hacktoberfest",
                        "hardware-acceleration",
                        "machine-learning",
                        "neural-networks",
                        "onnx",
                        "pytorch",
                        "scikit-learn",
                        "tensorflow"
                    ],
                    "visibility": "public",
                    "forks": 1862,
                    "open_issues": 1453,
                    "watchers": 7949,
                    "default_branch": "main",
                    "permissions": {
                        "admin": false,
                        "maintain": true,
                        "push": true,
                        "triage": true,
                        "pull": true
                    }
                },
                "pull_request": {
                    "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/10775",
                    "html_url": "https://github.com/microsoft/onnxruntime/pull/10775",
                    "diff_url": "https://github.com/microsoft/onnxruntime/pull/10775.diff",
                    "patch_url": "https://github.com/microsoft/onnxruntime/pull/10775.patch",
                    "merged_at": null
                },
                "body": "**Description**: \r\n\r\nThese tests are not stable. They cause problems when an external user wants to build onnx runtime from source. \r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\nSee #8367\r\n\r\nThis PR will make at least on V100 all the remaining tests are passing. ONNX Runtime training team uses V100 extensively. \r\n\r\n- If it fixes an open issue, please link to the issue here.\r\n",
                "reactions": {
                    "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775/reactions",
                    "total_count": 0,
                    "+1": 0,
                    "-1": 0,
                    "laugh": 0,
                    "hooray": 0,
                    "confused": 0,
                    "heart": 0,
                    "rocket": 0,
                    "eyes": 0
                },
                "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10775/timeline",
                "performed_via_github_app": null,
                "state_reason": null
            }
        },
        "event": "cross-referenced"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1059592512",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-1059592512",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 1059592512,
        "node_id": "IC_kwDOCVq1mM4_KBlA",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-04T23:03:06Z",
        "updated_at": "2022-03-04T23:03:06Z",
        "author_association": "MEMBER",
        "body": "\" CUDA error cudaErrorInvalidDeviceFunction:invalid device function\" These failures are not a problem of TensorRT. They were from our onnx runtime cuda execution provider. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1059592512/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        }
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1059598090",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/8367#issuecomment-1059598090",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/8367",
        "id": 1059598090,
        "node_id": "IC_kwDOCVq1mM4_KC8K",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-04T23:16:34Z",
        "updated_at": "2022-03-04T23:16:34Z",
        "author_association": "MEMBER",
        "body": "RTX 3090 has CUDA compute capability of 8.6. The number is not in our CMakeLists.txt. I guess it is the reason why you saw these  \"invalid device function\" error, though I don't understand why CUDA didn't do JIT. \r\n\r\nYou may add  \" --cmake_extra_defines CMAKE_CUDA_ARCHITECTURES=86\" to the arguments of build.bat.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1059598090/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null,
        "event": "commented",
        "actor": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        }
    }
]