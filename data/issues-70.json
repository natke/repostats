[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7207",
        "id": 848643294,
        "node_id": "MDU6SXNzdWU4NDg2NDMyOTQ=",
        "number": 7207,
        "title": "Segmentation fault when running onnxruntime inside docker with cpuset restrictions",
        "user": {
            "login": "yindavidyang",
            "id": 19674938,
            "node_id": "MDQ6VXNlcjE5Njc0OTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19674938?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yindavidyang",
            "html_url": "https://github.com/yindavidyang",
            "followers_url": "https://api.github.com/users/yindavidyang/followers",
            "following_url": "https://api.github.com/users/yindavidyang/following{/other_user}",
            "gists_url": "https://api.github.com/users/yindavidyang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yindavidyang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yindavidyang/subscriptions",
            "organizations_url": "https://api.github.com/users/yindavidyang/orgs",
            "repos_url": "https://api.github.com/users/yindavidyang/repos",
            "events_url": "https://api.github.com/users/yindavidyang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yindavidyang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 14,
        "created_at": "2021-04-01T17:11:12Z",
        "updated_at": "2023-02-23T10:05:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nOnnxruntime crashes when I run it inside Docker with CPU limitations specified by \"cpuset-cpus\". The crash doesn't happen when running Docker without \"cpuset-cpus\" arg, or running Docker with \"cpuset-cpus\" with a lot of CPU cores.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): pip\r\n- ONNX Runtime version: 1.7.0\r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\nHardware: 32 core AMD CPU (64 threads). 4x 2080Ti GPUs\r\n\r\nThe crash doesn't happen when I provision many cores, such as \"--cpuset-cpus 0-31\". \r\n\r\n```docker run --rm -it --gpus all --cpuset-cpus 0-15 nvidia/cuda:11.0.3-cudnn8-devel-ubuntu20.04```\r\n\r\nthen, inside docker container\r\n\r\n```\r\napt update\r\napt install python3-pip wget\r\npip3 install onnxruntime\r\nwget https://github.com/onnx/models/blob/master/vision/classification/mnist/model/mnist-7.onnx?raw=true -O mnist.onnx\r\npython3\r\n```\r\n\r\nthen, inside python3:\r\n\r\n```\r\nimport onnxruntime as ort\r\nort.InferenceSession('mnist.onnx') # crash!\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7207/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7208",
        "id": 848649620,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NTUzOTE3",
        "number": 7208,
        "title": "Fix Zip-Nuget-Java Packaging Pipeline",
        "user": {
            "login": "askhade",
            "id": 6475296,
            "node_id": "MDQ6VXNlcjY0NzUyOTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6475296?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/askhade",
            "html_url": "https://github.com/askhade",
            "followers_url": "https://api.github.com/users/askhade/followers",
            "following_url": "https://api.github.com/users/askhade/following{/other_user}",
            "gists_url": "https://api.github.com/users/askhade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/askhade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/askhade/subscriptions",
            "organizations_url": "https://api.github.com/users/askhade/orgs",
            "repos_url": "https://api.github.com/users/askhade/repos",
            "events_url": "https://api.github.com/users/askhade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/askhade/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-01T17:20:53Z",
        "updated_at": "2021-04-05T17:58:14Z",
        "closed_at": "2021-04-05T17:58:13Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7208",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7208",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7208.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7208.patch",
            "merged_at": "2021-04-05T17:58:13Z"
        },
        "body": "**Description**: Updating csharp test to ignore errors generated because of unsupported opset versions. \r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- Fixing packaging pipeline\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7208/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7209",
        "id": 848671038,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NTcxNzgy",
        "number": 7209,
        "title": "fix broken link in TensorRT-ExecutionProvider doc",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-01T17:55:10Z",
        "updated_at": "2021-04-02T15:44:36Z",
        "closed_at": "2021-04-02T15:44:35Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7209",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7209",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7209.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7209.patch",
            "merged_at": "2021-04-02T15:44:35Z"
        },
        "body": "fix link to notebook example.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7209/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7210",
        "id": 848700198,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NTk2Mzcy",
        "number": 7210,
        "title": "Support SkipLayerNorm for ROCm EP",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-01T18:40:34Z",
        "updated_at": "2021-04-02T16:06:29Z",
        "closed_at": "2021-04-02T16:03:31Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7210",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7210",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7210.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7210.patch",
            "merged_at": "2021-04-02T16:03:31Z"
        },
        "body": "This op is needed for GPT2-medium evaluation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7210/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7211",
        "id": 848789259,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NjcxMTQ2",
        "number": 7211,
        "title": "[NNAPI/CoreML EP] Add Onnx opset 14 support",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-01T21:06:30Z",
        "updated_at": "2021-04-02T20:18:49Z",
        "closed_at": "2021-04-02T20:18:48Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7211",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7211",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7211.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7211.patch",
            "merged_at": "2021-04-02T20:18:48Z"
        },
        "body": "**Description**: [NNAPI/CoreML EP] Add Onnx opset 14 support\r\n\r\n**Motivation and Context**\r\n- The only op need special handling (for NNAPI/CoreML EP) in Onnx opset 14 is ReShape with extra attributes \"allowzero\", detailed changes are here, https://github.com/onnx/onnx/wiki/Logistics-for-ONNX-Release-1.9\r\n- Disable NNAPI for com.microsoft.QLinearConv which is nhwc QLinearConv which is not supported yet\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7211/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7212",
        "id": 848824963,
        "node_id": "MDU6SXNzdWU4NDg4MjQ5NjM=",
        "number": 7212,
        "title": "Significant difference in the performance of pytorch and exported onnx models",
        "user": {
            "login": "II245",
            "id": 9077278,
            "node_id": "MDQ6VXNlcjkwNzcyNzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9077278?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/II245",
            "html_url": "https://github.com/II245",
            "followers_url": "https://api.github.com/users/II245/followers",
            "following_url": "https://api.github.com/users/II245/following{/other_user}",
            "gists_url": "https://api.github.com/users/II245/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/II245/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/II245/subscriptions",
            "organizations_url": "https://api.github.com/users/II245/orgs",
            "repos_url": "https://api.github.com/users/II245/repos",
            "events_url": "https://api.github.com/users/II245/events{/privacy}",
            "received_events_url": "https://api.github.com/users/II245/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 22,
        "created_at": "2021-04-01T22:19:56Z",
        "updated_at": "2022-08-12T08:39:38Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Performance issue**\r\nNoticed a significant difference in the performance of pytorch and exported onnx models with a simple conv layer.\r\nThe difference is more than 5 times after warming up.\r\n\r\n**Urgency**\r\nnone\r\n\r\n**System information**\r\nOS Platform and Distribution: Linux Ubuntu 18.04: Linux x86_64\r\nONNX Runtime installed from (source or binary): binary\r\nONNX Runtime version: onnxruntime-1.7.0\r\nPython version: Python 3.8.5\r\nPytorch version: 1.8.1\r\nCUDA/cuDNN version: CUDA Version: 11.1\r\nGPU model and memory: Tesla V100 (32G)\r\n\r\n**To Reproduce**\r\nRun the script below with parameters\r\n\r\nreproduce onnx performance. The script creates onnx model on the fly.\r\n```bash\r\nCUDA_VISIBLE_DEVICES=0 python3 benchmark_repro.py \\\r\n  --onnx conv_fp16.onnx \\\r\n  --iterations 30 \\\r\n  --channels 896 \\\r\n  --iterations-warmup 30 \\\r\n  --run-with-io-binding \\\r\n  -B 32 \\\r\n  -T 832\r\n```\r\n\r\noutput\r\n```\r\nBatch shape [32, 896, 832]\r\naverage load+fwd 35.92 msec\r\n```\r\n\r\nreproduce pytorch\r\n```bash\r\nCUDA_VISIBLE_DEVICES=0 python3 benchmark_repro.py \\\r\n  --iterations 30 \\\r\n  --channels 896 \\\r\n  --iterations-warmup 30 \\\r\n  -B 32 \\\r\n  -T 832\r\n```\r\n\r\noutput\r\n```\r\nBatch shape [32, 896, 832]\r\naverage load+fwd 10.41 msec\r\n```\r\n\r\n\r\n```python\r\nimport argparse\r\nimport time\r\nimport torch\r\nimport torch.cuda.profiler\r\nimport onnxruntime\r\nimport numpy as np\r\n\r\n\r\ndef infer_ort(onnxruntime_session, io_binding):\r\n\tonnxruntime_session.run_with_iobinding(io_binding)\r\n\r\n\r\ndef get_model(channels):\r\n\treturn torch.nn.Conv1d(in_channels=channels, out_channels=channels*2, kernel_size=19,\r\n\t\t\tstride=2, padding=(1 * 19 // 2), dilation=1, groups=1)\r\n\r\n\r\ndef export_onnx(onnx_path, channels, dtype = torch.float16):\r\n\tmodel = get_model(channels)\r\n\ttorch.set_grad_enabled(False)\r\n\tmodel.eval()\r\n\tmodel.to('cuda', dtype=dtype)\r\n\twaveform_input = torch.rand((4, channels, 128), device='cuda', dtype=dtype)\r\n\r\n\tlogits = model(waveform_input)\r\n\r\n\ttorch.onnx.export(\r\n\t\t\tmodel, (waveform_input),\r\n\t\t\tonnx_path,\r\n\t\t\topset_version=12,\r\n\t\t\texport_params=True,\r\n\t\t\tdo_constant_folding=True,\r\n\t\t\tinput_names=['input'],\r\n\t\t\tdynamic_axes=dict(input={\r\n\t\t\t\t0: 'B',\r\n\t\t\t\t2: 'T'\r\n\t\t\t})\r\n\t)\r\n\r\n\t## check export correctness\r\n\tonnxruntime_session = onnxruntime.InferenceSession(onnx_path)\r\n\t(logits_,) = onnxruntime_session.run(None, dict(input=waveform_input.cpu().to(dtype=dtype).numpy()))\r\n\r\n\tprint((torch.from_numpy(logits_) - logits.cpu()).abs().to(dtype=torch.float32).max())\r\n\tassert torch.allclose(\r\n\t\t\tlogits.cpu(),\r\n\t\t\ttorch.from_numpy(logits_),\r\n\t\t\t**{\r\n\t\t\t\t'rtol': 1e-01,\r\n\t\t\t\t'atol': 1e-01\r\n\t\t\t}\r\n\t)\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--iterations', type=int, default=16)\r\nparser.add_argument('--iterations-warmup', type=int, default=16)\r\nparser.add_argument('--channels', type=int, default=64)\r\nparser.add_argument('--onnx')\r\nparser.add_argument('-B', type=int)\r\nparser.add_argument('-T', type=int)\r\nparser.add_argument('--profile-cuda', action='store_true')\r\nparser.add_argument('--run-with-io-binding', action='store_true')\r\nargs = parser.parse_args()\r\n\r\nprint(args)\r\n\r\ndtype = torch.float16\r\nuse_cuda = True\r\n\r\nif args.onnx:\r\n\texport_onnx(args.onnx, args.channels, dtype)\r\n\tonnxruntime_session = onnxruntime.InferenceSession(args.onnx)\r\n\tmodel = lambda x: onnxruntime_session.run(None, dict(input=x))\r\n\tif args.run_with_io_binding:\r\n\t\tmodel = lambda io_binding: onnxruntime_session.run_with_iobinding(io_binding)\r\n\tpass\r\nelse:\r\n\tmodel = get_model(args.channels)\r\n\tmodel.to('cuda')\r\n\tmodel.eval()\r\n\tmodel.to(dtype=dtype)\r\n\r\ntictoc = lambda: (use_cuda and torch.cuda.synchronize()) or time.time()\r\n\r\nbatch_shape = [args.B, args.channels, args.T]\r\n\r\nbatch = torch.rand(*batch_shape, dtype=torch.float16)\r\n\r\nif args.onnx:\r\n\tio_binding = onnxruntime_session.io_binding()\r\n\tX_ortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(batch.numpy(), 'cuda', 0)\r\n\tio_binding.bind_input(name='input', device_type=X_ortvalue.device_name(), device_id=0, element_type=np.float16,\r\n\t\t\tshape=X_ortvalue.shape(), buffer_ptr=X_ortvalue.data_ptr())\r\n\tio_binding.bind_output('3', 'cuda')\r\n\tbatch = io_binding\r\n\tmodel = onnxruntime_session\r\n\tinfer = lambda model, batch: infer_ort(model, batch)\r\nelse:\r\n\tbatch = batch.to(device='cuda')\r\n\tinfer = lambda model, batch: model(batch).cpu()\r\n\r\nprint('Warming up for', args.iterations_warmup, 'iterations')\r\ntic_wall = tictoc()\r\ntorch.backends.cudnn.benchmark = True\r\nfor i in range(args.iterations_warmup):\r\n\ty = infer(model, batch)\r\nprint('Warmup done in {:.02f} wall clock seconds'.format(tictoc() - tic_wall))\r\nprint()\r\n\r\nif args.profile_cuda:\r\n\ttorch.cuda.profiler.start()\r\n\r\nprint('Starting benchmark for', args.iterations, 'iterations:', 'fwd')\r\ntimes_fwd = torch.zeros(args.iterations)\r\nbatch = torch.rand(*batch_shape, dtype=torch.float16)\r\n\r\nif args.onnx:\r\n\tio_binding = onnxruntime_session.io_binding()\r\n\tX_ortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(batch.numpy(), 'cuda', 0)\r\n\tio_binding.bind_input(name='input', device_type=X_ortvalue.device_name(), device_id=0, element_type=np.float16,\r\n\t\t\tshape=X_ortvalue.shape(), buffer_ptr=X_ortvalue.data_ptr())\r\n\tio_binding.bind_output('3', 'cuda')\r\n\tbatch = io_binding\r\n\tmodel = onnxruntime_session\r\n\tinfer = lambda model, batch: infer_ort(model, batch)\r\nelse:\r\n\tbatch = batch.to(device='cuda')\r\n\tinfer = lambda model, batch: model(batch)\r\n\r\nfor i in range(args.iterations):\r\n\ttic = tictoc()\r\n\ty = infer(model, batch)\r\n\ttimes_fwd[i] = tictoc() - tic\r\n\ty = None\r\n\r\nprint('Batch shape', batch_shape)\r\nprint('average load+fwd {:.02f} msec'.format(float(times_fwd.mean()) * 1e3))\r\n\r\n\r\n```\r\nFull cudnn logs here\r\n[updated_cudnn_logs.zip](https://github.com/microsoft/onnxruntime/files/6251174/updated_cudnn_logs.zip)\r\n\r\n\r\nTo get logs,traces pelase run: \r\n```\r\nTRACEFILE=profile_one_conv_onnx_with_warmup.sqlite\r\nTRACELOG=profile_one_conv_onnx_with_warmup.txt\r\nTRACEPYPROFLOG=profile_one_conv_onnx_with_warmup.pyprof.txt\r\nCUDNN_LOGDEST=profile_one_conv_onnx_with_warmup_cudnn_dbg.txt\r\nCUBLAS_LOGDEST=profile_one_conv_onnx_with_warmup_cublas_dbg.txt\r\n\r\nCUDA_VISIBLE_DEVICES=0 CUDNN_LOGINFO_DBG=1 CUDNN_LOGDEST_DBG=$CUDNN_LOGDEST CUBLAS_LOGINFO_DBG=1 CUBLAS_LOGDEST_DBG=$CUBLAS_LOGDEST nvprof -f -o $TRACEFILE -s --devices 0 --profile-from-start off -- python3 benchmark_repro.py \\\r\n  --onnx conv_fp16.onnx \\\r\n  --iterations 1 \\\r\n  --iterations-warmup 4 \\\r\n  --profile-cuda \\\r\n  -B 32 \\\r\n  -T 1664 &> $TRACELOG\r\n\r\npython3 nvprof2json.py $TRACEFILE > $TRACEFILE.json\r\n```\r\n\r\n\r\n**Expected behavior**\r\nOnnx performance is the same as pytorch.\r\n\r\n\r\n**Additional context**\r\n\r\nFound that some arguments of cudnnConvolutionForward differ (cudnn log).\r\n\r\npytorch \r\n```\r\nI! CuDNN (v8005) function cudnnConvolutionForward() called:\r\ni!     handle: type=cudnnHandle_t; streamId=(nil) (defaultStream);\r\ni!     alpha: type=CUDNN_DATA_FLOAT; val=1.000000;\r\ni!     xDesc: type=cudnnTensorDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[32,896,1,832];\r\ni!         strideA: type=int; val=[745472,832,832,1];\r\ni!     xData: location=dev; addr=0x7f1f48d80000;\r\ni!     wDesc: type=cudnnFilterDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         vect: type=int; val=0;\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[1792,896,1,19];\r\ni!         format: type=cudnnTensorFormat_t; val=CUDNN_TENSOR_NCHW (0);\r\ni!     wData: location=dev; addr=0x7f1fc4000000;\r\ni!     convDesc: type=cudnnConvolutionDescriptor_t:\r\ni!         mode: type=cudnnConvolutionMode_t; val=CUDNN_CROSS_CORRELATION (1);\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_FLOAT (0);\r\ni!         mathType: type=cudnnMathType_t; val=CUDNN_TENSOR_OP_MATH (1);\r\ni!         reorderType: type=int; val=0;\r\ni!         arrayLength: type=int; val=2;\r\ni!         padA: type=int; val=[0,9];\r\ni!         strideA: type=int; val=[1,2];\r\ni!         dilationA: type=int; val=[1,1];\r\ni!         groupCount: type=int; val=1;\r\ni!     algo: type=cudnnConvolutionFwdAlgo_t; val=CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM (1);\r\ni!     workSpace: location=dev; addr=0x7f1f24d80000;\r\ni!     workSpaceSizeInBytes: type=size_t; val=217458192;\r\ni!     beta: type=CUDNN_DATA_FLOAT; val=0.000000;\r\ni!     yDesc: type=cudnnTensorDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[32,1792,1,416];\r\ni!         strideA: type=int; val=[745472,416,416,1];\r\ni!     yData: location=dev; addr=0x7f1f22000000;\r\ni! Time: 2021-04-02T20:20:59.364486 (0d+0h+0m+7s since start)\r\ni! Process=20457; Thread=20457; GPU=0; Handle=0x562d0f5507f0; StreamId=(nil) (defaultStream).\r\n\r\n```\r\n\r\nonnx\r\n```\r\nI! CuDNN (v8005) function cudnnConvolutionForward() called:\r\ni!     handle: type=cudnnHandle_t; streamId=0x556d1919df70;\r\ni!     alpha: type=CUDNN_DATA_FLOAT; val=1.000000;\r\ni!     xDesc: type=cudnnTensorDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[32,896,832,1];\r\ni!         strideA: type=int; val=[745472,832,1,1];\r\ni!     xData: location=dev; addr=0x7fb90c000000;\r\ni!     wDesc: type=cudnnFilterDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         vect: type=int; val=0;\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[1792,896,19,1];\r\ni!         format: type=cudnnTensorFormat_t; val=CUDNN_TENSOR_NCHW (0);\r\ni!     wData: location=dev; addr=0x7fb97c000000;\r\ni!     convDesc: type=cudnnConvolutionDescriptor_t:\r\ni!         mode: type=cudnnConvolutionMode_t; val=CUDNN_CROSS_CORRELATION (1);\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         mathType: type=cudnnMathType_t; val=CUDNN_DEFAULT_MATH (0);\r\ni!         reorderType: type=int; val=0;\r\ni!         arrayLength: type=int; val=2;\r\ni!         padA: type=int; val=[9,0];\r\ni!         strideA: type=int; val=[2,1];\r\ni!         dilationA: type=int; val=[1,1];\r\ni!         groupCount: type=int; val=1;\r\ni!     algo: type=cudnnConvolutionFwdAlgo_t; val=CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM (0);\r\ni!     workSpace: location=dev; addr=NULL_PTR;\r\ni!     workSpaceSizeInBytes: type=size_t; val=0;\r\ni!     beta: type=CUDNN_DATA_FLOAT; val=0.000000;\r\ni!     yDesc: type=cudnnTensorDescriptor_t:\r\ni!         dataType: type=cudnnDataType_t; val=CUDNN_DATA_HALF (2);\r\ni!         nbDims: type=int; val=4;\r\ni!         dimA: type=int; val=[32,1792,416,1];\r\ni!         strideA: type=int; val=[745472,416,1,1];\r\ni!     yData: location=dev; addr=0x7fb914000000;\r\ni! Time: 2021-04-02T20:20:42.158192 (0d+0h+0m+4s since start)\r\ni! Process=20361; Thread=20361; GPU=0; Handle=0x556d193e9ea0; StreamId=0x556d1919df70.\r\n\r\n```\r\n\r\nList of noted differences:\r\n - xDesc.dimA and strideA onnx ([32,896,832,1] vs pytorch [32,896,1,832])\r\n - convDesc.dataType onnx val=CUDNN_DATA_HALF (2) vs pytorch val=CUDNN_DATA_FLOAT (0)\r\n - and time to time algo val becomes CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM instead of CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM\r\n \r\nAlso\r\nIn tracing used different matrix kernels\r\npytorch: volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1\r\nonnx: implicit_convolve_hhgemm\r\n\r\n\r\nCould you please answer what is the cause of the differences?\r\nOr what do I wrong in benchmarking or onnx setup?\r\n\r\n\r\n**UPDATE:**\r\n- Added io_binding. Copy result to cpu in both cases.\r\n- Changed script params and updated timings. Now performance differs two times.\r\n- Cudnn logs and gemm names updated.\r\n\r\n**UPDATE 2:**\r\n- removed copy from gpy to cpu\r\n- update performance comparison\r\nnow pytorch  ~3.5 times faster. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7212/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7213",
        "id": 848829173,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NzA0NjY0",
        "number": 7213,
        "title": "Zhalei/mlas test",
        "user": {
            "login": "zhanghuanrong",
            "id": 5163183,
            "node_id": "MDQ6VXNlcjUxNjMxODM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5163183?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhanghuanrong",
            "html_url": "https://github.com/zhanghuanrong",
            "followers_url": "https://api.github.com/users/zhanghuanrong/followers",
            "following_url": "https://api.github.com/users/zhanghuanrong/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhanghuanrong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhanghuanrong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhanghuanrong/subscriptions",
            "organizations_url": "https://api.github.com/users/zhanghuanrong/orgs",
            "repos_url": "https://api.github.com/users/zhanghuanrong/repos",
            "events_url": "https://api.github.com/users/zhanghuanrong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhanghuanrong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-01T22:28:03Z",
        "updated_at": "2021-04-10T00:02:39Z",
        "closed_at": "2021-04-10T00:02:38Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7213",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7213",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7213.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7213.patch",
            "merged_at": "2021-04-10T00:02:38Z"
        },
        "body": "Refactor mlas unittest using google test:\r\n    1) sperate into small piece with helper for gtest.\r\n    2) by default run tests from short execute, with --long, could run long run executes.\r\n    3) make heavy short execute test distinguish on different parameter.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7213/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7214",
        "id": 848899782,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NzYyNTUy",
        "number": 7214,
        "title": "Enable saving optimized models in OrtModule",
        "user": {
            "login": "SherlockNoMad",
            "id": 9906745,
            "node_id": "MDQ6VXNlcjk5MDY3NDU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9906745?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SherlockNoMad",
            "html_url": "https://github.com/SherlockNoMad",
            "followers_url": "https://api.github.com/users/SherlockNoMad/followers",
            "following_url": "https://api.github.com/users/SherlockNoMad/following{/other_user}",
            "gists_url": "https://api.github.com/users/SherlockNoMad/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SherlockNoMad/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SherlockNoMad/subscriptions",
            "organizations_url": "https://api.github.com/users/SherlockNoMad/orgs",
            "repos_url": "https://api.github.com/users/SherlockNoMad/repos",
            "events_url": "https://api.github.com/users/SherlockNoMad/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SherlockNoMad/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T01:49:34Z",
        "updated_at": "2021-04-02T19:37:06Z",
        "closed_at": "2021-04-02T19:37:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7214",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7214",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7214.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7214.patch",
            "merged_at": "2021-04-02T19:37:06Z"
        },
        "body": "As title. \r\nThese models are useful for performance investigation. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7214/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7215",
        "id": 848900269,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NzYyOTM4",
        "number": 7215,
        "title": "Make IDataTransfer be directly shared with shared providers",
        "user": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T01:51:25Z",
        "updated_at": "2021-04-02T03:39:17Z",
        "closed_at": "2021-04-02T03:39:16Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7215",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7215",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7215.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7215.patch",
            "merged_at": "2021-04-02T03:39:16Z"
        },
        "body": "**Description**: This is already part of the CUDA shared provider change, but is being separated out to unblock Cheng.\r\n\r\n**Motivation and Context**\r\nHaving more base classes being directly shared with the shared providers is a good thing, it keeps things simpler and more efficient.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7215/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7216",
        "id": 848933755,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3NzkwMzI4",
        "number": 7216,
        "title": "Round-to-even for integral types in Upsample/Resize",
        "user": {
            "login": "pranav-prakash",
            "id": 10335022,
            "node_id": "MDQ6VXNlcjEwMzM1MDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10335022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranav-prakash",
            "html_url": "https://github.com/pranav-prakash",
            "followers_url": "https://api.github.com/users/pranav-prakash/followers",
            "following_url": "https://api.github.com/users/pranav-prakash/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranav-prakash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranav-prakash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranav-prakash/subscriptions",
            "organizations_url": "https://api.github.com/users/pranav-prakash/orgs",
            "repos_url": "https://api.github.com/users/pranav-prakash/repos",
            "events_url": "https://api.github.com/users/pranav-prakash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranav-prakash/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "skottmckay",
                "id": 979079,
                "node_id": "MDQ6VXNlcjk3OTA3OQ==",
                "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/skottmckay",
                "html_url": "https://github.com/skottmckay",
                "followers_url": "https://api.github.com/users/skottmckay/followers",
                "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
                "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
                "organizations_url": "https://api.github.com/users/skottmckay/orgs",
                "repos_url": "https://api.github.com/users/skottmckay/repos",
                "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
                "received_events_url": "https://api.github.com/users/skottmckay/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 13,
        "created_at": "2021-04-02T03:35:37Z",
        "updated_at": "2022-08-12T08:17:54Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7216",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7216",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7216.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7216.patch",
            "merged_at": null
        },
        "body": "~~Register Resize op to work on int8 types. The kernel def is already templated (and already supports uint8_t), so we just need to add register the kernel version.~~\r\n\r\nAfter further discussion (see below), the scope of this PR was modified to just change the rounding behavior for integral types.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7216/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7217",
        "id": 848981126,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3ODI5NjA5",
        "number": 7217,
        "title": "Add gradient registration and tests for Min/Max",
        "user": {
            "login": "mindest",
            "id": 30493312,
            "node_id": "MDQ6VXNlcjMwNDkzMzEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/30493312?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mindest",
            "html_url": "https://github.com/mindest",
            "followers_url": "https://api.github.com/users/mindest/followers",
            "following_url": "https://api.github.com/users/mindest/following{/other_user}",
            "gists_url": "https://api.github.com/users/mindest/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mindest/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mindest/subscriptions",
            "organizations_url": "https://api.github.com/users/mindest/orgs",
            "repos_url": "https://api.github.com/users/mindest/repos",
            "events_url": "https://api.github.com/users/mindest/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mindest/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-04-02T05:49:41Z",
        "updated_at": "2021-04-20T10:14:33Z",
        "closed_at": "2021-04-20T10:14:32Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7217",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7217",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7217.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7217.patch",
            "merged_at": "2021-04-20T10:14:32Z"
        },
        "body": "**Description**: Add gradient registration and corresponding tests for ops `Min` and `Max`\r\n\r\n**Motivation and Context**\r\n- Support training of a model that uses `Max`\r\n- `Min` shares the same logic as `Max`",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7217/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7218",
        "id": 849050755,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA3ODg5MDQz",
        "number": 7218,
        "title": "Add fp16 support for BatchNormalization Forward/Backward",
        "user": {
            "login": "mindest",
            "id": 30493312,
            "node_id": "MDQ6VXNlcjMwNDkzMzEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/30493312?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mindest",
            "html_url": "https://github.com/mindest",
            "followers_url": "https://api.github.com/users/mindest/followers",
            "following_url": "https://api.github.com/users/mindest/following{/other_user}",
            "gists_url": "https://api.github.com/users/mindest/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mindest/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mindest/subscriptions",
            "organizations_url": "https://api.github.com/users/mindest/orgs",
            "repos_url": "https://api.github.com/users/mindest/repos",
            "events_url": "https://api.github.com/users/mindest/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mindest/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-02T07:52:27Z",
        "updated_at": "2021-08-05T05:37:53Z",
        "closed_at": "2021-05-10T23:46:37Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7218",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7218",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7218.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7218.patch",
            "merged_at": null
        },
        "body": "**Description**\r\n- Add fp16 support for BatchNormalization ForwardTraining/Backward\r\n- Bind inputs `mean` and `var` with outputs `mean` and `var`, respectively\r\n\r\n**Motivation and Context**\r\n- Currently BatchNormalization does not support fp16 and should be kept in fp32 when training\r\n- Fix the problem that `running_mean` and `running_var` do not change in training mode",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7218/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7220",
        "id": 849253229,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MDU4MTM3",
        "number": 7220,
        "title": "Support for saving and loading pytorch compatible state dictionaries",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T14:33:47Z",
        "updated_at": "2021-04-05T10:40:42Z",
        "closed_at": "2021-04-05T10:40:41Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7220",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7220",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7220.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7220.patch",
            "merged_at": "2021-04-05T10:40:41Z"
        },
        "body": "**Description**: When retrieving the ```state_dict``` from ```ORTModule```, the key names had the ```_flattened_output_module._base_module``` prefix for all states (because of the specialized module inside ```ORTModule``` called ```self._flattened_output_module._base_module```). As a result, the loading of the state dictionary from a pytorch model also failed (since ```ORTModule``` expected the prefix to be there for all states).\r\n\r\nThis pull request overrides the ```state_dict()``` and the ```load_state_dict()``` methods and calls the same methods on the underlying specialized ```torch.nn.Module```.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7220/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7221",
        "id": 849293702,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MDkxMjk1",
        "number": 7221,
        "title": "Suppress tracer warnings from onnx export in ORTModule",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-04-02T15:50:12Z",
        "updated_at": "2021-04-08T10:42:13Z",
        "closed_at": "2021-04-08T10:41:38Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7221",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7221",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7221.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7221.patch",
            "merged_at": "2021-04-08T10:41:38Z"
        },
        "body": "**Description**: When exporting the PyTorch model to ONNX, the exporter threw some warning log lines such as:\r\n\r\n```\r\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert batch_size > 0, \"batch_size has to be defined and > 0\"\r\n```\r\n\r\nThis could appear to the end user as being something serious where as it might not be. This pull request suppresses these warnings and writes them to ```os.devnull``` when exporting the onnx model.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7221/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7222",
        "id": 849385817,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MTcwNDE3",
        "number": 7222,
        "title": "Enable more unit tests for ROCM EP",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T18:18:14Z",
        "updated_at": "2021-04-02T22:57:09Z",
        "closed_at": "2021-04-02T22:57:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7222",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7222",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7222.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7222.patch",
            "merged_at": "2021-04-02T22:57:09Z"
        },
        "body": "",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7222/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7223",
        "id": 849417915,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MTk2Nzg2",
        "number": 7223,
        "title": "handle optional input in quant topo sort",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T19:32:11Z",
        "updated_at": "2021-04-03T03:42:50Z",
        "closed_at": "2021-04-03T03:42:49Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7223",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7223",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7223.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7223.patch",
            "merged_at": "2021-04-03T03:42:49Z"
        },
        "body": "**Description**: Describe your changes.\r\nHandle the case that input can be optional in quant topo sort. When computing the depency, those optional input should be excluded. For the instance like below, sequence and bias of gru don't exist, \r\n        gru_node = onnx.helper.make_node(\r\n            'GRU',\r\n            ['input', 'W_GRU', 'R_GRU', '', '', 'H_GRU'],\r\n            ['GRU_O'],\r\n            hidden_size = 8, \r\n            direction = 'bidirectional')",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7223/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7224",
        "id": 849448493,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MjI0NTgz",
        "number": 7224,
        "title": "HSA_NO_SCRATCH_RECLAIM and RCCL_ALLTOALL_KERNEL_DISABLE are not neede…",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T20:12:33Z",
        "updated_at": "2021-04-03T01:19:12Z",
        "closed_at": "2021-04-03T01:19:12Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7224",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7224",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7224.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7224.patch",
            "merged_at": "2021-04-03T01:19:12Z"
        },
        "body": "…d for ROCm 4.1\r\n\r\n**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7224/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7225",
        "id": 849476051,
        "node_id": "MDU6SXNzdWU4NDk0NzYwNTE=",
        "number": 7225,
        "title": "Explain in the docs that run() or run_with_binding() always synchronizes the CUDA stream prior to returning control (or an explicit note about proper benchmarking ONNX ops versus PyTorch ops also wrt CUDA syncs)",
        "user": {
            "login": "vadimkantorov",
            "id": 1041752,
            "node_id": "MDQ6VXNlcjEwNDE3NTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1041752?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vadimkantorov",
            "html_url": "https://github.com/vadimkantorov",
            "followers_url": "https://api.github.com/users/vadimkantorov/followers",
            "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions",
            "organizations_url": "https://api.github.com/users/vadimkantorov/orgs",
            "repos_url": "https://api.github.com/users/vadimkantorov/repos",
            "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vadimkantorov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "natke",
                "id": 3302433,
                "node_id": "MDQ6VXNlcjMzMDI0MzM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/natke",
                "html_url": "https://github.com/natke",
                "followers_url": "https://api.github.com/users/natke/followers",
                "following_url": "https://api.github.com/users/natke/following{/other_user}",
                "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
                "organizations_url": "https://api.github.com/users/natke/orgs",
                "repos_url": "https://api.github.com/users/natke/repos",
                "events_url": "https://api.github.com/users/natke/events{/privacy}",
                "received_events_url": "https://api.github.com/users/natke/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 9,
        "created_at": "2021-04-02T20:47:13Z",
        "updated_at": "2022-12-27T21:26:01Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "It is important for simplifying benchmarks as in https://github.com/microsoft/onnxruntime/issues/7212, i.e. avoid GPU->CPU transfer just to ensure the model actually completed execution.\r\n\r\nI found that execution providers have method `Sync()`. How to call it from Python?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7225/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7226",
        "id": 849494393,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MjY0NDc3",
        "number": 7226,
        "title": "Rename cuda_mem_limit and hip_mem_limit to gpu_mem_limit for both CUD…",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-02T21:35:41Z",
        "updated_at": "2021-04-05T16:04:06Z",
        "closed_at": "2021-04-05T16:04:05Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7226",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7226",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7226.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7226.patch",
            "merged_at": "2021-04-05T16:04:05Z"
        },
        "body": "…A EP and ROCm EP\r\n\r\nWith this change, differentiating CUDA EP and ROCm EP is not needed in training script when mem_limit option needs to be set.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7226/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7227",
        "id": 849502953,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MjcxNTc3",
        "number": 7227,
        "title": "CUDA ConvGrad Kernel",
        "user": {
            "login": "SherlockNoMad",
            "id": 9906745,
            "node_id": "MDQ6VXNlcjk5MDY3NDU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9906745?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SherlockNoMad",
            "html_url": "https://github.com/SherlockNoMad",
            "followers_url": "https://api.github.com/users/SherlockNoMad/followers",
            "following_url": "https://api.github.com/users/SherlockNoMad/following{/other_user}",
            "gists_url": "https://api.github.com/users/SherlockNoMad/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SherlockNoMad/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SherlockNoMad/subscriptions",
            "organizations_url": "https://api.github.com/users/SherlockNoMad/orgs",
            "repos_url": "https://api.github.com/users/SherlockNoMad/repos",
            "events_url": "https://api.github.com/users/SherlockNoMad/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SherlockNoMad/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-02T22:01:51Z",
        "updated_at": "2021-04-07T05:09:07Z",
        "closed_at": "2021-04-07T05:09:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7227",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7227",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7227.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7227.patch",
            "merged_at": "2021-04-07T05:09:06Z"
        },
        "body": "ConvGrad CUDA kernel that uses the default algo. \r\n\r\nWill implement algo search in the next PR. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7227/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7228",
        "id": 849574199,
        "node_id": "MDU6SXNzdWU4NDk1NzQxOTk=",
        "number": 7228,
        "title": "Different inference results Python vs C++",
        "user": {
            "login": "ledaiduongvnth",
            "id": 28498007,
            "node_id": "MDQ6VXNlcjI4NDk4MDA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/28498007?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ledaiduongvnth",
            "html_url": "https://github.com/ledaiduongvnth",
            "followers_url": "https://api.github.com/users/ledaiduongvnth/followers",
            "following_url": "https://api.github.com/users/ledaiduongvnth/following{/other_user}",
            "gists_url": "https://api.github.com/users/ledaiduongvnth/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ledaiduongvnth/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ledaiduongvnth/subscriptions",
            "organizations_url": "https://api.github.com/users/ledaiduongvnth/orgs",
            "repos_url": "https://api.github.com/users/ledaiduongvnth/repos",
            "events_url": "https://api.github.com/users/ledaiduongvnth/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ledaiduongvnth/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-04-03T04:23:53Z",
        "updated_at": "2021-04-05T04:29:55Z",
        "closed_at": "2021-04-05T04:29:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nDifferent inference results in Python vs C++.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu18.04\r\n- ONNX Runtime version:1.7.0\r\n- Python version:3.7\r\n\r\n**To Reproduce**\r\n\r\nonnx model :\r\nhttps://drive.google.com/file/d/1n9AGyg5mFWLeAWxIzNfUgFRHbPMr4NJA/view?usp=sharing\r\n\r\nPython code:\r\n```\r\nimport numpy as np\r\nimport onnxruntime as rt\r\n\r\nsess = rt.InferenceSession(\"/mnt/hdd/PycharmProjects/Pytorch_Retinaface/FaceDetector.onnx\")\r\ninput_name = \"input0\"\r\nimg = np.full((1, 3, 640, 640), 1).astype(np.float32)\r\noutput = [\"output0\", \"833\", \"832\"]\r\nresult = sess.run(output, {input_name: img})\r\nprint(result[0])\r\n```\r\nC++ code \r\n```\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <chrono>\r\n#include <string>\r\n#include <vector>\r\n#include <onnxruntime_cxx_api.h>\r\n#include \"FaceDetector.h\"\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n    std::string modelFilepath{\"/mnt/hdd/PycharmProjects/Pytorch_Retinaface/FaceDetector.onnx\"};\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING);\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(1);\r\n    sessionOptions.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_DISABLE_ALL);\r\n    Ort::Session session(env, modelFilepath.c_str(), sessionOptions);\r\n\r\n    Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);\r\n    auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n    std::vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n\r\n    std::vector<const char*> inputNames{\"input0\"};\r\n    std::vector<const char*> outputNames{\"output0\", \"833\", \"832\"};\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n\r\n    for (int i = 0; i < 1000; i ++){\r\n        cv::Mat img(640, 640, CV_32FC3, cv::Scalar(1, 1, 1));\r\n        cv::dnn::blobFromImage(img, img);\r\n        Ort::Value inputTensors = Ort::Value::CreateTensor<float>(memoryInfo, (float*)img.data, 640*640*3, inputDims.data(), 4);\r\n        std::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\r\n        std::vector<Ort::Value> ort_outputs = session.Run(Ort::RunOptions{nullptr}, inputNames.data(), &inputTensors, 1, outputNames.data(), 3);\r\n        std::vector<bbox> boxes;\r\n        float* firsValue = (float*)ort_outputs[0].GetTensorData<float>();\r\n        printf(\"%f \", *firsValue);\r\n        printf(\"%f\\n\", *firsValue + 1);\r\n    }\r\n}\r\n```\r\n\r\n**Expected behavior**\r\nThese versions of inference produce the same results.\r\n\r\nPlease help!\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7228/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7229",
        "id": 849592480,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4MzQwNjY3",
        "number": 7229,
        "title": "Update the build script for Android AAR package",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-03T06:37:50Z",
        "updated_at": "2021-04-05T23:37:23Z",
        "closed_at": "2021-04-05T23:37:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7229",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7229",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7229.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7229.patch",
            "merged_at": "2021-04-05T23:37:22Z"
        },
        "body": "**Description**: Update the build script for Android AAR package\r\n\r\n**Motivation and Context**\r\n- Update the script such that it can run under Linux or Window\r\n- Some other minor updates\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7229/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7230",
        "id": 849734389,
        "node_id": "MDU6SXNzdWU4NDk3MzQzODk=",
        "number": 7230,
        "title": "TensorrtExecutionProvider slower than CUDAExecutionProvider: Transformers",
        "user": {
            "login": "oborchers",
            "id": 26734737,
            "node_id": "MDQ6VXNlcjI2NzM0NzM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/26734737?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/oborchers",
            "html_url": "https://github.com/oborchers",
            "followers_url": "https://api.github.com/users/oborchers/followers",
            "following_url": "https://api.github.com/users/oborchers/following{/other_user}",
            "gists_url": "https://api.github.com/users/oborchers/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/oborchers/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/oborchers/subscriptions",
            "organizations_url": "https://api.github.com/users/oborchers/orgs",
            "repos_url": "https://api.github.com/users/oborchers/repos",
            "events_url": "https://api.github.com/users/oborchers/events{/privacy}",
            "received_events_url": "https://api.github.com/users/oborchers/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-04-03T20:31:45Z",
        "updated_at": "2022-08-12T08:46:29Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "EDIT: Provided proper notebook to replicate issue and dockerfile\r\n\r\n**Describe the bug**\r\nThe CUDAExecutionProvider provides a 2x speedup over the TensorrtExecutionProvider, which is completely counterintuitive.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): Source\r\n- ONNX Runtime version: 1.7.1\r\n- Python version: 3. 8\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1.1 / 8.0.5\r\n- GPU model and memory: Nvidia V100\r\n\r\n**To Reproduce**\r\n\r\n1) Build the following Dockerfile (may take some time)\r\n\r\nhttps://github.com/oborchers/Medium_Repo/blob/master/onnxruntime-issues/Dockerfile\r\n\r\n2) Run the following notebook:\r\n\r\nhttps://github.com/oborchers/Medium_Repo/blob/master/onnxruntime-issues/TensorRT%20Slow.ipynb\r\n\r\n**Expected behavior**\r\nAt least to my intuition, TensorRT should be faster.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7230/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7231",
        "id": 849849949,
        "node_id": "MDU6SXNzdWU4NDk4NDk5NDk=",
        "number": 7231,
        "title": "Rust support",
        "user": {
            "login": "mirecl",
            "id": 28476324,
            "node_id": "MDQ6VXNlcjI4NDc2MzI0",
            "avatar_url": "https://avatars.githubusercontent.com/u/28476324?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mirecl",
            "html_url": "https://github.com/mirecl",
            "followers_url": "https://api.github.com/users/mirecl/followers",
            "following_url": "https://api.github.com/users/mirecl/following{/other_user}",
            "gists_url": "https://api.github.com/users/mirecl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mirecl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mirecl/subscriptions",
            "organizations_url": "https://api.github.com/users/mirecl/orgs",
            "repos_url": "https://api.github.com/users/mirecl/repos",
            "events_url": "https://api.github.com/users/mirecl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mirecl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1267486731,
                "node_id": "MDU6TGFiZWwxMjY3NDg2NzMx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/contributions%20welcome",
                "name": "contributions welcome",
                "color": "545AB5",
                "default": false,
                "description": "lower priority issues for the core ORT teams"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2021-04-04T10:58:26Z",
        "updated_at": "2023-07-21T02:34:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Are you planning rust lang support for inference?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231/reactions",
            "total_count": 4,
            "+1": 4,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7231/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7232",
        "id": 849998389,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4NjM5ODY2",
        "number": 7232,
        "title": "Add error message for assertion error in ort_test_dir_utils",
        "user": {
            "login": "jcwchen",
            "id": 14194980,
            "node_id": "MDQ6VXNlcjE0MTk0OTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14194980?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcwchen",
            "html_url": "https://github.com/jcwchen",
            "followers_url": "https://api.github.com/users/jcwchen/followers",
            "following_url": "https://api.github.com/users/jcwchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcwchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcwchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcwchen/subscriptions",
            "organizations_url": "https://api.github.com/users/jcwchen/orgs",
            "repos_url": "https://api.github.com/users/jcwchen/repos",
            "events_url": "https://api.github.com/users/jcwchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcwchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T00:42:33Z",
        "updated_at": "2022-06-09T18:51:44Z",
        "closed_at": "2021-04-05T17:05:41Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7232",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7232",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7232.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7232.patch",
            "merged_at": "2021-04-05T17:05:41Z"
        },
        "body": "**Description**\r\nAdd detailed reason why this assertion error happens.\r\n\r\n**Motivation and Context**\r\nWhile running ORT backend test for ONNX Model Zoo https://github.com/onnx/models/pull/384, ort_test_dir_utils.py fails without error message.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7232/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7233",
        "id": 850029945,
        "node_id": "MDU6SXNzdWU4NTAwMjk5NDU=",
        "number": 7233,
        "title": "The speed of running the onnx model is 6x slower than the pytorch model on Jetson TX2",
        "user": {
            "login": "GavinJiacheng",
            "id": 29049548,
            "node_id": "MDQ6VXNlcjI5MDQ5NTQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/29049548?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GavinJiacheng",
            "html_url": "https://github.com/GavinJiacheng",
            "followers_url": "https://api.github.com/users/GavinJiacheng/followers",
            "following_url": "https://api.github.com/users/GavinJiacheng/following{/other_user}",
            "gists_url": "https://api.github.com/users/GavinJiacheng/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GavinJiacheng/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GavinJiacheng/subscriptions",
            "organizations_url": "https://api.github.com/users/GavinJiacheng/orgs",
            "repos_url": "https://api.github.com/users/GavinJiacheng/repos",
            "events_url": "https://api.github.com/users/GavinJiacheng/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GavinJiacheng/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2233218084,
                "node_id": "MDU6TGFiZWwyMjMzMjE4MDg0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:jetson",
                "name": "platform:jetson",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to the NVIDIA Jetson platform"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-05T02:47:20Z",
        "updated_at": "2022-08-12T08:39:38Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThe speed of running the onnx model is 6x slower than running it on PyTorch\r\n\r\n**Urgency**\r\nApril 20 /2020\r\n\r\n**System information**\r\n- OS Platform and Distribution: ubuntu18.04\r\n- ONNX Runtime installed from: source \r\n- ONNX Runtime version: 1.7\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: jetson TX2\r\n\r\n**To Reproduce**\r\nI ran the code to run the ONNX model:\r\n\r\n```python\r\n\r\nimport io\r\nimport numpy as np\r\n\r\nfrom torch import nn\r\nimport torch.utils.model_zoo as model_zoo\r\nimport torch.onnx\r\n\r\n# Super Resolution model definition in PyTorch\r\nimport torch.nn as nn\r\nimport torch.nn.init as init\r\n\r\nimport onnx\r\nimport onnxruntime\r\n\r\nimport time\r\n\r\n\r\nbatch_size = 1\r\n\r\n# Input to the model\r\nx1 = torch.randn(batch_size, 3, 384, 192, requires_grad=True, device='cuda')\r\nx2 = torch.randn(batch_size, 3, 384, 192, requires_grad=True, device='cuda')\r\n\r\nort_session = onnxruntime.InferenceSession(\"gwt_jetso.onnx\")\r\n\r\ndef to_numpy(tensor):\r\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\r\n\r\n\r\nortvalue1 = onnxruntime.OrtValue.ortvalue_from_numpy(to_numpy(x1), 'cuda', 0)\r\nortvalue2 = onnxruntime.OrtValue.ortvalue_from_numpy(to_numpy(x2), 'cuda', 0)\r\n\r\nort_inputs = {ort_session.get_inputs()[0].name: ortvalue1, ort_session.get_inputs()[1].name: ortvalue2}\r\nort_outs = ort_session.run([], ort_inputs)\r\n```\r\n\r\nThe model I used is the GwcNet, the model is:\r\n\r\n```python\r\n\r\nfrom __future__ import print_function\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.utils.data\r\nfrom torch.autograd import Variable\r\nimport torch.nn.functional as F\r\nfrom models.submodule import *\r\nimport math\r\n\r\n\r\nclass feature_extraction(nn.Module):\r\n    def __init__(self, concat_feature=False, concat_feature_channel=12):\r\n        super(feature_extraction, self).__init__()\r\n        self.concat_feature = concat_feature\r\n\r\n        self.inplanes = 32\r\n        self.firstconv = nn.Sequential(convbn(3, 32, 3, 2, 1, 1),\r\n                                       nn.ReLU(inplace=True),\r\n                                       convbn(32, 32, 3, 1, 1, 1),\r\n                                       nn.ReLU(inplace=True),\r\n                                       convbn(32, 32, 3, 1, 1, 1),\r\n                                       nn.ReLU(inplace=True))\r\n\r\n        self.layer1 = self._make_layer(BasicBlock, 32, 3, 1, 1, 1)\r\n        self.layer2 = self._make_layer(BasicBlock, 64, 16, 2, 1, 1)\r\n        self.layer3 = self._make_layer(BasicBlock, 128, 3, 1, 1, 1)\r\n        self.layer4 = self._make_layer(BasicBlock, 128, 3, 1, 1, 2)\r\n\r\n        if self.concat_feature:\r\n            self.lastconv = nn.Sequential(convbn(320, 128, 3, 1, 1, 1),\r\n                                          nn.ReLU(inplace=True),\r\n                                          nn.Conv2d(128, concat_feature_channel, kernel_size=1, padding=0, stride=1,\r\n                                                    bias=False))\r\n\r\n    def _make_layer(self, block, planes, blocks, stride, pad, dilation):\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            downsample = nn.Sequential(\r\n                nn.Conv2d(self.inplanes, planes * block.expansion,\r\n                          kernel_size=1, stride=stride, bias=False),\r\n                nn.BatchNorm2d(planes * block.expansion), )\r\n\r\n        layers = []\r\n        layers.append(block(self.inplanes, planes, stride, downsample, pad, dilation))\r\n        self.inplanes = planes * block.expansion\r\n        for i in range(1, blocks):\r\n            layers.append(block(self.inplanes, planes, 1, None, pad, dilation))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.firstconv(x)\r\n        x = self.layer1(x)\r\n        l2 = self.layer2(x)\r\n        l3 = self.layer3(l2)\r\n        l4 = self.layer4(l3)\r\n\r\n        gwc_feature = torch.cat((l2, l3, l4), dim=1)\r\n\r\n        if not self.concat_feature:\r\n            return {\"gwc_feature\": gwc_feature}\r\n        else:\r\n            concat_feature = self.lastconv(gwc_feature)\r\n            return {\"gwc_feature\": gwc_feature, \"concat_feature\": concat_feature}\r\n\r\n\r\nclass hourglass(nn.Module):\r\n    def __init__(self, in_channels):\r\n        super(hourglass, self).__init__()\r\n\r\n        self.conv1 = nn.Sequential(convbn_3d(in_channels, in_channels * 2, 3, 2, 1),\r\n                                   nn.ReLU(inplace=True))\r\n\r\n        self.conv2 = nn.Sequential(convbn_3d(in_channels * 2, in_channels * 2, 3, 1, 1),\r\n                                   nn.ReLU(inplace=True))\r\n\r\n        self.conv3 = nn.Sequential(convbn_3d(in_channels * 2, in_channels * 4, 3, 2, 1),\r\n                                   nn.ReLU(inplace=True))\r\n\r\n        self.conv4 = nn.Sequential(convbn_3d(in_channels * 4, in_channels * 4, 3, 1, 1),\r\n                                   nn.ReLU(inplace=True))\r\n\r\n        self.conv5 = nn.Sequential(\r\n            nn.ConvTranspose3d(in_channels * 4, in_channels * 2, 3, padding=1, output_padding=1, stride=2, bias=False),\r\n            nn.BatchNorm3d(in_channels * 2))\r\n\r\n        self.conv6 = nn.Sequential(\r\n            nn.ConvTranspose3d(in_channels * 2, in_channels, 3, padding=1, output_padding=1, stride=2, bias=False),\r\n            nn.BatchNorm3d(in_channels))\r\n\r\n        self.redir1 = convbn_3d(in_channels, in_channels, kernel_size=1, stride=1, pad=0)\r\n        self.redir2 = convbn_3d(in_channels * 2, in_channels * 2, kernel_size=1, stride=1, pad=0)\r\n\r\n    def forward(self, x):\r\n        conv1 = self.conv1(x)\r\n        conv2 = self.conv2(conv1)\r\n\r\n        conv3 = self.conv3(conv2)\r\n        conv4 = self.conv4(conv3)\r\n\r\n        conv5 = F.relu(self.conv5(conv4) + self.redir2(conv2), inplace=True)\r\n        conv6 = F.relu(self.conv6(conv5) + self.redir1(x), inplace=True)\r\n\r\n        return conv6\r\n\r\n\r\nclass GwcNet(nn.Module):\r\n    def __init__(self, maxdisp, use_concat_volume=False):\r\n        super(GwcNet, self).__init__()\r\n        self.maxdisp = maxdisp\r\n        self.use_concat_volume = use_concat_volume\r\n\r\n        self.num_groups = 40\r\n\r\n        if self.use_concat_volume:\r\n            self.concat_channels = 12\r\n            self.feature_extraction = feature_extraction(concat_feature=True,\r\n                                                         concat_feature_channel=self.concat_channels)\r\n        else:\r\n            self.concat_channels = 0\r\n            self.feature_extraction = feature_extraction(concat_feature=False)\r\n\r\n        self.dres0 = nn.Sequential(convbn_3d(self.num_groups + self.concat_channels * 2, 32, 3, 1, 1),\r\n                                   nn.ReLU(inplace=True),\r\n                                   convbn_3d(32, 32, 3, 1, 1),\r\n                                   nn.ReLU(inplace=True))\r\n\r\n        self.dres1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\r\n                                   nn.ReLU(inplace=True),\r\n                                   convbn_3d(32, 32, 3, 1, 1))\r\n\r\n        self.dres2 = hourglass(32)\r\n\r\n        self.dres3 = hourglass(32)\r\n\r\n        self.dres4 = hourglass(32)\r\n\r\n        self.classif0 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\r\n                                      nn.ReLU(inplace=True),\r\n                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False))\r\n\r\n        self.classif1 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\r\n                                      nn.ReLU(inplace=True),\r\n                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False))\r\n\r\n        self.classif2 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\r\n                                      nn.ReLU(inplace=True),\r\n                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False))\r\n\r\n        self.classif3 = nn.Sequential(convbn_3d(32, 32, 3, 1, 1),\r\n                                      nn.ReLU(inplace=True),\r\n                                      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False))\r\n\r\n        for m in self.modules():\r\n            if isinstance(m, nn.Conv2d):\r\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n                m.weight.data.normal_(0, math.sqrt(2. / n))\r\n            elif isinstance(m, nn.Conv3d):\r\n                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\r\n                m.weight.data.normal_(0, math.sqrt(2. / n))\r\n            elif isinstance(m, nn.BatchNorm2d):\r\n                m.weight.data.fill_(1)\r\n                m.bias.data.zero_()\r\n            elif isinstance(m, nn.BatchNorm3d):\r\n                m.weight.data.fill_(1)\r\n                m.bias.data.zero_()\r\n            elif isinstance(m, nn.Linear):\r\n                m.bias.data.zero_()\r\n\r\n    def forward(self, left, right):\r\n        features_left = self.feature_extraction(left)\r\n        features_right = self.feature_extraction(right)\r\n\r\n        gwc_volume = build_gwc_volume(features_left[\"gwc_feature\"], features_right[\"gwc_feature\"], self.maxdisp // 4,\r\n                                      self.num_groups)\r\n        if self.use_concat_volume:\r\n            concat_volume = build_concat_volume(features_left[\"concat_feature\"], features_right[\"concat_feature\"],\r\n                                                self.maxdisp // 4)\r\n            volume = torch.cat((gwc_volume, concat_volume), 1)\r\n        else:\r\n            volume = gwc_volume\r\n\r\n        cost0 = self.dres0(volume)\r\n        cost0 = self.dres1(cost0) + cost0\r\n\r\n        out1 = self.dres2(cost0)\r\n        out2 = self.dres3(out1)\r\n        out3 = self.dres4(out2)\r\n\r\n        if self.training:\r\n            cost0 = self.classif0(cost0)\r\n            cost1 = self.classif1(out1)\r\n            cost2 = self.classif2(out2)\r\n            cost3 = self.classif3(out3)\r\n\r\n            cost0 = F.upsample(cost0, [self.maxdisp, left.size()[2], left.size()[3]], mode='trilinear')\r\n            cost0 = torch.squeeze(cost0, 1)\r\n            pred0 = F.softmax(cost0, dim=1)\r\n            pred0 = disparity_regression(pred0, self.maxdisp)\r\n\r\n            cost1 = F.upsample(cost1, [self.maxdisp, left.size()[2], left.size()[3]], mode='trilinear')\r\n            cost1 = torch.squeeze(cost1, 1)\r\n            pred1 = F.softmax(cost1, dim=1)\r\n            pred1 = disparity_regression(pred1, self.maxdisp)\r\n\r\n            cost2 = F.upsample(cost2, [self.maxdisp, left.size()[2], left.size()[3]], mode='trilinear')\r\n            cost2 = torch.squeeze(cost2, 1)\r\n            pred2 = F.softmax(cost2, dim=1)\r\n            pred2 = disparity_regression(pred2, self.maxdisp)\r\n\r\n            cost3 = F.upsample(cost3, [self.maxdisp, left.size()[2], left.size()[3]], mode='trilinear')\r\n            cost3 = torch.squeeze(cost3, 1)\r\n            pred3 = F.softmax(cost3, dim=1)\r\n            pred3 = disparity_regression(pred3, self.maxdisp)\r\n            return [pred0, pred1, pred2, pred3]\r\n\r\n        else:\r\n            cost3 = self.classif3(out3)\r\n            cost3 = F.upsample(cost3, [self.maxdisp, left.size()[2], left.size()[3]], mode='trilinear')\r\n            cost3 = torch.squeeze(cost3, 1)\r\n            pred3 = F.softmax(cost3, dim=1)\r\n            pred3 = disparity_regression(pred3, self.maxdisp)\r\n            return [pred3]\r\n\r\n\r\n# Handle pre-trained weight and model.parallel\r\n# https://discuss.pytorch.org/t/loading-weights-from-dataparallel-models/20570/2\r\nclass WrappedModel(nn.Module):\r\n    def __init__(self, module):\r\n        super(WrappedModel, self).__init__()\r\n        self.module = module # that I actually define.\r\n    def forward(self, x, y):\r\n        return self.module(x, y)\r\n \r\n \r\ndef GwcNet_G(d):\r\n    model = GwcNet(d, use_concat_volume=False)\r\n    model = WrappedModel(model)\r\n    return model\r\n   # return GwcNet(d, use_concat_volume=False)\r\n \r\n \r\ndef GwcNet_GC(d):\r\n    model = GwcNet(d, use_concat_volume=True)\r\n    model = WrappedModel(model)\r\n    return model\r\n    #return GwcNet(d, use_concat_volume=True)\r\n\r\n```\r\nThe code we used to convert the PyTorch model to ONNX is:\r\n\r\n```python\r\n\r\ndef convert_model(model):\r\n \r\n    print('Converting')\r\n  \r\n    left = torch.randn(1, 3, 384, 192, requires_grad=True)\r\n    right = torch.randn(1, 3, 384, 192, requires_grad=True)\r\n    torch_out = model(left, right)\r\n \r\n   # Export the model\r\n    torch.onnx.export(model,                     # model being run\r\n                     (left, right),             # model input (or a tuple for multiple inputs)\r\n                     \"GwcNet_1.onnx\",             # where to save the model (can be a file or file-like object)\r\n                     export_params=True,        # store the trained parameter weights inside the model file\r\n                     opset_version=11,          # the ONNX version to export the model to\r\n                     do_constant_folding=True,  # whether to execute constant folding for optimization\r\n                     input_names = ['left', 'right'],   # the model's input names\r\n                     output_names = ['output'], # the model's output names\r\n                     dynamic_axes={'left' : [0, 2, 3],\r\n                                   'right' : [0, 2, 3],\r\n                                   'output' : [0, 2, 3],\r\n                                  }\r\n                                   )\r\n \r\n    print('Conversion successful')\r\n\r\n```\r\n\r\nThe code we used to run the model on PyTorch is:\r\n```python\r\n\r\n@make_nograd_func\r\ndef testsample():\r\n    left = torch.randn(1, 3, 384, 192, requires_grad=True, dtype=torch.float32).cuda()\r\n    right = torch.randn(1, 3, 384, 192, requires_grad=True, dtype=torch.float32).cuda()\r\n    torch_out = model(left, right)\r\n \r\n```\r\nThe [download link](https://drive.google.com/file/d/1b2iVsU_Btt4F3NDgWxtx8uu4BXkfuZrr/view?usp=sharing) of our ONNX file \r\n\r\n**Expected behavior**\r\n\r\nThe speed of running this model on PyTorch is around **2.5s** for one frame.\r\nHowever, it is around **14s** when we run it on the ONNX model. It is around 6 times slower.\r\n\r\nWe checked the log, didn't find the warning \"fall back to CPU\". \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7233/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7234",
        "id": 850031483,
        "node_id": "MDU6SXNzdWU4NTAwMzE0ODM=",
        "number": 7234,
        "title": "[Python API + ARM64] Running ResNet50 on ARM board using ACL Error and Performance Issue",
        "user": {
            "login": "JAEWOOKe",
            "id": 36403422,
            "node_id": "MDQ6VXNlcjM2NDAzNDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36403422?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JAEWOOKe",
            "html_url": "https://github.com/JAEWOOKe",
            "followers_url": "https://api.github.com/users/JAEWOOKe/followers",
            "following_url": "https://api.github.com/users/JAEWOOKe/following{/other_user}",
            "gists_url": "https://api.github.com/users/JAEWOOKe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JAEWOOKe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JAEWOOKe/subscriptions",
            "organizations_url": "https://api.github.com/users/JAEWOOKe/orgs",
            "repos_url": "https://api.github.com/users/JAEWOOKe/repos",
            "events_url": "https://api.github.com/users/JAEWOOKe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JAEWOOKe/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2192943459,
                "node_id": "MDU6TGFiZWwyMTkyOTQzNDU5",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:ACL",
                "name": "ep:ACL",
                "color": "0052CC",
                "default": false,
                "description": "issues related to ACL execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T02:52:58Z",
        "updated_at": "2021-04-05T07:11:03Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n1. Not able to run ARM Compute Library properly with ResNet50. (GEMM)\r\n2. Also, doesn't seem to accelerate operator kernels comparing to CPU.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\nI want to use ACL as soon as possible regarding my graduation project.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 aarch64\r\n- ONNX Runtime installed from (source or binary): Python wheel (cross-compiled)\r\n- ONNX Runtime version: 1.6.0\r\n- Python version: 3.5\r\n- Visual Studio version (if applicable): X\r\n- GCC/Compiler version (if compiling from source): aarch64-linux-gnu-gcc version 6.5.0\r\n- CUDA/cuDNN version: X\r\n- GPU model and memory: X\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite the investigation.\r\nRunning ResNet50 using ACLExecutionProvider. (model.onnx)\r\nhttps://drive.google.com/drive/folders/1r7Ii-h0yCuZjGDu-C_-XyJZ-wg3ksfUW?usp=sharing\r\nCMAKE cmd:\r\ncmake -Donnxruntime_GCC_STATIC_CPP_RUNTIME=ON -DCMAKE_BUILD_TYPE=Release -Dprotobuf_WITH_ZLIB=OFF -DCMAKE_TOOLCHAIN_FILE=../many-tool-chain.cmake -Donnxruntime_ENABLE_PYTHON=ON -DPYTHON_LIBRARY=dl -Donnxruntime_USE_ACL=ON -Donnxruntime_ACL_HOME=/home/jwlee/ComputeLibrary -Donnxruntime_ACL_LIBS=/home/jwlee/ComputeLibrary/build -DPYTHON_EXECUTABLE=/home/jwlee/anaconda3/envs/tmp/bin/python3 -DONNX_CUSTOM_PROTOC_EXECUTABLE=/home/jwlee/protoc-3/bin/protoc \"-DPYTHON_INCLUDE_DIR=/mnt/sdf2/usr/include;/mnt/sdf2/usr/include/python3.5m/\" -DNUMPY_INCLUDE_DIR=/mnt/sdf2/usr/local/lib/python3.5/dist-packages/numpy/core/include/numpy ../cmake\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nRunning on CPU shows the correct result, while ACL doesn't recognize parameters at the GEMM node (pred_w_0).\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n![image](https://user-images.githubusercontent.com/36403422/113530351-c6898600-9600-11eb-96f3-1d31525f5014.png)\r\n![image](https://user-images.githubusercontent.com/36403422/113530380-d903bf80-9600-11eb-81a2-5ef92c637bc3.png)\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\nUsing ACL doesn't seem to accelerate the operators.\r\nCPU: \r\nhttps://drive.google.com/file/d/1cFKMR9KiK4zMSWWPkKZLoNJmVjzaxQs8/view?usp=sharing\r\nACL:\r\nhttps://drive.google.com/file/d/13ZVTjSKVb2m9HO1Sd_0ZTUaSZIywUgSv/view?usp=sharing",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7234/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7235",
        "id": 850220225,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA4ODI3Mzg1",
        "number": 7235,
        "title": "yolov3 accuracy",
        "user": {
            "login": "sfatimar",
            "id": 64512376,
            "node_id": "MDQ6VXNlcjY0NTEyMzc2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64512376?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sfatimar",
            "html_url": "https://github.com/sfatimar",
            "followers_url": "https://api.github.com/users/sfatimar/followers",
            "following_url": "https://api.github.com/users/sfatimar/following{/other_user}",
            "gists_url": "https://api.github.com/users/sfatimar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sfatimar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sfatimar/subscriptions",
            "organizations_url": "https://api.github.com/users/sfatimar/orgs",
            "repos_url": "https://api.github.com/users/sfatimar/repos",
            "events_url": "https://api.github.com/users/sfatimar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sfatimar/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 16,
        "created_at": "2021-04-05T09:08:48Z",
        "updated_at": "2021-04-11T03:53:17Z",
        "closed_at": "2021-04-11T03:53:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7235",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7235",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7235.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7235.patch",
            "merged_at": "2021-04-11T03:53:17Z"
        },
        "body": "This one line change is to ensure myriad configuration is set to achieve maximum yolov3 accuracy. \r\n\r\n**Motivation and Context**\r\n-  We have found that the reason is that in this case preprocessing is not a part of the model and is performed separately (while the converted IRs usually have the preprocessing inside the model) which in turn affects MYX heuristic algorithms. To avoid the degradation we added an additional option, which should be used in this case.\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7235/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7236",
        "id": 850465922,
        "node_id": "MDU6SXNzdWU4NTA0NjU5MjI=",
        "number": 7236,
        "title": "Dockerfile.cuda and Dockerfile.source fail with dependency on Python 3.7",
        "user": {
            "login": "mvermeulen",
            "id": 5479696,
            "node_id": "MDQ6VXNlcjU0Nzk2OTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5479696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mvermeulen",
            "html_url": "https://github.com/mvermeulen",
            "followers_url": "https://api.github.com/users/mvermeulen/followers",
            "following_url": "https://api.github.com/users/mvermeulen/following{/other_user}",
            "gists_url": "https://api.github.com/users/mvermeulen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mvermeulen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mvermeulen/subscriptions",
            "organizations_url": "https://api.github.com/users/mvermeulen/orgs",
            "repos_url": "https://api.github.com/users/mvermeulen/repos",
            "events_url": "https://api.github.com/users/mvermeulen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mvermeulen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "snnn",
                "id": 856316,
                "node_id": "MDQ6VXNlcjg1NjMxNg==",
                "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/snnn",
                "html_url": "https://github.com/snnn",
                "followers_url": "https://api.github.com/users/snnn/followers",
                "following_url": "https://api.github.com/users/snnn/following{/other_user}",
                "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
                "organizations_url": "https://api.github.com/users/snnn/orgs",
                "repos_url": "https://api.github.com/users/snnn/repos",
                "events_url": "https://api.github.com/users/snnn/events{/privacy}",
                "received_events_url": "https://api.github.com/users/snnn/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-04-05T15:56:53Z",
        "updated_at": "2021-04-05T21:18:26Z",
        "closed_at": "2021-04-05T21:18:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nBuilding from the Dockerfile.cuda and Dockerfile.source files, get the following error failure:\r\n```\r\nProcessing /root/onnxruntime_gpu-1.7.0-cp36-cp36m-linux_x86_64.whl\r\nCollecting flatbuffers (from onnxruntime-gpu==1.7.0)\r\n  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\r\nCollecting protobuf (from onnxruntime-gpu==1.7.0)\r\n  Downloading https://files.pythonhosted.org/packages/d7/e8/bc878782a29afc80ef03345ff7a7c4071fbeedf58d5a9804469094df636b/protobuf-3.15.7-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\r\nCollecting numpy>=1.16.6 (from onnxruntime-gpu==1.7.0)\r\n  Downloading https://files.pythonhosted.org/packages/82/a8/1e0f86ae3f13f7ce260e9f782764c16559917f24382c74edfb52149897de/numpy-1.20.2.zip (7.8MB)\r\n    Complete output from command python setup.py egg_info:\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-build-sp8wt5me/numpy/setup.py\", line 30, in <module>\r\n        raise RuntimeError(\"Python version >= 3.7 required.\")\r\n    RuntimeError: Python version >= 3.7 required.\r\n    \r\n    ----------------------------------------\r\nCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-sp8wt5me/numpy/\r\n```\r\nThis did not fail one week previous.\r\n\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\nDockerfile recipes.\r\n\r\n**To Reproduce**\r\nBuild from Dockerfiles.\r\n\r\nNote, I was able to work around these issues by adding two lines immediately after the From ubuntu:18.04 line:\r\n```\r\nFROM ubuntu:18.04\r\nRUN  apt update && apt install -y python3-pip\r\nRUN pip3 install numpy==1.19.5\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7236/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7237",
        "id": 850515547,
        "node_id": "MDU6SXNzdWU4NTA1MTU1NDc=",
        "number": 7237,
        "title": "Cannot use Microsoft.ML.OnnxRuntime and WinUI 3 desktop: The target process exited without raising a CoreCLR started event",
        "user": {
            "login": "jdluzen",
            "id": 160958,
            "node_id": "MDQ6VXNlcjE2MDk1OA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/160958?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdluzen",
            "html_url": "https://github.com/jdluzen",
            "followers_url": "https://api.github.com/users/jdluzen/followers",
            "following_url": "https://api.github.com/users/jdluzen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdluzen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdluzen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdluzen/subscriptions",
            "organizations_url": "https://api.github.com/users/jdluzen/orgs",
            "repos_url": "https://api.github.com/users/jdluzen/repos",
            "events_url": "https://api.github.com/users/jdluzen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdluzen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jywu-msft",
                "id": 43355415,
                "node_id": "MDQ6VXNlcjQzMzU1NDE1",
                "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jywu-msft",
                "html_url": "https://github.com/jywu-msft",
                "followers_url": "https://api.github.com/users/jywu-msft/followers",
                "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
                "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
                "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
                "repos_url": "https://api.github.com/users/jywu-msft/repos",
                "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-05T17:11:36Z",
        "updated_at": "2021-05-03T21:57:56Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI am attempting to build a machine learning application with the recently released WinUI 3 desktop. Adding the package `Microsoft.ML.OnnxRuntime` to an out of the box WinUI 3 app results in it being unable to run or debug with the following: `The target process exited without raising a CoreCLR started event. Ensure that the target process is configured to use .NET Core. This may be expected if the target process did not run on .NET Core.`\r\n\r\n**Urgency**\r\nWhile I do not technically have a deadline, it is a complete blocker, and I cannot continue. After searching and debugging for many hours over at least two days, I have found no workarounds so far.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10 2004`\r\n- ONNX Runtime installed from (source or binary): `binary Nuget`\r\n- ONNX Runtime version: `1.7.0`\r\n- Python version: N/A\r\n- Visual Studio version (if applicable): `2019 16.9.3` and `2019 16.10.0 Preview 1.0`\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: `5700 XT 8GB`\r\n\r\n**To Reproduce**\r\n- Create a new Blank App, Packaged (WinUI 3 in Desktop)\r\n- Add package reference to `Microsoft.ML.OnnxRuntime`\r\n- Run (I use x64, but same behavior on x86)\r\n\r\n**Expected behavior**\r\nThe default WinUI 3 window to appear\r\n\r\n**Screenshots**\r\nN/A\r\n\r\n**Additional context**\r\nSome searches have suggested that upgrading the dependencies would resolve it, but the same behavior occurs.\r\nRelevant csproj:\r\n```\r\n    <TargetFramework>net5.0-windows10.0.19041.0</TargetFramework>\r\n    <TargetPlatformMinVersion>10.0.17763.0</TargetPlatformMinVersion>\r\n```\r\nIt works, at least it runs and debugger attaches, with a .net5 console app.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7237/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7238",
        "id": 850551993,
        "node_id": "MDU6SXNzdWU4NTA1NTE5OTM=",
        "number": 7238,
        "title": "GPT-Neo: Torch CUDA 2x faster than ONNX CUDA",
        "user": {
            "login": "oborchers",
            "id": 26734737,
            "node_id": "MDQ6VXNlcjI2NzM0NzM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/26734737?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/oborchers",
            "html_url": "https://github.com/oborchers",
            "followers_url": "https://api.github.com/users/oborchers/followers",
            "following_url": "https://api.github.com/users/oborchers/following{/other_user}",
            "gists_url": "https://api.github.com/users/oborchers/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/oborchers/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/oborchers/subscriptions",
            "organizations_url": "https://api.github.com/users/oborchers/orgs",
            "repos_url": "https://api.github.com/users/oborchers/repos",
            "events_url": "https://api.github.com/users/oborchers/events{/privacy}",
            "received_events_url": "https://api.github.com/users/oborchers/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1122493981,
                "node_id": "MDU6TGFiZWwxMTIyNDkzOTgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/feature%20request",
                "name": "feature request",
                "color": "5319E7",
                "default": false,
                "description": "request for unsupported feature or enhancement"
            },
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            },
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 16,
        "created_at": "2021-04-05T18:08:27Z",
        "updated_at": "2022-08-12T08:39:37Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have been heavily investigating GPT-Neo for our company. Most of our models run directly on GPU with ONNX as backend. The problem is as follows:\r\n\r\nRunning the `gpt-neo-1.3B` model in a custom build `onnxruntime` instance on a V100 is 2x slower than base pytorch (onnx: 300ms vs torch: 120 ms). This is usually exactly the other way around.\r\n\r\nI would assume that this is either a problem of `gpt-neo-1.3B` or of `onnxruntime`, most probably the first one. But I am now sure how to best determine the responsible part in this chain and how we can go ahead without altering the model significantly and manually.\r\n\r\nHelp would be very appreciated.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): Source\r\n- ONNX Runtime version: 1.7.1\r\n- Python version: 3. 8\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1.1 / 8.0.5\r\n- GPU model and memory: Nvidia V100\r\n\r\n**To Reproduce**\r\n\r\n1) Build the following Dockerfile (may take some time)\r\n\r\nhttps://github.com/oborchers/Medium_Repo/blob/master/onnxruntime-issues/Dockerfile\r\n\r\n2) Run the following notebook:\r\n\r\nhttps://github.com/oborchers/Medium_Repo/blob/master/onnxruntime-issues/GPT-Neo%20Slow-2.ipynb\r\n\r\nTorch: 1000 sentences took 53s at 18 sentences/s.\r\nONNX:  1000 sentences took 313s at 3 sentences/s.\r\n**Expected behavior**\r\nI would expect `onnxruntime` inference to be at least as fast as torch, which really surprised me.\r\n\r\nPartial Log:\r\n\r\n```\r\n2021-04-05 16:09:30.169135381 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_4368\r\n2021-04-05 16:09:30.169205679 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_4347\r\n2021-04-05 16:09:30.169232416 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_4326\r\n2021-04-05 16:09:30.169277052 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_4305\r\n2021-04-05 16:09:30.169305005 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_4284\r\n...\r\n2021-04-05 16:09:30.171179525 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: Pad node name: Pad_3045\r\n2021-04-05 16:09:30.171207277 [W:onnxruntime:Default, cuda_execution_provider.cc:1983 GetCapability] CUDA kernel not found in registries for Op type: LessOrEqual node name: LessOrEqual_7094\r\n...\r\n2021-04-05 16:09:30.358181987 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_5\r\n2021-04-05 16:09:30.358218137 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_17\r\n2021-04-05 16:09:30.358230511 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_18\r\n2021-04-05 16:09:30.358241440 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Add_13\r\n2021-04-05 16:09:30.358265649 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_37\r\n2021-04-05 16:09:30.358279929 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_38\r\n2021-04-05 16:09:30.358290325 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_85672\r\n2021-04-05 16:09:30.358301675 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_2\r\n2021-04-05 16:09:30.358311978 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_85670\r\n2021-04-05 16:09:30.358323299 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_85673\r\n2021-04-05 16:09:30.358344992 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_85\r\n2021-04-05 16:09:30.358356437 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_86\r\n2021-04-05 16:09:30.358373163 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Div_88\r\n2021-04-05 16:09:30.358386774 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_93\r\n2021-04-05 16:09:30.358399847 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_80\r\n2021-04-05 16:09:30.358410259 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_92\r\n2021-04-05 16:09:30.358425290 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_77\r\n2021-04-05 16:09:30.358437256 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_91\r\n2021-04-05 16:09:30.358452374 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_94\r\n2021-04-05 16:09:30.358476066 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_63\r\n2021-04-05 16:09:30.358490967 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_64\r\n2021-04-05 16:09:30.358503415 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Div_66\r\n2021-04-05 16:09:30.358515382 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_71\r\n2021-04-05 16:09:30.358528613 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_58\r\n2021-04-05 16:09:30.358538065 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_70\r\n2021-04-05 16:09:30.358551073 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_55\r\n2021-04-05 16:09:30.358562240 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_69\r\n2021-04-05 16:09:30.358578571 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_72\r\n2021-04-05 16:09:30.358601242 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_132\r\n2021-04-05 16:09:30.358612608 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_133\r\n2021-04-05 16:09:30.358623085 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_139\r\n2021-04-05 16:09:30.358639190 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_126\r\n2021-04-05 16:09:30.358648692 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_127\r\n2021-04-05 16:09:30.358659862 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Sub_134\r\n2021-04-05 16:09:30.358669326 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_135\r\n2021-04-05 16:09:30.358690866 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_11\r\n2021-04-05 16:09:30.358703730 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_20\r\n....\r\n2021-04-05 17:37:21.034558149 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_5\r\n2021-04-05 17:37:21.034596725 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_17\r\n2021-04-05 17:37:21.034649407 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_18\r\n2021-04-05 17:37:21.034679883 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Add_13\r\n2021-04-05 17:37:21.034709999 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_37\r\n2021-04-05 17:37:21.034741824 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_38\r\n2021-04-05 17:37:21.034771635 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_85672\r\n2021-04-05 17:37:21.034783311 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Gather_2\r\n2021-04-05 17:37:21.034813241 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_85670\r\n2021-04-05 17:37:21.034845762 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_85673\r\n2021-04-05 17:37:21.034885673 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_85\r\n2021-04-05 17:37:21.034918686 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Squeeze_86\r\n2021-04-05 17:37:21.034930886 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Div_88\r\n2021-04-05 17:37:21.035028500 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Unsqueeze_93\r\n...\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7238/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7239",
        "id": 850573040,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MTI0MjA4",
        "number": 7239,
        "title": "Add better model test error messaging",
        "user": {
            "login": "ryanlai2",
            "id": 16694211,
            "node_id": "MDQ6VXNlcjE2Njk0MjEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/16694211?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ryanlai2",
            "html_url": "https://github.com/ryanlai2",
            "followers_url": "https://api.github.com/users/ryanlai2/followers",
            "following_url": "https://api.github.com/users/ryanlai2/following{/other_user}",
            "gists_url": "https://api.github.com/users/ryanlai2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ryanlai2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ryanlai2/subscriptions",
            "organizations_url": "https://api.github.com/users/ryanlai2/orgs",
            "repos_url": "https://api.github.com/users/ryanlai2/repos",
            "events_url": "https://api.github.com/users/ryanlai2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ryanlai2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T18:41:39Z",
        "updated_at": "2021-04-05T21:59:21Z",
        "closed_at": "2021-04-05T21:59:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7239",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7239",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7239.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7239.patch",
            "merged_at": "2021-04-05T21:59:21Z"
        },
        "body": "This change adds an error message that prints when a model test collateral folder cannot be found from one of these 2 ways:\r\n\r\n- WINML_TEST_DATA_PATH environment variable being set\r\n- Local \"models\" folder that is contained next to the test executable.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7239/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7240",
        "id": 850642869,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MTgzMDI0",
        "number": 7240,
        "title": "Add BERT-L perf regression test on MI100 and re-enable batch size test",
        "user": {
            "login": "suffiank",
            "id": 4366369,
            "node_id": "MDQ6VXNlcjQzNjYzNjk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4366369?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suffiank",
            "html_url": "https://github.com/suffiank",
            "followers_url": "https://api.github.com/users/suffiank/followers",
            "following_url": "https://api.github.com/users/suffiank/following{/other_user}",
            "gists_url": "https://api.github.com/users/suffiank/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suffiank/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suffiank/subscriptions",
            "organizations_url": "https://api.github.com/users/suffiank/orgs",
            "repos_url": "https://api.github.com/users/suffiank/repos",
            "events_url": "https://api.github.com/users/suffiank/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suffiank/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T20:30:47Z",
        "updated_at": "2021-04-05T22:51:53Z",
        "closed_at": "2021-04-05T22:51:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7240",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7240",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7240.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7240.patch",
            "merged_at": "2021-04-05T22:51:53Z"
        },
        "body": "Enable C++ BERT-L perf and batch size tests for MI100.\r\nFor sequence length 128, expect 240 ex/sec and max batch size 200.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7240/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7241",
        "id": 850655188,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MTkxNzcx",
        "number": 7241,
        "title": "remove un-needed header file. (#7193)",
        "user": {
            "login": "smk2007",
            "id": 6754002,
            "node_id": "MDQ6VXNlcjY3NTQwMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6754002?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smk2007",
            "html_url": "https://github.com/smk2007",
            "followers_url": "https://api.github.com/users/smk2007/followers",
            "following_url": "https://api.github.com/users/smk2007/following{/other_user}",
            "gists_url": "https://api.github.com/users/smk2007/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smk2007/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smk2007/subscriptions",
            "organizations_url": "https://api.github.com/users/smk2007/orgs",
            "repos_url": "https://api.github.com/users/smk2007/repos",
            "events_url": "https://api.github.com/users/smk2007/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smk2007/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-05T20:47:45Z",
        "updated_at": "2021-04-13T22:22:30Z",
        "closed_at": "2021-04-13T22:21:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7241",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7241",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7241.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7241.patch",
            "merged_at": null
        },
        "body": "Co-authored-by: Weixing Zhang <wezhan@microsoft.com>\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7241/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7242",
        "id": 850655746,
        "node_id": "MDU6SXNzdWU4NTA2NTU3NDY=",
        "number": 7242,
        "title": "Deploy in Android App",
        "user": {
            "login": "evanescenceakii",
            "id": 81523640,
            "node_id": "MDQ6VXNlcjgxNTIzNjQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/81523640?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/evanescenceakii",
            "html_url": "https://github.com/evanescenceakii",
            "followers_url": "https://api.github.com/users/evanescenceakii/followers",
            "following_url": "https://api.github.com/users/evanescenceakii/following{/other_user}",
            "gists_url": "https://api.github.com/users/evanescenceakii/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/evanescenceakii/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/evanescenceakii/subscriptions",
            "organizations_url": "https://api.github.com/users/evanescenceakii/orgs",
            "repos_url": "https://api.github.com/users/evanescenceakii/repos",
            "events_url": "https://api.github.com/users/evanescenceakii/events{/privacy}",
            "received_events_url": "https://api.github.com/users/evanescenceakii/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2385898474,
                "node_id": "MDU6TGFiZWwyMzg1ODk4NDc0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:mobile",
                "name": "platform:mobile",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime mobile; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-05T20:48:14Z",
        "updated_at": "2021-05-10T22:01:15Z",
        "closed_at": "2021-05-10T22:01:14Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm trying to create an Android App that incorporates a Machine Learning Model. I had an onnx model, along with a Python script file, two json files with the label names, and some numpy data for mel spectrograms computation.\r\n\r\nI tried to go with onnxruntime, and followed [these ](https://github.com/microsoft/onnxruntime/blob/master/docs/ONNX_Runtime_for_Mobile_Platforms.md)instructions. So now I have created the model.ort file out of the onnx model and \"A minimal build for Android with NNAPI support\", so I have the Build onnxruntime pkg. I'm run the build in windows cmd.\r\n\r\nSince I'm completely new at this, how do I continue from here? How do I \"inference on device\" and deploy in my phone?\r\n\r\nAnd also, will I have to convert my python script that runs the model to Java? Or is there any other way? Thank you!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7242/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7243",
        "id": 850699478,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MjI5OTg2",
        "number": 7243,
        "title": "QDQ: type conversion and more ops support",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T21:29:27Z",
        "updated_at": "2021-04-06T22:30:32Z",
        "closed_at": "2021-04-06T22:30:31Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7243",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7243",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7243.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7243.patch",
            "merged_at": "2021-04-06T22:30:31Z"
        },
        "body": "As the title says, this pr:\r\n1. Add int8_t to uint8_t conversion \r\n2. Add Relu fusion support\r\n3. Add AveragePool support\r\n\r\nIn addition, refactor the code of qdq_transform.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7243/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7244",
        "id": 850707382,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MjM3MzE2",
        "number": 7244,
        "title": "Avoid passing zero bias to Gemm in gradients",
        "user": {
            "login": "mrry",
            "id": 192142,
            "node_id": "MDQ6VXNlcjE5MjE0Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/192142?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrry",
            "html_url": "https://github.com/mrry",
            "followers_url": "https://api.github.com/users/mrry/followers",
            "following_url": "https://api.github.com/users/mrry/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrry/subscriptions",
            "organizations_url": "https://api.github.com/users/mrry/orgs",
            "repos_url": "https://api.github.com/users/mrry/repos",
            "events_url": "https://api.github.com/users/mrry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-04-05T21:37:28Z",
        "updated_at": "2021-04-06T23:49:35Z",
        "closed_at": "2021-04-06T23:49:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7244",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7244",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7244.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7244.patch",
            "merged_at": "2021-04-06T23:49:34Z"
        },
        "body": "**Description**: The bias argument to Gemm is optional and defaults to zero. Therefore we do not need to generate zero initializers and pass them to that argument.\r\n\r\n**Motivation and Context**\r\n- Simplifies the graph generated by the gradient builder. Eventually, this may enable us to perform more graph transformations by more easily detecting that a Gemm node has no bias input.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7244/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7245",
        "id": 850752995,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mjc5MzM5",
        "number": 7245,
        "title": "Cleanup build.py",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T22:25:20Z",
        "updated_at": "2021-04-06T01:49:30Z",
        "closed_at": "2021-04-06T01:49:29Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7245",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7245",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7245.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7245.patch",
            "merged_at": "2021-04-06T01:49:29Z"
        },
        "body": "**Description**: \r\n\r\nRemove unused code. \r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n\r\n\"--trusted-host\" is unsafe, we should not use it.\r\n\r\n\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7245/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7246",
        "id": 850759393,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mjg1MTEy",
        "number": 7246,
        "title": "Update ContribOperators.md",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-05T22:32:09Z",
        "updated_at": "2021-04-06T00:11:34Z",
        "closed_at": "2021-04-06T00:11:33Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7246",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7246",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7246.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7246.patch",
            "merged_at": "2021-04-06T00:11:33Z"
        },
        "body": "**Description**: \r\n\r\nUpdate ContribOperators.md\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7246/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7247",
        "id": 850769568,
        "node_id": "MDU6SXNzdWU4NTA3Njk1Njg=",
        "number": 7247,
        "title": "Input device type check has syntax error",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-04-05T22:42:59Z",
        "updated_at": "2021-04-06T21:44:29Z",
        "closed_at": "2021-04-06T21:44:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "For non-CUDA EPs, the ORTTrainer API performs a check that the input tensor's device is cpu.\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/10102c09b67a1f1dd71e035a768fdeb86a1e85f2/orttraining/orttraining/python/training/orttrainer.py#L889\r\n\r\nThis was introduced in #7112 \r\n\r\nThe LHS should be input.device.type; otherwise, the assert always fails because a [torch.device](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device) is an object, not a string.\r\n\r\n**System information**\r\nOS Platform and Distribution: Windows 10 and Ubuntu 20.04 \r\nONNX Runtime installed from (source): source\r\nONNX Runtime version: ba51774a1f73f77948505816d8a57d405d40bd80 (more recent than onnxruntime-1.7.1)\r\nGCC/Compiler version (if compiling from source): cl 19.28.29913 on Windows 10 and Clang 11.1 on Ubuntu 20.04 ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7247/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7248",
        "id": 850771700,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mjk2NTUy",
        "number": 7248,
        "title": "Fix assert that the tensor's device type is 'cpu'",
        "user": {
            "login": "ashari4",
            "id": 70242157,
            "node_id": "MDQ6VXNlcjcwMjQyMTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/70242157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashari4",
            "html_url": "https://github.com/ashari4",
            "followers_url": "https://api.github.com/users/ashari4/followers",
            "following_url": "https://api.github.com/users/ashari4/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashari4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashari4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashari4/subscriptions",
            "organizations_url": "https://api.github.com/users/ashari4/orgs",
            "repos_url": "https://api.github.com/users/ashari4/repos",
            "events_url": "https://api.github.com/users/ashari4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashari4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-04-05T22:45:19Z",
        "updated_at": "2021-04-06T16:08:34Z",
        "closed_at": "2021-04-06T16:08:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7248",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7248",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7248.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7248.patch",
            "merged_at": "2021-04-06T16:08:34Z"
        },
        "body": "**Description**: Fix assert that the tensor's device type is 'cpu'\r\n\r\n**Motivation and Context**\r\nThe ort trainer api was extended to support non-cuda devices in #7112; however, there is a small typo as described in issue #7247\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7248/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7249",
        "id": 850798642,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MzIxNjIx",
        "number": 7249,
        "title": "Adding interface for batched integer gemm",
        "user": {
            "login": "chenfucn",
            "id": 1316708,
            "node_id": "MDQ6VXNlcjEzMTY3MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1316708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chenfucn",
            "html_url": "https://github.com/chenfucn",
            "followers_url": "https://api.github.com/users/chenfucn/followers",
            "following_url": "https://api.github.com/users/chenfucn/following{/other_user}",
            "gists_url": "https://api.github.com/users/chenfucn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chenfucn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chenfucn/subscriptions",
            "organizations_url": "https://api.github.com/users/chenfucn/orgs",
            "repos_url": "https://api.github.com/users/chenfucn/repos",
            "events_url": "https://api.github.com/users/chenfucn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chenfucn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-05T23:15:01Z",
        "updated_at": "2021-04-15T17:25:32Z",
        "closed_at": "2021-04-15T17:25:32Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7249",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7249",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7249.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7249.patch",
            "merged_at": "2021-04-15T17:25:31Z"
        },
        "body": "**Description**: Parallelize MinMax, Quantize and batched quantize GEMM\r\n\r\n**Motivation and Context**\r\nPerformance problem identified in T5 decoder model (quantized).  DynamicMatMul operator is identified as the culprit. This operator spend time on getting MinMax of a Tensor, quantize a tensor, and perform a batched gemm. All of these can be parallelized.\r\n\r\nCurrently GEMM is parallelized. However, in batched GEMM, we sequentially call GEMM multiple times. This causes multiple starting and ending of parallel sections, which can be slow sometimes.  We made the following changes:\r\n\r\n1. Parallel task partition no longer depends on degree of parallelism, only on shape of the matrices.\r\n2. In a single GEMM, perform 2D partition of the multiplication, along panel lines, to reduce repeated packing.\r\n3. For batched GEMM, all parallel tasks are executed in a single parallel section, reducing the cost of starting threads and waiting for them to finish.\r\n\r\n In GetQuantizeParameters function, MinMax was executed sequentially.  In this change, minmax was parallelized: (all time unit ns, benchmark parameters {array_size, threads}\r\n\r\nBaseline | --       | New Implementation | --\r\n--------- | -------: | ------ | --------------:\r\nBM_GetQuantParams/80000/real_time | 6,525 | -- | --\r\n-- | -- | BM_GetQuantParams/80000/2/real_time | 6,696\r\n-- | -- | BM_GetQuantParams/80000/4/real_time | 6,727\r\n-- | -- | BM_GetQuantParams/80000/6/real_time | 6,753\r\n-- | -- | BM_GetQuantParams/80000/8/real_time | 6,716\r\nBM_GetQuantParams/160000/real_time | 13,033 | -- | --\r\n-- | -- | BM_GetQuantParams/160000/2/real_time | 8,281\r\n-- | -- | BM_GetQuantParams/160000/4/real_time | 6,146\r\n-- | -- | BM_GetQuantParams/160000/6/real_time | 6,073\r\n-- | -- | BM_GetQuantParams/160000/8/real_time | 8,457\r\nBM_GetQuantParams/320000/real_time | 34,508 | -- | --\r\n-- | -- | BM_GetQuantParams/320000/2/real_time | 14,693\r\n-- | -- | BM_GetQuantParams/320000/4/real_time | 9,863\r\n-- | -- | BM_GetQuantParams/320000/6/real_time | 9,648\r\n-- | -- | BM_GetQuantParams/320000/8/real_time | 9,439\r\nBM_GetQuantParams/640000/real_time | 97,008 | -- | --\r\n-- | -- | BM_GetQuantParams/640000/2/real_time | 37,335\r\n-- | -- | BM_GetQuantParams/640000/4/real_time | 16,848\r\n-- | -- | BM_GetQuantParams/640000/6/real_time | 14,924\r\n-- | -- | BM_GetQuantParams/640000/8/real_time | 13,268\r\nBM_GetQuantParams/1280000/real_time | 193,904 | -- | --\r\n-- | -- | BM_GetQuantParams/1280000/2/real_time | 99,008\r\n-- | -- | BM_GetQuantParams/1280000/4/real_time | 43,086\r\n-- | -- | BM_GetQuantParams/1280000/6/real_time | 31,400\r\n-- | -- | BM_GetQuantParams/1280000/8/real_time | 23,842\r\n\r\n\r\n\r\nParallelization of Quantization function:  (all time unit ns, benchmark parameters {size, threads})\r\n\r\n\r\nBaseline | ns | New Implementation | ns\r\n-- | --: | -- | --:\r\nBM_Quantize/80000/real_time | 14,982 | BM_Quantize/80000/2/real_time | 9,244\r\n  |   | BM_Quantize/80000/4/real_time | 9,642\r\n  |   | BM_Quantize/80000/6/real_time | 7,043\r\n  |   | BM_Quantize/80000/8/real_time | 7,677\r\nBM_Quantize/160000/real_time | 29,869 | BM_Quantize/160000/2/real_time | 16,680\r\n  |   | BM_Quantize/160000/4/real_time | 10,958\r\n  |   | BM_Quantize/160000/6/real_time | 10,217\r\n  |   | BM_Quantize/160000/8/real_time | 10,917\r\nBM_Quantize/320000/real_time | 63,170 | BM_Quantize/320000/2/real_time | 31,690\r\n  |   | BM_Quantize/320000/4/real_time | 18,806\r\n  |   | BM_Quantize/320000/6/real_time | 15,859\r\n  |   | BM_Quantize/320000/8/real_time | 14,871\r\nBM_Quantize/640000/real_time | 126,762 | BM_Quantize/640000/2/real_time | 64,959\r\n  |   | BM_Quantize/640000/4/real_time | 34,477\r\n  |   | BM_Quantize/640000/6/real_time | 26,650\r\n  |   | BM_Quantize/640000/8/real_time | 22,863\r\nBM_Quantize/1280000/real_time | 256,442 | BM_Quantize/1280000/2/real_time | 132,517\r\n  |   | BM_Quantize/1280000/4/real_time | 70,511\r\n  |   | BM_Quantize/1280000/6/real_time | 50,509\r\n  |   | BM_Quantize/1280000/8/real_time | 38,917\r\n\r\n\r\n\r\nBatched QGemm. Existing implementation: multiple multiplication operations are executed sequentially, while each matric multiplication maybe parallelized. In the new implementation, we tried to parallelize the whole batch. Benchmark shows speedup of batched gemm, especially when B is not pre-packed, and when number of threads is high.\r\n\r\n\r\n  | Baseline | New\r\n-- | --: | --:\r\nQGEMM/PackB/M:512/N:64/K:512/Batch:12/Threads:4 | 266821 | 223233\r\nQGEMM/PackB/M:512/N:512/K:64/Batch:12/Threads:4 | 352279 | 333067\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:1/Threads:4 | 255532 | 250407\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:6/Threads:4 | 1717200 | 1763590\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:1/Threads:4 | 682238 | 630677\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:6/Threads:4 | 4184540 | 4355130\r\nQGEMM/PackB/M:512/N:64/K:512/Batch:12/Threads:8 | 189041 | 169766\r\nQGEMM/PackB/M:512/N:512/K:64/Batch:12/Threads:8 | 239872 | 231030\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:1/Threads:8 | 195874 | 196617\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:6/Threads:8 | 1184220 | 998407\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:1/Threads:8 | 307591 | 310912\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:6/Threads:8 | 2873200 | 2397180\r\nQGEMM/PackB/M:512/N:64/K:512/Batch:12/Threads:16 | 205724 | 113060\r\nQGEMM/PackB/M:512/N:512/K:64/Batch:12/Threads:16 | 228505 | 173621\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:1/Threads:16 | 98155 | 96369.3\r\nQGEMM/PackB/M:128/N:768/K:2304/Batch:6/Threads:16 | 875479 | 730881\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:1/Threads:16 | 223546 | 219434\r\nQGEMM/PackB/M:128/N:1024/K:4096/Batch:6/Threads:16 | 2046790 | 1687330\r\n-- | --: | --:\r\nQGEMM/NoPackB/M:512/N:64/K:512/Batch:12/Threads:4 | 297499 | 246691\r\nQGEMM/NoPackB/M:512/N:512/K:64/Batch:12/Threads:4 | 371799 | 329250\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:1/Threads:4 | 416085 | 430584\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:6/Threads:4 | 3214770 | 2056690\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:1/Threads:4 | 962293 | 959191\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:6/Threads:4 | 7631920 | 4983940\r\nQGEMM/NoPackB/M:512/N:64/K:512/Batch:12/Threads:8 | 240266 | 184689\r\nQGEMM/NoPackB/M:512/N:512/K:64/Batch:12/Threads:8 | 279545 | 237145\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:1/Threads:8 | 188994 | 186943\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:6/Threads:8 | 2341790 | 1155460\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:1/Threads:8 | 435023 | 422203\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:6/Threads:8 | 6108640 | 2771390\r\nQGEMM/NoPackB/M:512/N:64/K:512/Batch:12/Threads:16 | 253414 | 122915\r\nQGEMM/NoPackB/M:512/N:512/K:64/Batch:12/Threads:16 | 279043 | 182560\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:1/Threads:16 | 126859 | 120570\r\nQGEMM/NoPackB/M:128/N:768/K:2304/Batch:6/Threads:16 | 1895960 | 1074540\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:1/Threads:16 | 313716 | 299089\r\nQGEMM/NoPackB/M:128/N:1024/K:4096/Batch:6/Threads:16 | 4511390 | 2323350\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7249/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7250",
        "id": 850799343,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5MzIyMjgy",
        "number": 7250,
        "title": "MLAS: fix qgemm bus error with Android + ARM32",
        "user": {
            "login": "tracysh",
            "id": 42477615,
            "node_id": "MDQ6VXNlcjQyNDc3NjE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/42477615?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tracysh",
            "html_url": "https://github.com/tracysh",
            "followers_url": "https://api.github.com/users/tracysh/followers",
            "following_url": "https://api.github.com/users/tracysh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tracysh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tracysh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tracysh/subscriptions",
            "organizations_url": "https://api.github.com/users/tracysh/orgs",
            "repos_url": "https://api.github.com/users/tracysh/repos",
            "events_url": "https://api.github.com/users/tracysh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tracysh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-05T23:15:43Z",
        "updated_at": "2021-04-06T05:46:05Z",
        "closed_at": "2021-04-06T05:46:05Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7250",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7250",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7250.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7250.patch",
            "merged_at": "2021-04-06T05:46:04Z"
        },
        "body": "**Description**: Replace the use of vld1(q)_lane_u32 to load 32-bits from an unaligned buffer with integer loads/stores. WIth clang, vld1(q)_lane_u32 was generating a vldr instruction that specified the effective address must be 32-bit aligned. The sequence has been replaced with something a little less tricky looking. Previous ARM32 testing was done with GCC that didn't specify any required alignment.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7250/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7251",
        "id": 850863048,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mzc2Mjc1",
        "number": 7251,
        "title": "Update test_training_model.onnx to opset 12.",
        "user": {
            "login": "mrry",
            "id": 192142,
            "node_id": "MDQ6VXNlcjE5MjE0Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/192142?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrry",
            "html_url": "https://github.com/mrry",
            "followers_url": "https://api.github.com/users/mrry/followers",
            "following_url": "https://api.github.com/users/mrry/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrry/subscriptions",
            "organizations_url": "https://api.github.com/users/mrry/orgs",
            "repos_url": "https://api.github.com/users/mrry/repos",
            "events_url": "https://api.github.com/users/mrry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-06T00:56:29Z",
        "updated_at": "2021-04-06T14:52:59Z",
        "closed_at": "2021-04-06T14:49:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7251",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7251",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7251.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7251.patch",
            "merged_at": "2021-04-06T14:49:59Z"
        },
        "body": "**Description**: Update test_training_model.onnx to opset 12.\r\n\r\n**Motivation and Context**\r\n- Enables training unit tests to use gradient graph builders that generate code leveraging opset 12 features.\r\n- Unblocks https://github.com/microsoft/onnxruntime/pull/7244",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7251/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7252",
        "id": 850865233,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mzc3OTU2",
        "number": 7252,
        "title": "Output Tensor Shape Validation b/w ONNX inference and ORT ",
        "user": {
            "login": "sumitsays",
            "id": 11188170,
            "node_id": "MDQ6VXNlcjExMTg4MTcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/11188170?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sumitsays",
            "html_url": "https://github.com/sumitsays",
            "followers_url": "https://api.github.com/users/sumitsays/followers",
            "following_url": "https://api.github.com/users/sumitsays/following{/other_user}",
            "gists_url": "https://api.github.com/users/sumitsays/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sumitsays/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sumitsays/subscriptions",
            "organizations_url": "https://api.github.com/users/sumitsays/orgs",
            "repos_url": "https://api.github.com/users/sumitsays/repos",
            "events_url": "https://api.github.com/users/sumitsays/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sumitsays/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2021-04-06T01:02:41Z",
        "updated_at": "2021-05-03T19:56:10Z",
        "closed_at": "2021-05-03T19:56:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7252",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7252",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7252.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7252.patch",
            "merged_at": "2021-05-03T19:56:09Z"
        },
        "body": "**Background**:\r\nDuring the execution of a model on CPU, _output tensor shape generated by ONNX inference_ needs to be validated against the  _output tensor shape generated by ORT_. \r\nToday, this validation happens only if the space for output tensor is pre-allocated. But, to make the behavior consistent with GPU execution provider (DML), this validation needs to happen irrespective of the space pre-allocation.\r\n\r\n**Motivation**:\r\nBug raised by a user, when a in-consistency has been seen b/w the CPU ep and GPU ep. [Github Bug: 6075](https://github.com/microsoft/onnxruntime/issues/6075) ,\r\n\r\n **Implementation**:\r\nBefore the actual execution of a operator on cpu, this validation will happen. As of now, if this validation fails, it will display/log a warning message stating the validation failure and continue with the execution. But ideally to make it consistent with GPU behavior, ORT should also stop the execution then and there if the validation fails. It is done like this for now because there are multiples existing tests fail because of this validation failure. First those tests need to be fixed, then ORT should throw an exception and stop the execution. Known tests which were failing because of validation failure:\r\n•\tPadOpTest.Pad_Edge_DimWithZeroInput \r\n•\tReductionOpTest.ReduceDimWithZero\r\n•\tLoop.SubgraphInputShadowsOuterScopeValue\r\n\r\nThere were more tests which were failing, but actual reason needs to be investigated. Few of them were:\r\n•\tCudaKernelTest.LayerNorm_SmallSizeTensor_IntermediateAxis \r\n•\tCudaKernelTest.SimplifiedLayerNorm_SmallSizeTensor_IntermediateAxis\r\nThis was the [Azure build](https://dev.azure.com/onnxruntime/onnxruntime/_build/results?buildId=349705&view=logs&j=12f1170f-54f2-53f3-20dd-22fc7dff55f9&t=b24cf96b-e476-5cd6-97ae-776d6935d22f&l=8050) but it is not present anymore in the pipeline.\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7252/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7253",
        "id": 850877816,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5Mzg3NDYy",
        "number": 7253,
        "title": "change half gemm to use compute_32f as default",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-06T01:37:03Z",
        "updated_at": "2021-04-09T03:54:39Z",
        "closed_at": "2021-04-09T03:54:38Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7253",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7253",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7253.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7253.patch",
            "merged_at": "2021-04-09T03:54:38Z"
        },
        "body": "**Description**:  Current fp16 gemm in cuda is aggregated in fp16. It has some problems:\r\n(1) That will introduce loss in precision.\r\n(2) Some older GPU like M60 does not support that.\r\n\r\nThere are following changes: \r\n* The default compute type is changed to aggregate in fp32. In this way, it is consistent with training code. \r\n* Add an environment variable ORT_CUDA_GEMM_OPTIONS for testing purpose.\r\n* Update attention cuda operator to apply the above changes.\r\n* Add unit tests.\r\n\r\nBenchmark results (with CUDA 11.0) shows that the latency are very close in most cases, and sometime aggregating in fp16 could be faster:\r\n* HG: cublasHgemm (mode=CUBLAS_DEFAULT_MATH)\r\n* C16: cublasGemmEx (mode=CUBLAS_DEFAULT_MATH, compute=CUBLAS_COMPUTE_16F)\r\n* C32: cublasGemmEx (mode=CUBLAS_DEFAULT_MATH, compute=CUBLAS_COMPUTE_32F)\r\n* R32: (mode=CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION, compute=CUBLAS_COMPUTE_32F)\r\n* SG: cublasSgemm (mode=CUBLAS_DEFAULT_MATH)\r\n\r\nLatency in ms:\r\n\r\n| GPU            | M   | N    | K     | HG        | C16       | C32       | R32       | SG        | SG/HG  | C16/HG | C32/HG | \r\n|----------------|-----|------|-------|-----------|-----------|-----------|-----------|-----------|--------|--------|--------| \r\n| V100_PCIE_16GB | 128 | 768  | 2304  | 0.033     | 0.033     | 0.054     | 0.051     | 0.067     | 2.055  | 1.006  | 1.661  | \r\n| V100_PCIE_16GB | 128 | 1024 | 4096  | 0.050     | 0.051     | 0.051     | 0.054     | 0.114     | 2.281  | 1.023  | 1.028  | \r\n| V100_PCIE_16GB | 128 | 2048 | 8192  | 0.103     | 0.104     | 0.105     | 0.119     | 0.419     | 4.086  | 1.015  | 1.024  | \r\n| V100_PCIE_16GB | 128 | 4096 | 16384 | 0.428     | 0.428     | 0.423     | 0.855     | 1.455     | 3.399  | 0.999  | 0.989  | \r\n| T4             | 128 | 768  | 2304  | 0.048     | 0.048     | 0.047     | 0.051     | 0.157     | 3.293  | 0.999  | 0.991  | \r\n| T4             | 128 | 1024 | 4096  | 0.077     | 0.077     | 0.0783512 | 0.0829144 | 0.345557  | 4.497  | 1.005  | 1.020  | \r\n| T4             | 128 | 2048 | 8192  | 0.233901  | 0.235675  | 0.235363  | 0.257197  | 1.23644   | 5.286  | 1.008  | 1.006  | \r\n| T4             | 128 | 4096 | 16384 | 0.994887  | 1.00059   | 1.07501   | 1.05646   | 5.59483   | 5.624  | 1.006  | 1.081  | \r\n| A100           | 128 | 768  | 2304  | 0.023     | 0.0234237 | 0.0252972 | 0.0252992 | 0.0501979 | 2.138  | 0.998  | 1.077  | \r\n| A100           | 128 | 1024 | 4096  | 0.0272268 | 0.0272073 | 0.0368818 | 0.0371932 | 0.188455  | 6.922  | 0.999  | 1.355  | \r\n| A100           | 128 | 2048 | 8192  | 0.0513874 | 0.0515498 | 0.0545973 | 0.109438  | 0.265237  | 5.162  | 1.003  | 1.062  | \r\n| A100           | 128 | 4096 | 16384 | 0.122526  | 0.119485  | 0.126554  | 0.207907  | 1.32136   | 10.784 | 0.975  | 1.033  | \r\n| M60            | 128 | 768  | 2304  | NA        | NA        | 0.256     | 0.253     | 0.236     | NA     | NA     | NA     | \r\n| M60            | 128 | 1024 | 4096  | NA        | NA        | 0.424     | 0.425     | 0.463     | NA     | NA     | NA     | \r\n| M60            | 128 | 2048 | 8192  | NA        | NA        | 1.496     | 1.488     | 1.710     | NA     | NA     | NA     | \r\n| M60            | 128 | 4096 | 16384 | NA        | NA        | 6.410     | 6.347     | 7.617     | NA     | NA     | NA     | \r\n\r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n\r\nDuring testing GPT-2 model in fp16, we found that the error is too large compared to PyTorch outputs. In one example, max delta in output could be 1.5 for compute type fp16, and 0.03 for compute type fp32.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7253/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7254",
        "id": 850924902,
        "node_id": "MDU6SXNzdWU4NTA5MjQ5MDI=",
        "number": 7254,
        "title": "onnxruntime can't recognize my custom op even though onnx can!",
        "user": {
            "login": "dedoogong",
            "id": 12013568,
            "node_id": "MDQ6VXNlcjEyMDEzNTY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12013568?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dedoogong",
            "html_url": "https://github.com/dedoogong",
            "followers_url": "https://api.github.com/users/dedoogong/followers",
            "following_url": "https://api.github.com/users/dedoogong/following{/other_user}",
            "gists_url": "https://api.github.com/users/dedoogong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dedoogong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dedoogong/subscriptions",
            "organizations_url": "https://api.github.com/users/dedoogong/orgs",
            "repos_url": "https://api.github.com/users/dedoogong/repos",
            "events_url": "https://api.github.com/users/dedoogong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dedoogong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 22,
        "created_at": "2021-04-06T03:43:30Z",
        "updated_at": "2022-08-12T08:40:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I implemented a custome op of type \"ASLFeatPluginX\" in both onnx and onnx-runtime.\r\n\r\nafter loading my onnx model, it called onnx.checker.check_model(model) and it passed without any error.\r\nbut onnx-runtime shows \r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/onnxruntime/capi/session.py\", line 158, in __init__\r\n    self._load_model(providers)\r\n  File \"/usr/local/lib/python3.6/dist-packages/onnxruntime/capi/session.py\", line 177, in _load_model\r\n    self._sess.load_model(providers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. Error in Node:ASLFeatPluginX0 : No Op registered for ASLFeatPluginX with domain_version of 11\r\n\r\nI changed some codes as below;\r\n\r\n1. cpu/aslfeatx.cc\r\n``` \r\nnamespace onnxruntime {\r\nnamespace contrib { \r\n\r\n#define REGISTER_CPU_KERNEL_TYPED(T)                                            \\\r\n  ONNX_OPERATOR_TYPED_KERNEL_EX(                                                \\\r\n      ASLFeatPluginX,                                                           \\\r\n      kOnnxDomainAlias,                                                                \\\r\n      11,                                                                        \\\r\n      T,                                                                        \\\r\n      kCpuExecutionProvider,                                                    \\\r\n      KernelDefBuilder()                                                        \\\r\n          .TypeConstraint(\"T\", BuildKernelDefConstraints<T>()),                 \\\r\n      ASLFeatPluginX<T>); \r\n\r\nREGISTER_CPU_KERNEL_TYPED(float)\r\nREGISTER_CPU_KERNEL_TYPED(double)\r\n//REGISTER_CPU_KERNEL_TYPED(MLFloat16)        \r\n\r\ntemplate <typename T>\r\nASLFeatPluginX<T>::ASLFeatPluginX(const OpKernelInfo& op_kernel_info)\r\n    : OpKernel(op_kernel_info) { \r\n} \r\ntemplate <typename T>\r\nStatus ASLFeatPluginX<T>::Compute(OpKernelContext* p_ctx) const { \r\n....\r\n```\r\n2. cuda/aslfeatx.cc\r\n```\r\nnamespace onnxruntime {\r\nnamespace contrib { \r\nnamespace cuda { \r\n \r\n \r\n#define REGISTER_CUDA_KERNEL_TYPED(T)                                            \\\r\n  ONNX_OPERATOR_TYPED_KERNEL_EX(                                                \\\r\n      ASLFeatPluginX,                                                           \\\r\n      kOnnxDomainAlias,                                                                \\\r\n      11,                                                                        \\\r\n      T,                                                                        \\\r\n      kCudaExecutionProvider,                                                    \\\r\n      KernelDefBuilder()                                                        \\\r\n          .TypeConstraint(\"T\", BuildKernelDefConstraints<T>()),                 \\\r\n      ASLFeatPluginX<T>); \r\n        \r\nREGISTER_CUDA_KERNEL_TYPED(float)\r\n\r\ntemplate <typename T>\r\nASLFeatPluginX<T>::ASLFeatPluginX(const OpKernelInfo& op_kernel_info)\r\n    : CudaKernel(op_kernel_info) { \r\n} \r\n\r\ntemplate <typename T>//, typename U>\r\nStatus ASLFeatPluginX<T>::ComputeInternal(OpKernelContext* ctx) const {\r\n```\r\n3. operator_sets.h\r\n```\r\n....\r\n\r\nclass ONNX_OPERATOR_SET_SCHEMA_CLASS_NAME(Onnx, 11, ASLFeatPluginX);\r\n....\r\n....\r\n    fn(GetOpSchema<ONNX_OPERATOR_SET_SCHEMA_CLASS_NAME(Onnx, 11, ASLFeatPluginX)>());  \r\n....\r\n.... \r\n```\r\n4. contrib_defs.cc ( PATH : onnxruntime/onnxruntime/core/graph/contrib_ops/contrib_defs.cc)\r\n```\r\n\r\n  ONNX_CONTRIB_OPERATOR_SCHEMA(ASLFeatPluginX)\r\n      .SetDomain(kOnnxDomainAlias)\r\n      .SinceVersion(11)\r\n      .Input(0, \"X\", \"Input tensor. Every matrix in the batch must be invertible.\", \"T\")\r\n      .Output(0, \"Y\", \"Output tensor of the same type and shape as the input tensor.\", \"T\")\r\n      .TypeConstraint(\r\n          \"T\",\r\n          {//\"tensor(float16)\",\r\n           \"tensor(float)\"},\r\n           //\"tensor(double)\"},\r\n          \"Constrain input and output types to float tensors.\")\r\n      .TypeAndShapeInferenceFunction([](ONNX_NAMESPACE::InferenceContext& ctx) {\r\n        // Type inference\r\n        using namespace ONNX_NAMESPACE;\r\n```\r\n5.  defs.cc ( PATH : onnxruntime/onnx/onnx/defs/tensor/defs.cc)\r\n```\r\nONNX_OPERATOR_SET_SCHEMA(\r\n    ASLFeatPluginX,\r\n    11,\r\n    OpSchema() \r\n        .Attr(\r\n            \"ksizes\",          \r\n            \"Kernel Sizes.\",\r\n            AttributeProto::INTS,\r\n            OPTIONAL_VALUE)        \r\n        .Attr(\r\n            \"padding\",          \r\n            \"Padding Sizes.\",\r\n            AttributeProto::STRING,\r\n            OPTIONAL_VALUE)\r\n        .Attr(\r\n            \"rates\",          \r\n            \"Rates Sizes.\",\r\n            AttributeProto::INTS,\r\n            OPTIONAL_VALUE)  \r\n        .Attr(\r\n            \"strides\",          \r\n            \"Strides Sizes.\",\r\n            AttributeProto::INTS,\r\n            OPTIONAL_VALUE) \r\n        .Input(\r\n            0,\r\n            \"X\",\r\n            \"Input data tensor from the previous operator; \"\r\n            \"4-D feature map of shape (N, C, H, W), \"\r\n            \"where N is the batch size, C is the number of channels, \"\r\n            \"and H and W are the height and the width of the data.\",\r\n            \"T\")\r\n        .Output(\r\n            0,\r\n            \"Y\",\r\n            \"mesh-pached output, 4-D tensor of shape \"\r\n            \"(num_rois, C(9), output_height, output_width).\",\r\n            \"T\")\r\n        .TypeConstraint(\r\n            \"T\",\r\n            {\"tensor(float)\"},//\"tensor(float16)\", , \"tensor(double)\"\r\n            \"Constrain types to float tensors.\")\r\n        .TypeAndShapeInferenceFunction([](InferenceContext& ctx) {\r\n```\r\n\r\n**Urgency**\r\nVery Urgent for my project\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.8.1\r\n- Python version: 3.6\r\n- Visual Studio version (if applicable): no\r\n- GCC/Compiler version (if compiling from source): 7.5.0.\r\n- CUDA/cuDNN version: 11.0/8.0.1\r\n- GPU model and memory: V100/32GB\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7254/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7255",
        "id": 851244167,
        "node_id": "MDU6SXNzdWU4NTEyNDQxNjc=",
        "number": 7255,
        "title": "ACL (32bit) Execution Provider fails on gemm node",
        "user": {
            "login": "radikalliberal",
            "id": 7655152,
            "node_id": "MDQ6VXNlcjc2NTUxNTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7655152?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/radikalliberal",
            "html_url": "https://github.com/radikalliberal",
            "followers_url": "https://api.github.com/users/radikalliberal/followers",
            "following_url": "https://api.github.com/users/radikalliberal/following{/other_user}",
            "gists_url": "https://api.github.com/users/radikalliberal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/radikalliberal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/radikalliberal/subscriptions",
            "organizations_url": "https://api.github.com/users/radikalliberal/orgs",
            "repos_url": "https://api.github.com/users/radikalliberal/repos",
            "events_url": "https://api.github.com/users/radikalliberal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/radikalliberal/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2192943459,
                "node_id": "MDU6TGFiZWwyMTkyOTQzNDU5",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:ACL",
                "name": "ep:ACL",
                "color": "0052CC",
                "default": false,
                "description": "issues related to ACL execution provider"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2021-04-06T09:36:48Z",
        "updated_at": "2022-04-19T03:54:39Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen executing a model with a raspberry pi 4B and ACL the execution stops on the last fully connected layer.\r\n```\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Gemm node. Name:'Gemm_148' Status Message: /home/pi/dev/ort1.7/include/onnxruntime/core/framework/op_kernel.h:113 const T* onnxruntime::OpKernelContext::Input(int) const [with T = onnxruntime::Tensor] Missing Input: fc.weight\r\n```\r\nThis does however not happen if I constrain the use to only CPUExecutionProvider.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution: Raspbian GNU/Linux 10 (buster)\r\n- ONNX Runtime installed from: build from source with ACL\r\n- ONNX Runtime /ACL version: 1.7.0 / 20.02\r\n- Python version: 3.7.3\r\n- GCC/Compiler version: 8.3\r\n\r\n**To Reproduce**\r\n```\r\nimport numpy as np\r\nimport onnxruntime as rt\r\npath = '/home/pi/pfld-sim.onnx'\r\nsess = rt.InferenceSession(path)\r\ninput_name = sess.get_inputs()[0].name\r\n#sess.set_providers(['CPUExecutionProvider']) <- works when this line is not commented out\r\nx = np.random.random(sess.get_inputs()[0].shape).astype(np.float32)\r\nsess.run(None, {input_name: x})\r\n```\r\nhere is the [model](https://drive.google.com/file/d/1fkn2kTYT46Kca47tlH7FQ9VhgiW3QRKg/view?usp=sharing) I used. It's a landmark model generated from [this repo](https://github.com/polarisZhao/PFLD-pytorch). The model is working flawlessly on Linux/Windows with CPU and CUDA.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7255/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7256",
        "id": 851350240,
        "node_id": "MDU6SXNzdWU4NTEzNTAyNDA=",
        "number": 7256,
        "title": "onnxruntime c++ protobuf parsing failed.",
        "user": {
            "login": "dujtep-airtech",
            "id": 70559642,
            "node_id": "MDQ6VXNlcjcwNTU5NjQy",
            "avatar_url": "https://avatars.githubusercontent.com/u/70559642?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dujtep-airtech",
            "html_url": "https://github.com/dujtep-airtech",
            "followers_url": "https://api.github.com/users/dujtep-airtech/followers",
            "following_url": "https://api.github.com/users/dujtep-airtech/following{/other_user}",
            "gists_url": "https://api.github.com/users/dujtep-airtech/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dujtep-airtech/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dujtep-airtech/subscriptions",
            "organizations_url": "https://api.github.com/users/dujtep-airtech/orgs",
            "repos_url": "https://api.github.com/users/dujtep-airtech/repos",
            "events_url": "https://api.github.com/users/dujtep-airtech/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dujtep-airtech/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-04-06T11:56:23Z",
        "updated_at": "2021-04-07T07:25:13Z",
        "closed_at": "2021-04-07T06:49:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I used onnxruntime c++ library. i create session and try to load model zoo but i got error \r\n\"onnx/squeezenet/model/squeezenet1.1-7.onnx failed:Protobuf parsing failed.\"",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7256/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7257",
        "id": 851420129,
        "node_id": "MDU6SXNzdWU4NTE0MjAxMjk=",
        "number": 7257,
        "title": "rt.SessionOptions() AttributeError: no 'SessionOptions'",
        "user": {
            "login": "dedoogong",
            "id": 12013568,
            "node_id": "MDQ6VXNlcjEyMDEzNTY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12013568?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dedoogong",
            "html_url": "https://github.com/dedoogong",
            "followers_url": "https://api.github.com/users/dedoogong/followers",
            "following_url": "https://api.github.com/users/dedoogong/following{/other_user}",
            "gists_url": "https://api.github.com/users/dedoogong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dedoogong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dedoogong/subscriptions",
            "organizations_url": "https://api.github.com/users/dedoogong/orgs",
            "repos_url": "https://api.github.com/users/dedoogong/repos",
            "events_url": "https://api.github.com/users/dedoogong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dedoogong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-06T13:23:06Z",
        "updated_at": "2021-04-07T02:12:50Z",
        "closed_at": "2021-04-07T02:12:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nsess_options = rt.SessionOptions()\r\nAttributeError: module 'onnxruntime' has no attribute 'SessionOptions'\r\n\r\nI built onnxruntime from source successfully.\r\n```\r\n./build.sh --update --enable_training --use_cuda --config=RelWithDebInfo --build_wheel --skip_tests --parallel 64\r\n\r\n2021-04-06 13:24:08,610 build [INFO] - Build started\r\n2021-04-06 13:24:08,610 util.run [INFO] - Running subprocess in '/workspace/onnxruntime'\r\n['git', 'submodule', 'sync', '--recursive']\r\nSynchronizing submodule url for 'cmake/external/FeaturizersLibrary'\r\nSynchronizing submodule url for 'cmake/external/FeaturizersLibrary/src/3rdParty/eigen'\r\nSynchronizing submodule url for 'cmake/external/FeaturizersLibrary/src/3rdParty/re2'\r\nSynchronizing submodule url for 'cmake/external/SafeInt/safeint'\r\nSynchronizing submodule url for 'cmake/external/coremltools'\r\nSynchronizing submodule url for 'cmake/external/cub'\r\nSynchronizing submodule url for 'cmake/external/cxxopts'\r\nSynchronizing submodule url for 'cmake/external/date'\r\nSynchronizing submodule url for 'cmake/external/dlpack'\r\nSynchronizing submodule url for 'cmake/external/eigen'\r\nSynchronizing submodule url for 'cmake/external/flatbuffers'\r\nSynchronizing submodule url for 'cmake/external/googletest'\r\nSynchronizing submodule url for 'cmake/external/json'\r\nSynchronizing submodule url for 'cmake/external/libprotobuf-mutator'\r\nSynchronizing submodule url for 'cmake/external/mimalloc'\r\nSynchronizing submodule url for 'cmake/external/mp11'\r\nSynchronizing submodule url for 'cmake/external/nsync'\r\nSynchronizing submodule url for 'cmake/external/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/pybind11'\r\nSynchronizing submodule url for 'cmake/external/onnx-tensorrt/third_party/onnx/third_party/pybind11/tools/clang'\r\nSynchronizing submodule url for 'cmake/external/optional-lite'\r\nSynchronizing submodule url for 'cmake/external/protobuf'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/benchmark'\r\nSynchronizing submodule url for 'cmake/external/protobuf/third_party/googletest'\r\nSynchronizing submodule url for 'cmake/external/re2'\r\nSynchronizing submodule url for 'cmake/external/tensorboard'\r\nSynchronizing submodule url for 'cmake/external/tvm'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/HalideIR'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dlpack'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/dmlc-core'\r\nSynchronizing submodule url for 'cmake/external/tvm/3rdparty/rang'\r\nSynchronizing submodule url for 'cmake/external/wil'\r\nSynchronizing submodule url for 'server/external/spdlog'\r\n2021-04-06 13:24:08,881 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-04-06 13:24:08,881 util.run [INFO] - Running subprocess in '/workspace/onnxruntime'\r\n['git', 'submodule', 'update', '--init', '--recursive']\r\n2021-04-06 13:24:09,888 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-04-06 13:24:09,889 build [INFO] - Generating CMake build tree\r\n2021-04-06 13:24:09,890 util.run [INFO] - Running subprocess in '/workspace/onnxruntime/build/Linux/RelWithDebInfo'\r\n['/usr/local/bin/cmake', '/workspace/onnxruntime/cmake', '-Donnxruntime_RUN_ONNX_TESTS=OFF', '-Donnxruntime_BUILD_WINML_TESTS=ON', '-Donnxruntime_GENERATE_TEST_REPORTS=ON', '-Donnxruntime_DEV_MODE=ON', '-DPYTHON_EXECUTABLE=/usr/bin/python3', '-Donnxruntime_USE_CUDA=ON', '-Donnxruntime_CUDA_VERSION=', '-Donnxruntime_CUDA_HOME=/usr/local/cuda-11.0', '-Donnxruntime_CUDNN_HOME=/usr/local/cuda-11.0', '-Donnxruntime_USE_FEATURIZERS=OFF', '-Donnxruntime_USE_MIMALLOC_STL_ALLOCATOR=OFF', '-Donnxruntime_USE_MIMALLOC_ARENA_ALLOCATOR=OFF', '-Donnxruntime_ENABLE_PYTHON=ON', '-Donnxruntime_BUILD_CSHARP=OFF', '-Donnxruntime_BUILD_JAVA=OFF', '-Donnxruntime_BUILD_NODEJS=OFF', '-Donnxruntime_BUILD_SHARED_LIB=OFF', '-Donnxruntime_USE_DNNL=OFF', '-Donnxruntime_DNNL_GPU_RUNTIME=', '-Donnxruntime_DNNL_OPENCL_ROOT=', '-Donnxruntime_USE_NNAPI_BUILTIN=OFF', '-Donnxruntime_USE_RKNPU=OFF', '-Donnxruntime_USE_OPENMP=OFF', '-Donnxruntime_USE_TVM=OFF', '-Donnxruntime_USE_LLVM=OFF', '-Donnxruntime_ENABLE_MICROSOFT_INTERNAL=OFF', '-Donnxruntime_USE_VITISAI=OFF', '-Donnxruntime_USE_NUPHAR=OFF', '-Donnxruntime_USE_TENSORRT=OFF', '-Donnxruntime_TENSORRT_HOME=', '-Donnxruntime_USE_MIGRAPHX=OFF', '-Donnxruntime_MIGRAPHX_HOME=', '-Donnxruntime_CROSS_COMPILING=OFF', '-Donnxruntime_DISABLE_CONTRIB_OPS=OFF', '-Donnxruntime_DISABLE_ML_OPS=OFF', '-Donnxruntime_DISABLE_RTTI=OFF', '-Donnxruntime_DISABLE_EXCEPTIONS=OFF', '-Donnxruntime_DISABLE_ORT_FORMAT_LOAD=OFF', '-Donnxruntime_MINIMAL_BUILD=OFF', '-Donnxruntime_EXTENDED_MINIMAL_BUILD=OFF', '-Donnxruntime_MINIMAL_BUILD_CUSTOM_OPS=OFF', '-Donnxruntime_REDUCED_OPS_BUILD=OFF', '-Donnxruntime_MSVC_STATIC_RUNTIME=OFF', '-Donnxruntime_ENABLE_LANGUAGE_INTEROP_OPS=OFF', '-Donnxruntime_USE_DML=OFF', '-Donnxruntime_USE_WINML=OFF', '-Donnxruntime_BUILD_MS_EXPERIMENTAL_OPS=OFF', '-Donnxruntime_USE_TELEMETRY=OFF', '-Donnxruntime_ENABLE_LTO=OFF', '-Donnxruntime_USE_ACL=OFF', '-Donnxruntime_USE_ACL_1902=OFF', '-Donnxruntime_USE_ACL_1905=OFF', '-Donnxruntime_USE_ACL_1908=OFF', '-Donnxruntime_USE_ACL_2002=OFF', '-Donnxruntime_USE_ARMNN=OFF', '-Donnxruntime_ARMNN_RELU_USE_CPU=ON', '-Donnxruntime_ARMNN_BN_USE_CPU=ON', '-Donnxruntime_ENABLE_NVTX_PROFILE=OFF', '-Donnxruntime_ENABLE_TRAINING=ON', '-Donnxruntime_ENABLE_TRAINING_OPS=OFF', '-Donnxruntime_ENABLE_CPU_FP16_OPS=ON', '-Donnxruntime_USE_NCCL=ON', '-Donnxruntime_BUILD_BENCHMARKS=OFF', '-Donnxruntime_USE_ROCM=OFF', '-Donnxruntime_ROCM_HOME=', '-DOnnxruntime_GCOV_COVERAGE=OFF', '-Donnxruntime_USE_MPI=ON', '-Donnxruntime_ENABLE_MEMORY_PROFILE=OFF', '-Donnxruntime_ENABLE_CUDA_LINE_NUMBER_INFO=OFF', '-DCUDA_CUDA_LIBRARY=/usr/local/cuda-11.0/lib64/stubs', '-Donnxruntime_PYBIND_EXPORT_OPSCHEMA=OFF', '-Donnxruntime_ENABLE_MEMLEAK_CHECKER=OFF', '-DCMAKE_BUILD_TYPE=RelWithDebInfo']\r\nUse gtest from submodule\r\n-- Found PythonInterp: /usr/bin/python3 (found suitable version \"3.6.9\", minimum required is \"3.5\") \r\n-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so (found suitable version \"3.6.9\", minimum required is \"3.5\") \r\nUse protobuf from submodule\r\n-- \r\n-- 3.11.3.0\r\n-- Using the single-header code from /workspace/onnxruntime/cmake/external/json/single_include/\r\n-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \r\n-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so (found version \"3.6.9\") \r\nGenerated: /workspace/onnxruntime/build/Linux/RelWithDebInfo/external/onnx/onnx/onnx-ml.proto\r\nGenerated: /workspace/onnxruntime/build/Linux/RelWithDebInfo/external/onnx/onnx/onnx-operators-ml.proto\r\nGenerated: /workspace/onnxruntime/build/Linux/RelWithDebInfo/external/onnx/onnx/onnx-data.proto\r\n-- \r\n-- ******** Summary ********\r\n--   CMake version             : 3.14.4\r\n--   CMake command             : /usr/local/bin/cmake\r\n--   System                    : Linux\r\n--   C++ compiler              : /usr/bin/c++\r\n--   C++ compiler version      : 7.5.0\r\n--   CXX flags                 :  -ffunction-sections -fdata-sections -Wnon-virtual-dtor\r\n--   Build type                : RelWithDebInfo\r\n--   Compile definitions       : ENABLE_ORT_FORMAT_LOAD;EIGEN_MPL2_ONLY;ENABLE_CPU_FP16_TRAINING_OPS\r\n--   CMAKE_PREFIX_PATH         : \r\n--   CMAKE_INSTALL_PREFIX      : /usr/local\r\n--   CMAKE_MODULE_PATH         : /workspace/onnxruntime/cmake/external\r\n-- \r\n--   ONNX version              : 1.8.1\r\n--   ONNX NAMESPACE            : onnx\r\n--   ONNX_USE_LITE_PROTO       : ON\r\n--   USE_PROTOBUF_SHARED_LIBS  : OFF\r\n--   ONNX_DISABLE_EXCEPTIONS   : OFF\r\n--   ONNX_WERROR               : OFF\r\n--   ONNX_BUILD_TESTS          : OFF\r\n--   ONNX_BUILD_BENCHMARKS     : OFF\r\n--   ONNXIFI_DUMMY_BACKEND     : OFF\r\n--   ONNXIFI_ENABLE_EXT        : OFF\r\n-- \r\n--   Protobuf compiler         : \r\n--   Protobuf includes         : \r\n--   Protobuf libraries        : \r\n--   BUILD_ONNX_PYTHON         : OFF\r\n-- CMAKE_CUDA_COMPILER_VERSION: 11.0.221\r\n-- MPI Version: 4.0.4\r\n-- MPI (include: /usr/local/include, library: /usr/local/lib/libmpi.so)\r\n-- Determining NCCL version from the header file: /usr/include/nccl.h\r\n-- NCCL_MAJOR_VERSION: 2\r\n-- NCCL_MINOR_VERSION: 7\r\n-- NCCL P2P is enabled for supporting ncclSend and ncclRecv.\r\n-- NCCL (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libnccl.so)\r\n-- NCCL is enabled in Linux GPU Build.\r\n-- NumPy ver. 1.19.5 found (include: /usr/local/lib/python3.6/dist-packages/numpy/core/include)\r\nCMake Warning at flake8.cmake:74 (message):\r\n  'flake8' version is too old.  Requires 3.8 or later.  Found /bin/sh: 1:\r\n  /usr/local/bin/flake8: not found\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:1579 (include)\r\n\r\n\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /workspace/onnxruntime/build/Linux/RelWithDebInfo\r\n....\r\n....\r\n[100%] Building CXX object CMakeFiles/onnxruntime_test_all.dir/workspace/onnxruntime/onnxruntime/test/unittest_main/test_main.cc.o\r\n/workspace/onnxruntime/orttraining/orttraining/test/gradient/function_ops_test.cc: In function 'void onnxruntime::test::AssertEqual(const std::vector<OrtValue>&, const std::vector<OrtValue>&)':\r\n/workspace/onnxruntime/orttraining/orttraining/test/gradient/function_ops_test.cc:99:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < results1.size(); i++) {\r\n                   ~~^~~~~~~~~~~~~~~~~\r\n[100%] Linking CUDA device code CMakeFiles/onnxruntime_test_all.dir/cmake_device_link.o\r\n[100%] Linking CXX executable onnxruntime_test_all\r\n[100%] Built target onnxruntime_test_all\r\n2021-04-06 12:39:16,828 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-04-06 12:39:16,829 util.run [INFO] - Running subprocess in '/workspace/onnxruntime/build/Linux/RelWithDebInfo'\r\n['/usr/bin/python3', '/workspace/onnxruntime/setup.py', 'bdist_wheel', '--enable_training', '--use_cuda']\r\nrunning bdist_wheel\r\nrunning build\r\nrunning build_py\r\ncopying onnxruntime/__init__.py -> build/lib/onnxruntime\r\ncopying onnxruntime/backend/__init__.py -> build/lib/onnxruntime/backend\r\ncopying onnxruntime/backend/backend.py -> build/lib/onnxruntime/backend\r\ncopying onnxruntime/backend/backend_rep.py -> build/lib/onnxruntime/backend\r\ncopying onnxruntime/capi/onnxruntime_inference_collection.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/checkpointing_utils.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/ort_trainer.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/pt_patch.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/__init__.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/_ld_preload.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/_pybind_state.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/onnxruntime_validation.py -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/capi/training/__init__.py -> build/lib/onnxruntime/capi/training\r\ncopying onnxruntime/capi/training/training_session.py -> build/lib/onnxruntime/capi/training\r\ncopying onnxruntime/datasets/__init__.py -> build/lib/onnxruntime/datasets\r\ncopying onnxruntime/tools/__init__.py -> build/lib/onnxruntime/tools\r\ncopying onnxruntime/tools/onnxruntime_test.py -> build/lib/onnxruntime/tools\r\ncopying onnxruntime/tools/symbolic_shape_infer.py -> build/lib/onnxruntime/tools\r\ncopying onnxruntime/quantization/__init__.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/calibrate.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/onnx_model.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/onnx_quantizer.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/qdq_quantizer.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/quant_utils.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/quantize.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/registry.py -> build/lib/onnxruntime/quantization\r\ncopying onnxruntime/quantization/operators/__init__.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/activation.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/attention.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/base_operator.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/binary_op.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/conv.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/embed_layernorm.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/gather.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/gavgpool.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/lstm.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/matmul.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/maxpool.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/pad.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/qdq_base_operator.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/reshape.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/operators/split.py -> build/lib/onnxruntime/quantization/operators\r\ncopying onnxruntime/quantization/CalTableFlatBuffers/KeyValue.py -> build/lib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying onnxruntime/quantization/CalTableFlatBuffers/TrtTable.py -> build/lib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying onnxruntime/quantization/CalTableFlatBuffers/__init__.py -> build/lib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying onnxruntime/transformers/__init__.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/benchmark.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/benchmark_gpt2.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/benchmark_helper.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/bert_perf_test.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/bert_test_data.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/compare_bert_results.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/convert_tf_models_to_pytorch.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/convert_to_onnx.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_attention.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_base.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_biasgelu.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_embedlayer.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_fastgelu.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_gelu.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_gelu_approximation.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_gpt_attention.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_gpt_attention_no_past.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_layernorm.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_reshape.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_skiplayernorm.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/fusion_utils.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/gpt2_helper.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/gpt2_tester.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/huggingface_models.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/machine_info.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_exporter.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_model.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_model_bert.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_model_bert_keras.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_model_bert_tf.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/onnx_model_gpt2.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/optimizer.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/parity_check_helper.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/profiler.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/quantize_helper.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/shape_infer_helper.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/shape_optimizer.py -> build/lib/onnxruntime/transformers\r\ncopying onnxruntime/transformers/longformer/__init__.py -> build/lib/onnxruntime/transformers/longformer\r\ncopying onnxruntime/transformers/longformer/benchmark_longformer.py -> build/lib/onnxruntime/transformers/longformer\r\ncopying onnxruntime/transformers/longformer/convert_longformer_to_onnx.py -> build/lib/onnxruntime/transformers/longformer\r\ncopying onnxruntime/transformers/longformer/generate_test_data.py -> build/lib/onnxruntime/transformers/longformer\r\ncopying onnxruntime/transformers/longformer/longformer_helper.py -> build/lib/onnxruntime/transformers/longformer\r\ncopying onnxruntime/training/postprocess.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/runstateinfo.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/training_agent.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/register_custom_ops_pytorch_exporter.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/__init__.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/_checkpoint_storage.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/_ortmodule_output_transformation.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/_utils.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/checkpoint.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/model_desc_validation.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/ortmodule.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/orttrainer.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/orttrainer_options.py -> build/lib/onnxruntime/training\r\ncopying onnxruntime/training/amp/__init__.py -> build/lib/onnxruntime/training/amp\r\ncopying onnxruntime/training/amp/loss_scaler.py -> build/lib/onnxruntime/training/amp\r\ncopying onnxruntime/training/optim/__init__.py -> build/lib/onnxruntime/training/optim\r\ncopying onnxruntime/training/optim/config.py -> build/lib/onnxruntime/training/optim\r\ncopying onnxruntime/training/optim/lr_scheduler.py -> build/lib/onnxruntime/training/optim\r\ncopying onnxruntime/capi/onnxruntime_pybind11_state.so -> build/lib/onnxruntime/capi\r\ncopying onnxruntime/datasets/mul_1.onnx -> build/lib/onnxruntime/datasets\r\ncopying onnxruntime/datasets/logreg_iris.onnx -> build/lib/onnxruntime/datasets\r\ncopying onnxruntime/datasets/sigmoid.onnx -> build/lib/onnxruntime/datasets\r\ncopying onnxruntime/LICENSE -> build/lib/onnxruntime\r\ncopying onnxruntime/ThirdPartyNotices.txt -> build/lib/onnxruntime\r\ncopying onnxruntime/Privacy.md -> build/lib/onnxruntime\r\ninstalling to build/bdist.linux-x86_64/wheel\r\nrunning install\r\nrunning install_lib\r\ncreating build/bdist.linux-x86_64/wheel\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend\r\ncopying build/lib/onnxruntime/backend/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend\r\ncopying build/lib/onnxruntime/backend/backend.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend\r\ncopying build/lib/onnxruntime/backend/backend_rep.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/training\r\ncopying build/lib/onnxruntime/capi/training/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/training\r\ncopying build/lib/onnxruntime/capi/training/training_session.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/training\r\ncopying build/lib/onnxruntime/capi/onnxruntime_inference_collection.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/checkpointing_utils.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/ort_trainer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/pt_patch.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/_ld_preload.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/_pybind_state.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/onnxruntime_validation.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncopying build/lib/onnxruntime/capi/onnxruntime_pybind11_state.so -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets\r\ncopying build/lib/onnxruntime/datasets/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets\r\ncopying build/lib/onnxruntime/datasets/mul_1.onnx -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets\r\ncopying build/lib/onnxruntime/datasets/logreg_iris.onnx -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets\r\ncopying build/lib/onnxruntime/datasets/sigmoid.onnx -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools\r\ncopying build/lib/onnxruntime/tools/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools\r\ncopying build/lib/onnxruntime/tools/onnxruntime_test.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools\r\ncopying build/lib/onnxruntime/tools/symbolic_shape_infer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/activation.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/attention.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/base_operator.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/binary_op.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/conv.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/embed_layernorm.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/gather.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/gavgpool.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/lstm.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/matmul.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/maxpool.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/pad.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/qdq_base_operator.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/reshape.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncopying build/lib/onnxruntime/quantization/operators/split.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying build/lib/onnxruntime/quantization/CalTableFlatBuffers/KeyValue.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying build/lib/onnxruntime/quantization/CalTableFlatBuffers/TrtTable.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying build/lib/onnxruntime/quantization/CalTableFlatBuffers/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers\r\ncopying build/lib/onnxruntime/quantization/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/calibrate.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/onnx_model.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/onnx_quantizer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/qdq_quantizer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/quant_utils.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/quantize.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncopying build/lib/onnxruntime/quantization/registry.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/benchmark_gpt2.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/bert_test_data.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/convert_to_onnx.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/shape_infer_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/shape_optimizer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_attention.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_gelu_approximation.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_layernorm.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_skiplayernorm.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_base.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/longformer/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/longformer/benchmark_longformer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/longformer/convert_longformer_to_onnx.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/longformer/generate_test_data.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/longformer/longformer_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer\r\ncopying build/lib/onnxruntime/transformers/gpt2_tester.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/huggingface_models.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/machine_info.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_exporter.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_model.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_model_bert_tf.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/benchmark.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/benchmark_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/compare_bert_results.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_embedlayer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_fastgelu.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_gpt_attention.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_reshape.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/gpt2_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_model_gpt2.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/optimizer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/profiler.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/bert_perf_test.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/convert_tf_models_to_pytorch.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_model_bert_keras.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/parity_check_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/quantize_helper.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_gelu.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_gpt_attention_no_past.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_utils.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/onnx_model_bert.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncopying build/lib/onnxruntime/transformers/fusion_biasgelu.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/amp\r\ncopying build/lib/onnxruntime/training/amp/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/amp\r\ncopying build/lib/onnxruntime/training/amp/loss_scaler.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/amp\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim\r\ncopying build/lib/onnxruntime/training/optim/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim\r\ncopying build/lib/onnxruntime/training/optim/config.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim\r\ncopying build/lib/onnxruntime/training/optim/lr_scheduler.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim\r\ncopying build/lib/onnxruntime/training/postprocess.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/runstateinfo.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/training_agent.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/register_custom_ops_pytorch_exporter.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/_checkpoint_storage.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/_ortmodule_output_transformation.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/_utils.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/checkpoint.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/model_desc_validation.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/ortmodule.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/orttrainer.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/training/orttrainer_options.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training\r\ncopying build/lib/onnxruntime/__init__.py -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime\r\ncopying build/lib/onnxruntime/LICENSE -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime\r\ncopying build/lib/onnxruntime/ThirdPartyNotices.txt -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime\r\ncopying build/lib/onnxruntime/Privacy.md -> build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime\r\nrunning install_egg_info\r\nrunning egg_info\r\nwriting onnxruntime_gpu.egg-info/PKG-INFO\r\nwriting dependency_links to onnxruntime_gpu.egg-info/dependency_links.txt\r\nwriting entry points to onnxruntime_gpu.egg-info/entry_points.txt\r\nwriting requirements to onnxruntime_gpu.egg-info/requires.txt\r\nwriting top-level names to onnxruntime_gpu.egg-info/top_level.txt\r\nreading manifest file 'onnxruntime_gpu.egg-info/SOURCES.txt'\r\nwriting manifest file 'onnxruntime_gpu.egg-info/SOURCES.txt'\r\nCopying onnxruntime_gpu.egg-info to build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.data/purelib/onnxruntime_gpu-1.7.0-py3.6.egg-info\r\nrunning install_scripts\r\ncreating build/bdist.linux-x86_64/wheel/onnxruntime_gpu-1.7.0.dist-info/WHEEL\r\ncreating 'dist/onnxruntime_gpu-1.7.0-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/LICENSE'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/Privacy.md'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/ThirdPartyNotices.txt'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend/backend.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/backend/backend_rep.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/_ld_preload.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/_pybind_state.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/checkpointing_utils.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/onnxruntime_inference_collection.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/onnxruntime_pybind11_state.so'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/onnxruntime_validation.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/ort_trainer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/pt_patch.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/training/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/capi/training/training_session.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets/logreg_iris.onnx'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets/mul_1.onnx'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/datasets/sigmoid.onnx'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/calibrate.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/onnx_model.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/onnx_quantizer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/qdq_quantizer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/quant_utils.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/quantize.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/registry.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers/KeyValue.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers/TrtTable.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/CalTableFlatBuffers/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/activation.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/attention.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/base_operator.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/binary_op.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/conv.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/embed_layernorm.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/gather.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/gavgpool.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/lstm.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/matmul.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/maxpool.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/pad.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/qdq_base_operator.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/reshape.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/quantization/operators/split.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools/onnxruntime_test.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/tools/symbolic_shape_infer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/_checkpoint_storage.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/_ortmodule_output_transformation.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/_utils.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/checkpoint.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/model_desc_validation.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/ortmodule.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/orttrainer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/orttrainer_options.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/postprocess.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/register_custom_ops_pytorch_exporter.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/runstateinfo.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/training_agent.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/amp/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/amp/loss_scaler.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim/config.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/training/optim/lr_scheduler.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/benchmark.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/benchmark_gpt2.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/benchmark_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/bert_perf_test.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/bert_test_data.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/compare_bert_results.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/convert_tf_models_to_pytorch.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/convert_to_onnx.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_attention.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_base.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_biasgelu.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_embedlayer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_fastgelu.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_gelu.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_gelu_approximation.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_gpt_attention.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_gpt_attention_no_past.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_layernorm.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_reshape.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_skiplayernorm.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/fusion_utils.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/gpt2_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/gpt2_tester.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/huggingface_models.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/machine_info.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_exporter.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_model.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_model_bert.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_model_bert_keras.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_model_bert_tf.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/onnx_model_gpt2.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/optimizer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/parity_check_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/profiler.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/quantize_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/shape_infer_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/shape_optimizer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer/__init__.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer/benchmark_longformer.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer/convert_longformer_to_onnx.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer/generate_test_data.py'\r\nadding 'onnxruntime_gpu-1.7.0.data/purelib/onnxruntime/transformers/longformer/longformer_helper.py'\r\nadding 'onnxruntime_gpu-1.7.0.dist-info/METADATA'\r\nadding 'onnxruntime_gpu-1.7.0.dist-info/WHEEL'\r\nadding 'onnxruntime_gpu-1.7.0.dist-info/entry_points.txt'\r\nadding 'onnxruntime_gpu-1.7.0.dist-info/top_level.txt'\r\nadding 'onnxruntime_gpu-1.7.0.dist-info/RECORD'\r\nremoving build/bdist.linux-x86_64/wheel\r\n2021-04-06 12:39:55,790 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2021-04-06 12:39:55,791 build [INFO] - Build complete\r\n```\r\n**Urgency**\r\nVery Urgent\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- ONNX Runtime installed from (source or binary): source \r\n- ONNX Runtime version: 1.7.0\r\n- Python version: 3.6\r\n- Visual Studio version (if applicable): no\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 11.0, 8.0.1\r\n- GPU model and memory: V100, 32GB\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7257/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7258",
        "id": 851430517,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjA5ODU2MDg4",
        "number": 7258,
        "title": "Fixes in symbolic shape inference",
        "user": {
            "login": "orausch",
            "id": 22137236,
            "node_id": "MDQ6VXNlcjIyMTM3MjM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/22137236?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/orausch",
            "html_url": "https://github.com/orausch",
            "followers_url": "https://api.github.com/users/orausch/followers",
            "following_url": "https://api.github.com/users/orausch/following{/other_user}",
            "gists_url": "https://api.github.com/users/orausch/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/orausch/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/orausch/subscriptions",
            "organizations_url": "https://api.github.com/users/orausch/orgs",
            "repos_url": "https://api.github.com/users/orausch/repos",
            "events_url": "https://api.github.com/users/orausch/events{/privacy}",
            "received_events_url": "https://api.github.com/users/orausch/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 21,
        "created_at": "2021-04-06T13:34:03Z",
        "updated_at": "2021-04-14T09:03:17Z",
        "closed_at": "2021-04-14T05:17:31Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7258",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7258",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7258.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7258.patch",
            "merged_at": "2021-04-14T05:17:31Z"
        },
        "body": "**Description**: \r\n- Add transpose to the symbolic shape inference\r\n- Fix an issue in `_infer_Slice` where the steps were ignored",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7258/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7259",
        "id": 851620333,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMDExODgw",
        "number": 7259,
        "title": "Update test_training_model_{0,1,2}.onnx to opset 12.",
        "user": {
            "login": "mrry",
            "id": 192142,
            "node_id": "MDQ6VXNlcjE5MjE0Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/192142?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mrry",
            "html_url": "https://github.com/mrry",
            "followers_url": "https://api.github.com/users/mrry/followers",
            "following_url": "https://api.github.com/users/mrry/following{/other_user}",
            "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mrry/subscriptions",
            "organizations_url": "https://api.github.com/users/mrry/orgs",
            "repos_url": "https://api.github.com/users/mrry/repos",
            "events_url": "https://api.github.com/users/mrry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mrry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T16:59:40Z",
        "updated_at": "2021-04-06T20:03:22Z",
        "closed_at": "2021-04-06T20:02:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7259",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7259",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7259.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7259.patch",
            "merged_at": "2021-04-06T20:02:59Z"
        },
        "body": "**Description**: Update test_training_model_{0,1,2}.onnx to opset 12.\r\n\r\n**Motivation and Context**\r\n- Follow up to https://github.com/microsoft/onnxruntime/pull/7251, which fixes other tests when we start using modern ops in https://github.com/microsoft/onnxruntime/pull/7244.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7259/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7260",
        "id": 851806278,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMTY2MDY1",
        "number": 7260,
        "title": "Fix initializer counts when used as graph output",
        "user": {
            "login": "TomWildenhain-Microsoft",
            "id": 67606533,
            "node_id": "MDQ6VXNlcjY3NjA2NTMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/67606533?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TomWildenhain-Microsoft",
            "html_url": "https://github.com/TomWildenhain-Microsoft",
            "followers_url": "https://api.github.com/users/TomWildenhain-Microsoft/followers",
            "following_url": "https://api.github.com/users/TomWildenhain-Microsoft/following{/other_user}",
            "gists_url": "https://api.github.com/users/TomWildenhain-Microsoft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TomWildenhain-Microsoft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TomWildenhain-Microsoft/subscriptions",
            "organizations_url": "https://api.github.com/users/TomWildenhain-Microsoft/orgs",
            "repos_url": "https://api.github.com/users/TomWildenhain-Microsoft/repos",
            "events_url": "https://api.github.com/users/TomWildenhain-Microsoft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TomWildenhain-Microsoft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T20:59:37Z",
        "updated_at": "2021-04-07T02:52:23Z",
        "closed_at": "2021-04-07T02:52:23Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7260",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7260",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7260.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7260.patch",
            "merged_at": "2021-04-07T02:52:22Z"
        },
        "body": "Signed-off-by: Tom Wildenhain <tomwi@microsoft.com>\r\n\r\n**Description**: Change the usage count of initializers to include the graph outputs.\r\n\r\n**Motivation and Context**\r\nWhen an initializer is used as a graph output (and nowhere else) it might be removed if the count is 0.  The count should include the times the initializer appears as an output.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7260/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7261",
        "id": 851812970,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMTcxNjE1",
        "number": 7261,
        "title": "[wip] DO NOT REVIEW. ",
        "user": {
            "login": "codemzs",
            "id": 1211949,
            "node_id": "MDQ6VXNlcjEyMTE5NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1211949?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/codemzs",
            "html_url": "https://github.com/codemzs",
            "followers_url": "https://api.github.com/users/codemzs/followers",
            "following_url": "https://api.github.com/users/codemzs/following{/other_user}",
            "gists_url": "https://api.github.com/users/codemzs/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/codemzs/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/codemzs/subscriptions",
            "organizations_url": "https://api.github.com/users/codemzs/orgs",
            "repos_url": "https://api.github.com/users/codemzs/repos",
            "events_url": "https://api.github.com/users/codemzs/events{/privacy}",
            "received_events_url": "https://api.github.com/users/codemzs/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T21:10:17Z",
        "updated_at": "2021-04-06T21:16:30Z",
        "closed_at": "2021-04-06T21:16:30Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7261",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7261",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7261.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7261.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7261/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7262",
        "id": 851826711,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMTgzMTU3",
        "number": 7262,
        "title": "Remove ROCM workaround for half-to-double cast.",
        "user": {
            "login": "jessebenson",
            "id": 8907830,
            "node_id": "MDQ6VXNlcjg5MDc4MzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8907830?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jessebenson",
            "html_url": "https://github.com/jessebenson",
            "followers_url": "https://api.github.com/users/jessebenson/followers",
            "following_url": "https://api.github.com/users/jessebenson/following{/other_user}",
            "gists_url": "https://api.github.com/users/jessebenson/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jessebenson/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jessebenson/subscriptions",
            "organizations_url": "https://api.github.com/users/jessebenson/orgs",
            "repos_url": "https://api.github.com/users/jessebenson/repos",
            "events_url": "https://api.github.com/users/jessebenson/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jessebenson/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T21:33:32Z",
        "updated_at": "2021-04-07T00:46:48Z",
        "closed_at": "2021-04-07T00:46:47Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7262",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7262",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7262.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7262.patch",
            "merged_at": "2021-04-07T00:46:47Z"
        },
        "body": "**Description**:\r\nThe following code caused a compiler error with `hipcc` in ROCM 4.0 and earlier:\r\n\r\n```\r\nhalf x = 0;\r\ndouble y = static_cast<double>(x);\r\n```\r\n\r\nIn ROCM 4.1, `hipcc` now supports this cast.  Remove ROCM compiler workaround in onnxruntime code.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7262/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7263",
        "id": 851829189,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMTg1MjQz",
        "number": 7263,
        "title": "Update to website installation picker",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T21:38:01Z",
        "updated_at": "2021-04-07T00:15:18Z",
        "closed_at": "2021-04-07T00:15:18Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7263",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7263",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7263.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7263.patch",
            "merged_at": "2021-04-07T00:15:18Z"
        },
        "body": "Staged at: https://faxu.github.io/onnxruntime/\r\n\r\nKey changes:\r\n- grays out invalid options based on current selection and marks invalid options\r\n- allows deselect \r\n- updates to installation text and options for both inf and training sections\r\n- color updates",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7263/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7264",
        "id": 851870696,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMjE5Nzcy",
        "number": 7264,
        "title": "fix for using tensorrt:20.12 base image",
        "user": {
            "login": "jywu-msft",
            "id": 43355415,
            "node_id": "MDQ6VXNlcjQzMzU1NDE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/43355415?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jywu-msft",
            "html_url": "https://github.com/jywu-msft",
            "followers_url": "https://api.github.com/users/jywu-msft/followers",
            "following_url": "https://api.github.com/users/jywu-msft/following{/other_user}",
            "gists_url": "https://api.github.com/users/jywu-msft/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jywu-msft/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jywu-msft/subscriptions",
            "organizations_url": "https://api.github.com/users/jywu-msft/orgs",
            "repos_url": "https://api.github.com/users/jywu-msft/repos",
            "events_url": "https://api.github.com/users/jywu-msft/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jywu-msft/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T23:06:06Z",
        "updated_at": "2021-04-07T15:48:45Z",
        "closed_at": "2021-04-07T15:48:44Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7264",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7264",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7264.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7264.patch",
            "merged_at": "2021-04-07T15:48:44Z"
        },
        "body": "previously 20.12 image was not working due to conflict for libstdc++\r\nremove /opt/miniconda/lib from LD_LIBRARY_PATH which was causing conflict with system libstdc++",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7264/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7265",
        "id": 851879025,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMjI2Nzk1",
        "number": 7265,
        "title": "Support transpose by merge Reshape etc into direct xint8 operators.",
        "user": {
            "login": "zhanghuanrong",
            "id": 5163183,
            "node_id": "MDQ6VXNlcjUxNjMxODM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5163183?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhanghuanrong",
            "html_url": "https://github.com/zhanghuanrong",
            "followers_url": "https://api.github.com/users/zhanghuanrong/followers",
            "following_url": "https://api.github.com/users/zhanghuanrong/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhanghuanrong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhanghuanrong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhanghuanrong/subscriptions",
            "organizations_url": "https://api.github.com/users/zhanghuanrong/orgs",
            "repos_url": "https://api.github.com/users/zhanghuanrong/repos",
            "events_url": "https://api.github.com/users/zhanghuanrong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhanghuanrong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T23:26:27Z",
        "updated_at": "2021-04-10T19:48:24Z",
        "closed_at": "2021-04-09T01:00:36Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7265",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7265",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7265.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7265.patch",
            "merged_at": "2021-04-09T01:00:36Z"
        },
        "body": " * add quantized operator for those ops supprot xint8 intput[0]\r\n * merge reshape/maxpool to utilize above base\r\n * support transpose through above\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7265/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7266",
        "id": 851889705,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMjM1NzE0",
        "number": 7266,
        "title": "Enable CoreML EP for minimal extended mode",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-06T23:56:21Z",
        "updated_at": "2021-04-09T00:45:23Z",
        "closed_at": "2021-04-09T00:45:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7266",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7266",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7266.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7266.patch",
            "merged_at": "2021-04-09T00:45:22Z"
        },
        "body": "**Description**: Enable CoreML EP for minimal extended mode\r\n\r\n**Motivation and Context**\r\n- There may be user case for iOS ORT mobile using CoreML EP\r\n- Added UT for using coreml ep in minimal build\r\n- Add missing 3rd party notice for coremltools\r\n- Not included in this PR, CI change to run CoreML EP using ORT minimal and minimal ORT document updates\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7266/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7267",
        "id": 851936117,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMjcyNzUx",
        "number": 7267,
        "title": "Add ability to allocate initialized tensor memory from non-arena memory",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-07T02:03:40Z",
        "updated_at": "2021-04-21T03:27:49Z",
        "closed_at": "2021-04-21T03:27:48Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7267",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7267",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7267.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7267.patch",
            "merged_at": "2021-04-21T03:27:48Z"
        },
        "body": "**Description**: This is part-1 (of 2 changes) requested by an internal team to keep the growth of the CUDA memory arena in check. Currently, we do not expose all the arena configuration parameters to configure the CUDA memory arena and for some models with default arena configuration, the arena could have grown quite a bit when it is done with initialized tensor memory allocation and since the arena never shrinks, the growth is permanent and this \"extra memory\" being held may or may not be used while allocating memory required to process a Run() request. The initial idea was to provide the user configuration knobs to the arena (second part of the change) so that they are able to select a \"reasonable\" initial chunk to accommodate initializers + memory required to service almost all Run requests and we can avoid arena growth altogether by tuning these knobs. But the initial chunk is shared by all the per-thread CUDA allocators and the other allocators which do not allocate initialized tensor memory need not hold such a large initial chunk forever in its life-cycle. So, the idea is to allow users to by-pass the arena when allocating initialized tensor memory and set a large enough chunk for the arena that is needed just to process each Run request (this value is common to all per-thread allocators) so that they can avoid arena growth altogether. \r\n\r\n**Motivation and Context**\r\nUsed a branch that holds 2 sets of changes that was tried by the internal team and they are happy with the logic in that branch. Splitting the changes in that branch into 2 PRs so that it is easy to review.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7267/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7268",
        "id": 852031663,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwMzUwODI5",
        "number": 7268,
        "title": "Add QGEMM benchmark",
        "user": {
            "login": "chenfucn",
            "id": 1316708,
            "node_id": "MDQ6VXNlcjEzMTY3MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1316708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chenfucn",
            "html_url": "https://github.com/chenfucn",
            "followers_url": "https://api.github.com/users/chenfucn/followers",
            "following_url": "https://api.github.com/users/chenfucn/following{/other_user}",
            "gists_url": "https://api.github.com/users/chenfucn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chenfucn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chenfucn/subscriptions",
            "organizations_url": "https://api.github.com/users/chenfucn/orgs",
            "repos_url": "https://api.github.com/users/chenfucn/repos",
            "events_url": "https://api.github.com/users/chenfucn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chenfucn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-07T05:47:49Z",
        "updated_at": "2021-04-08T03:24:51Z",
        "closed_at": "2021-04-08T03:24:50Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7268",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7268",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7268.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7268.patch",
            "merged_at": "2021-04-08T03:24:50Z"
        },
        "body": "**Description**: \r\nAdd QGEMM benchmark to measure integer gemm performance",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7268/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7269",
        "id": 852049749,
        "node_id": "MDU6SXNzdWU4NTIwNDk3NDk=",
        "number": 7269,
        "title": "Weights not correctly saved for model trained using level 3 optimizations",
        "user": {
            "login": "pranav-prakash",
            "id": 10335022,
            "node_id": "MDQ6VXNlcjEwMzM1MDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10335022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranav-prakash",
            "html_url": "https://github.com/pranav-prakash",
            "followers_url": "https://api.github.com/users/pranav-prakash/followers",
            "following_url": "https://api.github.com/users/pranav-prakash/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranav-prakash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranav-prakash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranav-prakash/subscriptions",
            "organizations_url": "https://api.github.com/users/pranav-prakash/orgs",
            "repos_url": "https://api.github.com/users/pranav-prakash/repos",
            "events_url": "https://api.github.com/users/pranav-prakash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranav-prakash/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-07T06:16:51Z",
        "updated_at": "2021-10-12T16:09:26Z",
        "closed_at": "2021-10-12T16:09:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen performing model training using [level-3 optimizations](https://github.com/microsoft/onnxruntime/blob/master/orttraining/orttraining/core/optimizer/graph_transformer_utils.cc#L200), initializer weights are changed to use e.g. nhwc or nchwc layouts. The names of these initializers [are also updated](https://github.com/microsoft/onnxruntime/blob/4bc17ca04eccfb15fa2db0b0f1b4f5bd6d369a47/onnxruntime/core/optimizer/nchwc_transformer.cc#L757)\r\n\r\nThis poses an issue because when a trained model is to be saved, the original untrained model is first loaded from disk then any initializers with matching names are copied over. With transformations that change initializer names, however, this means that the model is ultimately not saved properly.\r\n\r\n\r\nI can think of 3 possible means by which we can solve this\r\n* Prevent level 3 optimizations during training – this isn't a good solution for us because we _must_ perform training in NHWC format to make use of our accelerator\r\n* Invert the layout transform before saving - this works (and is what we plan to use as a stop-gap), but it feels like a hack since there's currently no mapping of pre-transform -> post-transform names stored, so you have to rely on checking the suffix of the name for `_nhwc`.\r\n* Perform the same layout optimization on reloaded model, so the model is ultimately saved in nchwc/nhwc format.\r\n\r\n\r\n**Urgency**\r\nNone",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7269/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7270",
        "id": 852056887,
        "node_id": "MDU6SXNzdWU4NTIwNTY4ODc=",
        "number": 7270,
        "title": "ai.onnxruntime.OrtException: This tensor is not representable in Java, it's too big",
        "user": {
            "login": "anandvsr",
            "id": 66105422,
            "node_id": "MDQ6VXNlcjY2MTA1NDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/66105422?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anandvsr",
            "html_url": "https://github.com/anandvsr",
            "followers_url": "https://api.github.com/users/anandvsr/followers",
            "following_url": "https://api.github.com/users/anandvsr/following{/other_user}",
            "gists_url": "https://api.github.com/users/anandvsr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anandvsr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anandvsr/subscriptions",
            "organizations_url": "https://api.github.com/users/anandvsr/orgs",
            "repos_url": "https://api.github.com/users/anandvsr/repos",
            "events_url": "https://api.github.com/users/anandvsr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anandvsr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1805781160,
                "node_id": "MDU6TGFiZWwxODA1NzgxMTYw",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api:Java",
                "name": "api:Java",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to the Java API"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2021-04-07T06:27:35Z",
        "updated_at": "2023-02-28T02:09:22Z",
        "closed_at": "2021-04-14T04:25:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "get `This tensor is not representable in Java, it's too big`, while inference fasterrcnn_resnet50_fpn model in onnx.\r\n\r\nexport_onnx.py (Python Source):\r\n```\r\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\r\n    x = [torch.rand(3, 1970, 1080)]\r\n    torch.onnx.export(model, x, \"faster_rcnn.onnx\", opset_version = 11)\r\n```\r\n\r\nbuild.gradle (Gradle Source):\r\n```\r\n    dependencies {\r\n          implementation group: 'com.microsoft.onnxruntime', name: 'onnxruntime', version: '1.7.0'\r\n    }\r\n```\r\n\r\nPridiction.java (Java Source):\r\n```\r\n47| try(OrtSession session = env.createSession(modelPath.toFile().getAbsolutePath(), \r\n48|                    new OrtSession.SessionOptions())) {\r\n49|\r\n50|     OnnxTensor t1 = OnnxTensor.createTensor(env, sourceData, dimensions);\r\n51|     OrtSession.Result result = session.run(Collections.singletonMap(\"image.1\", t1));\r\n52|\r\n53|     for (int i = 0; i < result.size(); i++) {\r\n54|         System.out.println(result.get(i).getValue());\r\n55|     }\r\n56|\r\n57|     result.close();\r\n58|     t1.close();\r\n59| }\r\n```\r\n\r\nException while inference:\r\n```\r\nai.onnxruntime.OrtException: This tensor is not representable in Java, it's too big - shape = [0, 4]\r\n\tat ai.onnxruntime.TensorInfo.makeCarrier(TensorInfo.java:171)\r\n\tat ai.onnxruntime.OnnxTensor.getValue(OnnxTensor.java:99)\r\n\tat onnx.predict.Pridiction.main(Pridiction.java:54)\r\n```\r\n\r\nRefered sites:\r\n```\r\n       1. https://www.onnxruntime.ai/docs/reference/api/java-api.html\r\n       2. https://pytorch.org/vision/stable/models.html#faster-r-cnn\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7270/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7271",
        "id": 852112863,
        "node_id": "MDU6SXNzdWU4NTIxMTI4NjM=",
        "number": 7271,
        "title": "Memory leak of using dynamic shapes with Openvino",
        "user": {
            "login": "ledaiduongvnth",
            "id": 28498007,
            "node_id": "MDQ6VXNlcjI4NDk4MDA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/28498007?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ledaiduongvnth",
            "html_url": "https://github.com/ledaiduongvnth",
            "followers_url": "https://api.github.com/users/ledaiduongvnth/followers",
            "following_url": "https://api.github.com/users/ledaiduongvnth/following{/other_user}",
            "gists_url": "https://api.github.com/users/ledaiduongvnth/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ledaiduongvnth/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ledaiduongvnth/subscriptions",
            "organizations_url": "https://api.github.com/users/ledaiduongvnth/orgs",
            "repos_url": "https://api.github.com/users/ledaiduongvnth/repos",
            "events_url": "https://api.github.com/users/ledaiduongvnth/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ledaiduongvnth/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1624868154,
                "node_id": "MDU6TGFiZWwxNjI0ODY4MTU0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:OpenVINO",
                "name": "ep:OpenVINO",
                "color": "0052CC",
                "default": false,
                "description": "issues related to OpenVINO execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2021-04-07T07:40:44Z",
        "updated_at": "2021-09-24T08:30:45Z",
        "closed_at": "2021-04-19T07:50:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nRun model Inference with Openvino supported causes memory leak. The issue occurs only with dynamic input shape, which is [2, 3](height, width) in my case.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu18.04\r\n- ONNX Runtime installed from source with Openvino(2021.2.200) supported\r\n- ONNX Runtime version: 1.7.1\r\n\r\n**To Reproduce**\r\nThe following code works fine without Openvino\r\n```\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <chrono>\r\n#include <string>\r\n#include <vector>\r\n#include <onnxruntime_cxx_api.h>\r\n#include <opencv2/dnn.hpp>\r\n\r\nint main(int argc, char* argv[]){\r\n    std::string modelFilepath{\"/mnt/hdd/PycharmProjects/Pytorch_Retinaface/FaceDetector.onnx\"};\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING);\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(1);\r\n    OrtOpenVINOProviderOptions options;\r\n    options.device_type = \"CPU_FP32\";\r\n    options.num_of_threads = 1;\r\n//    sessionOptions.AppendExecutionProvider_OpenVINO(options);\r\n    sessionOptions.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_DISABLE_ALL);\r\n    Ort::Session session(env, modelFilepath.c_str(), sessionOptions);\r\n\r\n    std::vector<const char*> inputNames{\"input\"};\r\n    std::vector<const char*> outputNames{\"output\", \"outputt\", \"outputtt\"};\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n\r\n    while  (true){\r\n        // Create random number between 640 and 2500\r\n        int range = 2500 - 640 + 1;\r\n        int num = rand() % range + 640;\r\n        \r\n        std::vector<int64_t> inputDims {1, 3, num, num};\r\n        cv::Mat img(num, num, CV_32FC3, cv::Scalar(113, 113, 113));\r\n        cv::dnn::blobFromImage(img, img);\r\n        Ort::Value inputTensors = Ort::Value::CreateTensor<float>(memoryInfo, (float*)img.data, num*num*3, inputDims.data(), 4);\r\n        std::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\r\n        // Run inference\r\n        std::vector<Ort::Value> ort_outputs = session.Run(Ort::RunOptions{nullptr}, inputNames.data(), &inputTensors, 1, outputNames.data(), 3);\r\n    }\r\n}\r\n```\r\nThe following code causes memory leak and warning while using with Openvino:\r\n\r\n```\r\n[WARN] 2021-04-07T07:23:07z ngraph/frontend/onnx_import/src/core/graph.cpp 98\tCould not create an nGraph Constant for initializer '678'. Detailed error:\r\nCheck 'values.size() == 1 || values.size() == shape_size(m_shape)' failed at ngraph/core/include/ngraph/op/constant.hpp:69:\r\nWhile validating node 'v0::Constant Constant_68227 () -> (f32{})' with friendly_name 'Constant_68227':\r\nDid not get the expected number of literals for a constant of shape Shape{} (got 0, expected 1).\r\n```\r\n\r\n\r\n```\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <chrono>\r\n#include <string>\r\n#include <vector>\r\n#include <onnxruntime_cxx_api.h>\r\n#include <opencv2/dnn.hpp>\r\n\r\nint main(int argc, char* argv[]){\r\n    std::string modelFilepath{\"/mnt/hdd/PycharmProjects/Pytorch_Retinaface/FaceDetector.onnx\"};\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING);\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(1);\r\n    OrtOpenVINOProviderOptions options;\r\n    options.device_type = \"CPU_FP32\";\r\n    options.num_of_threads = 1;\r\n    sessionOptions.AppendExecutionProvider_OpenVINO(options);\r\n    sessionOptions.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_DISABLE_ALL);\r\n    Ort::Session session(env, modelFilepath.c_str(), sessionOptions);\r\n\r\n    std::vector<const char*> inputNames{\"input\"};\r\n    std::vector<const char*> outputNames{\"output\", \"outputt\", \"outputtt\"};\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n\r\n    while  (true){\r\n        // Create random number between 640 and 2500\r\n        int range = 2500 - 640 + 1;\r\n        int num = rand() % range + 640;\r\n\r\n        std::vector<int64_t> inputDims {1, 3, num, num};\r\n        cv::Mat img(num, num, CV_32FC3, cv::Scalar(113, 113, 113));\r\n        cv::dnn::blobFromImage(img, img);\r\n        Ort::Value inputTensors = Ort::Value::CreateTensor<float>(memoryInfo, (float*)img.data, num*num*3, inputDims.data(), 4);\r\n        std::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\r\n        // Run inference\r\n        std::vector<Ort::Value> ort_outputs = session.Run(Ort::RunOptions{nullptr}, inputNames.data(), &inputTensors, 1, outputNames.data(), 3);\r\n    }\r\n}\r\n```\r\nModel: https://drive.google.com/file/d/1WShOvxZ7gTgZ64KSOcJ5bz9RsMaJL6Wj/view?usp=sharing",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7271/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7272",
        "id": 852202402,
        "node_id": "MDU6SXNzdWU4NTIyMDI0MDI=",
        "number": 7272,
        "title": "onnxruntime gpu version can't installed, how to fix it?",
        "user": {
            "login": "davidqing2000",
            "id": 6468219,
            "node_id": "MDQ6VXNlcjY0NjgyMTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6468219?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/davidqing2000",
            "html_url": "https://github.com/davidqing2000",
            "followers_url": "https://api.github.com/users/davidqing2000/followers",
            "following_url": "https://api.github.com/users/davidqing2000/following{/other_user}",
            "gists_url": "https://api.github.com/users/davidqing2000/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/davidqing2000/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/davidqing2000/subscriptions",
            "organizations_url": "https://api.github.com/users/davidqing2000/orgs",
            "repos_url": "https://api.github.com/users/davidqing2000/repos",
            "events_url": "https://api.github.com/users/davidqing2000/events{/privacy}",
            "received_events_url": "https://api.github.com/users/davidqing2000/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-07T09:17:20Z",
        "updated_at": "2021-08-18T17:01:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "pip3 install onnxruntime_gpu-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl\r\nonnxruntime_gpu-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl is not a supported wheel on this platform.\r\n\r\nmy linux version:\r\nLinux version 3.10.0-957.12.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Tue May 14 21:24:32 UTC 2019\r\n\r\npython version:3.6",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7272/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7273",
        "id": 852224392,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwNTEzMDYz",
        "number": 7273,
        "title": "ConvGrad CUDA Kernel Bugfix",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-04-07T09:42:15Z",
        "updated_at": "2021-04-08T03:13:10Z",
        "closed_at": "2021-04-08T00:22:19Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7273",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7273",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7273.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7273.patch",
            "merged_at": "2021-04-08T00:22:19Z"
        },
        "body": "ConvGrad CUDA kernel bugfix.\r\n\r\nThe original code will get segmentation fault when set input's requires_grad flag to False. It's possible that dX and dW is nullptr, so we can pass X and W to PrepareArgs as inside that only the shape info is needed, and they have same shapes as dX and dW.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7273/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7274",
        "id": 852464146,
        "node_id": "MDU6SXNzdWU4NTI0NjQxNDY=",
        "number": 7274,
        "title": "Couldn't install Microsoft.ML.OnnxRuntime on .net core 3.1 project with Visual Studio 2019",
        "user": {
            "login": "lomizandtyd",
            "id": 5525904,
            "node_id": "MDQ6VXNlcjU1MjU5MDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5525904?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lomizandtyd",
            "html_url": "https://github.com/lomizandtyd",
            "followers_url": "https://api.github.com/users/lomizandtyd/followers",
            "following_url": "https://api.github.com/users/lomizandtyd/following{/other_user}",
            "gists_url": "https://api.github.com/users/lomizandtyd/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lomizandtyd/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lomizandtyd/subscriptions",
            "organizations_url": "https://api.github.com/users/lomizandtyd/orgs",
            "repos_url": "https://api.github.com/users/lomizandtyd/repos",
            "events_url": "https://api.github.com/users/lomizandtyd/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lomizandtyd/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-07T14:22:18Z",
        "updated_at": "2021-04-09T08:02:01Z",
        "closed_at": "2021-04-09T08:02:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nAs titled. The response from NuGet is `System.InvalidOperationException: Unable to find metadata of Microsoft.NETCore.Platforms.1.1.0`.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Windows 10\r\n- ONNX Runtime installed from (source or binary): Nuget Package manager in Visual studio 2019 (up-to-date)\r\n- ONNX Runtime version: 1.7.0\r\n- Visual Studio version (if applicable): Visual Studio 2019, Version 16.9.3\r\n\r\n**To Reproduce**\r\n- Just create a empty project, and install Microsoft.ML.OnnxRuntime from Nuget;\r\n\r\n**Screenshots**\r\nReproduced page:\r\n![image](https://user-images.githubusercontent.com/5525904/113882146-a4a22600-97ef-11eb-93a2-3ae0ee588512.png)\r\n\r\nDetailed error message:\r\n![image](https://user-images.githubusercontent.com/5525904/113881042-a3bcc480-97ee-11eb-98ee-499d597c366a.png)\r\n\r\n**Additional context**\r\nIf changed the target framework of solution from `.Net Core 3.1` to `.Net Core 2.1`, we can install it. Then switch back to `.Net Core v3.1`. Everything works fine.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7274/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7275",
        "id": 852468580,
        "node_id": "MDU6SXNzdWU4NTI0Njg1ODA=",
        "number": 7275,
        "title": "Mention nightly builds on README.md and onnxruntime.ai main page",
        "user": {
            "login": "vadimkantorov",
            "id": 1041752,
            "node_id": "MDQ6VXNlcjEwNDE3NTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1041752?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vadimkantorov",
            "html_url": "https://github.com/vadimkantorov",
            "followers_url": "https://api.github.com/users/vadimkantorov/followers",
            "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}",
            "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions",
            "organizations_url": "https://api.github.com/users/vadimkantorov/orgs",
            "repos_url": "https://api.github.com/users/vadimkantorov/repos",
            "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vadimkantorov/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "assignees": [
            {
                "login": "faxu",
                "id": 20780999,
                "node_id": "MDQ6VXNlcjIwNzgwOTk5",
                "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/faxu",
                "html_url": "https://github.com/faxu",
                "followers_url": "https://api.github.com/users/faxu/followers",
                "following_url": "https://api.github.com/users/faxu/following{/other_user}",
                "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
                "organizations_url": "https://api.github.com/users/faxu/orgs",
                "repos_url": "https://api.github.com/users/faxu/repos",
                "events_url": "https://api.github.com/users/faxu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/faxu/received_events",
                "type": "User",
                "site_admin": true
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-07T14:26:36Z",
        "updated_at": "2023-01-20T00:13:25Z",
        "closed_at": "2023-01-19T20:21:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Currently they're only mentioned at https://www.onnxruntime.ai/docs/get-started/install.html\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7275/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7276",
        "id": 852583760,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEwODEwMDU2",
        "number": 7276,
        "title": "Fix TRT EP memory leak (#7195 revisited)",
        "user": {
            "login": "AhmadZakaria",
            "id": 774529,
            "node_id": "MDQ6VXNlcjc3NDUyOQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/774529?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AhmadZakaria",
            "html_url": "https://github.com/AhmadZakaria",
            "followers_url": "https://api.github.com/users/AhmadZakaria/followers",
            "following_url": "https://api.github.com/users/AhmadZakaria/following{/other_user}",
            "gists_url": "https://api.github.com/users/AhmadZakaria/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AhmadZakaria/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AhmadZakaria/subscriptions",
            "organizations_url": "https://api.github.com/users/AhmadZakaria/orgs",
            "repos_url": "https://api.github.com/users/AhmadZakaria/repos",
            "events_url": "https://api.github.com/users/AhmadZakaria/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AhmadZakaria/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2021-04-07T16:29:58Z",
        "updated_at": "2021-04-13T16:43:20Z",
        "closed_at": "2021-04-13T16:43:19Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7276",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7276",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7276.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7276.patch",
            "merged_at": "2021-04-13T16:43:19Z"
        },
        "body": "This PR fixes a problem with #7195.\r\nOur final solution (after discussion with @stevenlix) was keeping a pointer to trt_profile in the state struct. However, I overlooked that the pointer was passed by value, and so, it was leaked as soon it was out of scope. \r\n\r\nFixing it by passing a pointer pointer, and setting it correctly. I tested this solution to make sure it doesn't leak memory anymore. It works finally.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7276/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7277",
        "id": 852733563,
        "node_id": "MDU6SXNzdWU4NTI3MzM1NjM=",
        "number": 7277,
        "title": "Information in deleted BUILD.md left out onnxruntime.ai",
        "user": {
            "login": "jeyblu",
            "id": 63478620,
            "node_id": "MDQ6VXNlcjYzNDc4NjIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/63478620?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeyblu",
            "html_url": "https://github.com/jeyblu",
            "followers_url": "https://api.github.com/users/jeyblu/followers",
            "following_url": "https://api.github.com/users/jeyblu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeyblu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeyblu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeyblu/subscriptions",
            "organizations_url": "https://api.github.com/users/jeyblu/orgs",
            "repos_url": "https://api.github.com/users/jeyblu/repos",
            "events_url": "https://api.github.com/users/jeyblu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeyblu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1311608287,
                "node_id": "MDU6TGFiZWwxMzExNjA4Mjg3",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/documentation",
                "name": "documentation",
                "color": "1D76DB",
                "default": true,
                "description": "improvements or additions to documentation; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "natke",
                "id": 3302433,
                "node_id": "MDQ6VXNlcjMzMDI0MzM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/natke",
                "html_url": "https://github.com/natke",
                "followers_url": "https://api.github.com/users/natke/followers",
                "following_url": "https://api.github.com/users/natke/following{/other_user}",
                "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
                "organizations_url": "https://api.github.com/users/natke/orgs",
                "repos_url": "https://api.github.com/users/natke/repos",
                "events_url": "https://api.github.com/users/natke/events{/privacy}",
                "received_events_url": "https://api.github.com/users/natke/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-07T19:20:26Z",
        "updated_at": "2023-01-17T23:52:57Z",
        "closed_at": "2023-01-17T23:52:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nDocumentation on how to build the dnnl execution provider for gpu that was in BUILD.md, which was deleted in [commit c170061998e1adfb5a37dfe87d2f845b202cd348](https://github.com/microsoft/onnxruntime/commit/c170061998e1adfb5a37dfe87d2f845b202cd348), was left out in the new documentation [page](https://www.onnxruntime.ai/docs/how-to/build.html#dnnl-and-mklml-1)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7277/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7278",
        "id": 852833515,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMDI1MTU1",
        "number": 7278,
        "title": "Restrict ConvGrad to __CUDA_ARCH__>=700",
        "user": {
            "login": "SherlockNoMad",
            "id": 9906745,
            "node_id": "MDQ6VXNlcjk5MDY3NDU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9906745?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SherlockNoMad",
            "html_url": "https://github.com/SherlockNoMad",
            "followers_url": "https://api.github.com/users/SherlockNoMad/followers",
            "following_url": "https://api.github.com/users/SherlockNoMad/following{/other_user}",
            "gists_url": "https://api.github.com/users/SherlockNoMad/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SherlockNoMad/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SherlockNoMad/subscriptions",
            "organizations_url": "https://api.github.com/users/SherlockNoMad/orgs",
            "repos_url": "https://api.github.com/users/SherlockNoMad/repos",
            "events_url": "https://api.github.com/users/SherlockNoMad/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SherlockNoMad/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "liqunfu",
            "id": 3318051,
            "node_id": "MDQ6VXNlcjMzMTgwNTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3318051?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/liqunfu",
            "html_url": "https://github.com/liqunfu",
            "followers_url": "https://api.github.com/users/liqunfu/followers",
            "following_url": "https://api.github.com/users/liqunfu/following{/other_user}",
            "gists_url": "https://api.github.com/users/liqunfu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/liqunfu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/liqunfu/subscriptions",
            "organizations_url": "https://api.github.com/users/liqunfu/orgs",
            "repos_url": "https://api.github.com/users/liqunfu/repos",
            "events_url": "https://api.github.com/users/liqunfu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/liqunfu/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "liqunfu",
                "id": 3318051,
                "node_id": "MDQ6VXNlcjMzMTgwNTE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3318051?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/liqunfu",
                "html_url": "https://github.com/liqunfu",
                "followers_url": "https://api.github.com/users/liqunfu/followers",
                "following_url": "https://api.github.com/users/liqunfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/liqunfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/liqunfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/liqunfu/subscriptions",
                "organizations_url": "https://api.github.com/users/liqunfu/orgs",
                "repos_url": "https://api.github.com/users/liqunfu/repos",
                "events_url": "https://api.github.com/users/liqunfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/liqunfu/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-07T21:31:10Z",
        "updated_at": "2021-04-08T03:10:30Z",
        "closed_at": "2021-04-08T03:10:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7278",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7278",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7278.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7278.patch",
            "merged_at": "2021-04-08T03:10:29Z"
        },
        "body": "ConvGrad is not yet tested on non-V100 device. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7278/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7279",
        "id": 852921832,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMTAzNzc4",
        "number": 7279,
        "title": "NCHWc: avoid buffer reordering around Add nodes",
        "user": {
            "login": "tracysh",
            "id": 42477615,
            "node_id": "MDQ6VXNlcjQyNDc3NjE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/42477615?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tracysh",
            "html_url": "https://github.com/tracysh",
            "followers_url": "https://api.github.com/users/tracysh/followers",
            "following_url": "https://api.github.com/users/tracysh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tracysh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tracysh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tracysh/subscriptions",
            "organizations_url": "https://api.github.com/users/tracysh/orgs",
            "repos_url": "https://api.github.com/users/tracysh/repos",
            "events_url": "https://api.github.com/users/tracysh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tracysh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-07T23:36:27Z",
        "updated_at": "2021-04-10T19:21:38Z",
        "closed_at": "2021-04-08T16:57:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7279",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7279",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7279.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7279.patch",
            "merged_at": "2021-04-08T16:57:24Z"
        },
        "body": "**Description**: The NCHWc optimizer currently uses various source of shape data to recognize if the tensors from Add(A,B) have the identical shape. If they do, then the Add can use the NCHWc data from A and B directly. There are cases when the input shape is dynamic that the optimizer cannot verify at model load time that the shapes are identical: for example, a segment using Conv with strides[2,2] and then doing 2x upsampling. With this combination, if the input shape is too small, then the height/width can stick to 1 and should then be a broadcast.\r\n\r\nTo make Add work without needing expensive reorders, the optimizer now inserts Reshape nodes around the Add so that Add sees the true [N][C][H][W][c] tensor shape. The optimizer still requires that both inputs to the Add are NCHWc and the channel count must match but N/H/W can be flexible.\r\n\r\nNow this particular optimization could support Mul as well. This comes up in models such as SENets where a matrix is transformed to a vector that is then multiplied with the original matrix. Doing this optimization now results in a performance loss because Mul is unable to broadcast the [c] vector compared to the reordered NCHW output where it could hit the scalar broadcast path for a given channel. This particular pattern could be handled better with a dedicated nchwc.Scale op to do the matrix/vector multiplication. Not needed yet.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7279/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7280",
        "id": 852949480,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMTI2ODMz",
        "number": 7280,
        "title": "[java] Fix codeql warning",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-08T00:40:05Z",
        "updated_at": "2021-04-08T18:08:13Z",
        "closed_at": "2021-04-08T18:08:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7280",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7280",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7280.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7280.patch",
            "merged_at": "2021-04-08T18:08:13Z"
        },
        "body": "**Description**: [java] Fix codeql warning\r\n\r\n**Motivation and Context**\r\n- Scan using codeql on ort java api, base on the requirements of Microsoft 1CS for shipping Android java package\r\n- Here are the 1 warning and 1 recommendation\r\n```\r\n\"Unread local variable\",\"A local variable that is never read is redundant.\",\"recommendation\",\"Variable 'int bufferSize' is never read.\",\"/java/src/main/java/ai/onnxruntime/OnnxTensor.java\",\"561\",\"7\",\"561\",\"39\"\r\n\"Dereferenced variable may be null\",\"Dereferencing a variable whose value may be 'null' may cause a 'NullPointerException'.\",\"warning\",\"Variable [[\"\"tempDirectory\"\"|\"\"relative:///java/src/main/java/ai/onnxruntime/OnnxRuntime.java:94:5:94:92\"\"]] may be null here because of [[\"\"this\"\"|\"\"relative:///java/src/main/java/ai/onnxruntime/OnnxRuntime.java:94:10:94:91\"\"]] assignment.\",\"/java/src/main/java/ai/onnxruntime/OnnxRuntime.java\",\"103\",\"17\",\"103\",\"29\"\r\n```\r\n- Fix the warning and the recommandation\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7280/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7281",
        "id": 852957024,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMTMyNTI4",
        "number": 7281,
        "title": "Narrow profiling scope",
        "user": {
            "login": "RandySheriffH",
            "id": 48490400,
            "node_id": "MDQ6VXNlcjQ4NDkwNDAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/48490400?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RandySheriffH",
            "html_url": "https://github.com/RandySheriffH",
            "followers_url": "https://api.github.com/users/RandySheriffH/followers",
            "following_url": "https://api.github.com/users/RandySheriffH/following{/other_user}",
            "gists_url": "https://api.github.com/users/RandySheriffH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RandySheriffH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RandySheriffH/subscriptions",
            "organizations_url": "https://api.github.com/users/RandySheriffH/orgs",
            "repos_url": "https://api.github.com/users/RandySheriffH/repos",
            "events_url": "https://api.github.com/users/RandySheriffH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RandySheriffH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-08T01:00:49Z",
        "updated_at": "2021-04-09T00:47:18Z",
        "closed_at": "2021-04-09T00:47:18Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7281",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7281",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7281.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7281.patch",
            "merged_at": "2021-04-09T00:47:18Z"
        },
        "body": "Collecting op end time earlier to avoid noise generated by thread pool profiler.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7281/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7282",
        "id": 853052736,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMjAzMzcw",
        "number": 7282,
        "title": "Support symbolic shape inference flag for dynamic shape input",
        "user": {
            "login": "ytaous",
            "id": 4484531,
            "node_id": "MDQ6VXNlcjQ0ODQ1MzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4484531?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ytaous",
            "html_url": "https://github.com/ytaous",
            "followers_url": "https://api.github.com/users/ytaous/followers",
            "following_url": "https://api.github.com/users/ytaous/following{/other_user}",
            "gists_url": "https://api.github.com/users/ytaous/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ytaous/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ytaous/subscriptions",
            "organizations_url": "https://api.github.com/users/ytaous/orgs",
            "repos_url": "https://api.github.com/users/ytaous/repos",
            "events_url": "https://api.github.com/users/ytaous/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ytaous/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-08T04:42:30Z",
        "updated_at": "2021-04-08T16:47:10Z",
        "closed_at": "2021-04-08T16:47:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7282",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7282",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7282.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7282.patch",
            "merged_at": "2021-04-08T16:47:09Z"
        },
        "body": "**Description**: For the models with dynamic shape inputs, we are experiencing long latency due to many extra ReduceSum D2D memcpy. The graph is not fully optimized due to lack of shape information. Back in orttrainer, we used to have a flag to enable symbolic shape inference. But the flag is not part of today's ORTModule. After test it with the flag enabled, the model graph is further optimized, with the elimination of D2D memcpy. And we see ~ 7%+ gain in training speed. Thus reenable the support of the flag.\r\n\r\nSample graph output with all the shapes populated \r\n![image](https://user-images.githubusercontent.com/9906745/113970669-21cb9c00-97ec-11eb-9635-9276cec1da2f.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7282/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7283",
        "id": 853074278,
        "node_id": "MDU6SXNzdWU4NTMwNzQyNzg=",
        "number": 7283,
        "title": "Question about quantization of Yolo.",
        "user": {
            "login": "Kentaro-Mikami",
            "id": 81408025,
            "node_id": "MDQ6VXNlcjgxNDA4MDI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/81408025?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Kentaro-Mikami",
            "html_url": "https://github.com/Kentaro-Mikami",
            "followers_url": "https://api.github.com/users/Kentaro-Mikami/followers",
            "following_url": "https://api.github.com/users/Kentaro-Mikami/following{/other_user}",
            "gists_url": "https://api.github.com/users/Kentaro-Mikami/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Kentaro-Mikami/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Kentaro-Mikami/subscriptions",
            "organizations_url": "https://api.github.com/users/Kentaro-Mikami/orgs",
            "repos_url": "https://api.github.com/users/Kentaro-Mikami/repos",
            "events_url": "https://api.github.com/users/Kentaro-Mikami/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Kentaro-Mikami/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "yufenglee",
                "id": 30486710,
                "node_id": "MDQ6VXNlcjMwNDg2NzEw",
                "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/yufenglee",
                "html_url": "https://github.com/yufenglee",
                "followers_url": "https://api.github.com/users/yufenglee/followers",
                "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
                "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
                "organizations_url": "https://api.github.com/users/yufenglee/orgs",
                "repos_url": "https://api.github.com/users/yufenglee/repos",
                "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
                "received_events_url": "https://api.github.com/users/yufenglee/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-08T05:25:33Z",
        "updated_at": "2021-05-14T20:54:56Z",
        "closed_at": "2021-05-14T20:54:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nWe checked quantization example for Yolo network.\r\nThis example show the way by combination TensorRT and Onnx runtime.\r\nhttps://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/quantization/E2E_example_model/object_detection/trt/yolov3\r\n\r\nAlthough we can use \"quantize_dynamic\" or \"quantize_static\" for classification network,\r\nDo we need to use the combination TensorRT and Onnx runtime?\r\nOr can we use \"quantize_dynamic\" or \"quantize_static\" for Yolo network also?\r\n\r\n**System information**\r\n- ONNX Runtime version (you are using):1.7.0",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7283/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7284",
        "id": 853106298,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMjQ4MzY0",
        "number": 7284,
        "title": "Add ability for memory arenas to \"shrink\" periodically",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-08T06:18:37Z",
        "updated_at": "2021-05-08T14:53:22Z",
        "closed_at": "2021-05-08T14:53:21Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7284",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7284",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7284.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7284.patch",
            "merged_at": "2021-05-08T14:53:21Z"
        },
        "body": "**Description**:\r\nThis is part 2 of changes continuing from https://github.com/microsoft/onnxruntime/pull/7267.\r\n\r\nThis change contains 2 major sub-changes:\r\n\r\n1) Expose an interface for an end-user to configure the default memory arena associated with the CUDA EP. The scope of this change itself is limited to only supporting configuration of the **default** memory arena of the CUDA EP (i.e.) other related arena based allocators such as CUDAPinned and CUDA_CPU associated with the CUDA EP are not configurable just yet (and it may not be needed as well). We will re-visit if they needed to be configured later.\r\n\r\n2) Expose a flag in the arena configuration struct that can be set by the user so as to potentially \"shrink\" the arena on some cadence (the supported cadence is on every Run() end for now). This feature was requested by an internal team who want to set the initial chunk size for the arena that can be used to service most of the Run requests. But they are planning to host a dynamic shape sequence model that can occasionally process a very large sequence which triggers arena growth and this growth with the current logic will be held on forever.\r\nIn the shrink logic, we poll all allocations made by the device allocator (except the initial allocations) and if any of the allocations are unused, de-allocate them (thus \"shrinking\" the arena) and perform the associated book-keeping in the arena. Currently, the possibility of \"shrinking\" the arena is limited to just the **default** memory arena of the CUDA EP.\r\nThe pro of the arena shrinkage logic is that it can keep the arena growth checked. The con of the arena shrinkage is the de-allocation cost and re-allocation cost (for future requests that need more memory). It is left to the user to weigh the trade-offs involved and choose appropriately.\r\n\r\n**Motivation and Context**\r\nThis feature has been tested by an internal team - formalizing the changes in the test branch into a PR for review.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7284/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7285",
        "id": 853181206,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExMzExMjgx",
        "number": 7285,
        "title": "[Symbolic shape infer] fix scalar shape in Expand",
        "user": {
            "login": "ke1337",
            "id": 22626095,
            "node_id": "MDQ6VXNlcjIyNjI2MDk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/22626095?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ke1337",
            "html_url": "https://github.com/ke1337",
            "followers_url": "https://api.github.com/users/ke1337/followers",
            "following_url": "https://api.github.com/users/ke1337/following{/other_user}",
            "gists_url": "https://api.github.com/users/ke1337/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ke1337/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ke1337/subscriptions",
            "organizations_url": "https://api.github.com/users/ke1337/orgs",
            "repos_url": "https://api.github.com/users/ke1337/repos",
            "events_url": "https://api.github.com/users/ke1337/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ke1337/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-08T07:53:17Z",
        "updated_at": "2021-04-08T17:26:30Z",
        "closed_at": "2021-04-08T17:26:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7285",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7285",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7285.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7285.patch",
            "merged_at": "2021-04-08T17:26:29Z"
        },
        "body": "**Description**: Fixes for a model when Expand shape is scalar\r\n\r\n**Motivation and Context**\r\n- Without the fix, symbolic shape inference would throw error",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7285/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7286",
        "id": 853555778,
        "node_id": "MDU6SXNzdWU4NTM1NTU3Nzg=",
        "number": 7286,
        "title": "Memory leaks and valgrind errors when running with TensorRT",
        "user": {
            "login": "matthill",
            "id": 508260,
            "node_id": "MDQ6VXNlcjUwODI2MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/508260?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/matthill",
            "html_url": "https://github.com/matthill",
            "followers_url": "https://api.github.com/users/matthill/followers",
            "following_url": "https://api.github.com/users/matthill/following{/other_user}",
            "gists_url": "https://api.github.com/users/matthill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/matthill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/matthill/subscriptions",
            "organizations_url": "https://api.github.com/users/matthill/orgs",
            "repos_url": "https://api.github.com/users/matthill/repos",
            "events_url": "https://api.github.com/users/matthill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/matthill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2204061391,
                "node_id": "MDU6TGFiZWwyMjA0MDYxMzkx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:TensorRT",
                "name": "ep:TensorRT",
                "color": "0052CC",
                "default": false,
                "description": "issues related to TensorRT execution provider"
            },
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "chilo-ms",
            "id": 54722500,
            "node_id": "MDQ6VXNlcjU0NzIyNTAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chilo-ms",
            "html_url": "https://github.com/chilo-ms",
            "followers_url": "https://api.github.com/users/chilo-ms/followers",
            "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
            "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
            "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
            "repos_url": "https://api.github.com/users/chilo-ms/repos",
            "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "chilo-ms",
                "id": 54722500,
                "node_id": "MDQ6VXNlcjU0NzIyNTAw",
                "avatar_url": "https://avatars.githubusercontent.com/u/54722500?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/chilo-ms",
                "html_url": "https://github.com/chilo-ms",
                "followers_url": "https://api.github.com/users/chilo-ms/followers",
                "following_url": "https://api.github.com/users/chilo-ms/following{/other_user}",
                "gists_url": "https://api.github.com/users/chilo-ms/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/chilo-ms/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/chilo-ms/subscriptions",
                "organizations_url": "https://api.github.com/users/chilo-ms/orgs",
                "repos_url": "https://api.github.com/users/chilo-ms/repos",
                "events_url": "https://api.github.com/users/chilo-ms/events{/privacy}",
                "received_events_url": "https://api.github.com/users/chilo-ms/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-08T14:50:07Z",
        "updated_at": "2022-12-12T14:28:28Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nRunning inference either with address sanitization enabled or under Valgrind using TensorRT produces a number of Valgrind errors (a few memory leaks on initialization/destruction, a number of mismatched delete/delete[], and uninitilized values)\r\n\r\n**Urgency**\r\nnone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04, 18.04, Jetson\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: tested on 1.5.2 and 1.7.1\r\n- Python version: none\r\n- Visual Studio version (if applicable): none\r\n- GCC/Compiler version (if compiling from source): 9.3\r\n- CUDA/cuDNN version: 11 / 7.1\r\n- GPU model and memory: RTX 2080, Jetson Tx-2\r\n\r\n**To Reproduce**\r\nCompile software using ONNXRuntime with TensorRT.  In this case, the model uses a dynamic batch size. \r\nEither enable address sanitization on the compile, or run under valgrind\r\nvalgrind --leak-check=full --show-posssibly-lost=no [binary]\r\n\r\n**Expected behavior**\r\nOutput should be clean\r\n\r\n**Additional context**\r\n\r\n==132002== LEAK SUMMARY:\r\n==132002==    definitely lost: 96 bytes in 2 blocks\r\n==132002==    indirectly lost: 48 bytes in 2 blocks\r\n\r\n==132002== 72 (48 direct, 24 indirect) bytes in 1 blocks are definitely lost in loss record 3,517 of 5,620\r\n==132002==    at 0x483CFE3: operator new(unsigned long) (vg_replace_malloc.c:417)\r\n==132002==    by 0x10C5E5BAB: createInferRuntime_INTERNAL (in /usr/lib/libnvinfer.so.7.1.3)\r\n==132002==    by 0xFF027C51: nvinfer1::(anonymous namespace)::createInferRuntime(nvinfer1::ILogger&) (NvInferRuntime.h:1906)\r\n==132002==    by 0xFF02A191: onnxruntime::TensorrtExecutionProvider::TensorrtExecutionProvider(onnxruntime::TensorrtExecutionProviderInfo const&) (tensorrt_execution_provider.cc:226)\r\n==132002==    by 0xFF074DBF: std::_MakeUniq<onnxruntime::TensorrtExecutionProvider>::__single_object std::make_unique<onnxruntime::TensorrtExecutionProvider, onnxruntime::TensorrtExecutionProviderInfo&>(onnxruntime::TensorrtExecutionProviderInfo&) (unique_ptr.h:857)\r\n==132002==    by 0xFF074C66: onnxruntime::TensorrtProviderFactory::CreateProvider() (tensorrt_provider_factory.cc:28)\r\n==132002==    by 0x6740220: onnxruntime::IExecutionProviderFactory_Translator::CreateProvider() (provider_bridge_ort.cc:709)\r\n==132002==    by 0x590B690: (anonymous namespace)::InitializeSession(OrtSessionOptions const*, std::unique_ptr<onnxruntime::InferenceSession, std::default_delete<onnxruntime::InferenceSession> >&) (onnxruntime_c_api.cc:457)\r\n==132002==    by 0x590BCC0: OrtApis::CreateSessionFromArray(OrtEnv const*, void const*, unsigned long, OrtSessionOptions const*, OrtSession**) (onnxruntime_c_api.cc:508)\r\n\r\n==132002== 72 (48 direct, 24 indirect) bytes in 1 blocks are definitely lost in loss record 3,516 of 5,620\r\n==132002==    at 0x483CFE3: operator new(unsigned long) (vg_replace_malloc.c:417)\r\n==132002==    by 0x10C5E5BAB: createInferRuntime_INTERNAL (in /usr/lib/libnvinfer.so.7.1.3)\r\n==132002==    by 0xFF027C51: nvinfer1::(anonymous namespace)::createInferRuntime(nvinfer1::ILogger&) (NvInferRuntime.h:1906)\r\n==132002==    by 0xFF02A191: onnxruntime::TensorrtExecutionProvider::TensorrtExecutionProvider(onnxruntime::TensorrtExecutionProviderInfo const&) (tensorrt_execution_provider.cc:226)\r\n==132002==    by 0xFF074DBF: std::_MakeUniq<onnxruntime::TensorrtExecutionProvider>::__single_object std::make_unique<onnxruntime::TensorrtExecutionProvider, onnxruntime::TensorrtExecutionProviderInfo&>(onnxruntime::TensorrtExecutionProviderInfo&) (unique_ptr.h:857)\r\n==132002==    by 0xFF074C66: onnxruntime::TensorrtProviderFactory::CreateProvider() (tensorrt_provider_factory.cc:28)\r\n==132002==    by 0x6740220: onnxruntime::IExecutionProviderFactory_Translator::CreateProvider() (provider_bridge_ort.cc:709)\r\n==132002==    by 0x590B690: (anonymous namespace)::InitializeSession(OrtSessionOptions const*, std::unique_ptr<onnxruntime::InferenceSession, std::default_delete<onnxruntime::InferenceSession> >&) (onnxruntime_c_api.cc:457)\r\n==132002==    by 0x590BCC0: OrtApis::CreateSessionFromArray(OrtEnv const*, void const*, unsigned long, OrtSessionOptions const*, OrtSession**) (onnxruntime_c_api.cc:508)\r\n\r\n\r\n==132002== Conditional jump or move depends on uninitialised value(s)\r\n==132002==    at 0xD4347DC7: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4337142: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4208565: cudnnReduceTensor (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0x5AE3227: onnxruntime::common::Status onnxruntime::cuda::ReduceComputeCore<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::CUDAExecutionProvider&, onnxruntime::Tensor const&, onnxruntime::cuda::PrepareReduceMetadata&, onnxruntime::Tensor&, cudnnReduceTensorOp_t, std::vector<long, std::allocator<long> > const&, bool, bool, bool, bool, onnxruntime::TensorShape const*) (reduction_ops.cc:597)\r\n==132002==    by 0x5ADECF9: onnxruntime::common::Status onnxruntime::cuda::ReduceKernel<false>::ComputeImpl<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::OpKernelContext*, cudnnReduceTensorOp_t) const (reduction_ops.cc:636)\r\n==132002==    by 0x5ADDFF5: onnxruntime::cuda::ArgMax<float>::ComputeInternal(onnxruntime::OpKernelContext*) const (reduction_ops.h:97)\r\n==132002==    by 0x59F20A0: onnxruntime::cuda::CudaKernel::Compute(onnxruntime::OpKernelContext*) const (cuda_common.h:66)\r\n==132002==    by 0x67A90D3: onnxruntime::SequentialExecutor::Execute(onnxruntime::SessionState const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, std::unordered_map<unsigned long, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)>, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)> > > > const&, onnxruntime::logging::Logger const&) (sequential_executor.cc:305)\r\n\r\n==132002== Conditional jump or move depends on uninitialised value(s)\r\n==132002==    at 0xD4347D20: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4337142: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4208565: cudnnReduceTensor (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0x5AE3227: onnxruntime::common::Status onnxruntime::cuda::ReduceComputeCore<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::CUDAExecutionProvider&, onnxruntime::Tensor const&, onnxruntime::cuda::PrepareReduceMetadata&, onnxruntime::Tensor&, cudnnReduceTensorOp_t, std::vector<long, std::allocator<long> > const&, bool, bool, bool, bool, onnxruntime::TensorShape const*) (reduction_ops.cc:597)\r\n==132002==    by 0x5ADECF9: onnxruntime::common::Status onnxruntime::cuda::ReduceKernel<false>::ComputeImpl<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::OpKernelContext*, cudnnReduceTensorOp_t) const (reduction_ops.cc:636)\r\n==132002==    by 0x5ADDFF5: onnxruntime::cuda::ArgMax<float>::ComputeInternal(onnxruntime::OpKernelContext*) const (reduction_ops.h:97)\r\n==132002==    by 0x59F20A0: onnxruntime::cuda::CudaKernel::Compute(onnxruntime::OpKernelContext*) const (cuda_common.h:66)\r\n==132002==    by 0x67A90D3: onnxruntime::SequentialExecutor::Execute(onnxruntime::SessionState const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, std::unordered_map<unsigned long, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)>, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)> > > > const&, onnxruntime::logging::Logger const&) (sequential_executor.cc:305)\r\n==132002==    by 0x678EE21: onnxruntime::utils::ExecuteGraphImpl(onnxruntime::SessionState const&, onnxruntime::FeedsFetchesManager const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, std::unordered_map<unsigned long, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)>, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)> > > > const&, ExecutionMode, bool const&, onnxruntime::logging::Logger const&, bool) (utils.cc:492)\r\n==132002==    by 0x678F277: onnxruntime::utils::ExecuteGraph(onnxruntime::SessionState const&, onnxruntime::FeedsFetchesManager&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, ExecutionMode, bool const&, onnxruntime::logging::Logger const&, bool) (utils.cc:516)\r\n==132002==    by 0x598BB3B: onnxruntime::InferenceSession::Run(OrtRunOptions const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<OrtValue, std::allocator<OrtValue> >*, std::vector<OrtDevice, std::allocator<OrtDevice> > const*) (inference_session.cc:1464)\r\n\r\n\r\n==132002== Conditional jump or move depends on uninitialised value(s)\r\n==132002==    at 0xD4347B1F: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4337142: ??? (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0xD4208565: cudnnReduceTensor (in /usr/lib/libcudnn_ops_infer.so.8.0.4)\r\n==132002==    by 0x5AE3227: onnxruntime::common::Status onnxruntime::cuda::ReduceComputeCore<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::CUDAExecutionProvider&, onnxruntime::Tensor const&, onnxruntime::cuda::PrepareReduceMetadata&, onnxruntime::Tensor&, cudnnReduceTensorOp_t, std::vector<long, std::allocator<long> > const&, bool, bool, bool, bool, onnxruntime::TensorShape const*) (reduction_ops.cc:597)\r\n==132002==    by 0x5ADECF9: onnxruntime::common::Status onnxruntime::cuda::ReduceKernel<false>::ComputeImpl<float, (cudnnReduceTensorIndices_t)1>(onnxruntime::OpKernelContext*, cudnnReduceTensorOp_t) const (reduction_ops.cc:636)\r\n==132002==    by 0x5ADDFF5: onnxruntime::cuda::ArgMax<float>::ComputeInternal(onnxruntime::OpKernelContext*) const (reduction_ops.h:97)\r\n==132002==    by 0x59F20A0: onnxruntime::cuda::CudaKernel::Compute(onnxruntime::OpKernelContext*) const (cuda_common.h:66)\r\n==132002==    by 0x67A90D3: onnxruntime::SequentialExecutor::Execute(onnxruntime::SessionState const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, std::unordered_map<unsigned long, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)>, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)> > > > const&, onnxruntime::logging::Logger const&) (sequential_executor.cc:305)\r\n\r\n\r\n==132002== Mismatched free() / delete / delete []\r\n==132002==    at 0x484065D: operator delete[](void*) (vg_replace_malloc.c:938)\r\n==132002==    by 0x673D0B2: onnxruntime::ProviderHostImpl::HeapFree(void*) (provider_bridge_ort.cc:296)\r\n==132002==    by 0xFF01B3F5: operator delete(void*) (provider_bridge_provider.cc:49)\r\n==132002==    by 0xFF2BCC2F: std::experimental::filesystem::v1::__cxx11::path::_Cmpt& std::vector<std::experimental::filesystem::v1::__cxx11::path::_Cmpt, std::allocator<std::experimental::filesystem::v1::__cxx11::path::_Cmpt> >::emplace_back<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::experimental::filesystem::v1::__cxx11::path::_Type, unsigned long&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&, std::experimental::filesystem::v1::__cxx11::path::_Type&&, unsigned long&) (in /storage/projects/alpr/modules/libonnxruntime/build/Linux/Debug/libonnxruntime_providers_tensorrt.so)\r\n==132002==    by 0xFF2BCE35: std::experimental::filesystem::v1::__cxx11::path::_M_add_filename(unsigned long, unsigned long) (in /storage/projects/alpr/modules/libonnxruntime/build/Linux/Debug/libonnxruntime_providers_tensorrt.so)\r\n==132002==    by 0xFF2BC211: std::experimental::filesystem::v1::__cxx11::path::_M_split_cmpts() (in /storage/projects/alpr/modules/libonnxruntime/build/Linux/Debug/libonnxruntime_providers_tensorrt.so)\r\n==132002==    by 0xFF02817F: std::experimental::filesystem::v1::__cxx11::path::_M_append(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (fs_path.h:437)\r\n==132002==    by 0xFF039980: std::enable_if<std::__and_<std::__not_<std::is_same<std::remove_cv<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::type, std::experimental::filesystem::v1::__cxx11::path> >, std::__not_<std::is_void<std::remove_pointer<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::type> >, std::experimental::filesystem::v1::__cxx11::path::__constructible_from<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void> >::value, std::experimental::filesystem::v1::__cxx11::path>::type& std::experimental::filesystem::v1::__cxx11::path::append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (fs_path.h:273)\r\n==132002==    by 0xFF02833D: (anonymous namespace)::GetEnginePath(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (tensorrt_execution_provider.cc:41)\r\n==132002==    by 0xFF032B0E: onnxruntime::TensorrtExecutionProvider::Provider_Compile(std::vector<onnxruntime::Provider_Node*, std::allocator<onnxruntime::Provider_Node*> > const&, std::vector<onnxruntime::NodeComputeInfo, std::allocator<onnxruntime::NodeComputeInfo> >&)::{lambda(void*, OrtApi const*, OrtKernelContext*)#3}::operator()(void*, OrtApi const*, OrtKernelContext*) const (tensorrt_execution_provider.cc:1052)\r\n==132002==    by 0xFF055D62: std::_Function_handler<onnxruntime::common::Status (void*, OrtApi const*, OrtKernelContext*), onnxruntime::TensorrtExecutionProvider::Provider_Compile(std::vector<onnxruntime::Provider_Node*, std::allocator<onnxruntime::Provider_Node*> > const&, std::vector<onnxruntime::NodeComputeInfo, std::allocator<onnxruntime::NodeComputeInfo> >&)::{lambda(void*, OrtApi const*, OrtKernelContext*)#3}>::_M_invoke(std::_Any_data const&, void*&&, OrtApi const*&&, OrtKernelContext*&&) (std_function.h:286)\r\n==132002==    by 0x6718F60: std::function<onnxruntime::common::Status (void*, OrtApi const*, OrtKernelContext*)>::operator()(void*, OrtApi const*, OrtKernelContext*) const (std_function.h:688)\r\n==132002==  Address 0x1305056e0 is 0 bytes inside a block of size 95 alloc'd\r\n==132002==    at 0x483CFE3: operator new(unsigned long) (vg_replace_malloc.c:417)\r\n==132002==    by 0xFF0563E2: void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char const*>(char const*, char const*, std::forward_iterator_tag) (basic_string.tcc:219)\r\n==132002==    by 0xFF2BCE20: std::experimental::filesystem::v1::__cxx11::path::_M_add_filename(unsigned long, unsigned long) (in /storage/projects/alpr/modules/libonnxruntime/build/Linux/Debug/libonnxruntime_providers_tensorrt.so)\r\n==132002==    by 0xFF2BC211: std::experimental::filesystem::v1::__cxx11::path::_M_split_cmpts() (in /storage/projects/alpr/modules/libonnxruntime/build/Linux/Debug/libonnxruntime_providers_tensorrt.so)\r\n==132002==    by 0xFF02817F: std::experimental::filesystem::v1::__cxx11::path::_M_append(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (fs_path.h:437)\r\n==132002==    by 0xFF039980: std::enable_if<std::__and_<std::__not_<std::is_same<std::remove_cv<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::type, std::experimental::filesystem::v1::__cxx11::path> >, std::__not_<std::is_void<std::remove_pointer<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::type> >, std::experimental::filesystem::v1::__cxx11::path::__constructible_from<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, void> >::value, std::experimental::filesystem::v1::__cxx11::path>::type& std::experimental::filesystem::v1::__cxx11::path::append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (fs_path.h:273)\r\n==132002==    by 0xFF02833D: (anonymous namespace)::GetEnginePath(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (tensorrt_execution_provider.cc:41)\r\n==132002==    by 0xFF032B0E: onnxruntime::TensorrtExecutionProvider::Provider_Compile(std::vector<onnxruntime::Provider_Node*, std::allocator<onnxruntime::Provider_Node*> > const&, std::vector<onnxruntime::NodeComputeInfo, std::allocator<onnxruntime::NodeComputeInfo> >&)::{lambda(void*, OrtApi const*, OrtKernelContext*)#3}::operator()(void*, OrtApi const*, OrtKernelContext*) const (tensorrt_execution_provider.cc:1052)\r\n==132002==    by 0xFF055D62: std::_Function_handler<onnxruntime::common::Status (void*, OrtApi const*, OrtKernelContext*), onnxruntime::TensorrtExecutionProvider::Provider_Compile(std::vector<onnxruntime::Provider_Node*, std::allocator<onnxruntime::Provider_Node*> > const&, std::vector<onnxruntime::NodeComputeInfo, std::allocator<onnxruntime::NodeComputeInfo> >&)::{lambda(void*, OrtApi const*, OrtKernelContext*)#3}>::_M_invoke(std::_Any_data const&, void*&&, OrtApi const*&&, OrtKernelContext*&&) (std_function.h:286)\r\n==132002==    by 0x6718F60: std::function<onnxruntime::common::Status (void*, OrtApi const*, OrtKernelContext*)>::operator()(void*, OrtApi const*, OrtKernelContext*) const (std_function.h:688)\r\n==132002==    by 0x6716B54: onnxruntime::FunctionKernel::Compute(onnxruntime::OpKernelContext*) const (func_kernel.h:41)\r\n==132002==    by 0x67A90D3: onnxruntime::SequentialExecutor::Execute(onnxruntime::SessionState const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> > const&, std::vector<int, std::allocator<int> > const&, std::vector<OrtValue, std::allocator<OrtValue> >&, std::unordered_map<unsigned long, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)>, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::function<onnxruntime::common::Status (onnxruntime::TensorShape const&, OrtMemoryInfo const&, OrtValue&, bool&)> > > > const&, onnxruntime::logging::Logger const&) (sequential_executor.cc:305)\r\n\r\n==132002== Mismatched free() / delete / delete []\r\n==132002==    at 0x483F651: operator delete(void*) (vg_replace_malloc.c:802)\r\n==132002==    by 0x59EAA8D: __gnu_cxx::new_allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > >::deallocate(std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >*, unsigned long) (new_allocator.h:128)\r\n==132002==    by 0x59E70D7: std::allocator_traits<std::allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > > >::deallocate(std::allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > >&, std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >*, unsigned long) (alloc_traits.h:470)\r\n==132002==    by 0x59E326D: std::_Vector_base<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >, std::allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > > >::_M_deallocate(std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >*, unsigned long) (stl_vector.h:351)\r\n==132002==    by 0x59DF6AD: std::_Vector_base<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >, std::allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > > >::~_Vector_base() (stl_vector.h:332)\r\n==132002==    by 0x59DF702: std::vector<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> >, std::allocator<std::unique_ptr<onnxruntime::ComputeCapability, std::default_delete<onnxruntime::ComputeCapability> > > >::~vector() (stl_vector.h:680)\r\n==132002==    by 0x67180E9: onnxruntime::GraphPartitioner::Partition(onnxruntime::Graph&, bool, onnxruntime::FuncManager&) const (graph_partitioner.cc:179)\r\n==132002==    by 0x5985600: onnxruntime::InferenceSession::TransformGraph(onnxruntime::Graph&, onnxruntime::GraphTransformerManager const&, onnxruntime::ExecutionProviders const&, onnxruntime::KernelRegistryManager&, onnxruntime::InsertCastTransformer const&, onnxruntime::SessionState&) (inference_session.cc:803)\r\n==132002==    by 0x59885EB: onnxruntime::InferenceSession::Initialize() (inference_session.cc:1116)\r\n==132002==    by 0x590B7EF: (anonymous namespace)::InitializeSession(OrtSessionOptions const*, std::unique_ptr<onnxruntime::InferenceSession, std::default_delete<onnxruntime::InferenceSession> >&) (onnxruntime_c_api.cc:469)\r\n==132002==    by 0x590BCC0: OrtApis::CreateSessionFromArray(OrtEnv const*, void const*, unsigned long, OrtSessionOptions const*, OrtSession**) (onnxruntime_c_api.cc:508)\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7286/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7287",
        "id": 853825542,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExODU4MTMy",
        "number": 7287,
        "title": "Better error message when ORTModule used with torch.DataParallel",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-08T19:55:35Z",
        "updated_at": "2021-04-09T17:07:24Z",
        "closed_at": "2021-04-09T17:07:23Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7287",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7287",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7287.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7287.patch",
            "merged_at": "2021-04-09T17:07:23Z"
        },
        "body": "Display a better error message when ```ORTModule``` is used with ```torch.DataParallel``` than the vague error message:\r\n```sh\r\nRuntimeError: Input, output and indices must be on the current device\r\n```\r\n\r\nThe new error message displayed will be:\r\n```sh\r\nNotImplementedError: ORTModule is not compatible with torch.nn.DataParallel. Please use torch.nn.parallel.DistributedDataParallel instead.\r\n```\r\n\r\n\r\n```torch.nn.DataParallel``` requires the model to be replicated across multiple devices, and in this process, ```ORTModule``` tries to export the model to onnx on multiple devices with the same sample input. Because of this multiple device export with the same sample input, torch throws an exception that reads: \"RuntimeError: Input, output and indices must be on the current device\" which can be vague to the user since they might not be aware of what happens behind the scene.\r\n\r\nWe therefore try to preemptively catch use of ```ORTModule``` with ```torch.nn.DataParallel``` and throw a more meaningful exception.\r\n\r\nUsers must use ```torch.nn.parallel.DistributedDataParallel``` instead of ```torch.nn.DataParallel``` which does not need model replication and is also recommended by torch to use instead.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7287/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7288",
        "id": 853855362,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExODg1MjYy",
        "number": 7288,
        "title": "Change initialization of ort environment to be static.",
        "user": {
            "login": "chandru-r",
            "id": 41447659,
            "node_id": "MDQ6VXNlcjQxNDQ3NjU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/41447659?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chandru-r",
            "html_url": "https://github.com/chandru-r",
            "followers_url": "https://api.github.com/users/chandru-r/followers",
            "following_url": "https://api.github.com/users/chandru-r/following{/other_user}",
            "gists_url": "https://api.github.com/users/chandru-r/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chandru-r/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chandru-r/subscriptions",
            "organizations_url": "https://api.github.com/users/chandru-r/orgs",
            "repos_url": "https://api.github.com/users/chandru-r/repos",
            "events_url": "https://api.github.com/users/chandru-r/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chandru-r/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-08T20:21:11Z",
        "updated_at": "2021-05-28T19:11:47Z",
        "closed_at": "2021-04-14T21:58:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7288",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7288",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7288.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7288.patch",
            "merged_at": null
        },
        "body": "Currently ort_kernel_invoker uses a singleton environment which is used for logging and initialized the first time ort_kernel_invoker is constructed. This revealed an issue with Apollo ExecutionProvider integration. During creation of EP, it uses the logger which fails due to it being null. Hence switching this to be a static so it is initialized before the constructor. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7288/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7289",
        "id": 853876437,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExOTA0NDMz",
        "number": 7289,
        "title": "Add Tile grad",
        "user": {
            "login": "harshithapv",
            "id": 54084812,
            "node_id": "MDQ6VXNlcjU0MDg0ODEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/54084812?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/harshithapv",
            "html_url": "https://github.com/harshithapv",
            "followers_url": "https://api.github.com/users/harshithapv/followers",
            "following_url": "https://api.github.com/users/harshithapv/following{/other_user}",
            "gists_url": "https://api.github.com/users/harshithapv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/harshithapv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/harshithapv/subscriptions",
            "organizations_url": "https://api.github.com/users/harshithapv/orgs",
            "repos_url": "https://api.github.com/users/harshithapv/repos",
            "events_url": "https://api.github.com/users/harshithapv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/harshithapv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-08T20:39:21Z",
        "updated_at": "2021-04-13T19:54:46Z",
        "closed_at": "2021-04-13T19:54:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7289",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7289",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7289.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7289.patch",
            "merged_at": "2021-04-13T19:54:46Z"
        },
        "body": "Adding Tile grad implementation. \r\n\r\n**Motivation and Context**\r\nSome models like HF-Deberta require gradient to Tile Op. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7289/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7290",
        "id": 853896032,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExOTIyNDY3",
        "number": 7290,
        "title": "NCHWc: Support \"sizes\" argument for Resize transform",
        "user": {
            "login": "tracysh",
            "id": 42477615,
            "node_id": "MDQ6VXNlcjQyNDc3NjE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/42477615?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tracysh",
            "html_url": "https://github.com/tracysh",
            "followers_url": "https://api.github.com/users/tracysh/followers",
            "following_url": "https://api.github.com/users/tracysh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tracysh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tracysh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tracysh/subscriptions",
            "organizations_url": "https://api.github.com/users/tracysh/orgs",
            "repos_url": "https://api.github.com/users/tracysh/repos",
            "events_url": "https://api.github.com/users/tracysh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tracysh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-08T20:52:13Z",
        "updated_at": "2021-04-09T20:54:17Z",
        "closed_at": "2021-04-09T20:54:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7290",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7290",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7290.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7290.patch",
            "merged_at": "2021-04-09T20:54:16Z"
        },
        "body": "**Description**: Update the NCHWc transformer to support the optional \"sizes\" input for Resize. The output shape must be constant and must result in an integral multiplier, just as required of the existing \"scales\" input support.\r\n\r\nSome internal models were heading down this alternate path and not getting fully optimized. Removing these unnecessary buffer reorderings and using the NCHWc Upsample shaved off .5ms from model inference time.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7290/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7291",
        "id": 853947578,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjExOTY5NTQx",
        "number": 7291,
        "title": "Add CoreML EP document",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-08T21:37:22Z",
        "updated_at": "2021-09-14T01:37:43Z",
        "closed_at": "2021-05-28T21:16:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7291",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7291",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7291.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7291.patch",
            "merged_at": null
        },
        "body": "**Description**: Add CoreML EP document\r\n\r\n**Motivation and Context**\r\n- Add CoreML EP document\r\n- Also corrected some dead link in NNAPI EP and some minor updates for Build.MD\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7291/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7292",
        "id": 854021836,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMDM0NjI5",
        "number": 7292,
        "title": "Website: customer quotes and format updates",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-08T23:45:46Z",
        "updated_at": "2021-04-09T17:35:34Z",
        "closed_at": "2021-04-09T17:35:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7292",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7292",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7292.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7292.patch",
            "merged_at": "2021-04-09T17:35:28Z"
        },
        "body": "Staged at: https://faxu.github.io/onnxruntime/\r\n\r\nKey changes:\r\n- added new quotes \r\n- new formatting for news and hardware ecosystem sections\r\n- resized logos and removed out-of-date images\r\n- fixed broken anchor links in installation picker",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7292/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7293",
        "id": 854073709,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMDc3MDg2",
        "number": 7293,
        "title": "Quantization tools using one more extra_options on interface.",
        "user": {
            "login": "zhanghuanrong",
            "id": 5163183,
            "node_id": "MDQ6VXNlcjUxNjMxODM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5163183?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhanghuanrong",
            "html_url": "https://github.com/zhanghuanrong",
            "followers_url": "https://api.github.com/users/zhanghuanrong/followers",
            "following_url": "https://api.github.com/users/zhanghuanrong/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhanghuanrong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhanghuanrong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhanghuanrong/subscriptions",
            "organizations_url": "https://api.github.com/users/zhanghuanrong/orgs",
            "repos_url": "https://api.github.com/users/zhanghuanrong/repos",
            "events_url": "https://api.github.com/users/zhanghuanrong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhanghuanrong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-09T01:47:12Z",
        "updated_at": "2021-05-05T20:51:51Z",
        "closed_at": "2021-05-05T20:51:50Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7293",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7293",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7293.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7293.patch",
            "merged_at": "2021-05-05T20:51:50Z"
        },
        "body": "handle nnapi special sigmoid options.\r\n\r\n**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7293/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7294",
        "id": 854093932,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMDk0NTg3",
        "number": 7294,
        "title": "Polish Adam kernel",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-09T02:24:10Z",
        "updated_at": "2021-04-09T08:11:10Z",
        "closed_at": "2021-04-09T08:11:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7294",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7294",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7294.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7294.patch",
            "merged_at": "2021-04-09T08:11:09Z"
        },
        "body": "1. In Adam, changing computation to be done in float, and only casting the values when they are assigned to the outputs such as moment_1_out, momnet_2_out, weights_out, grads_outs.\r\n2. With this change, the CUDA implementation can be leveraged for ROCm EP. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7294/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7295",
        "id": 854149832,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMTQwNTEx",
        "number": 7295,
        "title": "Create Android Package pipeline",
        "user": {
            "login": "guoyu-wang",
            "id": 62914304,
            "node_id": "MDQ6VXNlcjYyOTE0MzA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/62914304?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guoyu-wang",
            "html_url": "https://github.com/guoyu-wang",
            "followers_url": "https://api.github.com/users/guoyu-wang/followers",
            "following_url": "https://api.github.com/users/guoyu-wang/following{/other_user}",
            "gists_url": "https://api.github.com/users/guoyu-wang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guoyu-wang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guoyu-wang/subscriptions",
            "organizations_url": "https://api.github.com/users/guoyu-wang/orgs",
            "repos_url": "https://api.github.com/users/guoyu-wang/repos",
            "events_url": "https://api.github.com/users/guoyu-wang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guoyu-wang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-09T04:35:40Z",
        "updated_at": "2021-04-13T00:56:26Z",
        "closed_at": "2021-04-13T00:56:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7295",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7295",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7295.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7295.patch",
            "merged_at": "2021-04-13T00:56:25Z"
        },
        "body": "**Description**: Create Android Package pipeline\r\n\r\n**Motivation and Context**\r\n- This is the preparation work for publish ORT-Mobile package in 1.8.0 release\r\n- Update the manylinux2014 docker image be able to use jdk11 (using jdk11 is Microsoft 1cs requirement)\r\n- Update the description of Android AAR package\r\n- Some minor updates\r\n- Test run result here, https://aiinfra.visualstudio.com/Lotus/_build/results?buildId=149091&view=results\r\n- Some details are not final yet, such as the choice of op/types to be included in the mobile package, Release or MinSizeRel as the package build config, include NNAPI EP or not, these will be updated before 1.8 release",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7295/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7296",
        "id": 854191007,
        "node_id": "MDU6SXNzdWU4NTQxOTEwMDc=",
        "number": 7296,
        "title": "can I use the windows_x86 to run with gpu?",
        "user": {
            "login": "YAwei666",
            "id": 34396185,
            "node_id": "MDQ6VXNlcjM0Mzk2MTg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34396185?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YAwei666",
            "html_url": "https://github.com/YAwei666",
            "followers_url": "https://api.github.com/users/YAwei666/followers",
            "following_url": "https://api.github.com/users/YAwei666/following{/other_user}",
            "gists_url": "https://api.github.com/users/YAwei666/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YAwei666/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YAwei666/subscriptions",
            "organizations_url": "https://api.github.com/users/YAwei666/orgs",
            "repos_url": "https://api.github.com/users/YAwei666/repos",
            "events_url": "https://api.github.com/users/YAwei666/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YAwei666/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-09T05:59:41Z",
        "updated_at": "2021-04-09T14:44:32Z",
        "closed_at": "2021-04-09T14:43:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\n![image](https://user-images.githubusercontent.com/34396185/114135133-6285fb00-993b-11eb-99d8-7da1542bf981.png)\r\nI notice that there's only cpu type for windows_x86 version, I just wondering that if a gpu version for windows_x86 supported or can  I build it from the source code,thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7296/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7297",
        "id": 854210062,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMTg5NTQ5",
        "number": 7297,
        "title": "Improve logged message for nodes that are forced to execute on CPU rather than some other EP (usually CUDA)",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T06:30:46Z",
        "updated_at": "2021-04-09T08:36:20Z",
        "closed_at": "2021-04-09T08:36:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7297",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7297",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7297.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7297.patch",
            "merged_at": "2021-04-09T08:36:20Z"
        },
        "body": "**Description**: Sometimes ORT force places some nodes pertaining to some specific kinds of subgraphs on CPU (usually shape related subgraphs but not limited to just these). Improving the logged message to indicate that this was  choice made by ORT as it perceives this as an optimization so that users can contrast this message with the message they see when nodes get forced to CPU because EPs lack an implementation for such nodes.\r\n\r\n**Motivation and Context**\r\nImprove logged message\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7297/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7298",
        "id": 854227888,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMjA0MDEy",
        "number": 7298,
        "title": "Adding Bernoulli contrib op",
        "user": {
            "login": "hwangdeyu",
            "id": 10047193,
            "node_id": "MDQ6VXNlcjEwMDQ3MTkz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10047193?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hwangdeyu",
            "html_url": "https://github.com/hwangdeyu",
            "followers_url": "https://api.github.com/users/hwangdeyu/followers",
            "following_url": "https://api.github.com/users/hwangdeyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/hwangdeyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hwangdeyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hwangdeyu/subscriptions",
            "organizations_url": "https://api.github.com/users/hwangdeyu/orgs",
            "repos_url": "https://api.github.com/users/hwangdeyu/repos",
            "events_url": "https://api.github.com/users/hwangdeyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hwangdeyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2021-04-09T06:56:26Z",
        "updated_at": "2021-06-21T09:00:18Z",
        "closed_at": "2021-06-21T09:00:18Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7298",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7298",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7298.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7298.patch",
            "merged_at": null
        },
        "body": "**Description**: Adding Bernoulli contrib op based on pytorch bernoulli.\r\n\r\n**Motivation and Context**\r\nNeed the op to produce bernoulli samples for pytorch export.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7298/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7299",
        "id": 854308545,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMjczMDgz",
        "number": 7299,
        "title": "Polish Lamb Kernel",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T08:38:17Z",
        "updated_at": "2021-04-09T16:55:58Z",
        "closed_at": "2021-04-09T16:55:58Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7299",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7299",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7299.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7299.patch",
            "merged_at": "2021-04-09T16:55:57Z"
        },
        "body": "Similar to commit 8ad5007, to have better accuracy, the computation of lamb kernels should be done in higher precision (e.g. float or double).\r\n\r\nNVBert Throughput with bs=64, seq_len=128:\r\n\r\nBefore: 213.899 Examples / Second\r\nAfter: 213.883 Examples / Second",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7299/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7300",
        "id": 854322784,
        "node_id": "MDU6SXNzdWU4NTQzMjI3ODQ=",
        "number": 7300,
        "title": "Invalid model after quantization with onnxruntime 1.7.0 ",
        "user": {
            "login": "leqiao-1",
            "id": 61653207,
            "node_id": "MDQ6VXNlcjYxNjUzMjA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/61653207?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/leqiao-1",
            "html_url": "https://github.com/leqiao-1",
            "followers_url": "https://api.github.com/users/leqiao-1/followers",
            "following_url": "https://api.github.com/users/leqiao-1/following{/other_user}",
            "gists_url": "https://api.github.com/users/leqiao-1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/leqiao-1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/leqiao-1/subscriptions",
            "organizations_url": "https://api.github.com/users/leqiao-1/orgs",
            "repos_url": "https://api.github.com/users/leqiao-1/repos",
            "events_url": "https://api.github.com/users/leqiao-1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/leqiao-1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2021-04-09T08:56:15Z",
        "updated_at": "2023-01-20T03:09:00Z",
        "closed_at": "2021-05-15T06:34:12Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nModel quantized successfully with onnxruntime 1.7.0, but can not be inferenced with onnxruntime 1.7.0:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 127, in <module>\r\n    init()\r\n  File \"test.py\", line 42, in init\r\n    session = ort.InferenceSession(model)\r\n  File \"/opt/miniconda/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 280, in __init__\r\n    self._create_inference_session(providers, provider_options)\r\n  File \"/opt/miniconda/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 307, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from ./res_after_quant.onnx failed:This is an invalid model. Error in Node:custom_rnn_scan_Scan__58 : Nodes in a graph must be topologically sorted, however input 'encoder_0/bidirectional_rnn/fw/gated_gru_cell/W/read/_9__cf__9:0' of node:\r\n\r\n;encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3:0\r\n@encoder_0/bidirectional_rnn/fw/gated_gru_cell/W/read/_9__cf__9:0\r\nBencoder_0/bidirectional_rnn/fw/gated_gru_cell/b/read/_10__cf__10:0\r\nGemm__12:Gemm__12\"Gemm*\r\ntransB\r\n```\r\nQuantization finished without error.\r\n\r\nModel can be quantized and inferenced with onnxruntime 1.6.0.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- ONNX Runtime installed from pypi\r\n- ONNX Runtime version: 1.7.0\r\n- Python version: 3.6\r\n\r\n**To Reproduce**\r\nquantize.py\r\n```\r\n'''onnx model quantization'''\r\nimport logging\r\nimport os\r\nimport onnx\r\nfrom shutil import copy\r\nfrom onnxruntime import quantization\r\n\r\nquantization.quantize_dynamic(\"res.onnx\", 'res_after_quant.onnx')\r\n```\r\nmodel before quantization can be found here.\r\n[res.zip](https://github.com/microsoft/onnxruntime/files/6284436/res.zip)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7300/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7301",
        "id": 854333344,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyMjkzODM0",
        "number": 7301,
        "title": "Remove Identity op for GemmGradient builder",
        "user": {
            "login": "ytaous",
            "id": 4484531,
            "node_id": "MDQ6VXNlcjQ0ODQ1MzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4484531?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ytaous",
            "html_url": "https://github.com/ytaous",
            "followers_url": "https://api.github.com/users/ytaous/followers",
            "following_url": "https://api.github.com/users/ytaous/following{/other_user}",
            "gists_url": "https://api.github.com/users/ytaous/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ytaous/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ytaous/subscriptions",
            "organizations_url": "https://api.github.com/users/ytaous/orgs",
            "repos_url": "https://api.github.com/users/ytaous/repos",
            "events_url": "https://api.github.com/users/ytaous/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ytaous/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-04-09T09:09:13Z",
        "updated_at": "2021-10-08T05:25:26Z",
        "closed_at": "2021-04-09T17:36:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7301",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7301",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7301.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7301.patch",
            "merged_at": null
        },
        "body": "**Description**: For a model with dynamic shape inputs, an Identity node remains in the final optimized training graph between GemmGrad/ReduceSum node and gradient output. This introduces an extra memcpy from Identity op during training. The solution is to eliminate the node in gradient graph builder. So that final graph could avoid the memcpy and get better performance.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n\r\n![image](https://user-images.githubusercontent.com/4484531/114155907-dc37cd80-98d6-11eb-9036-d337fd1ccec5.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7301/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7302",
        "id": 854475350,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNDE0ODU1",
        "number": 7302,
        "title": "Fix split op in the way it deals with the optional input",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2021-04-09T12:22:45Z",
        "updated_at": "2021-04-12T17:26:09Z",
        "closed_at": "2021-04-12T17:26:09Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7302",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7302",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7302.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7302.patch",
            "merged_at": "2021-04-12T17:26:09Z"
        },
        "body": "**Description**: As title\r\n\r\n**Motivation and Context**\r\nResolve https://github.com/microsoft/onnxruntime/issues/7075\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7302/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7303",
        "id": 854598534,
        "node_id": "MDU6SXNzdWU4NTQ1OTg1MzQ=",
        "number": 7303,
        "title": "Memory leak",
        "user": {
            "login": "davipeag",
            "id": 40247372,
            "node_id": "MDQ6VXNlcjQwMjQ3Mzcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/40247372?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/davipeag",
            "html_url": "https://github.com/davipeag",
            "followers_url": "https://api.github.com/users/davipeag/followers",
            "following_url": "https://api.github.com/users/davipeag/following{/other_user}",
            "gists_url": "https://api.github.com/users/davipeag/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/davipeag/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/davipeag/subscriptions",
            "organizations_url": "https://api.github.com/users/davipeag/orgs",
            "repos_url": "https://api.github.com/users/davipeag/repos",
            "events_url": "https://api.github.com/users/davipeag/events{/privacy}",
            "received_events_url": "https://api.github.com/users/davipeag/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-04-09T14:53:06Z",
        "updated_at": "2021-10-08T19:30:12Z",
        "closed_at": "2021-10-08T19:30:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nEven after disposing the Microsoft.ML.PredictionEngine and Microsoft.ML.Transforms.Onnx.OnnxTransformer objects, memory is not freed\r\n\r\n**Urgency**\r\nThis issue is hindering the application of our machine learning model into production. \r\n\r\n**System information**\r\n- Windows 10\r\n- ONNX Runtime installed from nugget\r\n- ONNX Runtime version: 1.5.2\r\n- CPU only\r\n\r\n**To Reproduce**\r\n\r\n- here is the sample code:\r\nprogram.cs\r\n```csharp\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML;\r\n\r\nnamespace Test\r\n{\r\n    class LstmCellInput\r\n    {\r\n        [ColumnName(\"attributes\")]\r\n        [VectorType(1,1,8)]\r\n        public float[] Attributes { get; set; }\r\n\r\n        [ColumnName(\"h_in\")]\r\n        [VectorType(1, 1, 16)]\r\n        public float[] HiddenState { get; set; }\r\n\r\n        [ColumnName(\"c_in\")]\r\n        [VectorType(1, 1, 16)]\r\n        public float[] CellState { get; set; }\r\n    }\r\n\r\n    class LSTMCellOutput\r\n    {\r\n        [ColumnName(\"prediction\")]\r\n        [VectorType(1, 1, 1)]\r\n        public float[] Prediction { get; set; }\r\n\r\n        [ColumnName(\"h_out\")]\r\n        [VectorType(1, 1, 16)]\r\n        public float[] HiddenState { get; set; }\r\n\r\n        [ColumnName(\"c_out\")]\r\n        [VectorType(1, 1, 16)]\r\n        public float[] CellState { get; set; }\r\n    }\r\n\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(\"start\");\r\n\r\n            var x = new LstmCellInput {\r\n                HiddenState = new float[16],\r\n                CellState = new float[16],\r\n                Attributes = new float[8]\r\n            };\r\n\r\n            for (int i = 0; i < 5000; i++)\r\n            {\r\n                var context = new MLContext();\r\n                var transforms = context.Transforms.ApplyOnnxModel(\r\n                    modelFile: \"celllstm.onnx\",\r\n                    inputColumnNames: new String[] { \"attributes\", \"h_in\", \"c_in\" },\r\n                    outputColumnNames: new String[] { \"prediction\", \"h_out\", \"c_out\" }\r\n                );\r\n                \r\n                var model = transforms.Fit(context.Data.LoadFromEnumerable(new List<LstmCellInput>()));\r\n                var engine = context.Model.CreatePredictionEngine<LstmCellInput, LSTMCellOutput>(model);\r\n                var y = engine.Predict(x);\r\n                model.Dispose();\r\n                engine.Dispose();\r\n            }\r\n\r\n            Console.WriteLine(\"finish\");\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n**Expected behavior**\r\nWe expected memory consumption to remain nearly constant, but it has spiked\r\n\r\n\r\n**Additional context**\r\nThe onnx model was converted from pytorch\r\n* This sample program along with the onnx model is attached\r\n[Test.zip](https://github.com/microsoft/onnxruntime/files/6286545/Test.zip)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7303/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7304",
        "id": 854630635,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNTQ1MzMx",
        "number": 7304,
        "title": "Add ARM64EC onnxruntime.dll build instructions",
        "user": {
            "login": "mcfi",
            "id": 6384579,
            "node_id": "MDQ6VXNlcjYzODQ1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6384579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mcfi",
            "html_url": "https://github.com/mcfi",
            "followers_url": "https://api.github.com/users/mcfi/followers",
            "following_url": "https://api.github.com/users/mcfi/following{/other_user}",
            "gists_url": "https://api.github.com/users/mcfi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mcfi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mcfi/subscriptions",
            "organizations_url": "https://api.github.com/users/mcfi/orgs",
            "repos_url": "https://api.github.com/users/mcfi/repos",
            "events_url": "https://api.github.com/users/mcfi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mcfi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T15:31:31Z",
        "updated_at": "2021-04-09T22:46:48Z",
        "closed_at": "2021-04-09T22:46:48Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7304",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7304",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7304.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7304.patch",
            "merged_at": "2021-04-09T22:46:48Z"
        },
        "body": "[PR 6999](https://github.com/microsoft/onnxruntime/pull/6999) added build support for ARM64EC, and this PR adds build instructions for ARM64EC.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7304/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7305",
        "id": 854743634,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNjM4NTY0",
        "number": 7305,
        "title": "Add Optype to type mismatch message",
        "user": {
            "login": "jingyanwangms",
            "id": 47403504,
            "node_id": "MDQ6VXNlcjQ3NDAzNTA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/47403504?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jingyanwangms",
            "html_url": "https://github.com/jingyanwangms",
            "followers_url": "https://api.github.com/users/jingyanwangms/followers",
            "following_url": "https://api.github.com/users/jingyanwangms/following{/other_user}",
            "gists_url": "https://api.github.com/users/jingyanwangms/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jingyanwangms/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jingyanwangms/subscriptions",
            "organizations_url": "https://api.github.com/users/jingyanwangms/orgs",
            "repos_url": "https://api.github.com/users/jingyanwangms/repos",
            "events_url": "https://api.github.com/users/jingyanwangms/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jingyanwangms/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T18:02:09Z",
        "updated_at": "2021-04-09T20:40:49Z",
        "closed_at": "2021-04-09T20:40:48Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7305",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7305",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7305.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7305.patch",
            "merged_at": "2021-04-09T20:40:48Z"
        },
        "body": "**Description**: Add Optype to type mismatch message. It will help use identify the node in the graph",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7305/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7306",
        "id": 854759550,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNjUxNzk0",
        "number": 7306,
        "title": "Gemm transpose fusion",
        "user": {
            "login": "ashbhandare",
            "id": 14295305,
            "node_id": "MDQ6VXNlcjE0Mjk1MzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/14295305?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashbhandare",
            "html_url": "https://github.com/ashbhandare",
            "followers_url": "https://api.github.com/users/ashbhandare/followers",
            "following_url": "https://api.github.com/users/ashbhandare/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashbhandare/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashbhandare/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashbhandare/subscriptions",
            "organizations_url": "https://api.github.com/users/ashbhandare/orgs",
            "repos_url": "https://api.github.com/users/ashbhandare/repos",
            "events_url": "https://api.github.com/users/ashbhandare/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashbhandare/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-04-09T18:28:00Z",
        "updated_at": "2021-04-20T16:35:07Z",
        "closed_at": "2021-04-20T16:35:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7306",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7306",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7306.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7306.patch",
            "merged_at": "2021-04-20T16:35:06Z"
        },
        "body": "This fusion fuses Gemm and Transpose nodes to a single Gemm node.\r\nThis fusion can be applied in the following scenarios:\r\n1) Transpose at input(s) of Gemm: The Transpose can be removed and transA/B attr\r\n    is set accordingly\r\n2) Transpose at output of Gemm: The Transpose can be fused with Gemm by the rule:\r\n    (AB)' = B' A'; provided that C input is missing.\r\n    This is supported for Opset >= 11 as Gemm input C becomes optional from then\r\n3) Transpose at Input(s) and Output: The fusion is applied by the rules in 1 and 2\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7306/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/7307",
        "id": 854785098,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNjczMTI5",
        "number": 7307,
        "title": "Enable more unit tests for ROCM EP",
        "user": {
            "login": "weixingzhang",
            "id": 20581345,
            "node_id": "MDQ6VXNlcjIwNTgxMzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20581345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weixingzhang",
            "html_url": "https://github.com/weixingzhang",
            "followers_url": "https://api.github.com/users/weixingzhang/followers",
            "following_url": "https://api.github.com/users/weixingzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weixingzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weixingzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weixingzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weixingzhang/orgs",
            "repos_url": "https://api.github.com/users/weixingzhang/repos",
            "events_url": "https://api.github.com/users/weixingzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weixingzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T19:09:21Z",
        "updated_at": "2021-04-09T22:15:14Z",
        "closed_at": "2021-04-09T22:15:14Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/7307",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/7307",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/7307.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/7307.patch",
            "merged_at": "2021-04-09T22:15:14Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7307/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]