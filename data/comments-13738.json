[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1325331658",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/13738#issuecomment-1325331658",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/13738",
        "id": 1325331658,
        "node_id": "IC_kwDOCVq1mM5O_vTK",
        "user": {
            "login": "xadupre",
            "id": 22452781,
            "node_id": "MDQ6VXNlcjIyNDUyNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/22452781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xadupre",
            "html_url": "https://github.com/xadupre",
            "followers_url": "https://api.github.com/users/xadupre/followers",
            "following_url": "https://api.github.com/users/xadupre/following{/other_user}",
            "gists_url": "https://api.github.com/users/xadupre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xadupre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xadupre/subscriptions",
            "organizations_url": "https://api.github.com/users/xadupre/orgs",
            "repos_url": "https://api.github.com/users/xadupre/repos",
            "events_url": "https://api.github.com/users/xadupre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xadupre/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-23T16:19:25Z",
        "updated_at": "2022-11-23T16:19:25Z",
        "author_association": "MEMBER",
        "body": "I fixed your example. [OnnxInference](http://www.xavierdupre.fr/app/mlprodict/helpsphinx/mlprodict/onnxrt/onnx_inference.html) is a tool I developed to help debugging models produced by [sklearn-onnx](https://onnx.ai/sklearn-onnx/). You should use [onnxruntime.InferenceSession](https://onnxruntime.ai/docs/api/python/api_summary.html#inferencesession).\r\n\r\n```python\r\nimport numpy as np\r\n# from mlprodict.onnxrt import OnnxInference\r\nfrom onnxruntime import InferenceSession\r\nfrom onnxcustom.training.grad_helper import onnx_derivative\r\nimport onnx\r\nfrom mlprodict import __max_supported_opset__\r\nimport torch\r\nfrom torch import nn\r\nclass MatMulBasic(nn.Module):\r\n    def __init__(self,hidden_size=10, hidden_out_size=10):\r\n        super().__init__()\r\n        self.query = nn.Linear(hidden_size,hidden_out_size)\r\n        self.key = nn.Linear(hidden_size, hidden_out_size)\r\n\r\n    def forward(self, x):\r\n        x1 = x.reshape(x.shape[0],10)\r\n        x2 = x.reshape(x.shape[0],10)\r\n        query = self.query(x1)\r\n        key= self.key(x2)\r\n        res = torch.matmul(query,key)\r\n        return res\r\nclass MatMulReshape(nn.Module):\r\n    def __init__(self,hidden_size=768, hidden_out_size=100):\r\n        super().__init__()\r\n        self.query = nn.Linear(hidden_size,hidden_out_size)\r\n        self.key = nn.Linear(hidden_size, hidden_out_size)\r\n        #self.value = nn.Linear(hidden_size, hidden_out_size)\r\n\r\n    def forward(self, x):\r\n        query = self.query(x)\r\n        key = self.key(x)\r\n\r\n        query_reshaped = query.reshape(query.shape[0],10, 10)\r\n        key_reshaped = key.reshape(key.shape[0],10, 10)\r\n\r\n        res = torch.matmul(query_reshaped,key_reshaped)\r\n        return res\r\n\r\nif __name__==\"__main__\":\r\n    ## MatMul no reshape\r\n    sample_data = np.random.random((10,10))\r\n    matmul_layer = MatMulBasic()\r\n    torch.onnx.export(\r\n            matmul_layer,\r\n            torch.Tensor(sample_data),\r\n            \"matmul_basic.onnx\",\r\n            verbose=True,\r\n            input_names=[\"inputs\"],\r\n            output_names=[\"outputs\"],\r\n            do_constant_folding=True,\r\n            opset_version=13\r\n        )\r\n\r\n    onnx_square = onnx.load(\"matmul_basic.onnx\")\r\n    runtime = \"onnxruntime1\"\r\n\r\n    # square_oinf = OnnxInference(onnx_square, runtime=runtime, target_opset=13)\r\n    # square_res = square_oinf.run({\"inputs\":sample_data.astype(np.float32)})\r\n\r\n    square_grad = onnx_derivative(onnx_square)\r\n    # square_grad_oinf = OnnxInference(square_grad,target_opset=13)\r\n    square_grad_oinf = InferenceSession(square_grad.SerializeToString())\r\n\r\n    state_dict = {n.name: onnx.numpy_helper.to_array(n) for n in onnx_square.graph.initializer}\r\n\r\n    square_grad_res = square_grad_oinf.run(\r\n        None,\r\n        {\"inputs\": sample_data.astype(np.float32),\r\n         \"outputs_grad\" : np.random.random((10,10)).astype(np.float32)} | state_dict)\r\n\r\n    ## MatMul with reshape -> FAILS\r\n    sample_data = np.random.random((2,768))\r\n    matmul_layer = MatMulReshape(hidden_out_size=100)\r\n    torch.onnx.export(\r\n            matmul_layer,\r\n            torch.Tensor(sample_data),\r\n            \"matmul_reshape.onnx\",\r\n            verbose=True,\r\n            input_names=[\"inputs\"],\r\n            output_names=[\"outputs\"],\r\n            dynamic_axes={\r\n                'inputs': {0: 'batch_size'},\r\n                'outputs': {0: 'batch_size'}\r\n            },\r\n            do_constant_folding=True,\r\n            opset_version=13\r\n        )\r\n\r\n    onnx_square = onnx.load(\"matmul_reshape.onnx\")\r\n    runtime = \"onnxruntime1\"\r\n\r\n    # square_oinf = OnnxInference(onnx_square, runtime=runtime, target_opset=13)\r\n    square_oinf = InferenceSession(onnx_square.SerializeToString())\r\n    square_res = square_oinf.run(None, {\"inputs\":sample_data.astype(np.float32)})\r\n\r\n    square_grad = onnx_derivative(onnx_square)\r\n    # square_grad_oinf = OnnxInference(square_grad,target_opset=13)\r\n    square_grad_oinf = InferenceSession(square_grad.SerializeToString())\r\n\r\n    state_dict = {n.name: onnx.numpy_helper.to_array(n) for n in onnx_square.graph.initializer}\r\n\r\n    square_grad_res = square_grad_oinf.run(\r\n        None,\r\n        {\"inputs\": sample_data.astype(np.float32),\r\n         \"outputs_grad\" : np.random.random((2,10,10)).astype(np.float32)} | state_dict)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1325331658/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]