[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1386185167",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14317#issuecomment-1386185167",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14317",
        "id": 1386185167,
        "node_id": "IC_kwDOCVq1mM5Sn4HP",
        "user": {
            "login": "RyanUnderhill",
            "id": 38674843,
            "node_id": "MDQ6VXNlcjM4Njc0ODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38674843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RyanUnderhill",
            "html_url": "https://github.com/RyanUnderhill",
            "followers_url": "https://api.github.com/users/RyanUnderhill/followers",
            "following_url": "https://api.github.com/users/RyanUnderhill/following{/other_user}",
            "gists_url": "https://api.github.com/users/RyanUnderhill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RyanUnderhill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RyanUnderhill/subscriptions",
            "organizations_url": "https://api.github.com/users/RyanUnderhill/orgs",
            "repos_url": "https://api.github.com/users/RyanUnderhill/repos",
            "events_url": "https://api.github.com/users/RyanUnderhill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RyanUnderhill/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-17T22:45:20Z",
        "updated_at": "2023-01-17T22:45:20Z",
        "author_association": "MEMBER",
        "body": "Onnxruntime 1.12 is an older version, can you try it with 1.13?\r\n\r\nAre you required to use 1.12?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1386185167/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1386340538",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14317#issuecomment-1386340538",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14317",
        "id": 1386340538,
        "node_id": "IC_kwDOCVq1mM5SoeC6",
        "user": {
            "login": "baoachun",
            "id": 22114318,
            "node_id": "MDQ6VXNlcjIyMTE0MzE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22114318?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baoachun",
            "html_url": "https://github.com/baoachun",
            "followers_url": "https://api.github.com/users/baoachun/followers",
            "following_url": "https://api.github.com/users/baoachun/following{/other_user}",
            "gists_url": "https://api.github.com/users/baoachun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baoachun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baoachun/subscriptions",
            "organizations_url": "https://api.github.com/users/baoachun/orgs",
            "repos_url": "https://api.github.com/users/baoachun/repos",
            "events_url": "https://api.github.com/users/baoachun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baoachun/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-18T01:37:07Z",
        "updated_at": "2023-01-18T01:37:07Z",
        "author_association": "NONE",
        "body": "> Onnxruntime 1.12 is an older version, can you try it with 1.13?\r\n> \r\n> Are you required to use 1.12?\r\n\r\nYes, we have to use version 1.12.\r\n\r\nI have just found that the problem is caused by without setting `SetIntraOpNumThreads`, the program is running successfully by setting `session_options.SetIntraOpNumThreads(4);` in c++. Is there no default value for this setting? In Python, if I do not set this parallelism, there will be a pthread warning. Therefore, I think this is a very important setting, and there needs to be a default value or warning if the user does not set it.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1386340538/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1396072367",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14317#issuecomment-1396072367",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14317",
        "id": 1396072367,
        "node_id": "IC_kwDOCVq1mM5TNl-v",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-18T20:53:02Z",
        "updated_at": "2023-01-18T20:53:02Z",
        "author_association": "MEMBER",
        "body": "Intra op num threads defaults to the number of physical cores. How many cores do you've on your machine? It's strange that this could be the reason for the hang.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1396072367/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1407662368",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14317#issuecomment-1407662368",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14317",
        "id": 1407662368,
        "node_id": "IC_kwDOCVq1mM5T5zkg",
        "user": {
            "login": "baoachun",
            "id": 22114318,
            "node_id": "MDQ6VXNlcjIyMTE0MzE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22114318?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baoachun",
            "html_url": "https://github.com/baoachun",
            "followers_url": "https://api.github.com/users/baoachun/followers",
            "following_url": "https://api.github.com/users/baoachun/following{/other_user}",
            "gists_url": "https://api.github.com/users/baoachun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baoachun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baoachun/subscriptions",
            "organizations_url": "https://api.github.com/users/baoachun/orgs",
            "repos_url": "https://api.github.com/users/baoachun/repos",
            "events_url": "https://api.github.com/users/baoachun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baoachun/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-29T13:21:21Z",
        "updated_at": "2023-01-29T13:21:21Z",
        "author_association": "NONE",
        "body": "> Intra op num threads defaults to the number of physical cores. How many cores do you've on your machine? It's strange that this could be the reason for the hang.\r\n\r\n48 cores",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1407662368/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1407664274",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14317#issuecomment-1407664274",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14317",
        "id": 1407664274,
        "node_id": "IC_kwDOCVq1mM5T50CS",
        "user": {
            "login": "baoachun",
            "id": 22114318,
            "node_id": "MDQ6VXNlcjIyMTE0MzE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22114318?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baoachun",
            "html_url": "https://github.com/baoachun",
            "followers_url": "https://api.github.com/users/baoachun/followers",
            "following_url": "https://api.github.com/users/baoachun/following{/other_user}",
            "gists_url": "https://api.github.com/users/baoachun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baoachun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baoachun/subscriptions",
            "organizations_url": "https://api.github.com/users/baoachun/orgs",
            "repos_url": "https://api.github.com/users/baoachun/repos",
            "events_url": "https://api.github.com/users/baoachun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baoachun/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-29T13:29:37Z",
        "updated_at": "2023-01-29T13:29:37Z",
        "author_association": "NONE",
        "body": "The program also will stuck when turning on tensorrt even setting `SetIntraOpNumThreads`.\r\n\r\n```\r\n  OrtCUDAProviderOptions cuda_options;\r\n  session_options.AppendExecutionProvider_CUDA(cuda_options);\r\n\r\n  OrtTensorRTProviderOptions* trt_options = new OrtTensorRTProviderOptions();\r\n  trt_options->device_id = 0;\r\n  trt_options->trt_dump_subgraphs = 1;\r\n  trt_options->trt_engine_cache_enable = 1;\r\n  trt_options->trt_engine_cache_path = \"./trt-cache/\";\r\n  trt_options->trt_max_workspace_size = 1073741824;\r\n  trt_options->trt_max_partition_iterations = 1;\r\n  trt_options->trt_min_subgraph_size = 3;\r\n  session_options.AppendExecutionProvider_TensorRT(*trt_options);\r\n  Ort::Session* session = new Ort::Session(env, model_path, session_options);\r\n```\r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007f0b5ee7e3f0 in strlen@plt () from /data/cpp_env/lib64/libstdc++.so.6\r\n#1  0x00007f0b5eecabf8 in std::char_traits<char>::length (__s=<optimized out>)\r\n    at /data/cpp_env_install/gcc-10.2.0/x86_64-pc-linux-gnu/libstdc++-v3/include/bits/basic_string.tcc:1428\r\n#2  std::string::compare (this=<optimized out>, __s=0x35981218 \"predict_330:0\")\r\n    at /data/cpp_env_install/gcc-10.2.0/x86_64-pc-linux-gnu/libstdc++-v3/include/bits/basic_string.tcc:1433\r\n#3  0x00007f0ac3235d60 in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#4  0x00007f0ac3239c3e in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#5  0x00007f0ac323df91 in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#6  0x00007f0ac34edff5 in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#7  0x00007f0ac34ee3d9 in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#8  0x00007f0ac34eea7e in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n#9  0x00007f0b0a5ede3e in onnx2trt::ShapeTensor::ShapeTensor(nvinfer1::ITensor&, int) ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#10 0x00007f0b0a5ef257 in onnx2trt::op(onnx2trt::IImporterContext*, onnx2trt::ShapeTensor const&, onnx2trt::ShapeTensor const&, nvinfer1::ElementWiseOperation, bool, long, std::function<long (long, long)> const&&) () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#11 0x00007f0b0a5ef733 in onnx2trt::min(onnx2trt::IImporterContext*, onnx2trt::ShapeTensor const&, onnx2trt::ShapeTensor const&) ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#12 0x00007f0b0a5d3dc6 in onnx2trt::decodeOnnxStartsAndEnds(onnx2trt::IImporterContext*, onnx2trt::ShapeTensor const&, onnx2trt::ShapeTensor const&, onnx2trt::ShapeTensor&, onnx2trt::ShapeTensor&) () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#13 0x00007f0b0a5d077e in onnx2trt::(anonymous namespace)::importSlice(onnx2trt::IImporterContext*, onnx::NodeProto const&, std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> >&) () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#14 0x00007f0b0a5753ef in std::_Function_handler<onnx2trt::ValueOrStatus<std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> > > (onnx2trt::IImporterContext*, onnx::NodeProto const&, std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> >&), onnx2trt::ValueOrStatus<std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> > > (*)(onnx2trt::IImporterContext*, onnx::NodeProto const&, std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> >&)>::_M_invoke(std::_Any_data const&, onnx2trt::IImporterContext*&&, onnx::NodeProto const&, std::vector<onnx2trt::TensorOrWeights, std::allocator<onnx2trt::TensorOrWeights> >&)\r\n    () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#15 0x00007f0b0a56a944 in onnx2trt::parseGraph(onnx2trt::IImporterContext*, onnx::GraphProto const&, bool, int*) ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n---Type <return> to continue, or q <return> to quit---\r\n#16 0x00007f0b0a56f320 in onnx2trt::ModelImporter::importModel(onnx::ModelProto const&) ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#17 0x00007f0b0a56476a in onnx2trt::ModelImporter::parseWithWeightDescriptors(void const*, unsigned long) ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#18 0x00007f0b0a571ab6 in onnx2trt::ModelImporter::supportsModel(void const*, unsigned long, std::vector<std::pair<std::vector<unsigned long, std::allocator<unsigned long> >, bool>, std::allocator<std::pair<std::vector<unsigned long, std::allocator<unsigned long> >, bool> > >&, char const*) () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#19 0x00007f0b0a547ede in onnxruntime::TensorrtExecutionProvider::GetSupportedList(std::vector<std::pair<std::vector<unsigned long, std::allocator<unsigned long> >, bool>, std::allocator<std::pair<std::vector<unsigned long, std::allocator<unsigned long> >, bool> > >, int, int, onnxruntime::GraphViewer const&, bool*) const [clone .localalias] () from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#20 0x00007f0b0a54d4fb in onnxruntime::TensorrtExecutionProvider::GetCapability(onnxruntime::GraphViewer const&, std::vector<onnxruntime::KernelRegistry const*, std::allocator<onnxruntime::KernelRegistry const*> > const&) const ()\r\n   from /data/cpp_env/lib64/libonnxruntime_providers_tensorrt.so\r\n#21 0x00007f0b5fd3a0d7 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#22 0x00007f0b5fd3defe in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#23 0x00007f0b5fd3fe5d in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#24 0x00007f0b5fd40304 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#25 0x00007f0b5f60b621 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#26 0x00007f0b5f614333 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#27 0x00007f0b5f59e7c0 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#28 0x00007f0b5f5a6bb5 in ?? () from /data/cpp_env/lib64/libonnxruntime.so.1.12.0\r\n#29 0x000000000040360a in Ort::Session::Session(Ort::Env&, char const*, Ort::SessionOptions const&) ()\r\n#30 0x0000000000401c8f in main ()\r\n```\r\n\r\n```\r\n(gdb) info thread\r\n  Id   Target Id         Frame \r\n* 1    Thread 0x7f0b60643880 (LWP 101476) \"onnx_test\" 0x00007f0ac33388c3 in ?? () from /usr/local/TensorRT-8.4.3.1/lib/libnvinfer.so.8\r\n  2    Thread 0x7f0b0bb6c700 (LWP 101479) \"cuda-EvtHandlr\" 0x00007f0b5e5f5ddd in poll () from /data/cpp_env/lib64/libc.so.6\r\n  3    Thread 0x7f0b0b36b700 (LWP 101480) \"cuda-EvtHandlr\" 0x00007f0b5e5f5ddd in poll () from /data/cpp_env/lib64/libc.so.6\r\n  4    Thread 0x7f0b0a4e0700 (LWP 101515) \"onnx_test\" 0x00007f0b5e5fae29 in syscall () from /data/cpp_env/lib64/libc.so.6\r\n  5    Thread 0x7f0b09cdf700 (LWP 101516) \"onnx_test\" 0x00007f0b5e5fae29 in syscall () from /data/cpp_env/lib64/libc.so.6\r\n  6    Thread 0x7f0b094de700 (LWP 101517) \"onnx_test\" 0x00007f0b5e5fae29 in syscall () from /data/cpp_env/lib64/libc.so.6\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1407664274/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]