[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1189344303",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1189344303",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1189344303,
        "node_id": "IC_kwDOCVq1mM5G4_Qv",
        "user": {
            "login": "jcwchen",
            "id": 14194980,
            "node_id": "MDQ6VXNlcjE0MTk0OTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14194980?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcwchen",
            "html_url": "https://github.com/jcwchen",
            "followers_url": "https://api.github.com/users/jcwchen/followers",
            "following_url": "https://api.github.com/users/jcwchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcwchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcwchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcwchen/subscriptions",
            "organizations_url": "https://api.github.com/users/jcwchen/orgs",
            "repos_url": "https://api.github.com/users/jcwchen/repos",
            "events_url": "https://api.github.com/users/jcwchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcwchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-19T17:08:47Z",
        "updated_at": "2022-07-19T17:08:47Z",
        "author_association": "MEMBER",
        "body": "Hi @IzanCatalan,\r\n\r\nFor notebooks related to mxnet in ONNX Model Zoo, probably many of them cannot work with the latest mxnet and onnx, because  onnx import module from mxnet has not been maintained for a long time. See issue: https://github.com/apache/incubator-mxnet/issues/20985. To solve that, the notebook was contributed in 07/2019 so perhaps you can try mxnet 1.4.1 (released on 05/2019) with corresponding ONNX version if you really want to use mxnet. Also please note that I don't think mxnet's onnx importer supports quantization-based ONNX operators so probably you cannot run any quantized ONNX model with mxnet.\r\n\r\nOr, you can always try ONNX Runtime (ORT) to inference the ONNX Model Zoo models. I have verified the models couple weeks ago with ORT's CPU provider and most of them should work well. If you see any issue with ORT on ONNX Model Zoo models, please file an issue in https://github.com/onnx/models/issues.\r\n\r\nRegarding https://github.com/onnx/models/blob/main/vision/classification/onnxrt_inference.ipynb, it works fine in my local with the latest onnx and onnxruntime, may I understand what errors did you get for this notebook?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1189344303/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1190331092",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1190331092",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1190331092,
        "node_id": "IC_kwDOCVq1mM5G8wLU",
        "user": {
            "login": "IzanCatalan",
            "id": 40836734,
            "node_id": "MDQ6VXNlcjQwODM2NzM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/40836734?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IzanCatalan",
            "html_url": "https://github.com/IzanCatalan",
            "followers_url": "https://api.github.com/users/IzanCatalan/followers",
            "following_url": "https://api.github.com/users/IzanCatalan/following{/other_user}",
            "gists_url": "https://api.github.com/users/IzanCatalan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IzanCatalan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IzanCatalan/subscriptions",
            "organizations_url": "https://api.github.com/users/IzanCatalan/orgs",
            "repos_url": "https://api.github.com/users/IzanCatalan/repos",
            "events_url": "https://api.github.com/users/IzanCatalan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IzanCatalan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-20T14:05:21Z",
        "updated_at": "2022-07-20T14:05:21Z",
        "author_association": "NONE",
        "body": "Hi @jcwchen ,\r\n\r\nI'm going to change my MxNet configuration to 1.4.1 in order to check if it works. I will reinstall also protobuf because running  https://github.com/onnx/models/blob/main/vision/classification/onnxrt_inference.ipynb still reports an error saying:\r\n101 raise google.protobuf.message.DecodeError(\r\n102 \"Protobuf decoding consumed too few bytes: {} out of {}\".format(\r\n103 decoded, len(s)))\r\n\r\nYou understood correctly my doubts, however, I'm trying also to check the top1 and top5 accuracy of quantize and no quantize onnx model files from model zoo repo. \r\n\r\nI would like also to check it with Imagenet dataset and validate the accuracy already tested on the readme files like:\r\nhttps://github.com/onnx/models/tree/main/vision/classification/resnet -> on this file, you can read that they recommend to use notebooks with mxnet.\r\n\r\nDo you know another way or framework to validate accuracy for quantize or not quantize onnx models with imagenet dataset?\r\n\r\nThanks for you help!\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1190331092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1190907624",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1190907624",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1190907624,
        "node_id": "IC_kwDOCVq1mM5G-87o",
        "user": {
            "login": "jcwchen",
            "id": 14194980,
            "node_id": "MDQ6VXNlcjE0MTk0OTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14194980?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcwchen",
            "html_url": "https://github.com/jcwchen",
            "followers_url": "https://api.github.com/users/jcwchen/followers",
            "following_url": "https://api.github.com/users/jcwchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcwchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcwchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcwchen/subscriptions",
            "organizations_url": "https://api.github.com/users/jcwchen/orgs",
            "repos_url": "https://api.github.com/users/jcwchen/repos",
            "events_url": "https://api.github.com/users/jcwchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcwchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-21T00:38:47Z",
        "updated_at": "2022-07-21T00:38:47Z",
        "author_association": "MEMBER",
        "body": "> Do you know another way or framework to validate accuracy for quantize or not quantize onnx models with imagenet dataset?\r\n\r\nONNX Runtime (ORT) supports backward compatibility so I believe even latest ORT is still reliable (quantize and no quantize) with ancient ONNX models. As mentioned above, I have verified [this notebook](https://github.com/onnx/models/blob/main/vision/classification/onnxrt_inference.ipynb) (which takes resnet50 as an example). Please give it a try and let me know if there is any issue. Thanks!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1190907624/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1191238817",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1191238817",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1191238817,
        "node_id": "IC_kwDOCVq1mM5HANyh",
        "user": {
            "login": "IzanCatalan",
            "id": 40836734,
            "node_id": "MDQ6VXNlcjQwODM2NzM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/40836734?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IzanCatalan",
            "html_url": "https://github.com/IzanCatalan",
            "followers_url": "https://api.github.com/users/IzanCatalan/followers",
            "following_url": "https://api.github.com/users/IzanCatalan/following{/other_user}",
            "gists_url": "https://api.github.com/users/IzanCatalan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IzanCatalan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IzanCatalan/subscriptions",
            "organizations_url": "https://api.github.com/users/IzanCatalan/orgs",
            "repos_url": "https://api.github.com/users/IzanCatalan/repos",
            "events_url": "https://api.github.com/users/IzanCatalan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IzanCatalan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-21T09:08:27Z",
        "updated_at": "2022-07-21T15:20:04Z",
        "author_association": "NONE",
        "body": "Yes @jcwchen , I already saw it, however with that notebook, you only check the probability of one image. Therefore, if I want to use the entire Imagenet Dataset, should I pass all images one by one? Otherwise, how I can get the top1 69.93%  and top5 89.29% values for Resnet18 accuracy tested on https://github.com/onnx/models/tree/main/vision/classification/resnet ? Thanks!!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1191238817/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1191594455",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1191594455",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1191594455,
        "node_id": "IC_kwDOCVq1mM5HBknX",
        "user": {
            "login": "IzanCatalan",
            "id": 40836734,
            "node_id": "MDQ6VXNlcjQwODM2NzM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/40836734?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IzanCatalan",
            "html_url": "https://github.com/IzanCatalan",
            "followers_url": "https://api.github.com/users/IzanCatalan/followers",
            "following_url": "https://api.github.com/users/IzanCatalan/following{/other_user}",
            "gists_url": "https://api.github.com/users/IzanCatalan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IzanCatalan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IzanCatalan/subscriptions",
            "organizations_url": "https://api.github.com/users/IzanCatalan/orgs",
            "repos_url": "https://api.github.com/users/IzanCatalan/repos",
            "events_url": "https://api.github.com/users/IzanCatalan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IzanCatalan/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-21T15:01:38Z",
        "updated_at": "2022-07-21T15:20:21Z",
        "author_association": "NONE",
        "body": "@jcwchen I also updated my numpy version to 1.23.1 and my onnx to 1.12.0 in order to check https://github.com/onnx/models/blob/main/vision/classification/onnxrt_inference.ipynb , however this is the output\r\n![onnxrt](https://user-images.githubusercontent.com/40836734/180246875-0214d784-db0a-4188-bbcc-beabe9d8d1fe.png)\r\n:",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1191594455/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1195745189",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12235#issuecomment-1195745189",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12235",
        "id": 1195745189,
        "node_id": "IC_kwDOCVq1mM5HRZ-l",
        "user": {
            "login": "jcwchen",
            "id": 14194980,
            "node_id": "MDQ6VXNlcjE0MTk0OTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14194980?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcwchen",
            "html_url": "https://github.com/jcwchen",
            "followers_url": "https://api.github.com/users/jcwchen/followers",
            "following_url": "https://api.github.com/users/jcwchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcwchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcwchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcwchen/subscriptions",
            "organizations_url": "https://api.github.com/users/jcwchen/orgs",
            "repos_url": "https://api.github.com/users/jcwchen/repos",
            "events_url": "https://api.github.com/users/jcwchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcwchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-26T17:03:02Z",
        "updated_at": "2022-07-26T17:03:02Z",
        "author_association": "MEMBER",
        "body": "> therefore, if I want to use the entire Imagenet Dataset, should I pass all images one by one? Otherwise, how I can get the top1 69.93% and top5 89.29% values for Resnet18 accuracy\r\n\r\nThe demo code for onnxruntime only provides inference example for single image. Thus you need to write your own code to go through the whole dataset and get top1/top5 accuracy results. IIUC, not every ONNX Model Zoo model supports batch. If you do see symbolic dimension in the input, you can try to run onnxruntime by giving a batch. At least recently we just batchified ResNet models: https://github.com/onnx/models/pull/537.\r\n\r\n> @jcwchen I also updated my numpy version to 1.23.1 and my onnx to 1.12.0 in order to check https://github.com/onnx/models/blob/main/vision/classification/onnxrt_inference.ipynb , however this is the output\r\n\r\nIt seems like an output limitation from Visual Studio Code, although I don't see this error from my VSCode (perhaps different settings). You can either modify the settings for output (see [here](https://stackoverflow.com/questions/72823258/vscode-interactive-python-output-exceeds-size-limit)) or run the notebook via other ways (for instance, put them into a python file).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1195745189/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]