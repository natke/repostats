[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11918",
        "id": 1277338139,
        "node_id": "PR_kwDOCVq1mM45-IJv",
        "number": 11918,
        "title": "Explicit installation of deps for python wheel building (wheel>=0.35.1)",
        "user": {
            "login": "adrianlizarraga",
            "id": 19691973,
            "node_id": "MDQ6VXNlcjE5NjkxOTcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/19691973?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adrianlizarraga",
            "html_url": "https://github.com/adrianlizarraga",
            "followers_url": "https://api.github.com/users/adrianlizarraga/followers",
            "following_url": "https://api.github.com/users/adrianlizarraga/following{/other_user}",
            "gists_url": "https://api.github.com/users/adrianlizarraga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adrianlizarraga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adrianlizarraga/subscriptions",
            "organizations_url": "https://api.github.com/users/adrianlizarraga/orgs",
            "repos_url": "https://api.github.com/users/adrianlizarraga/repos",
            "events_url": "https://api.github.com/users/adrianlizarraga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adrianlizarraga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-20T20:02:59Z",
        "updated_at": "2022-08-10T00:46:33Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11918",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11918",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11918.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11918.patch",
            "merged_at": null
        },
        "body": "**Description**: Explicitly installs the `wheel` and `setuptools` dependencies when building the ORT python wheel.\r\n\r\n**Motivation and Context**\r\n[This PR](https://github.com/microsoft/onnxruntime/pull/11834) updated the required version of the python wheel package. However, this new dependency requirement has not been fully propagated. Thus, attempting to build the ORT python wheel (e.g., `./build.sh --build_wheel ...`) will fail if the appropriate version of the wheel package is not already installed.\r\n\r\n```console\r\n  /opt/miniconda/bin/python3 /code/onnxruntime/setup.py bdist_wheel --wheel_name_suffix=gpu\r\nTraceback (most recent call last):\r\n  File \"/code/onnxruntime/setup.py\", line 19, in <module>\r\n    from wheel.vendored.packaging.tags import sys_tags\r\nModuleNotFoundError: No module named 'wheel.vendored'\r\nTraceback (most recent call last):\r\n  File \"/code/onnxruntime/tools/ci_build/build.py\", line 2744, in <module>\r\n    sys.exit(main())\r\n  File \"/code/onnxruntime/tools/ci_build/build.py\", line 2709, in main\r\n    build_eager_mode=args.build_eager_mode,\r\n  File \"/code/onnxruntime/tools/ci_build/build.py\", line 2050, in build_python_wheel\r\n    run_subprocess(args, cwd=cwd)\r\n  File \"/code/onnxruntime/tools/ci_build/build.py\", line 714, in run_subprocess\r\n    return run(*args, cwd=cwd, capture_stdout=capture_stdout, shell=shell, env=my_env)\r\n  File \"/code/onnxruntime/tools/python/util/run.py\", line 57, in run\r\n    shell=shell,\r\n  File \"/opt/miniconda/lib/python3.7/subprocess.py\", line 468, in run\r\n    output=stdout, stderr=stderr)\r\n```\r\n\r\nThis PR modifies [tools/ci_build/build.py](https://github.com/microsoft/onnxruntime/blob/master/tools/ci_build/build.py#L1980) to ensure that wheel>=0.35.1 is installed before calling [setup.py](https://github.com/microsoft/onnxruntime/blob/master/setup.py). However, because [wheel does not have a stable API and is not intended to be used as a library](https://github.com/pypa/wheel#wheel), this PR pins wheel to the latest known working version (0.37.1).\r\n\r\n**NOT TESTED YET**\r\n- `Linux OpenVINO CI Pipeline` fails due to permission error.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11918/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11919",
        "id": 1277404130,
        "node_id": "PR_kwDOCVq1mM45-WJU",
        "number": 11919,
        "title": "Optimize beamsearch with unexpanded T5 encoder",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-20T21:30:12Z",
        "updated_at": "2022-06-21T01:59:14Z",
        "closed_at": "2022-06-20T22:37:58Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11919",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11919",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11919.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11919.patch",
            "merged_at": null
        },
        "body": "**Description**: Describe your changes.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11919/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11920",
        "id": 1277434077,
        "node_id": "PR_kwDOCVq1mM45-cYq",
        "number": 11920,
        "title": "Offline tooling readme",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-20T22:19:33Z",
        "updated_at": "2022-06-22T00:57:45Z",
        "closed_at": "2022-06-22T00:57:45Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11920",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11920",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11920.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11920.patch",
            "merged_at": "2022-06-22T00:57:45Z"
        },
        "body": "Document going over how to generate the training graphs with the offline tooling.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11920/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11921",
        "id": 1277452159,
        "node_id": "I_kwDOCVq1mM5MJF9_",
        "number": 11921,
        "title": "onnx value_info can contain graph inputs/outputs in filtered graphs",
        "user": {
            "login": "MikeHolman",
            "id": 4925255,
            "node_id": "MDQ6VXNlcjQ5MjUyNTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4925255?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MikeHolman",
            "html_url": "https://github.com/MikeHolman",
            "followers_url": "https://api.github.com/users/MikeHolman/followers",
            "following_url": "https://api.github.com/users/MikeHolman/following{/other_user}",
            "gists_url": "https://api.github.com/users/MikeHolman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MikeHolman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MikeHolman/subscriptions",
            "organizations_url": "https://api.github.com/users/MikeHolman/orgs",
            "repos_url": "https://api.github.com/users/MikeHolman/repos",
            "events_url": "https://api.github.com/users/MikeHolman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MikeHolman/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-20T22:41:52Z",
        "updated_at": "2022-07-11T22:22:25Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nSerialized ONNX graphs have `input`, `output`, and `value_info` properties, which contain shape/type information about values in the graph. `value_info` is only supposed to contain information about values that are not inputs or outputs.\r\nhttps://github.com/onnx/onnx/blob/main/docs/IR.md#graph\r\nWhen serializing a `FusedNodeAndGraph::filtered_graph` after partitioning a graph, inputs also are showing up in the value_info list.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.7.2\r\n- Python version: 3.9.7\r\n- Visual Studio version (if applicable): VS 2022\r\n- GCC/Compiler version (if compiling from source): MSVC 14.32.31326\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**To Reproduce**\r\nCreate a model that gets partitioned into different subgraphs, such that some internal value_info becomes an input to the second subgraph.\r\nIn `ExecutionProvider::Compile` get the graph proto from `nodeAndGraph.filtered_graph` and serialize it.\r\nInspect the `input` and `value_info` lists of the second subgraph, and note that the `value_info` list contains input values.\r\n\r\n**Expected behavior**\r\n`value_info` does not contain inputs or outputs.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11921/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11922",
        "id": 1277489570,
        "node_id": "PR_kwDOCVq1mM45-o09",
        "number": 11922,
        "title": "Deprecate APIs returning raw ptrs and provide replacements",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-20T23:23:20Z",
        "updated_at": "2022-07-06T16:55:40Z",
        "closed_at": "2022-06-24T16:50:05Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11922",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11922",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11922.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11922.patch",
            "merged_at": "2022-06-24T16:50:04Z"
        },
        "body": "**Description**: \r\nDeprecate APIs that return pointes to buffers that are allocated using an instance of `OrtAllocator.`\r\nProvide replacements that return smart pointers with bound allocator pointers. Those release buffers automatically.\r\n\r\n**Motivation and Context**\r\nThese buffers require explicit deallocation using the same allocator that allocated them.\r\nHowever, there is not a convenient and exception-safe way of doing it without customer writing additional code.\r\nThe end results the customers often leak those buffers.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11922/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11923",
        "id": 1277503827,
        "node_id": "PR_kwDOCVq1mM45-r-4",
        "number": 11923,
        "title": "Update Linux Multi GPU TensorRT pipeline to TensorRT 8.4",
        "user": {
            "login": "adrianlizarraga",
            "id": 19691973,
            "node_id": "MDQ6VXNlcjE5NjkxOTcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/19691973?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adrianlizarraga",
            "html_url": "https://github.com/adrianlizarraga",
            "followers_url": "https://api.github.com/users/adrianlizarraga/followers",
            "following_url": "https://api.github.com/users/adrianlizarraga/following{/other_user}",
            "gists_url": "https://api.github.com/users/adrianlizarraga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adrianlizarraga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adrianlizarraga/subscriptions",
            "organizations_url": "https://api.github.com/users/adrianlizarraga/orgs",
            "repos_url": "https://api.github.com/users/adrianlizarraga/repos",
            "events_url": "https://api.github.com/users/adrianlizarraga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adrianlizarraga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-20T23:44:30Z",
        "updated_at": "2022-06-21T14:59:12Z",
        "closed_at": "2022-06-21T14:59:11Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11923",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11923",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11923.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11923.patch",
            "merged_at": "2022-06-21T14:59:11Z"
        },
        "body": "**Description**: Update the multi-gpu pipeline to tensorrt 8.4\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11923/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11924",
        "id": 1277536679,
        "node_id": "PR_kwDOCVq1mM45-zAq",
        "number": 11924,
        "title": "Update ONNX to 1.12",
        "user": {
            "login": "garymm",
            "id": 421339,
            "node_id": "MDQ6VXNlcjQyMTMzOQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/421339?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/garymm",
            "html_url": "https://github.com/garymm",
            "followers_url": "https://api.github.com/users/garymm/followers",
            "following_url": "https://api.github.com/users/garymm/following{/other_user}",
            "gists_url": "https://api.github.com/users/garymm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/garymm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/garymm/subscriptions",
            "organizations_url": "https://api.github.com/users/garymm/orgs",
            "repos_url": "https://api.github.com/users/garymm/repos",
            "events_url": "https://api.github.com/users/garymm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/garymm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-21T00:39:41Z",
        "updated_at": "2022-07-06T16:56:33Z",
        "closed_at": "2022-06-22T00:19:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11924",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11924",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11924.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11924.patch",
            "merged_at": "2022-06-22T00:19:53Z"
        },
        "body": "Follow-ups that need to happen after this and before the next ORT release:\r\n* Support SequenceMap with https://github.com/microsoft/onnxruntime/pull/11731\r\n* Support signal ops with https://github.com/microsoft/onnxruntime/pull/11778\r\n\r\nFollow-ups that need to happen after this but don't necessarily need to happen before the release:\r\n* https://github.com/microsoft/onnxruntime/issues/11916\r\n\r\nFixes #11640",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11924/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11925",
        "id": 1277652431,
        "node_id": "PR_kwDOCVq1mM45_NRG",
        "number": 11925,
        "title": "MeanVarianceNormalization CPU EP axes attribute validation",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-21T02:03:16Z",
        "updated_at": "2022-06-22T19:03:15Z",
        "closed_at": "2022-06-22T19:03:14Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11925",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11925",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11925.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11925.patch",
            "merged_at": "2022-06-22T19:03:14Z"
        },
        "body": "**Description**: The CPU EP [MVN](https://github.com/onnx/onnx/blob/main/docs/Operators.md#MeanVarianceNormalization) kernel doesn't actually support the `axes` parameter (any arbitrary axes), which caused some test failures when comparing against the DML EP (which fully supports `axes`). Not supporting them is *okay*, but what's worse is that the code silently returns the wrong results for unsupported combinations, like HW and NC, which get mapped incorrectly to NHW and NCHW respectively. This change more robustly checks the `axes` parameter, rather than just checking for the presence of axis 1 without checking the other axes, given the CPU EP only supports 4D NCHW and NHW.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- *If it fixes an open issue, please link to the issue here.* https://github.com/microsoft/onnxruntime/issues/1828\r\n\r\n```\r\nonnxruntime_test_all.exe\r\n...\r\n[==========] 3319 tests from 230 test suites ran. (372903 ms total)\r\n[  PASSED  ] 3319 tests.\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11925/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11926",
        "id": 1277698853,
        "node_id": "PR_kwDOCVq1mM45_Xtk",
        "number": 11926,
        "title": "Optimize t5 encoder in beam search",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-21T02:32:13Z",
        "updated_at": "2022-07-06T16:56:17Z",
        "closed_at": "2022-06-22T19:45:03Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11926",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11926",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11926.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11926.patch",
            "merged_at": "2022-06-22T19:45:03Z"
        },
        "body": "**Description**: Describe your changes.\r\nRun EncoderDecoderInit with original inputs and expand the output.\r\nzcode(cpu) inference time 17s -> 11s\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11926/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11927",
        "id": 1277959038,
        "node_id": "I_kwDOCVq1mM5MLBt-",
        "number": 11927,
        "title": "ConvTranspose with auto_pad attribute",
        "user": {
            "login": "furiosa-JeongminPark",
            "id": 89759051,
            "node_id": "MDQ6VXNlcjg5NzU5MDUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/89759051?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/furiosa-JeongminPark",
            "html_url": "https://github.com/furiosa-JeongminPark",
            "followers_url": "https://api.github.com/users/furiosa-JeongminPark/followers",
            "following_url": "https://api.github.com/users/furiosa-JeongminPark/following{/other_user}",
            "gists_url": "https://api.github.com/users/furiosa-JeongminPark/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/furiosa-JeongminPark/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/furiosa-JeongminPark/subscriptions",
            "organizations_url": "https://api.github.com/users/furiosa-JeongminPark/orgs",
            "repos_url": "https://api.github.com/users/furiosa-JeongminPark/repos",
            "events_url": "https://api.github.com/users/furiosa-JeongminPark/events{/privacy}",
            "received_events_url": "https://api.github.com/users/furiosa-JeongminPark/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-21T06:33:56Z",
        "updated_at": "2022-08-12T08:37:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nConvTranspose operator with auto_pad == \"SAME_LOWER\", \"SAME_UPPER\" implementations seem to be wrong.\r\n\r\n**Urgency**\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): from pip install\r\n- ONNX Runtime version: onnxruntime==1.11.1\r\n- Python version: 3.8.12\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n- ONNX version: onnx==1.12.0\r\n\r\n**To Reproduce**\r\n```\r\n#! usr/bin/env python3\r\nimport numpy as np\r\nimport onnx\r\nimport onnxruntime as ort\r\n\r\n\r\ndef main():\r\n    model_name = \"conv_transpose\"\r\n    graph = onnx.helper.make_graph(\r\n        # nodes\r\n        [\r\n            onnx.helper.make_node(\r\n                'ConvTranspose',\r\n                inputs=['x', 'w'],\r\n                outputs=['y'],\r\n                strides=[2, 2],\r\n                auto_pad=\"SAME_UPPER\",\r\n                # pads=[0, 0, 1, 1],\r\n                output_padding=[1, 1],\r\n            )\r\n        ],\r\n        # graph name\r\n        model_name,\r\n        # input\r\n        [\r\n            onnx.helper.make_tensor_value_info(\"x\", onnx.TensorProto.FLOAT, (1, 2, 3, 3)),\r\n        ],\r\n        # output\r\n        [\r\n            onnx.helper.make_tensor_value_info(\"y\", onnx.TensorProto.FLOAT, (1, 1, 6, 6)),\r\n        ],\r\n        # initializer\r\n        [\r\n            onnx.helper.make_tensor(\r\n                \"w\", onnx.TensorProto.FLOAT, (2, 1, 3, 3), [i for i in range(2 * 1 * 3 * 3)]\r\n            ),\r\n        ],\r\n    )\r\n    model = onnx.helper.make_model(graph, opset_imports=[onnx.helper.make_opsetid(\"\", 12)])\r\n\r\n    model = onnx.shape_inference.infer_shapes(model, check_type=True, strict_mode=True)\r\n    onnx.checker.check_model(model)\r\n    onnx.save_model(model, f'{model_name}.onnx')\r\n\r\n    sess = ort.InferenceSession(model.SerializeToString())\r\n    x = np.array([i for i in range(1 * 2 * 3 * 3)]).reshape(1, 2, 3, 3).astype(np.float32)\r\n    print(sess.run(None, {\"x\": x}))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n\r\nfrom the script above, experiment on (auto_pad, pads) option == (\"SAME_LOWER\", None), (\"SAME_UPPER\", None), (None, [0, 0, 1, 1]), (None, [1, 1, 0, 0])\r\n\r\n\r\n- (auto_pad, pads) == (\"SAME_UPPER\", None)\r\n```\r\n[array([[[[117., 249., 134., 283., 151., 164.],\r\n         [267., 564., 301., 632., 335., 367.],\r\n         [168., 351., 185., 385., 202., 221.],\r\n         [369., 768., 403., 836., 437., 481.],\r\n         [219., 453., 236., 487., 253., 278.],\r\n         [282., 585., 305., 631., 328., 353.]]]], dtype=float32)]\r\n```\r\n- (auto_pad, pads) == (\"SAME_LOWER\", None)\r\n```\r\n[array([[[[ 81.,  90., 189., 101., 211., 112.],\r\n         [108., 117., 249., 134., 283., 151.],\r\n         [243., 267., 564., 301., 632., 335.],\r\n         [153., 168., 351., 185., 385., 202.],\r\n         [333., 369., 768., 403., 836., 437.],\r\n         [198., 219., 453., 236., 487., 253.]]]], dtype=float32)]\r\n```\r\n- (auto_pad, pads) == (None, [0, 0, 1, 1])\r\n```\r\n[array([[[[ 81.,  90., 189., 101., 211., 112.],\r\n         [108., 117., 249., 134., 283., 151.],\r\n         [243., 267., 564., 301., 632., 335.],\r\n         [153., 168., 351., 185., 385., 202.],\r\n         [333., 369., 768., 403., 836., 437.],\r\n         [198., 219., 453., 236., 487., 253.]]]], dtype=float32)]\r\n```\r\n- (auto_pad, pads) == (None, [1, 1, 0, 0])\r\n```\r\n[array([[[[117., 249., 134., 283., 151., 164.],\r\n         [267., 564., 301., 632., 335., 367.],\r\n         [168., 351., 185., 385., 202., 221.],\r\n         [369., 768., 403., 836., 437., 481.],\r\n         [219., 453., 236., 487., 253., 278.],\r\n         [282., 585., 305., 631., 328., 353.]]]], dtype=float32)]\r\n```\r\n**Expected behavior**\r\noutputs from\r\n(auto_pad, pads) = (\"SAME_UPPER\", None), (auto_pad, pads) == (None, [0, 0, 1, 1]) should match and\r\n(auto_pad, pads) = (\"SAME_LOWER\", None), (auto_pad, pads) == (None, [1, 1, 0, 0]) should match.\r\n\r\nBut the opposite holds.\r\n\r\n\r\n**Screenshots**\r\n\r\n**Additional context**\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11927/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11928",
        "id": 1278238574,
        "node_id": "I_kwDOCVq1mM5MMF9u",
        "number": 11928,
        "title": "Percentile/entropy calibration not working for quantizing Resnet-50/MobileNet",
        "user": {
            "login": "regisss",
            "id": 15324346,
            "node_id": "MDQ6VXNlcjE1MzI0MzQ2",
            "avatar_url": "https://avatars.githubusercontent.com/u/15324346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/regisss",
            "html_url": "https://github.com/regisss",
            "followers_url": "https://api.github.com/users/regisss/followers",
            "following_url": "https://api.github.com/users/regisss/following{/other_user}",
            "gists_url": "https://api.github.com/users/regisss/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/regisss/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/regisss/subscriptions",
            "organizations_url": "https://api.github.com/users/regisss/orgs",
            "repos_url": "https://api.github.com/users/regisss/repos",
            "events_url": "https://api.github.com/users/regisss/events{/privacy}",
            "received_events_url": "https://api.github.com/users/regisss/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2022-06-21T10:30:00Z",
        "updated_at": "2022-11-16T08:41:51Z",
        "closed_at": "2022-07-13T00:04:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nThe [image classification CPU example](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/image_classification/cpu) of `onnxruntime-inference-examples` returns an error with `calibrate_method=CalibrationMethod.Entropy` or `calibrate_method=CalibrationMethod.Percentile` and `quant_format=QDQ`.\r\n\r\nHere is the error I got with Resnet-50:\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 144, in <module>\r\n    main()\r\n  File \"run.py\", line 125, in main\r\n    quantize_static(\r\n  File \"/home/regis/HuggingFace/dev/venv/lib/python3.8/site-packages/onnxruntime/quantization/quantize.py\", line 290, in quantize_static\r\n    quantizer.quantize_model()\r\n  File \"/home/regis/HuggingFace/dev/venv/lib/python3.8/site-packages/onnxruntime/quantization/qdq_quantizer.py\", line 114, in quantize_model\r\n    self.quantize_tensors()\r\n  File \"/home/regis/HuggingFace/dev/venv/lib/python3.8/site-packages/onnxruntime/quantization/qdq_quantizer.py\", line 169, in quantize_tensors\r\n    raise ValueError(\r\nValueError: Quantization parameters are not specified for param resnetv17_dense0_fwd.In static mode quantization params for inputs and outputs of nodes to be quantized are required.\r\n```\r\n\r\nIt seems no data were collected for the output of the model.\r\n\r\n**I get the same error with the MobileNet model of the same example**.\r\n\r\n**Urgency**\r\nI think this is pretty urgent because the only way to statically quantize such models at the moment is to use MinMax calibration.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): installed with `pip`\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: 3.8.10\r\n- Visual Studio version (if applicable): /\r\n- GCC/Compiler version (if compiling from source): /\r\n- CUDA/cuDNN version: not using GPU\r\n- GPU model and memory: not using GPU\r\n\r\n**To Reproduce**\r\nI ran [this official example](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/image_classification/cpu) with two small modifications to be able to use another calibration method:\r\n\r\n- add `from onnxruntime.quantization import CalibrationMethod`\r\n- add the argument `calibrate_method=CalibrationMethod.Entropy` to `quantize_static` on line 111\r\n\r\nThe command: `python run.py --input_model resnet50-v1-13.onnx --output_model resnet50-v1-13_quant.onnx --calibrate_dataset ./test_images/ --quant_format QDQ` returns the error above.\r\n\r\n**Expected behavior**\r\nQuantization of these models should work with percentile/entropy calibration.\r\n\r\n**Additional context**\r\nI tried with the Hugging Face implementation of Resnet-50 and got the same issue, so I do not think it is related to these models in particular.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11928/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11929",
        "id": 1278370899,
        "node_id": "PR_kwDOCVq1mM46Bonx",
        "number": 11929,
        "title": "fix: handle setBindingDimensions return value in TensorRT EP",
        "user": {
            "login": "senysenyseny16",
            "id": 82811840,
            "node_id": "MDQ6VXNlcjgyODExODQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/82811840?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/senysenyseny16",
            "html_url": "https://github.com/senysenyseny16",
            "followers_url": "https://api.github.com/users/senysenyseny16/followers",
            "following_url": "https://api.github.com/users/senysenyseny16/following{/other_user}",
            "gists_url": "https://api.github.com/users/senysenyseny16/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/senysenyseny16/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/senysenyseny16/subscriptions",
            "organizations_url": "https://api.github.com/users/senysenyseny16/orgs",
            "repos_url": "https://api.github.com/users/senysenyseny16/repos",
            "events_url": "https://api.github.com/users/senysenyseny16/events{/privacy}",
            "received_events_url": "https://api.github.com/users/senysenyseny16/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2022-06-21T12:23:53Z",
        "updated_at": "2022-06-21T21:30:28Z",
        "closed_at": "2022-06-21T21:30:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11929",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11929",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11929.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11929.patch",
            "merged_at": "2022-06-21T21:30:27Z"
        },
        "body": "Handle status of `setBindingDimensions` ([link](https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/classnvinfer1_1_1_i_execution_context.html#a3983767d1765d5bf8585433e7dd86e4a)) in TensorRT EP.\r\n\r\n**Motivation and Context**\r\nWithout checking the result of `setBindingDimensions` TensorRT may load cached engine for model with different input shape, for example it can load engine generated for model with dynamic shapes for model with fixed shape.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11929/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11931",
        "id": 1278628469,
        "node_id": "PR_kwDOCVq1mM46CgKh",
        "number": 11931,
        "title": "Correcting a typo in the path for ort-nighty ",
        "user": {
            "login": "Gooogr",
            "id": 32438284,
            "node_id": "MDQ6VXNlcjMyNDM4Mjg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32438284?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Gooogr",
            "html_url": "https://github.com/Gooogr",
            "followers_url": "https://api.github.com/users/Gooogr/followers",
            "following_url": "https://api.github.com/users/Gooogr/following{/other_user}",
            "gists_url": "https://api.github.com/users/Gooogr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Gooogr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Gooogr/subscriptions",
            "organizations_url": "https://api.github.com/users/Gooogr/orgs",
            "repos_url": "https://api.github.com/users/Gooogr/repos",
            "events_url": "https://api.github.com/users/Gooogr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Gooogr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-21T15:34:11Z",
        "updated_at": "2022-06-21T15:44:14Z",
        "closed_at": "2022-06-21T15:44:09Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11931",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11931",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11931.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11931.patch",
            "merged_at": null
        },
        "body": "\r\n**Description**\r\nRemoved the unnecessary space in the link `https://test.pypi.org/simple/ ort-nightly >>pip_output.txt`\r\n\r\n**Motivation and Context**\r\nIn the previous version, the URL link gave a 404 error. Because of this ort-nightly would not install, the onnxruntime package was missing.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11931/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11932",
        "id": 1278770660,
        "node_id": "PR_kwDOCVq1mM46C-EI",
        "number": 11932,
        "title": "Enable Pad test cases with initializer inputs only when building NNAPI EP on Android.",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-21T17:30:12Z",
        "updated_at": "2022-06-27T19:09:34Z",
        "closed_at": "2022-06-21T21:16:55Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11932",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11932",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11932.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11932.patch",
            "merged_at": "2022-06-21T21:16:55Z"
        },
        "body": "**Description**\r\nEnable Pad test cases with initializer inputs only when building NNAPI EP on Android.\r\n\r\n**Motivation and Context**\r\nQEMU aarch64 CI build is failing due to excessive memory usage.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11932/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11933",
        "id": 1278930347,
        "node_id": "PR_kwDOCVq1mM46Dhmc",
        "number": 11933,
        "title": "Fix trainer",
        "user": {
            "login": "ashbhandare",
            "id": 14295305,
            "node_id": "MDQ6VXNlcjE0Mjk1MzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/14295305?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashbhandare",
            "html_url": "https://github.com/ashbhandare",
            "followers_url": "https://api.github.com/users/ashbhandare/followers",
            "following_url": "https://api.github.com/users/ashbhandare/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashbhandare/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashbhandare/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashbhandare/subscriptions",
            "organizations_url": "https://api.github.com/users/ashbhandare/orgs",
            "repos_url": "https://api.github.com/users/ashbhandare/repos",
            "events_url": "https://api.github.com/users/ashbhandare/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashbhandare/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-21T19:13:45Z",
        "updated_at": "2022-06-22T15:48:20Z",
        "closed_at": "2022-06-22T15:48:19Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11933",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11933",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11933.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11933.patch",
            "merged_at": "2022-06-22T15:48:19Z"
        },
        "body": "Trainer has hardcoding for input type, which makes it difficult for users to run the trainer for a smoke test for installation\r\nThis fix still doesnt remove the hardcoding but makes it possible for the user to set the dummy model config through command line",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11933/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11934",
        "id": 1279020874,
        "node_id": "PR_kwDOCVq1mM46D11U",
        "number": 11934,
        "title": "Update DML 1.9 Nuget package to fix WindowsAI nuget pipeline build issue",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-21T20:26:28Z",
        "updated_at": "2022-06-21T22:56:02Z",
        "closed_at": "2022-06-21T22:55:52Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11934",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11934",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11934.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11934.patch",
            "merged_at": "2022-06-21T22:55:52Z"
        },
        "body": "**Description**: Sheil K pointed out the WindowsAI nuget pipeline is failing to build due to a renamed file in the package.\r\n\r\n```\r\nCould not copy the file \"D:\\a\\_work\\1\\s\\csharp\\test\\Microsoft.AI.MachineLearning.Tests\\packages\\microsoft.ai.directml.preview\\1.9.0-devd10042c94985065a565c042540e15eb75b554663\\bin\\x64-win\\DirectML.d10042c94985065a565c042540e15eb75b554663.pdb\" because it was not found.\r\n```\r\n\r\n**Motivation and Context**\r\n- *Why is this change required? What problem does it solve?* See above.\r\n- *If it fixes an open issue, please link to the issue here.* NA",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11934/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11935",
        "id": 1279021737,
        "node_id": "PR_kwDOCVq1mM46D2Br",
        "number": 11935,
        "title": "Improve performance of BiasGelu on oneDNN execution provider",
        "user": {
            "login": "georgen117",
            "id": 16688936,
            "node_id": "MDQ6VXNlcjE2Njg4OTM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16688936?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/georgen117",
            "html_url": "https://github.com/georgen117",
            "followers_url": "https://api.github.com/users/georgen117/followers",
            "following_url": "https://api.github.com/users/georgen117/following{/other_user}",
            "gists_url": "https://api.github.com/users/georgen117/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/georgen117/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/georgen117/subscriptions",
            "organizations_url": "https://api.github.com/users/georgen117/orgs",
            "repos_url": "https://api.github.com/users/georgen117/repos",
            "events_url": "https://api.github.com/users/georgen117/events{/privacy}",
            "received_events_url": "https://api.github.com/users/georgen117/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2022-06-21T20:27:10Z",
        "updated_at": "2022-06-27T15:34:35Z",
        "closed_at": "2022-06-27T15:34:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11935",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11935",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11935.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11935.patch",
            "merged_at": "2022-06-27T15:34:12Z"
        },
        "body": "This modifies how BiasGelu is handled by the oneDNN execution provider\r\nby executing the gelu_erf primitive as a postop of the binary_add primitive.\r\n\r\nAlso fixes extra data copies made when running on GPU.\r\n\r\nSigned-off-by: George Nash <george.nash@intel.com>\r\n\r\n**Description**: \r\nThis is a small update to run BiasGelu as a single primitive instead or 2 primitives in the oneDNN execution provider.\r\nThis has an effect of speeding up the BiasGelu op when run on oneDNN ep.\r\n\r\n**Motivation and Context**\r\n- Why is this change required?\r\nWe are attempting to speed up the performance on the oneDNN ep for NLP models like DistilBERT. \r\n-  What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11935/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11936",
        "id": 1279166825,
        "node_id": "PR_kwDOCVq1mM46EXP7",
        "number": 11936,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts/training/ortmodule/stage1/requirements_torch1.11.0_rocm5.1.1",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 41,
        "created_at": "2022-06-21T22:09:05Z",
        "updated_at": "2022-11-01T18:36:52Z",
        "closed_at": "2022-11-01T18:36:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11936",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11936",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11936.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11936.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11936/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11937",
        "id": 1279166886,
        "node_id": "PR_kwDOCVq1mM46EXQy",
        "number": 11937,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2022-06-21T22:09:09Z",
        "updated_at": "2022-08-19T06:08:52Z",
        "closed_at": "2022-08-19T06:08:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11937",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11937",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11937.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11937.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11937/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11938",
        "id": 1279166902,
        "node_id": "PR_kwDOCVq1mM46EXRC",
        "number": 11938,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-21T22:09:10Z",
        "updated_at": "2022-12-23T07:15:30Z",
        "closed_at": "2022-12-23T07:15:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11938",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11938",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11938.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11938.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11938/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11939",
        "id": 1279166975,
        "node_id": "PR_kwDOCVq1mM46EXSI",
        "number": 11939,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts/training",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 76,
        "created_at": "2022-06-21T22:09:14Z",
        "updated_at": "2023-04-26T02:22:57Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11939",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11939",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11939.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11939.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nYou can trigger a rebase of this PR by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>> **Note**\n> Automatic rebases have been disabled on this pull request as it has been open for over 30 days.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11939/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11940",
        "id": 1279166992,
        "node_id": "PR_kwDOCVq1mM46EXSW",
        "number": 11940,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts/training/ortmodule/stage1/requirements_torch1.11.0_rocm4.3.1",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 55,
        "created_at": "2022-06-21T22:09:15Z",
        "updated_at": "2022-11-01T18:35:19Z",
        "closed_at": "2022-11-01T18:35:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11940",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11940",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11940.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11940.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11940/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11941",
        "id": 1279167017,
        "node_id": "PR_kwDOCVq1mM46EXSs",
        "number": 11941,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts/manylinux",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-21T22:09:17Z",
        "updated_at": "2023-04-04T17:56:27Z",
        "closed_at": "2023-04-04T17:56:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11941",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11941",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11941.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11941.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11941/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11942",
        "id": 1279167175,
        "node_id": "PR_kwDOCVq1mM46EXU8",
        "number": 11942,
        "title": "Bump numpy from 1.21.0 to 1.22.0 in /tools/ci_build/github/linux/docker/scripts/training/ortmodule/stage2",
        "user": {
            "login": "dependabot[bot]",
            "id": 49699333,
            "node_id": "MDM6Qm90NDk2OTkzMzM=",
            "avatar_url": "https://avatars.githubusercontent.com/in/29110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dependabot%5Bbot%5D",
            "html_url": "https://github.com/apps/dependabot",
            "followers_url": "https://api.github.com/users/dependabot%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/dependabot%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/dependabot%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dependabot%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dependabot%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/dependabot%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/dependabot%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/dependabot%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dependabot%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-21T22:09:26Z",
        "updated_at": "2023-04-04T18:53:27Z",
        "closed_at": "2023-04-04T18:53:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11942",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11942",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11942.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11942.patch",
            "merged_at": null
        },
        "body": "Bumps [numpy](https://github.com/numpy/numpy) from 1.21.0 to 1.22.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/numpy/numpy/releases\">numpy's releases</a>.</em></p>\n<blockquote>\n<h2>v1.22.0</h2>\n<h1>NumPy 1.22.0 Release Notes</h1>\n<p>NumPy 1.22.0 is a big release featuring the work of 153 contributors\nspread over 609 pull requests. There have been many improvements,\nhighlights are:</p>\n<ul>\n<li>Annotations of the main namespace are essentially complete. Upstream\nis a moving target, so there will likely be further improvements,\nbut the major work is done. This is probably the most user visible\nenhancement in this release.</li>\n<li>A preliminary version of the proposed Array-API is provided. This is\na step in creating a standard collection of functions that can be\nused across application such as CuPy and JAX.</li>\n<li>NumPy now has a DLPack backend. DLPack provides a common interchange\nformat for array (tensor) data.</li>\n<li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The\nnew methods provide a complete set of the methods commonly found in\nthe literature.</li>\n<li>A new configurable allocator for use by downstream projects.</li>\n</ul>\n<p>These are in addition to the ongoing work to provide SIMD support for\ncommonly used functions, improvements to F2PY, and better documentation.</p>\n<p>The Python versions supported in this release are 3.8-3.10, Python 3.7\nhas been dropped. Note that 32 bit wheels are only provided for Python\n3.8 and 3.9 on Windows, all other wheels are 64 bits on account of\nUbuntu, Fedora, and other Linux distributions dropping 32 bit support.\nAll 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix\nthe occasional problems encountered by folks using truly huge arrays.</p>\n<h2>Expired deprecations</h2>\n<h3>Deprecated numeric style dtype strings have been removed</h3>\n<p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,\nand <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19539\">gh-19539</a>)</p>\n<h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>\n<p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that\nusers use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both\ndeprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with\nthe appropriate value for the <code>usemask</code> parameter.</p>\n<p>(<a href=\"https://github-redirect.dependabot.com/numpy/numpy/pull/19615\">gh-19615</a>)</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03\"><code>4adc87d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20685\">#20685</a> from charris/prepare-for-1.22.0-release</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf\"><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba\"><code>125304b</code></a> wip</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea\"><code>c283859</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20682\">#20682</a> from charris/backport-20416</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee\"><code>5399c03</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20681\">#20681</a> from charris/backport-20954</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e\"><code>f9c45f8</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/numpy/numpy/issues/20680\">#20680</a> from charris/backport-20663</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b\"><code>794b36f</code></a> Update armccompiler.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f\"><code>d93b14e</code></a> Update test_public_api.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6\"><code>7662c07</code></a> Update <strong>init</strong>.py</li>\n<li><a href=\"https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef\"><code>311ab52</code></a> Update armccompiler.py</li>\n<li>Additional commits viewable in <a href=\"https://github.com/numpy/numpy/compare/v1.21.0...v1.22.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.0&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microsoft/onnxruntime/network/alerts).\n\n</details>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11942/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11943",
        "id": 1279172464,
        "node_id": "PR_kwDOCVq1mM46EYiK",
        "number": 11943,
        "title": "Fix a couple of typos",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-21T22:14:23Z",
        "updated_at": "2022-06-27T00:32:15Z",
        "closed_at": "2022-06-27T00:32:15Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11943",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11943",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11943.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11943.patch",
            "merged_at": "2022-06-27T00:32:15Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11943/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11944",
        "id": 1279206645,
        "node_id": "PR_kwDOCVq1mM46EgOY",
        "number": 11944,
        "title": "[js/web][bugfix] fix negative axes for unsqueeze",
        "user": {
            "login": "Yosshi999",
            "id": 8027142,
            "node_id": "MDQ6VXNlcjgwMjcxNDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8027142?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Yosshi999",
            "html_url": "https://github.com/Yosshi999",
            "followers_url": "https://api.github.com/users/Yosshi999/followers",
            "following_url": "https://api.github.com/users/Yosshi999/following{/other_user}",
            "gists_url": "https://api.github.com/users/Yosshi999/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Yosshi999/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Yosshi999/subscriptions",
            "organizations_url": "https://api.github.com/users/Yosshi999/orgs",
            "repos_url": "https://api.github.com/users/Yosshi999/repos",
            "events_url": "https://api.github.com/users/Yosshi999/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Yosshi999/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2022-06-21T22:54:41Z",
        "updated_at": "2022-06-28T18:28:35Z",
        "closed_at": "2022-06-28T18:28:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11944",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11944",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11944.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11944.patch",
            "merged_at": "2022-06-28T18:28:35Z"
        },
        "body": "**Description**: Describe your changes.\r\nI fixed the unsqueeze's behavior against negative axis based on the C++ implementation at https://github.com/microsoft/onnxruntime/blob/7e092a7e3f8f9f590de0ac5548035e8fa4d512f8/onnxruntime/core/providers/cpu/tensor/unsqueeze.cc#L65\r\n\r\n**Motivation and Context**\r\n\r\nWhen a tensor X has a shape (p, q, r), the result shape of unsqueeze(X, axes=[-1]) must be (p, q, r, 1).\r\nHowever, the current implementation of onnxruntime-web outputs (p, q, 1, r).\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11944/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11945",
        "id": 1279313265,
        "node_id": "PR_kwDOCVq1mM46E37R",
        "number": 11945,
        "title": "[ROCm] Enable build option for autograd",
        "user": {
            "login": "ytaous",
            "id": 4484531,
            "node_id": "MDQ6VXNlcjQ0ODQ1MzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4484531?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ytaous",
            "html_url": "https://github.com/ytaous",
            "followers_url": "https://api.github.com/users/ytaous/followers",
            "following_url": "https://api.github.com/users/ytaous/following{/other_user}",
            "gists_url": "https://api.github.com/users/ytaous/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ytaous/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ytaous/subscriptions",
            "organizations_url": "https://api.github.com/users/ytaous/orgs",
            "repos_url": "https://api.github.com/users/ytaous/repos",
            "events_url": "https://api.github.com/users/ytaous/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ytaous/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-22T01:22:31Z",
        "updated_at": "2022-07-06T01:11:30Z",
        "closed_at": "2022-07-06T01:11:29Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11945",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11945",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11945.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11945.patch",
            "merged_at": "2022-07-06T01:11:29Z"
        },
        "body": "**Description**: the current ROCm 5.1.1 whl included in PTCA image is having export issue on PythonOp. Checked and found ORT's ROCM CIs for python packages is missing the build option \"--enable_training_torch_interop\".  \r\n\r\n- Verified on local build with the option, the export issue is addressed \r\n- Also verified the newly generated whl from CIs\r\n\r\nIn addition, found the AMD CIs is also missing the build option, and it's still using torch 1.10. In order to cover ortmodule UTs in the pipeline, need to upgrade the torch to 1.11 for that particular step. Using https://repo.radeon.com/rocm/manylinux/rocm-rel-5.1.3/ at the moment as it's not available on Torch's website yet.   \r\n\r\nAlthough, some UTs are disabled in packaging pipeline, they are still covered by AMD CI pipeline.\r\nIn future, those UTs could be run in reporting pipeline like Anubis using these whls. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11945/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11946",
        "id": 1279395903,
        "node_id": "I_kwDOCVq1mM5MQgg_",
        "number": 11946,
        "title": "how to get inference time with c# onnxruntime-gpu-1.6.0",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-22T02:36:23Z",
        "updated_at": "2022-06-22T23:42:03Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubantu18\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:1.6.0\r\n- Python version:\r\n- Visual Studio version (if applicable): 2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 10.2/cudnn 8.0\r\n- GPU model and memory:2080ti\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\ni get the inference time by c# code\r\nvar start1 = Data.Now.ticks;\r\nsession.run()\r\nvar end1 = Data.Now.ticks - start;\r\nresults:\r\nthe end1 is 40ms\r\n\r\nvar start2 = Data.Now.ticks;\r\npostprocess();\r\nvar end2 = Data.Now.ticks - start;\r\nthe end2 is 20ms;\r\n\r\nvar start3 = Data.Now.ticks;\r\nsession.run()\r\npostprocess();\r\nvar end3 = Data.Now.ticks - star\r\n\r\nthe end3 is 200ms, the end3 is always greater  than end1 + end2,that's amazing,,is't it equal to end1 + end2?\r\n\r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11946/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11947",
        "id": 1279443133,
        "node_id": "I_kwDOCVq1mM5MQsC9",
        "number": 11947,
        "title": "excute dnnl provider error",
        "user": {
            "login": "jia-jidong",
            "id": 31591825,
            "node_id": "MDQ6VXNlcjMxNTkxODI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/31591825?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jia-jidong",
            "html_url": "https://github.com/jia-jidong",
            "followers_url": "https://api.github.com/users/jia-jidong/followers",
            "following_url": "https://api.github.com/users/jia-jidong/following{/other_user}",
            "gists_url": "https://api.github.com/users/jia-jidong/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jia-jidong/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jia-jidong/subscriptions",
            "organizations_url": "https://api.github.com/users/jia-jidong/orgs",
            "repos_url": "https://api.github.com/users/jia-jidong/repos",
            "events_url": "https://api.github.com/users/jia-jidong/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jia-jidong/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1630303001,
                "node_id": "MDU6TGFiZWwxNjMwMzAzMDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:oneDNN",
                "name": "ep:oneDNN",
                "color": "0052CC",
                "default": false,
                "description": "questions/issues related to DNNL EP"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-22T03:29:56Z",
        "updated_at": "2022-07-12T21:59:28Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I built onnxruntime use the commond:\r\n./build.sh --config Release --build_shared_lib --use_dnnl\r\n\r\nThen I code my app using dnnl provider, but I got the following error message:\r\n\r\n2022-06-22 10:42:43.619136547 [E:onnxruntime:, sequential_executor.cc:368 Execute] Non-zero status code returned while running DNNL_12891192397758778371_0 node. Name:'DnnlExecutionProvider_DNNL_12891192397758778371_0_0' Status Message: could not construct a memory descriptor using a format tag\r\nNon-zero status code returned while running DNNL_12891192397758778371_0 node. Name:'DnnlExecutionProvider_DNNL_12891192397758778371_0_0' Status Message: could not construct a memory descriptor using a format tag\r\ndebug-run\r\nSegmentation fault (core dumped)\r\n\r\nIf use cpu provider everything is OK, but I want to use dnnl provider!\r\n\r\n**System information**\r\n- OS Platform and Distribution :Ubuntu 9.3.0-17ubuntu1~20.04\r\n- ONNX Runtime installed from: source\r\n- ONNX Runtime version: 1.11.1\r\n- Python version:3.8.3\r\n- Visual Studio version (if applicable): n/a\r\n- GCC/Compiler version (if compiling from source): 7.5\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**To Reproduce**\r\nRun the model using dnnl provider.\r\nModel download url: https://zenodo.org/record/6221127#.YrKJW3VByUk\r\n\r\n**Expected behavior**\r\nNo error report using dnnl provider.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11947/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11948",
        "id": 1279626035,
        "node_id": "PR_kwDOCVq1mM46F9yV",
        "number": 11948,
        "title": "Bump ort version number",
        "user": {
            "login": "RandySheriffH",
            "id": 48490400,
            "node_id": "MDQ6VXNlcjQ4NDkwNDAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/48490400?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RandySheriffH",
            "html_url": "https://github.com/RandySheriffH",
            "followers_url": "https://api.github.com/users/RandySheriffH/followers",
            "following_url": "https://api.github.com/users/RandySheriffH/following{/other_user}",
            "gists_url": "https://api.github.com/users/RandySheriffH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RandySheriffH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RandySheriffH/subscriptions",
            "organizations_url": "https://api.github.com/users/RandySheriffH/orgs",
            "repos_url": "https://api.github.com/users/RandySheriffH/repos",
            "events_url": "https://api.github.com/users/RandySheriffH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RandySheriffH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-22T06:37:02Z",
        "updated_at": "2022-07-22T19:55:54Z",
        "closed_at": "2022-07-22T19:55:53Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11948",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11948",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11948.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11948.patch",
            "merged_at": "2022-07-22T19:55:53Z"
        },
        "body": "Bump ort version after the creation of release candidate of 1.12.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11948/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11949",
        "id": 1279626258,
        "node_id": "PR_kwDOCVq1mM46F91a",
        "number": 11949,
        "title": "support optimizer opt for deepspeed 0.5.9",
        "user": {
            "login": "zhijxu-MS",
            "id": 43435212,
            "node_id": "MDQ6VXNlcjQzNDM1MjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/43435212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhijxu-MS",
            "html_url": "https://github.com/zhijxu-MS",
            "followers_url": "https://api.github.com/users/zhijxu-MS/followers",
            "following_url": "https://api.github.com/users/zhijxu-MS/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhijxu-MS/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhijxu-MS/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhijxu-MS/subscriptions",
            "organizations_url": "https://api.github.com/users/zhijxu-MS/orgs",
            "repos_url": "https://api.github.com/users/zhijxu-MS/repos",
            "events_url": "https://api.github.com/users/zhijxu-MS/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhijxu-MS/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-22T06:37:15Z",
        "updated_at": "2022-07-18T20:25:19Z",
        "closed_at": "2022-06-30T03:26:14Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11949",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11949",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11949.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11949.patch",
            "merged_at": "2022-06-30T03:26:14Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11949/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11950",
        "id": 1279887895,
        "node_id": "I_kwDOCVq1mM5MSYoX",
        "number": 11950,
        "title": "windows11+onnxruntime1.8.0+vs2019 inferencing  crash",
        "user": {
            "login": "sdnusqy-art",
            "id": 73977336,
            "node_id": "MDQ6VXNlcjczOTc3MzM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/73977336?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sdnusqy-art",
            "html_url": "https://github.com/sdnusqy-art",
            "followers_url": "https://api.github.com/users/sdnusqy-art/followers",
            "following_url": "https://api.github.com/users/sdnusqy-art/following{/other_user}",
            "gists_url": "https://api.github.com/users/sdnusqy-art/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sdnusqy-art/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sdnusqy-art/subscriptions",
            "organizations_url": "https://api.github.com/users/sdnusqy-art/orgs",
            "repos_url": "https://api.github.com/users/sdnusqy-art/repos",
            "events_url": "https://api.github.com/users/sdnusqy-art/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sdnusqy-art/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-22T10:01:29Z",
        "updated_at": "2022-06-22T23:33:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "windows11+onnxruntime1.8.0+vs2019 inferencing  crash\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows11\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.8.0\r\n- Python version: 3.6.8\r\n- Visual Studio version (if applicable): vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11950/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11951",
        "id": 1279939953,
        "node_id": "I_kwDOCVq1mM5MSlVx",
        "number": 11951,
        "title": "Multi thread of single session Python vs C++ (end with core dumped)",
        "user": {
            "login": "RomainCendre",
            "id": 18599849,
            "node_id": "MDQ6VXNlcjE4NTk5ODQ5",
            "avatar_url": "https://avatars.githubusercontent.com/u/18599849?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RomainCendre",
            "html_url": "https://github.com/RomainCendre",
            "followers_url": "https://api.github.com/users/RomainCendre/followers",
            "following_url": "https://api.github.com/users/RomainCendre/following{/other_user}",
            "gists_url": "https://api.github.com/users/RomainCendre/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RomainCendre/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RomainCendre/subscriptions",
            "organizations_url": "https://api.github.com/users/RomainCendre/orgs",
            "repos_url": "https://api.github.com/users/RomainCendre/repos",
            "events_url": "https://api.github.com/users/RomainCendre/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RomainCendre/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-22T10:43:15Z",
        "updated_at": "2023-02-17T08:11:21Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nHi everyone,\r\nI dunno if it's a bug or a wrong use of ONNX, but the basic idea is to make some multi thread call of ONNX using a single session. Using python seems really convenient for this, but problem comes with CPP. See the examples bellow:\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 21\r\n- ONNX Runtime installed from (source or binary): 1.11\r\n- Python version: 3.9.7\r\n\r\n**To Reproduce**\r\nFrom Python code\r\n```\r\n# imports\r\nfrom multiprocessing.pool import ThreadPool\r\nimport onnxruntime\r\nimport numpy\r\nimport time\r\nimport os\r\n\r\nTHREAD_NUMBER = 100\r\n\r\n# Prepare inference\r\nort_session_options = onnxruntime.SessionOptions()\r\nort_session_options.add_session_config_entry(\"session.set_denormal_as_zero\", \"1\")\r\nort_session = onnxruntime.InferenceSession(\"./model.onnx\", ort_session_options)\r\n\r\n# Shape reading\r\ninput_shape = ort_session.get_inputs()[0].shape\r\nprint(f\"Detected shape : {input_shape}\")\r\n\r\n# zero input\r\ninput_var = numpy.zeros(input_shape).astype(numpy.float32)\r\n\r\n# zero inference\r\n# Pooling test\r\npool = ThreadPool(THREAD_NUMBER)\r\n## Original pred\r\ndef f_python_onnx(input_var):\r\n    print(\"Start Id\", threading.get_native_id())\r\n    ort_inputs = {ort_session.get_inputs()[0].name: input_var}\r\n    ort_session.run(None, ort_inputs)[0]\r\n    print(\"End Id\", threading.get_native_id())\r\n\r\nt0 = time.time()\r\npool.map(f_python_onnx, [input_var]*THREAD_NUMBER)\r\nt_orig = time.time() - t0\r\n```\r\nEverything seems to be fine here. So Ok, let's go with CPP:\r\n\r\n```\r\n#include <thread>\r\n#include <stdlib.h>\r\n\r\nvoid forward(Ort::Session* pSession, int thread = 0)\r\n{\r\n    if(!pSession)\r\n        return;\r\n\r\n    // Prepare allocators\r\n    Ort::AllocatorWithDefaultOptions allocator;\r\n    const char* inputName = pSession->GetInputName(0, allocator);\r\n    const char* outputName = pSession->GetOutputName(0, allocator);\r\n\r\n    // Inputs parameters\r\n    Ort::TypeInfo inputTypeInfo = pSession->GetInputTypeInfo(0);\r\n    auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n    std::vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n\r\n    // Check input / Fix batch size\r\n    if(inputDims.size() == 0)\r\n        return;\r\n\r\n    // Outputs parameters\r\n    Ort::TypeInfo outputTypeInfo = pSession->GetOutputTypeInfo(0);\r\n    auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();\r\n    std::vector<int64_t> outputDims = outputTensorInfo.GetShape();\r\n\r\n    // Check output / Fix batch size\r\n    if(outputDims.size() == 0)\r\n        return;\r\n\r\n    std::cout << \"Begin \"<<std::to_string(thread)<<\"- Reading dimensions\" << std::endl;\r\n\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n\r\n    // Prepare input tensor\r\n    size_t inputTensorSize = vectorProduct(inputDims);\r\n    std::vector<float> inputData(inputTensorSize);\r\n    std::vector<const char*> inputNames{inputName};\r\n    std::vector<Ort::Value> inputTensors;\r\n    inputTensors.push_back(\r\n            Ort::Value::CreateTensor<float>(\r\n                        memoryInfo, inputData.data(), \r\n                        inputTensorSize, inputDims.data(),\r\n                        inputDims.size()));\r\n\r\n    // Prepare output tensor\r\n    size_t outputTensorSize = vectorProduct(outputDims);\r\n    std::vector<float> outputData(outputTensorSize);\r\n    std::vector<const char*> outputNames{outputName};\r\n    std::vector<Ort::Value> outputTensors;\r\n    outputTensors.push_back(\r\n            Ort::Value::CreateTensor<float>(\r\n                        memoryInfo, outputData.data(), \r\n                        outputTensorSize, outputDims.data(), \r\n                        outputDims.size()));\r\n\r\n    // Run the inference !!!!\r\n    pSession->Run(\r\n            Ort::RunOptions{nullptr}, inputNames.data(),\r\n            inputTensors.data(), 1, outputNames.data(),\r\n            outputTensors.data(), 1);\r\n\r\n    return;\r\n}\r\n\r\nint main() {\r\n    int THREAD_NUMBER = 100\r\n    // Session parameters\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING, SESSION_NAME);\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.AddConfigEntry(kOrtSessionOptionsConfigSetDenormalAsZero, \"1\");\r\n\r\n    // Create session and prepare input / output\r\n    Ort::Session* pSession = new Ort::Session(env, \"model.onnx\", sessionOptions);\r\n    \r\n    // Threading\r\n    std::vector<std::thread> threads; \r\n    for (int i = 0; i < THREAD_NUMBER; i++) {\r\n        threads.push_back(std::thread(forward, pSession, i));\r\n    }\r\n    \r\n    for (auto &th : threads) {\r\n        th.join();\r\n    }\r\n    delete pSession;\r\n    return 0;\r\n}\r\n```\r\nIt ends with the famous \"Core dumped\" error, yeaaaah.....\r\nAny ideas if I'm facing a bug or not using correctly the C++ API? Without threads, everything works fine.\r\nBest regards\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11951/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11953",
        "id": 1280409003,
        "node_id": "PR_kwDOCVq1mM46Iog4",
        "number": 11953,
        "title": "Dll version fix ovep4.1",
        "user": {
            "login": "preetha-intel",
            "id": 88426960,
            "node_id": "MDQ6VXNlcjg4NDI2OTYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/88426960?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/preetha-intel",
            "html_url": "https://github.com/preetha-intel",
            "followers_url": "https://api.github.com/users/preetha-intel/followers",
            "following_url": "https://api.github.com/users/preetha-intel/following{/other_user}",
            "gists_url": "https://api.github.com/users/preetha-intel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/preetha-intel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/preetha-intel/subscriptions",
            "organizations_url": "https://api.github.com/users/preetha-intel/orgs",
            "repos_url": "https://api.github.com/users/preetha-intel/repos",
            "events_url": "https://api.github.com/users/preetha-intel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/preetha-intel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-22T15:48:10Z",
        "updated_at": "2022-07-06T16:56:24Z",
        "closed_at": "2022-06-22T18:09:37Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11953",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11953",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11953.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11953.patch",
            "merged_at": "2022-06-22T18:09:37Z"
        },
        "body": "Update the changes as per validation\r\n\r\n1) Set VERSION_* variables before including the onnxruntime-provider.cmake as it has a dependency. \r\n2) Add nested if block for dynamic shapes feature\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11953/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11954",
        "id": 1280675594,
        "node_id": "PR_kwDOCVq1mM46Jj1x",
        "number": 11954,
        "title": "[NNAPI EP] Update NNAPI headers",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-22T18:12:48Z",
        "updated_at": "2022-06-28T01:54:07Z",
        "closed_at": "2022-06-28T01:54:07Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11954",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11954",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11954.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11954.patch",
            "merged_at": "2022-06-28T01:54:07Z"
        },
        "body": "**Description**\r\nUpdate the NNAPI headers to a more recent version (copied from TF Lite v2.9.1).\r\n\r\n**Motivation and Context**\r\nEnables use of newer NNAPI functionality such as the ANEURALNETWORKS_BATCH_MATMUL operation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11954/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11955",
        "id": 1280777894,
        "node_id": "PR_kwDOCVq1mM46J6lo",
        "number": 11955,
        "title": "Improved OneDNN performance by preventing thread oversubscription",
        "user": {
            "login": "eralmual",
            "id": 22269643,
            "node_id": "MDQ6VXNlcjIyMjY5NjQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/22269643?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eralmual",
            "html_url": "https://github.com/eralmual",
            "followers_url": "https://api.github.com/users/eralmual/followers",
            "following_url": "https://api.github.com/users/eralmual/following{/other_user}",
            "gists_url": "https://api.github.com/users/eralmual/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eralmual/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eralmual/subscriptions",
            "organizations_url": "https://api.github.com/users/eralmual/orgs",
            "repos_url": "https://api.github.com/users/eralmual/repos",
            "events_url": "https://api.github.com/users/eralmual/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eralmual/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 11,
        "created_at": "2022-06-22T19:37:37Z",
        "updated_at": "2022-07-01T23:20:04Z",
        "closed_at": "2022-07-01T23:20:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11955",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11955",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11955.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11955.patch",
            "merged_at": null
        },
        "body": "Users can now control the number of threads allocated to OneDNN and the default provider using OrtDnnlProviderOptions to fine tune performance according to each model op coverage. By default we improve thread distribution to prevent oversubscription. An example on how to tune threads and use the available options can be found on the ort_test_session.cc on the perftest folder.\r\n\r\nSigned-off-by: Erick Muñoz [erick.munoz.alvarado@intel.com](mailto:erick.munoz.alvarado@intel.com)\r\n\r\nDescription: Previously OneDNN ep suffered from thread oversubscription due to ORT creating it's own thread pool and OneDNN creating another one, this update aims to fix this issue by making the number of threads used by OneDNN accessible to the user and setting the default threading options to be 3/4 of the available (Or user defined threads for OneDNN) and the remaining threads for default provider (This behavior can be overridden by the user explicitly defining the number of threads for OneDNN and for the default provider)\r\n\r\nMotivation and Context\r\n\r\nWhy is this change required? What problem does it solve?\r\nPerformance related fix, prevents thread oversubscription, improves performance on CPU and allows the user to customize thread distribution according to their workload.\r\nIf it fixes an open issue, please link to the issue here.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11955/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11956",
        "id": 1280848521,
        "node_id": "PR_kwDOCVq1mM46KKZY",
        "number": 11956,
        "title": "Resize optimization for all architectures",
        "user": {
            "login": "yihonglyu",
            "id": 8860750,
            "node_id": "MDQ6VXNlcjg4NjA3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8860750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yihonglyu",
            "html_url": "https://github.com/yihonglyu",
            "followers_url": "https://api.github.com/users/yihonglyu/followers",
            "following_url": "https://api.github.com/users/yihonglyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/yihonglyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yihonglyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yihonglyu/subscriptions",
            "organizations_url": "https://api.github.com/users/yihonglyu/orgs",
            "repos_url": "https://api.github.com/users/yihonglyu/repos",
            "events_url": "https://api.github.com/users/yihonglyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yihonglyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-22T20:33:14Z",
        "updated_at": "2022-06-29T16:19:21Z",
        "closed_at": "2022-06-29T16:19:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11956",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11956",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11956.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11956.patch",
            "merged_at": "2022-06-29T16:19:20Z"
        },
        "body": "With this patch, it optimizes Resize when the input X is 4D int8/uint8 tensor\r\nand the mode is linear by:\r\n\r\n* Transforming NCHW Resize to NHWC variant\r\n* Using the NHWC Resize kernel without floating-point computation\r\n\r\nIt improves DeepLab V3 with uint8 quantization by 19% on X64. It also improves\r\nResize of DeepLab V3 with int8 quantization by 15%~18% on X64.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11956/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11957",
        "id": 1281002992,
        "node_id": "PR_kwDOCVq1mM46KtiL",
        "number": 11957,
        "title": "Add Learning Rate Scheduler C API",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-22T21:52:54Z",
        "updated_at": "2022-08-15T16:17:13Z",
        "closed_at": "2022-08-15T16:10:25Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11957",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11957",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11957.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11957.patch",
            "merged_at": "2022-08-15T16:10:25Z"
        },
        "body": "This pull request adds an API for registering a scheduler with the training session.\r\n\r\n```cc\r\n// c api\r\nOrtTrainingSession* session;\r\ng_ort_training_api->CreateTrainingSession(env, session_options, checkpoint_state,\r\n                                          training_model.c_str(), eval_model.c_str(),\r\n                                          optimizer_model.c_str(), &session));\r\n\r\n// Register the linear leaning rate scheduler with an initial learning rate.\r\nauto lr_scheduler_parameters = std::make_unique<OrtLinearLRSchedulerParameters>().get();\r\nlr_scheduler_parameters->total_step_count =total_step_count;\r\nlr_scheduler_parameters->warmup_step_count =warmup_step_count;\r\ng_ort_training_api->RegisterLRScheduler(\r\n    session, reinterpret_cast<void*>(lr_scheduler_parameters), OrtLRSchedulerType::LinearLRScheduler, initial_lr);\r\n\r\n// Take a scheduler step.\r\ng_ort_training_api->SchedulerStep(session);\r\n```\r\n\r\nIf the user would like to use their own scheduler, they can invoke `SetLearningRate` on each loop\r\n\r\n```cc\r\n// c api\r\nOrtTrainingSession* session;\r\ng_ort_training_api->CreateTrainingSession(env, session_options, checkpoint_state,\r\n                                          training_model.c_str(), eval_model.c_str(),\r\n                                          optimizer_model.c_str(), &session));\r\n\r\n// Training loop\r\n...\r\n\r\n// Calculate the new learning rate using the custom learning rate scheduler.\r\nauto learning_rate = my_scheduler.Step();\r\n\r\n// Set the learning rate on the training session\r\ng_ort_training_api->SetLearningRate(learning_rate);\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11957/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11958",
        "id": 1281336199,
        "node_id": "PR_kwDOCVq1mM46L3Ww",
        "number": 11958,
        "title": "MT5 onnx conversion for beam search",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-23T00:07:09Z",
        "updated_at": "2022-06-23T17:54:00Z",
        "closed_at": "2022-06-23T17:23:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11958",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11958",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11958.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11958.patch",
            "merged_at": "2022-06-23T17:23:28Z"
        },
        "body": "**Description**: \r\nSupport mT5 model to onnx conversion for beam search like:\r\n```\r\npython convert_beam_search.py -m google/mt5-large --model_type mt5 --output mt5-large-beamsearch.onnx -e\r\n```\r\nThe output will have two files (like mt5-large-beamsearch.onnx and mt5-large-beamsearch.onnx.data) when external data format (-e) is used. \r\n\r\nNote: please install **ONNX 1.12 package** for this. Otherwise, you might encounter error like 'Message onnx.ModelProto exceeds maximum protobuf size of 2GB:' during saving the output model.\r\n\r\nSome intermediate encoder or decoder onnx models can be found in ./google, and those files are not needed (They are preserved for debugging purpose).\r\n\r\nRight now the model can run, but max diff could be like 8e-3 for encoder or decoder, which could cause beam search result difference between PyTorch and ORT. That's a separate issue for pytorch exporter.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n\r\nRelated issues: https://github.com/microsoft/onnxruntime/issues/11813, https://github.com/microsoft/onnxruntime/issues/11848",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11958/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11959",
        "id": 1281521168,
        "node_id": "I_kwDOCVq1mM5MYnYQ",
        "number": 11959,
        "title": "Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb Error",
        "user": {
            "login": "liulhdarks",
            "id": 7029328,
            "node_id": "MDQ6VXNlcjcwMjkzMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7029328?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/liulhdarks",
            "html_url": "https://github.com/liulhdarks",
            "followers_url": "https://api.github.com/users/liulhdarks/followers",
            "following_url": "https://api.github.com/users/liulhdarks/following{/other_user}",
            "gists_url": "https://api.github.com/users/liulhdarks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/liulhdarks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/liulhdarks/subscriptions",
            "organizations_url": "https://api.github.com/users/liulhdarks/orgs",
            "repos_url": "https://api.github.com/users/liulhdarks/repos",
            "events_url": "https://api.github.com/users/liulhdarks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/liulhdarks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1974915201,
                "node_id": "MDU6TGFiZWwxOTc0OTE1MjAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/model:transformer",
                "name": "model:transformer",
                "color": "4EF6CD",
                "default": false,
                "description": "issues related to a transformer model: BERT, GPT2, Hugging Face, Longformer, T5, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-23T02:09:55Z",
        "updated_at": "2022-08-12T08:33:49Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI want to try 'Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb' to convert beamsearch from pytorch, but it failed to run 'ONNX Runtime Inference' cell after succeed to export onnx model. The error below:\r\n```\r\n2022-06-23 10:02:08.982620 [E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running Equal node. Name:'Equal_2629' Status Message: /Users/runner/miniforge3/conda-bld/onnxruntime_1639384858062/work/onnxruntime/core/framework/op_kernel.cc:78 OrtValue *onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape &) status.IsOK() was false. Shape mismatch attempting to re-use buffer. {1,1} != {1,4}. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeException                          Traceback (most recent call last)\r\n/Users/lihua.llh/Documents/codes/lab/python/gpt2_demo/tools/torch/onnx/Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb Cell 10' in <cell line: 53>()\r\n     [51](vscode-notebook-cell:/Users/lihua.llh/Documents/codes/lab/python/gpt2_demo/tools/torch/onnx/Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb#ch0000009?line=50) for i, past_i in enumerate(empty_past):\r\n     [52](vscode-notebook-cell:/Users/lihua.llh/Documents/codes/lab/python/gpt2_demo/tools/torch/onnx/Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb#ch0000009?line=51)     ort_inputs[f'past_{i}'] = numpy.ascontiguousarray(past_i.cpu().numpy())\r\n---> [53](vscode-notebook-cell:/Users/lihua.llh/Documents/codes/lab/python/gpt2_demo/tools/torch/onnx/Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb#ch0000009?line=52) ort_outputs = session.run(None, ort_inputs)\r\n\r\nFile ~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:192, in Session.run(self, output_names, input_feed, run_options)\r\n    190     output_names = [output.name for output in self._outputs_meta]\r\n    191 try:\r\n--> 192     return self._sess.run(output_names, input_feed, run_options)\r\n    193 except C.EPFail as err:\r\n    194     if self._enable_fallback:\r\n\r\nRuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Equal node. Name:'Equal_2629' Status Message: /Users/runner/miniforge3/conda-bld/onnxruntime_1639384858062/work/onnxruntime/core/framework/op_kernel.cc:78 OrtValue *onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape &) status.IsOK() was false. Shape mismatch attempting to re-use buffer. {1,1} != {1,4}. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Apple M1 Pro and MacOS Monterey\r\n- ONNX Runtime installed from (source or binary):  binary\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.9.4\r\n- Huggingface transformers: 4.16.2\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11959/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11960",
        "id": 1281585171,
        "node_id": "PR_kwDOCVq1mM46MxDP",
        "number": 11960,
        "title": "Include opset 15 in Conv+BatchNormalization fusion",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-23T02:52:18Z",
        "updated_at": "2022-07-06T16:55:22Z",
        "closed_at": "2022-06-27T17:59:15Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11960",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11960",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11960.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11960.patch",
            "merged_at": "2022-06-27T17:59:15Z"
        },
        "body": "**Description**: Adds the missing opset version for BatchNormalization 15.\r\n\r\n**Motivation and Context**\r\n- *Why is this change required? What problem does it solve?* Performance regresses if a user upgrades to opset 15.\r\n- *If it fixes an open issue, please link to the issue here.* NA\r\n\r\n**Verification**\r\n\r\nVerified the fusion is happening for opset 15 (and that batch normalization is *not* being executed, via debugger):\r\n\r\n- The fusion now happens for opset 15 like 14 and earlier, for homogeneous inputs (all same input data type, float16, float32...).\r\n- It does not happen for heterogeneous inputs (nor did it before), leaving it as two separate operators. There's an existing check for same data type, which is no worse than before. We just don't want to regress the *existing* scenario of same input types.\r\n\r\n![image](https://user-images.githubusercontent.com/1809166/175196596-b278eff5-d519-401b-a822-4765f9a39eba.png)\r\n\r\n**Tests run**\r\n\r\n`onnxruntime_perf_test.exe -e cpu -I -r 1 -u o:\\out.onnx testmodel.onnx`\r\n`onnxruntime_perf_test.exe -e dml -I -r 1 -u o:\\out.onnx testmodel.onnx`\r\n`te.exe OnnxConformanceTests.dll /name:*ConvBatch*`\r\n\r\nMini-test model added to the WindowsAI ONNX conformance suite:\r\n\r\n```\r\nir_version: 4\r\nproducer_name: \"OnnxConformanceTest\"\r\ngraph {\r\n  node {\r\n    input: \"ConvX\"\r\n    input: \"ConvW\"\r\n    input: \"ConvB\"\r\n    output: \"ConvY\"\r\n    op_type: \"Conv\"\r\n    attribute {\r\n      name: \"auto_pad\"\r\n      s: \"NOTSET\"\r\n      type: STRING\r\n    }\r\n    attribute {\r\n      name: \"strides\"\r\n      ints: 1\r\n      ints: 1\r\n      type: INTS\r\n    }\r\n    attribute {\r\n      name: \"dilations\"\r\n      ints: 1\r\n      ints: 1\r\n      type: INTS\r\n    }\r\n    attribute {\r\n      name: \"kernel_shape\"\r\n      ints: 1\r\n      ints: 5\r\n      type: INTS\r\n    }\r\n    attribute {\r\n      name: \"pads\"\r\n      ints: 0\r\n      ints: 0\r\n      ints: 0\r\n      ints: 0\r\n      type: INTS\r\n    }\r\n    domain: \"\"\r\n  }\r\n  node {\r\n    input: \"ConvY\"\r\n    input: \"BatchNormalizationScale\"\r\n    input: \"BatchNormalizationB\"\r\n    input: \"BatchNormalizationMean\"\r\n    input: \"BatchNormalizationVar\"\r\n    output: \"BatchNormalizationY\"\r\n    op_type: \"BatchNormalization\"\r\n    attribute {\r\n      name: \"momentum\"\r\n      f: 2\r\n      type: FLOAT\r\n    }\r\n    attribute {\r\n      name: \"epsilon\"\r\n      f: 0\r\n      type: FLOAT\r\n    }\r\n    domain: \"\"\r\n  }\r\n  name: \"Conv+BatchNormalization_fusion\"\r\n  initializer {\r\n    dims: 1\r\n    dims: 1\r\n    dims: 1\r\n    dims: 5\r\n    data_type: 1\r\n    name: \"ConvW\"\r\n    raw_data: \"\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\000@\\000\\000\\200?\"\r\n  }\r\n  initializer {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"ConvB\"\r\n    raw_data: \"\\000\\000\\200?\"\r\n  }\r\n  initializer {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"BatchNormalizationScale\"\r\n    raw_data: \"\\000\\000\\200?\"\r\n  }\r\n  initializer {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"BatchNormalizationB\"\r\n    raw_data: \"\\000\\000\\000\\000\"\r\n  }\r\n  initializer {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"BatchNormalizationMean\"\r\n    raw_data: \"\\000\\000\\000\\000\"\r\n  }\r\n  initializer {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"BatchNormalizationVar\"\r\n    raw_data: \"\\000\\000\\200?\"\r\n  }\r\n  input {\r\n    name: \"ConvX\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: 1\r\n        shape {\r\n          dim {\r\n            dim_value: 2\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n          dim {\r\n            dim_value: 10\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  output {\r\n    name: \"BatchNormalizationY\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: 1\r\n        shape {\r\n          dim {\r\n            dim_value: 2\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n          dim {\r\n            dim_value: 6\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nopset_import {\r\n  domain: \"\"\r\n  version: 7\r\n}\r\nopset_import {\r\n  domain: \"\"\r\n  version: 15\r\n}\r\n```\r\n\r\n```\r\n{\r\n  \"tests\": [\r\n    {\r\n      \"graph_name\": \"Conv+BatchNormalization fusion\",\r\n      \"version\": 15,\r\n      \"nodes\": [\r\n        {\r\n          \"op_type\": \"Conv\",\r\n          \"version\": 15,\r\n          \"auto_pad\": \"NOTSET\",\r\n          \"strides\": [1,1],\r\n          \"dilations\": [1,1],\r\n          \"kernel_shape\": [1,5],\r\n          \"pads\": [0,0, 0,0], // ONNX Runtime requires 2 * N, even if 1D input.\r\n          \"inputs\": {\r\n            \"ConvX\": {}, //\"X\": {\"dims\": [2,1,1,10], \"function\": \"iota\"},\r\n            \"ConvW\": [[[[1,2,3,2,1]]]],\r\n            \"ConvB\": [1]\r\n          },\r\n          \"outputs\": {\r\n            \"ConvY\": {} // \"Y\": {\"dims\": [2,1,1,6], \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]},\r\n          },\r\n          \"T\": \"float32\"\r\n        },\r\n        {\r\n          \"op_type\": \"BatchNormalization\",\r\n          \"version\": 15,\r\n          \"inputs\": {\r\n            \"ConvY\": {}, // \"X\": {\"dims\": [2,1,1,6], \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]},\r\n            \"BatchNormalizationScale\": [1],\r\n            \"BatchNormalizationB\": [0],\r\n            \"BatchNormalizationMean\": [0],\r\n            \"BatchNormalizationVar\": [1]\r\n          },\r\n          \"momentum\": 2.0,\r\n          \"epsilon\": 0,\r\n          \"outputs\": {\r\n            \"BatchNormalizationY\": {} // \"Y\": [[[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]]],\r\n          },\r\n          \"T\": \"float32\",\r\n          \"verification\": { \"relative_tolerance\": 0.00001 }\r\n        }\r\n      ], // nodes\r\n      \"inputs\": {\r\n        \"ConvX\": {\r\n          \"type\": \"float32\",\r\n          \"dims\": [2,1,1,10],\r\n          \"function\": \"iota\"\r\n        }\r\n      },\r\n      \"outputs\": {\r\n        \"BatchNormalizationY\": {\r\n          \"type\": \"float32\",\r\n          \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]\r\n        }\r\n      }\r\n    },\r\n    {\r\n      \"graph_name\": \"Conv+BatchNormalization fusion mixed input data types\",\r\n      \"version\": 15,\r\n      \"nodes\": [\r\n        {\r\n          \"op_type\": \"Conv\",\r\n          \"version\": 15,\r\n          \"auto_pad\": \"NOTSET\",\r\n          \"strides\": [1,1],\r\n          \"dilations\": [1,1],\r\n          \"kernel_shape\": [1,5],\r\n          \"pads\": [0,0, 0,0], // ONNX Runtime requires 2 * N, even if 1D input.\r\n          \"inputs\": {\r\n            \"ConvX\": {}, //\"X\": {\"dims\": [2,1,1,10], \"function\": \"iota\"},\r\n            \"ConvW\": {\"type\": \"float16\", \"value\": [[[[1,2,3,2,1]]]]},\r\n            \"ConvB\": {\"type\": \"float16\", \"value\": [1]}\r\n          },\r\n          \"outputs\": {\r\n            \"ConvY\": {} // \"Y\": {\"dims\": [2,1,1,6], \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]},\r\n          },\r\n          \"T\": \"float16\"\r\n        },\r\n        {\r\n          \"op_type\": \"BatchNormalization\",\r\n          \"version\": 15,\r\n          \"inputs\": {\r\n            \"ConvY\": {}, // \"X\": {\"dims\": [2,1,1,6], \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]},\r\n            \"BatchNormalizationScale\": {\"type\": \"float32\", \"value\": [1]},\r\n            \"BatchNormalizationB\": {\"type\": \"float32\", \"value\": [0]},\r\n            \"BatchNormalizationMean\": [0],\r\n            \"BatchNormalizationVar\": [1]\r\n          },\r\n          \"momentum\": 2.0,\r\n          \"epsilon\": 0,\r\n          \"outputs\": {\r\n            \"BatchNormalizationY\": {} // \"Y\": [[[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]]],\r\n          },\r\n          \"T\": \"float16\",\r\n          \"verification\": { \"relative_tolerance\": 0.00001 }\r\n        }\r\n      ], // nodes\r\n      \"inputs\": {\r\n        \"ConvX\": {\r\n          \"type\": \"float16\",\r\n          \"dims\": [2,1,1,10],\r\n          \"function\": \"iota\"\r\n        }\r\n      },\r\n      \"outputs\": {\r\n        \"BatchNormalizationY\": {\r\n          \"type\": \"float16\",\r\n          \"value\": [[[[19,28,37,46,55,64]]], [[[109,118,127,136,145,154]]]]\r\n        }\r\n      }\r\n    }\r\n  ], // tests\r\n\r\n  \"schema\": [\r\n    {\r\n      \"op_type\": \"BatchNormalization\",\r\n      \"version\": 7,\r\n      \"attributes\": {\r\n        \"epsilon\": {\"type\": \"float32\"},\r\n        \"momentum\": {\"type\": \"float32\"},\r\n        \"spatial\": {\"type\": \"int64\"} // defaults to 1/true.\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"scale\": {\"type\": \"T\"},\r\n        \"B\": {\"type\": \"T\"},\r\n        \"mean\": {\"type\": \"T\"},\r\n        \"var\": {\"type\": \"T\"}\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"},\r\n        \"mean\": {\"type\": \"T\"},\r\n        \"var\": {\"type\": \"T\"},\r\n        \"saved_mean\": {\"type\": \"T\"},\r\n        \"saved_var\": {\"type\": \"T\"}\r\n      },\r\n      \"types\": {\"T\": [\"float32\", \"float16\", \"float64\"]}\r\n    },\r\n    {\r\n      \"op_type\": \"BatchNormalization\",\r\n      \"version\": 9, // Removes 'spatial' attribute.\r\n      \"attributes\": {\r\n        \"epsilon\": {\"type\": \"float32\"},\r\n        \"momentum\": {\"type\": \"float32\"}\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"scale\": {\"type\": \"T\"},\r\n        \"B\": {\"type\": \"T\"},\r\n        \"mean\": {\"type\": \"T\"},\r\n        \"var\": {\"type\": \"T\"}\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"},\r\n        \"mean\": {\"type\": \"T\"},\r\n        \"var\": {\"type\": \"T\"},\r\n        \"saved_mean\": {\"type\": \"T\"},\r\n        \"saved_var\": {\"type\": \"T\"}\r\n      },\r\n      \"types\": {\"T\": [\"float32\", \"float16\", \"float64\"]}\r\n    },\r\n    {\r\n      \"op_type\": \"BatchNormalization\",\r\n      // Adds 'training_mode' attribute.\r\n      // Renames input mean/var with prefix input_*.\r\n      // Consolidates output mean and variance to running_*.\r\n      // Adds bfloat16.\r\n      \"version\": 14,\r\n      \"attributes\": {\r\n        \"epsilon\": {\"type\": \"float32\"},\r\n        \"momentum\": {\"type\": \"float32\"},\r\n        \"training_mode\": {\"type\": \"int64\"} // default = 0\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"scale\": {\"type\": \"T\"},\r\n        \"B\": {\"type\": \"T\"},\r\n        \"input_mean\": {\"type\": \"U\"},\r\n        \"input_var\": {\"type\": \"U\"}\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"},\r\n        \"running_mean\": {\"type\": \"U\"},\r\n        \"running_var\": {\"type\": \"U\"}\r\n      },\r\n      \"types\": {\r\n        \"T\": [\"float32\", \"float16\", \"bfloat16\", \"float64\"],\r\n        \"U\": [\"float32\", \"float16\", \"bfloat16\", \"float64\"]\r\n      }\r\n    },\r\n    {\r\n      \"op_type\": \"BatchNormalization\",\r\n      \"version\": 15, // Allows scale and bias data type to differ from input X type.\r\n      \"attributes\": {\r\n        \"epsilon\": {\"type\": \"float32\"},\r\n        \"momentum\": {\"type\": \"float32\"},\r\n        \"training_mode\": {\"type\": \"int64\"} // default = 0\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"scale\": {\"type\": \"T1\"},\r\n        \"B\": {\"type\": \"T1\"},\r\n        \"input_mean\": {\"type\": \"T2\"},\r\n        \"input_var\": {\"type\": \"T2\"}\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"},\r\n        \"running_mean\": {\"type\": \"T2\"},\r\n        \"running_var\": {\"type\": \"T2\"}\r\n      },\r\n      \"types\": {\r\n        \"T\": [\"float32\", \"float16\", \"bfloat16\", \"float64\"],\r\n        \"T1\": [\"float32\", \"float16\", \"bfloat16\", \"float64\"],\r\n        \"T2\": [\"float32\", \"float16\", \"bfloat16\", \"float64\"]\r\n      }\r\n    },\r\n    {\r\n      \"op_type\": \"Conv\",\r\n      \"version\": 1,\r\n      \"attributes\": {\r\n        \"auto_pad\": {\"type\": \"string8\"}, // \"SAME_UPPER\", \"SAME_LOWER\", \"VALID\"\r\n        \"dilations\": {\"type\": \"int64\"}, // list, defaults = 1\r\n        \"group\": {\"type\": \"int64\"}, // default = 1\r\n        \"kernel_shape\": {\"type\": \"int64\"}, // list, default = input tensor W\r\n        \"pads\": {\"type\": \"int64\"}, // list [x1_begin, x2_begin...x1_end, x2_end,...], defaults = 0\r\n        \"strides\": {\"type\": \"int64\"} // list, defaults = 1\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"W\": {\"type\": \"T\"},\r\n        \"B\": {\"type\": \"T\"} // optional, size M\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"}\r\n      },\r\n      \"types\": {\"T\": [\"float32\", \"float16\", \"float64\"]}\r\n    },\r\n    {\r\n      \"op_type\": \"Conv\",\r\n      \"version\": 15, // No difference from 1 or 11 (except clarification that strides default to 1).\r\n      \"attributes\": {\r\n        \"auto_pad\": {\"type\": \"string8\"}, // \"SAME_UPPER\", \"SAME_LOWER\", \"VALID\", \"NOTSET\"\r\n        \"dilations\": {\"type\": \"int64\"}, // list, defaults = 1\r\n        \"group\": {\"type\": \"int64\"}, // default = 1\r\n        \"kernel_shape\": {\"type\": \"int64\"}, // list, default = input tensor W\r\n        \"pads\": {\"type\": \"int64\"}, // list [x1_begin, x2_begin...x1_end, x2_end,...], defaults = 0\r\n        \"strides\": {\"type\": \"int64\"} // list, defaults = 1\r\n      },\r\n      \"inputs\": {\r\n        \"X\": {\"type\": \"T\"},\r\n        \"W\": {\"type\": \"T\"},\r\n        \"B\": {\"type\": \"T\"} // optional, size M\r\n      },\r\n      \"outputs\": {\r\n        \"Y\": {\"type\": \"T\"}\r\n      },\r\n      \"types\": {\"T\": [\"float32\", \"float16\", \"float64\"]}\r\n    }\r\n  ]\r\n}\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11960/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11961",
        "id": 1281885140,
        "node_id": "I_kwDOCVq1mM5MaAPU",
        "number": 11961,
        "title": "Question about quantize Gemm OP",
        "user": {
            "login": "yeliang2258",
            "id": 30516196,
            "node_id": "MDQ6VXNlcjMwNTE2MTk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/30516196?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yeliang2258",
            "html_url": "https://github.com/yeliang2258",
            "followers_url": "https://api.github.com/users/yeliang2258/followers",
            "following_url": "https://api.github.com/users/yeliang2258/following{/other_user}",
            "gists_url": "https://api.github.com/users/yeliang2258/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yeliang2258/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yeliang2258/subscriptions",
            "organizations_url": "https://api.github.com/users/yeliang2258/orgs",
            "repos_url": "https://api.github.com/users/yeliang2258/repos",
            "events_url": "https://api.github.com/users/yeliang2258/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yeliang2258/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-23T06:35:08Z",
        "updated_at": "2022-06-24T02:11:05Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\nWhy can't the following Gems be merged into QGemm? \r\n![image](https://user-images.githubusercontent.com/30516196/175230775-39912aa9-612a-4901-ac6e-90f5b0680620.png)\r\n\r\nThe original graph is as follows\r\n![image](https://user-images.githubusercontent.com/30516196/175231816-8395e326-8059-4361-9258-f4daf3190837.png)\r\n\r\n\r\nI read GemmNodeGroupSelector class, it should meet the merge condition.\r\n![image](https://user-images.githubusercontent.com/30516196/175231208-b8b76774-b996-4c65-b110-1a8ba8926ce4.png)\r\n\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: python3.7\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11961/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11962",
        "id": 1282021225,
        "node_id": "PR_kwDOCVq1mM46OPke",
        "number": 11962,
        "title": "Development",
        "user": {
            "login": "smicic-htec",
            "id": 96046546,
            "node_id": "U_kgDOBbmN0g",
            "avatar_url": "https://avatars.githubusercontent.com/u/96046546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smicic-htec",
            "html_url": "https://github.com/smicic-htec",
            "followers_url": "https://api.github.com/users/smicic-htec/followers",
            "following_url": "https://api.github.com/users/smicic-htec/following{/other_user}",
            "gists_url": "https://api.github.com/users/smicic-htec/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smicic-htec/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smicic-htec/subscriptions",
            "organizations_url": "https://api.github.com/users/smicic-htec/orgs",
            "repos_url": "https://api.github.com/users/smicic-htec/repos",
            "events_url": "https://api.github.com/users/smicic-htec/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smicic-htec/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-23T08:31:18Z",
        "updated_at": "2022-06-24T12:44:13Z",
        "closed_at": "2022-06-23T08:32:59Z",
        "author_association": "FIRST_TIME_CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11962",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11962",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11962.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11962.patch",
            "merged_at": null
        },
        "body": "**Description**: \r\nAdd option to run model using MIGraphX as an engine.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11962/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11964",
        "id": 1282156558,
        "node_id": "I_kwDOCVq1mM5MbCgO",
        "number": 11964,
        "title": "Got segmentation fault error when using 'InferenceSession' API",
        "user": {
            "login": "baoachun",
            "id": 22114318,
            "node_id": "MDQ6VXNlcjIyMTE0MzE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22114318?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baoachun",
            "html_url": "https://github.com/baoachun",
            "followers_url": "https://api.github.com/users/baoachun/followers",
            "following_url": "https://api.github.com/users/baoachun/following{/other_user}",
            "gists_url": "https://api.github.com/users/baoachun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baoachun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baoachun/subscriptions",
            "organizations_url": "https://api.github.com/users/baoachun/orgs",
            "repos_url": "https://api.github.com/users/baoachun/repos",
            "events_url": "https://api.github.com/users/baoachun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baoachun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-23T10:07:41Z",
        "updated_at": "2022-07-29T16:22:52Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI'm using onnxruntime Python API to do inference, but there is segmentation fault error when using 'InferenceSession'.\r\n![image](https://user-images.githubusercontent.com/22114318/175274043-bf5d0378-9c4e-4b25-8caf-bbf712c03ea5.png)\r\n\r\n\r\n**Urgency**\r\nemergency\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos\r\n- ONNX Runtime installed from (source or binary): pypi\r\n- ONNX Runtime version: 1.11.0\r\n- Python version: 3.8.6\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N\r\n- GPU model and memory: N\r\n\r\n**To Reproduce**\r\n```\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport torch\r\nimport torchvision\r\n\r\nmodel = torchvision.models.alexnet()\r\nmodel.eval()\r\ninput_names = ['input']\r\noutput_names = ['output']\r\nx = torch.randn(1,3,224,224, requires_grad=False)\r\ntorch.onnx.export(model, x, 'alexnet.onnx', input_names=input_names, output_names=output_names, verbose='True', opset_version=12)\r\n\r\nmodel_onnx = onnx.load('alexnet.onnx')\r\nonnx.checker.check_model(model_onnx)\r\nsession = ort.InferenceSession('alexnet.onnx')\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\ngdb message\r\n![image](https://user-images.githubusercontent.com/22114318/175274611-0ab93522-2f76-4183-b78a-17ee61ca5c4a.png)\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11964/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11965",
        "id": 1282271965,
        "node_id": "PR_kwDOCVq1mM46PGjX",
        "number": 11965,
        "title": "Fix orttraining-linux-ci-pipeline - Symbolic shape infer",
        "user": {
            "login": "pengwa",
            "id": 10530022,
            "node_id": "MDQ6VXNlcjEwNTMwMDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10530022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pengwa",
            "html_url": "https://github.com/pengwa",
            "followers_url": "https://api.github.com/users/pengwa/followers",
            "following_url": "https://api.github.com/users/pengwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/pengwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pengwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pengwa/subscriptions",
            "organizations_url": "https://api.github.com/users/pengwa/orgs",
            "repos_url": "https://api.github.com/users/pengwa/repos",
            "events_url": "https://api.github.com/users/pengwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pengwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-23T11:45:18Z",
        "updated_at": "2022-07-06T20:18:13Z",
        "closed_at": "2022-06-23T15:23:36Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11965",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11965",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11965.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11965.patch",
            "merged_at": "2022-06-23T15:23:36Z"
        },
        "body": "**Description**: Describe your changes.\r\n\r\nfix symbolic shape error due to upgraded numpy + legacy sympy\r\n\r\n    File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/onnxruntime/tools/symbolic_shape_infer.py\", line 2127, in _infer_impl\r\n      self.dispatcher_[node.op_type](node)\r\n    File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/onnxruntime/tools/symbolic_shape_infer.py\", line 1700, in _infer_Slice\r\n      new_sympy_shape[i] = sympy.simplify((e - s + t + (-1 if t > 0 else 1)) // t)\r\n    File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/sympy/simplify/simplify.py\", line 508, in simplify\r\n      expr = sympify(expr)\r\n    File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/sympy/core/sympify.py\", line 266, in sympify\r\n      return func(np.asscalar(a))\r\n    File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/numpy/__init__.py\", line 311, in __getattr__\r\n      raise AttributeError(\"module {!r} has no attribute \"\r\n  AttributeError: module 'numpy' has no attribute 'asscalar'\r\n\r\nJune 23, numpy upgraded on PYPI. The sympy version we used is old, which used a deprecated numpy function. \r\n\r\n  Collecting sympy==1.1.1\r\n    Downloading sympy-1.1.1.tar.gz (4.6 MB)\r\n  \r\n  Collecting numpy>=1.16.6\r\n    Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 137.9 MB/s eta 0:00:00\r\n\r\nThe version controlled sympy for orttraining-linux-ci-pipeline is:\r\n\r\n    $(Build.SourcesDirectory)/tools/ci_build/github/linux/docker/scripts/manylinux/requirements.txt\r\n\r\nBut I fixed other two places for parity. Let me know if you think they are not required. \r\n\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11965/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11966",
        "id": 1282467333,
        "node_id": "I_kwDOCVq1mM5McOYF",
        "number": 11966,
        "title": "how to configure lobal/shared threadpool with multithread, in c#API?",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-23T14:07:45Z",
        "updated_at": "2022-08-12T08:23:03Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 11\r\n- ONNX Runtime installed from (source or binary):\r\n- ONNX Runtime version:1.6.0 GPU\r\n- Python version:\r\n- Visual Studio version (if applicable):vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.2/8.0\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n\r\nhow to configure globalpooling with multithread, in c#API? i did't find any reference call in c#API, can you help?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11966/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11967",
        "id": 1282612817,
        "node_id": "I_kwDOCVq1mM5Mcx5R",
        "number": 11967,
        "title": "set gpu option failed ",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-23T15:45:29Z",
        "updated_at": "2022-06-27T08:24:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10\r\n- ONNX Runtime installed from (source or binary):binary in Nuget\r\n- ONNX Runtime version: 1.6.0 GPU\r\n- Python version:\r\n- Visual Studio version (if applicable): 2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2 / 8.0\r\n- GPU model and memory:2080ti\r\n\r\ni set GPU SessionOptions as follows:\r\n\r\nSessionOptions op = new SessionOptions();\r\n  op.GraphOptimizationLevel = GraphOptimizationLevel.ORT_ENABLE_EXTENDED;\r\n  op.InterOpNumThreads = numThread;\r\n  op.IntraOpNumThreads = numThread;\r\n  op.AppendExecutionProvider_CUDA(gpuid);\r\n  //SessionOptions.MakeSessionOptionWithCudaProvider(gpuid);\r\n  model= new InferenceSession(path, op);\r\n\r\nbut when i run code herr is warings:\r\n022-06-23 23:37:13.1873487 [I:onnxruntime:, inference_session.cc:230 onnxruntime::InferenceSession::ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n2022-06-23 23:37:13.2378044 [I:onnxruntime:, inference_session.cc:1081 onnxruntime::InferenceSession::Initialize] Initializing session.\r\n2022-06-23 23:37:13.2379046 [I:onnxruntime:, inference_session.cc:1106 onnxruntime::InferenceSession::Initialize] Adding default CPU execution provider.\r\n\r\nNo GPU  execution provider only use cpu, can you  help me? nvcc -v and nvidia-smi is ok and i test onnxruntime-gpu 1.6.0 on linux there are  no knobs like this and it is faster than on windows\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11967/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11968",
        "id": 1282888659,
        "node_id": "PR_kwDOCVq1mM46RNgv",
        "number": 11968,
        "title": "[ROCm] Add AveragePool, GlobalAveragePool, MaxPool, GlobalMaxPool Ops",
        "user": {
            "login": "xinyazhang",
            "id": 11429462,
            "node_id": "MDQ6VXNlcjExNDI5NDYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11429462?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinyazhang",
            "html_url": "https://github.com/xinyazhang",
            "followers_url": "https://api.github.com/users/xinyazhang/followers",
            "following_url": "https://api.github.com/users/xinyazhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinyazhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinyazhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinyazhang/subscriptions",
            "organizations_url": "https://api.github.com/users/xinyazhang/orgs",
            "repos_url": "https://api.github.com/users/xinyazhang/repos",
            "events_url": "https://api.github.com/users/xinyazhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinyazhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 34,
        "created_at": "2022-06-23T20:14:12Z",
        "updated_at": "2022-08-03T21:37:19Z",
        "closed_at": "2022-08-03T21:36:37Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11968",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11968",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11968.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11968.patch",
            "merged_at": "2022-08-03T21:36:37Z"
        },
        "body": "**Description**: [ROCm] Add AveragePool, GlobalAveragePool, MaxPool, GlobalMaxPool Ops.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n    * AveragePool, GlobalAveragePool, MaxPool, GlobalMaxPool Ops are missing in ROCm provider.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11968/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11969",
        "id": 1282890396,
        "node_id": "PR_kwDOCVq1mM46RN5H",
        "number": 11969,
        "title": "[ROCm] Enable GridSample Op.",
        "user": {
            "login": "xinyazhang",
            "id": 11429462,
            "node_id": "MDQ6VXNlcjExNDI5NDYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11429462?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinyazhang",
            "html_url": "https://github.com/xinyazhang",
            "followers_url": "https://api.github.com/users/xinyazhang/followers",
            "following_url": "https://api.github.com/users/xinyazhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinyazhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinyazhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinyazhang/subscriptions",
            "organizations_url": "https://api.github.com/users/xinyazhang/orgs",
            "repos_url": "https://api.github.com/users/xinyazhang/repos",
            "events_url": "https://api.github.com/users/xinyazhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinyazhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2022-06-23T20:16:06Z",
        "updated_at": "2022-07-20T03:44:31Z",
        "closed_at": "2022-07-20T03:44:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11969",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11969",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11969.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11969.patch",
            "merged_at": "2022-07-20T03:44:30Z"
        },
        "body": "**Description**: Enable GridSample Op in ROCm.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n    * The GridSample op was implemented but not enabled.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11969/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11970",
        "id": 1282959994,
        "node_id": "PR_kwDOCVq1mM46RcUZ",
        "number": 11970,
        "title": "Add eager support for aten::equal and expand the test coverage around…",
        "user": {
            "login": "WilBrady",
            "id": 25513670,
            "node_id": "MDQ6VXNlcjI1NTEzNjcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/25513670?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilBrady",
            "html_url": "https://github.com/WilBrady",
            "followers_url": "https://api.github.com/users/WilBrady/followers",
            "following_url": "https://api.github.com/users/WilBrady/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilBrady/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilBrady/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilBrady/subscriptions",
            "organizations_url": "https://api.github.com/users/WilBrady/orgs",
            "repos_url": "https://api.github.com/users/WilBrady/repos",
            "events_url": "https://api.github.com/users/WilBrady/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilBrady/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-23T21:26:16Z",
        "updated_at": "2022-07-14T14:23:18Z",
        "closed_at": "2022-07-11T18:39:14Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11970",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11970",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11970.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11970.patch",
            "merged_at": null
        },
        "body": "**Description**: Do not review. This is a variety of changes that I will be breaking up into smaller PRs\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11970/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11971",
        "id": 1283002696,
        "node_id": "PR_kwDOCVq1mM46RkuK",
        "number": 11971,
        "title": "[ROCm] NGramRepeatBlock, LongformerAttention and DecoderAttention Ops",
        "user": {
            "login": "xinyazhang",
            "id": 11429462,
            "node_id": "MDQ6VXNlcjExNDI5NDYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11429462?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinyazhang",
            "html_url": "https://github.com/xinyazhang",
            "followers_url": "https://api.github.com/users/xinyazhang/followers",
            "following_url": "https://api.github.com/users/xinyazhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinyazhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinyazhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinyazhang/subscriptions",
            "organizations_url": "https://api.github.com/users/xinyazhang/orgs",
            "repos_url": "https://api.github.com/users/xinyazhang/repos",
            "events_url": "https://api.github.com/users/xinyazhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinyazhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 38,
        "created_at": "2022-06-23T22:10:49Z",
        "updated_at": "2022-09-15T04:55:13Z",
        "closed_at": "2022-08-12T02:32:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11971",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11971",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11971.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11971.patch",
            "merged_at": "2022-08-12T02:32:08Z"
        },
        "body": "**Description**: Add NGramRepeatBlock, LongformerAttention and DecoderAttention Op to ROCm and/or enable their tests\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n    * Add and test NGramRepeatBlock, LongformerAttention and DecoderAttention Ops.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11971/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11972",
        "id": 1283022720,
        "node_id": "PR_kwDOCVq1mM46RnHf",
        "number": 11972,
        "title": "[ROCm] InstanceNormalization, BatchNormalization and LRN Ops",
        "user": {
            "login": "xinyazhang",
            "id": 11429462,
            "node_id": "MDQ6VXNlcjExNDI5NDYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11429462?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinyazhang",
            "html_url": "https://github.com/xinyazhang",
            "followers_url": "https://api.github.com/users/xinyazhang/followers",
            "following_url": "https://api.github.com/users/xinyazhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinyazhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinyazhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinyazhang/subscriptions",
            "organizations_url": "https://api.github.com/users/xinyazhang/orgs",
            "repos_url": "https://api.github.com/users/xinyazhang/repos",
            "events_url": "https://api.github.com/users/xinyazhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinyazhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 18,
        "created_at": "2022-06-23T22:15:40Z",
        "updated_at": "2022-08-03T06:14:27Z",
        "closed_at": "2022-08-03T06:14:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11972",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11972",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11972.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11972.patch",
            "merged_at": "2022-08-03T06:14:27Z"
        },
        "body": "**Description**: Add InstanceNormalization, BatchNormalization (fp16/fp32) and LRN Ops, and/or enable their unit tests.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n    * InstanceNormalization, BatchNormalization and LRN Ops were missing in ROCm backend.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11972/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11973",
        "id": 1283040826,
        "node_id": "I_kwDOCVq1mM5MeaY6",
        "number": 11973,
        "title": "Wrong header included for CoreML provider factory",
        "user": {
            "login": "carsonswope",
            "id": 13283503,
            "node_id": "MDQ6VXNlcjEzMjgzNTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/13283503?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/carsonswope",
            "html_url": "https://github.com/carsonswope",
            "followers_url": "https://api.github.com/users/carsonswope/followers",
            "following_url": "https://api.github.com/users/carsonswope/following{/other_user}",
            "gists_url": "https://api.github.com/users/carsonswope/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/carsonswope/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/carsonswope/subscriptions",
            "organizations_url": "https://api.github.com/users/carsonswope/orgs",
            "repos_url": "https://api.github.com/users/carsonswope/repos",
            "events_url": "https://api.github.com/users/carsonswope/events{/privacy}",
            "received_events_url": "https://api.github.com/users/carsonswope/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1267486731,
                "node_id": "MDU6TGFiZWwxMjY3NDg2NzMx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/contributions%20welcome",
                "name": "contributions welcome",
                "color": "545AB5",
                "default": false,
                "description": "lower priority issues for the core ORT teams"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-23T22:41:38Z",
        "updated_at": "2022-07-12T15:24:31Z",
        "closed_at": "2022-07-12T01:27:02Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "In the latest macOS release (`onnxruntime-osx-arm64-1.11.1`) the header `coreml_execution_provider.h` is included. I think that the correct header to include is `coreml_provider_factory.h`.\r\n\r\nApologies if this is totally wrong, I'm pretty new to onnx-runtime. Anyway, here's my reasoning:\r\n\r\nI needed to call `OrtSessionOptionsAppendExecutionProvider_CoreML` to add the CoreML EP to my session options pointer. Indeed the function is exported from `libonnxruntime.dylib` (i.e. run `nm -gU libonnxruntime.dylib`), but the only header it is declared in is `coreml_provider_factory.h`. I had to add `#include <coreml_provider_factory.h>`, then I could call the function because I was already linking to `libonnxruntime.dylib`. Also, `coreml_execution_provider.h` includes header files that seem to be internal to onnxruntime and not part of the public API.\r\n\r\nI guess this would be a change to `copy_strip_binary.sh`, like what happened in https://github.com/microsoft/onnxruntime/pull/10675 , but just a different file name. Happy to make a PR for this, just would like some confirmation that it's correct first.\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11973/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11974",
        "id": 1283129646,
        "node_id": "PR_kwDOCVq1mM46R-Re",
        "number": 11974,
        "title": "[DML EP] Pad operator: Handle negative pad counts",
        "user": {
            "login": "sumitsays",
            "id": 11188170,
            "node_id": "MDQ6VXNlcjExMTg4MTcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/11188170?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sumitsays",
            "html_url": "https://github.com/sumitsays",
            "followers_url": "https://api.github.com/users/sumitsays/followers",
            "following_url": "https://api.github.com/users/sumitsays/following{/other_user}",
            "gists_url": "https://api.github.com/users/sumitsays/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sumitsays/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sumitsays/subscriptions",
            "organizations_url": "https://api.github.com/users/sumitsays/orgs",
            "repos_url": "https://api.github.com/users/sumitsays/repos",
            "events_url": "https://api.github.com/users/sumitsays/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sumitsays/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-24T01:09:28Z",
        "updated_at": "2022-07-06T16:54:09Z",
        "closed_at": "2022-06-28T07:41:58Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11974",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11974",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11974.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11974.patch",
            "merged_at": "2022-06-28T07:41:58Z"
        },
        "body": "**Description**: DML_PADDING1_OPERATOR_DESC doesn't support negative pad count. Right now, to unblock users of ORT+DML in opset 9 models, mitigate it by falling back to the CPU EP for opsets version < 11. DML EP will resolve this issue thoroughly in next ORT release.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11974/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11975",
        "id": 1283166283,
        "node_id": "I_kwDOCVq1mM5Me5BL",
        "number": 11975,
        "title": "quant onnx model slower than pytorch with mish6 activation, howerver faster with relu6",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            },
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-24T02:07:06Z",
        "updated_at": "2022-08-12T08:39:21Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI have an model, which has activation function as mish6, but when i quant the model in onnx and pytorch, I get inference time as followings:\r\n```\r\nonnxruntime float:61.45ms.   torchscript float:86.3ms\r\nonnxruntime quant:44.84ms   torchscript quant:22.3ms\r\nhowever when I change the activation function to relu6, the result change:\r\nonnxruntime float:32.26ms.   torchscript float:71.28ms\r\nonnxruntime quant:13.61ms.   torchscript quant:14.81ms\r\n\r\n```\r\nthe result seems that, the same model with mish6 activation,quant onnx slower than pytorch, but relu6 onnx faster than pytorch\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux\r\n- ONNX Runtime installed from (source or binary):pip install onnxruntime and torch\r\n- ONNX Runtime version:1.11.0, pytorch version:1.8.1\r\n- Python version:3.8\r\n- Visual Studio version (if applicable):NO\r\n- GCC/Compiler version (if compiling from source):9.3.0\r\n- CUDA/cuDNN version:No\r\n- GPU model and memory:No",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11975/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11976",
        "id": 1283271184,
        "node_id": "PR_kwDOCVq1mM46SbCM",
        "number": 11976,
        "title": "[CUDA] Add Strided Tensor Support for Expand->GatherElements for Training",
        "user": {
            "login": "er3x3",
            "id": 11661208,
            "node_id": "MDQ6VXNlcjExNjYxMjA4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11661208?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/er3x3",
            "html_url": "https://github.com/er3x3",
            "followers_url": "https://api.github.com/users/er3x3/followers",
            "following_url": "https://api.github.com/users/er3x3/following{/other_user}",
            "gists_url": "https://api.github.com/users/er3x3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/er3x3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/er3x3/subscriptions",
            "organizations_url": "https://api.github.com/users/er3x3/orgs",
            "repos_url": "https://api.github.com/users/er3x3/repos",
            "events_url": "https://api.github.com/users/er3x3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/er3x3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-24T05:13:49Z",
        "updated_at": "2022-07-25T08:05:27Z",
        "closed_at": "2022-07-25T08:05:26Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11976",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11976",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11976.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11976.patch",
            "merged_at": "2022-07-25T08:05:26Z"
        },
        "body": "The PR add strided tensor support for Expand and GatherElements[Grad] for CUDA kernels:\r\n- Expand can generate strided tensor as output\r\n- GatherElements[Grad] supports taking strided tensor as \"indices\" input\r\n\r\nSome training models contains Expand->GatherElements pattern, the output of Expand is the GatherElements' \"indices\" input, which will also be used by GatherElementsGrad. Its lifetime is long cross from forward to backward, which contributes to the peak memory. Using strided tensor can save the memory usage. This also help to improve the time perf, as we don't need real compute for Expand, the perf for GatherElements[Grad] is also faster because more efficient data read (in smaller data buffer size).\r\n\r\nTake torch.gather(input[4,32,512,1023], -1, indices[4,1,512,512].expand(-1,32,-1,-1)) as example:\r\n- Before the change, perf is Expand 0.4ms + GatherElements 0.9ms + GatherElementsGrad 1.6ms = 2.9ms, max mem allocated is 1032MB\r\n- After the change, perf is GatherElements 0.7ms + GatherElementsGrad 1.5ms = 2.2ms, max mem allocated is 920MB. Both mem and perf are better.\r\n\r\nWe also observed from one of the customer models that has quite some number of Expand->GatherElements that the peak mem usage reduces from 35GB to 26GB after this change.\r\n\r\nThe PR also refactored the kernel code for GatherElements/ScatterElements/GatherElementsGrad, the refactor has nearly no impact to the kernel perf:\r\n- For 2D case (torch.gather(input[4,32,512,1023], -1, indices[4,32,512,512)), run 2 steps:\r\nBefore:\r\n![image](https://user-images.githubusercontent.com/11661208/175466407-f4f00f22-1ea2-4db8-9605-a359a6f7aff9.png)\r\nAfter:\r\n![image](https://user-images.githubusercontent.com/11661208/175466434-16d7c579-b675-4f47-ae4e-95ca5bd6af9e.png)\r\n- For general case (torch.gather(input[4,32,1023,512], -2, indices[4,32,512,512)), run 2 steps:\r\nBefore:\r\n![image](https://user-images.githubusercontent.com/11661208/175466474-a763147b-11c5-4337-be2a-5b67382d8f7c.png)\r\nAfter:\r\n![image](https://user-images.githubusercontent.com/11661208/175466497-19616ddb-4c86-4c7a-b350-14e4eadbcdec.png)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976/reactions",
            "total_count": 3,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11976/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11977",
        "id": 1283271925,
        "node_id": "I_kwDOCVq1mM5MfSz1",
        "number": 11977,
        "title": "support pytorch 1.11 in export onnx scripts",
        "user": {
            "login": "HaoboGu",
            "id": 8640918,
            "node_id": "MDQ6VXNlcjg2NDA5MTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8640918?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/HaoboGu",
            "html_url": "https://github.com/HaoboGu",
            "followers_url": "https://api.github.com/users/HaoboGu/followers",
            "following_url": "https://api.github.com/users/HaoboGu/following{/other_user}",
            "gists_url": "https://api.github.com/users/HaoboGu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/HaoboGu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/HaoboGu/subscriptions",
            "organizations_url": "https://api.github.com/users/HaoboGu/orgs",
            "repos_url": "https://api.github.com/users/HaoboGu/repos",
            "events_url": "https://api.github.com/users/HaoboGu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/HaoboGu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-24T05:15:08Z",
        "updated_at": "2022-07-11T09:41:28Z",
        "closed_at": "2022-07-11T09:41:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello, I'm trying to convert distilgpt2 to onnx using `onnxruntime.transformers.convert_to_onnx`, but I got an error:\r\n\r\n<img width=\"1644\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8640918/175466726-f5413339-a61a-424d-a723-6cf00e2543cc.png\">\r\n\r\n\r\nPytorch 1.11.x removes some arguments for `torch.onnx.export()`, which causes this error: https://github.com/pytorch/pytorch/releases/tag/v1.11.0\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11977/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11978",
        "id": 1283448440,
        "node_id": "PR_kwDOCVq1mM46TA6z",
        "number": 11978,
        "title": "CPU AdamW implementation",
        "user": {
            "login": "pengwa",
            "id": 10530022,
            "node_id": "MDQ6VXNlcjEwNTMwMDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10530022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pengwa",
            "html_url": "https://github.com/pengwa",
            "followers_url": "https://api.github.com/users/pengwa/followers",
            "following_url": "https://api.github.com/users/pengwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/pengwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pengwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pengwa/subscriptions",
            "organizations_url": "https://api.github.com/users/pengwa/orgs",
            "repos_url": "https://api.github.com/users/pengwa/repos",
            "events_url": "https://api.github.com/users/pengwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pengwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1913759001,
                "node_id": "MDU6TGFiZWwxOTEzNzU5MDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/training",
                "name": "training",
                "color": "BFD4F2",
                "default": false,
                "description": "issues related to ONNX Runtime training; typically submitted using template"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-24T08:43:23Z",
        "updated_at": "2022-07-25T01:43:54Z",
        "closed_at": "2022-07-25T01:43:53Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11978",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11978",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11978.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11978.patch",
            "merged_at": "2022-07-25T01:43:53Z"
        },
        "body": "**Description**: CPU AdamW implementation\r\n\r\nAdded the CPU kernels and its unit tests. \r\n\r\nThis is currently needed by some on-device training customers .\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11978/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11979",
        "id": 1283499660,
        "node_id": "I_kwDOCVq1mM5MgKaM",
        "number": 11979,
        "title": "Different inference results in C++ and Python",
        "user": {
            "login": "tony-laoshi",
            "id": 73882144,
            "node_id": "MDQ6VXNlcjczODgyMTQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/73882144?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tony-laoshi",
            "html_url": "https://github.com/tony-laoshi",
            "followers_url": "https://api.github.com/users/tony-laoshi/followers",
            "following_url": "https://api.github.com/users/tony-laoshi/following{/other_user}",
            "gists_url": "https://api.github.com/users/tony-laoshi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tony-laoshi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tony-laoshi/subscriptions",
            "organizations_url": "https://api.github.com/users/tony-laoshi/orgs",
            "repos_url": "https://api.github.com/users/tony-laoshi/repos",
            "events_url": "https://api.github.com/users/tony-laoshi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tony-laoshi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-24T09:24:43Z",
        "updated_at": "2022-06-30T02:08:33Z",
        "closed_at": "2022-06-30T02:08:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nAfter the network model was exported, I used **onnx runtime** in Python and C++ for inference (other conditions were kept consistent), and the inference results differed greatly.\r\n\r\n**Urgency**\r\n None.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary):  binary(c++),  pip(python)\r\n- ONNX Runtime version: 1.11.1(c++),  1.11.1(python)\r\n- Python version: 3.8.10\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: \r\n\r\n**To Reproduce**\r\n- In this [folder](https://github.com/tony-laoshi/AnyNet/tree/master/onnx%20test), there are the **.ipynb** script and **.cpp** source files that I used for testing, as well as the exported ONNX model and images that I used for testing\r\n\r\n**Expected behavior**\r\nThe test results in C++ are clearly wrong. the test results in Python appear to be correct. Trying to get the correct result in C++\r\n\r\n**Screenshots**\r\n![py](https://user-images.githubusercontent.com/73882144/175505026-7eb1309f-addc-4d67-9a3c-d4a7aedea263.png)\r\ntest results in Python\r\n\r\n![c++](https://user-images.githubusercontent.com/73882144/175505146-ec5f9150-199e-407e-bbe0-eeb722d1c006.png)\r\ntest results in C++\r\n\r\n\r\n**Additional context**\r\n[Function to export model](https://github.com/tony-laoshi/AnyNet/blob/48779389f6684d4328a2b5d28790a506909c95cf/finetune.py#L230)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11979/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11980",
        "id": 1283557033,
        "node_id": "I_kwDOCVq1mM5MgYap",
        "number": 11980,
        "title": "How to use webgl version?",
        "user": {
            "login": "fmscole",
            "id": 8135902,
            "node_id": "MDQ6VXNlcjgxMzU5MDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8135902?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fmscole",
            "html_url": "https://github.com/fmscole",
            "followers_url": "https://api.github.com/users/fmscole/followers",
            "following_url": "https://api.github.com/users/fmscole/following{/other_user}",
            "gists_url": "https://api.github.com/users/fmscole/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fmscole/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fmscole/subscriptions",
            "organizations_url": "https://api.github.com/users/fmscole/orgs",
            "repos_url": "https://api.github.com/users/fmscole/repos",
            "events_url": "https://api.github.com/users/fmscole/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fmscole/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-24T10:10:58Z",
        "updated_at": "2022-06-26T14:59:53Z",
        "closed_at": "2022-06-26T14:59:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I set the tag in the html file:\r\n`<script src=\"./ort.webgl.min.js\" type=\"module\"></script>`\r\n\r\nI get the bug:\r\n```\r\nUncaught (in promise) Error: no available backend found. ERR: \r\n    at backend-impl.js:80:11\r\n    at h.create (inference-session-impl.js:169:31)\r\n    at start ((index):97:48)\r\n```\r\n So,myquestion is how to use the webgl version?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11980/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11981",
        "id": 1283706097,
        "node_id": "PR_kwDOCVq1mM46T5Pp",
        "number": 11981,
        "title": "MIGraphx as an Engine",
        "user": {
            "login": "smicic-htec",
            "id": 96046546,
            "node_id": "U_kgDOBbmN0g",
            "avatar_url": "https://avatars.githubusercontent.com/u/96046546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smicic-htec",
            "html_url": "https://github.com/smicic-htec",
            "followers_url": "https://api.github.com/users/smicic-htec/followers",
            "following_url": "https://api.github.com/users/smicic-htec/following{/other_user}",
            "gists_url": "https://api.github.com/users/smicic-htec/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smicic-htec/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smicic-htec/subscriptions",
            "organizations_url": "https://api.github.com/users/smicic-htec/orgs",
            "repos_url": "https://api.github.com/users/smicic-htec/repos",
            "events_url": "https://api.github.com/users/smicic-htec/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smicic-htec/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 16,
        "created_at": "2022-06-24T12:42:38Z",
        "updated_at": "2022-08-10T00:46:33Z",
        "closed_at": null,
        "author_association": "FIRST_TIME_CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11981",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11981",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11981.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11981.patch",
            "merged_at": null
        },
        "body": "**Description**: Adding MIGraphx as an engine\r\n\r\n**Motivation and Context**\r\n- Additional option when comparing performances between runs.\r\n- Comparing migraphx as an engine vs as an execution provider (ONNX)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11981/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11982",
        "id": 1283877701,
        "node_id": "PR_kwDOCVq1mM46Uecr",
        "number": 11982,
        "title": "Eager mode: support abs.out",
        "user": {
            "login": "jamill",
            "id": 2045976,
            "node_id": "MDQ6VXNlcjIwNDU5NzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2045976?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamill",
            "html_url": "https://github.com/jamill",
            "followers_url": "https://api.github.com/users/jamill/followers",
            "following_url": "https://api.github.com/users/jamill/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamill/subscriptions",
            "organizations_url": "https://api.github.com/users/jamill/orgs",
            "repos_url": "https://api.github.com/users/jamill/repos",
            "events_url": "https://api.github.com/users/jamill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-24T15:19:43Z",
        "updated_at": "2022-06-30T15:37:03Z",
        "closed_at": "2022-06-30T15:37:03Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11982",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11982",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11982.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11982.patch",
            "merged_at": null
        },
        "body": "**Description**: Implement support for abs.out operator, built on `resize_` support\r\n\r\n**Motivation and Context**\r\nAdd support for abs.out operator and necessary changes to support <func>.out operators in general.\r\n\r\n\r\nThis change also includes tests for the various flavors of the `abs` operator (`abs` and `abs_`).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11982/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11983",
        "id": 1283927084,
        "node_id": "I_kwDOCVq1mM5Mhyws",
        "number": 11983,
        "title": "inference time is not stable",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-24T16:08:01Z",
        "updated_at": "2022-07-01T02:25:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- ONNX Runtime installed from (source or binary): \r\n- ONNX Runtime version: 1.60 GPU\r\n- Python version:\r\n- Visual Studio version (if applicable): vs 2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 10.2 / cudnn 8.0\r\n- GPU model and memory: 2080ti\r\n\r\n var startTicks = DateTime.Now.Ticks;\r\n  using (IDisposableReadOnlyCollection<DisposableNamedOnnxValue> results = textDetNet.Run(inputs))\r\n  {\r\n      var endTicks = DateTime.Now.Ticks;\r\n      var fullDetectTime = (endTicks - startTicks) / 10000F;\r\n\r\n}\r\n\r\n\r\nth time is not stable ， as follows: that's wired\r\n513.0026 ms\r\n745.782 ms\r\n606.0461 ms\r\n35.8829 ms\r\n33.8879 ms \r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11983/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11984",
        "id": 1284070078,
        "node_id": "PR_kwDOCVq1mM46VIGI",
        "number": 11984,
        "title": "Add warning about future computation change for ConvTranspose with auto_pad",
        "user": {
            "login": "jcwchen",
            "id": 14194980,
            "node_id": "MDQ6VXNlcjE0MTk0OTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14194980?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jcwchen",
            "html_url": "https://github.com/jcwchen",
            "followers_url": "https://api.github.com/users/jcwchen/followers",
            "following_url": "https://api.github.com/users/jcwchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/jcwchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jcwchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jcwchen/subscriptions",
            "organizations_url": "https://api.github.com/users/jcwchen/orgs",
            "repos_url": "https://api.github.com/users/jcwchen/repos",
            "events_url": "https://api.github.com/users/jcwchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jcwchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-24T18:43:30Z",
        "updated_at": "2022-07-06T16:54:00Z",
        "closed_at": "2022-06-29T13:53:32Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11984",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11984",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11984.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11984.patch",
            "merged_at": "2022-06-29T13:53:31Z"
        },
        "body": "**Description**:\r\nAdd a warning about future computation change for ConvTranspose with auto_pad (SAME_UPPER and SAME_LOWER).\r\n\r\nPerhaps we can just merge this PR to ORT's 1.12 release branch and merge my fix #9740 into the main branch?\r\n\r\n**Motivation and Context**\r\nWarning for future fix: #9740 in next ORT 1.13 release since it might compromise backward compatibility.\r\n\r\nI am not sure whether it is the right way to show backward compatibility warning. Please review it. Thanks!\r\ncc @pranavsharma, @hariharans29",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11984/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11985",
        "id": 1284134679,
        "node_id": "I_kwDOCVq1mM5MilcX",
        "number": 11985,
        "title": "Import Error in Windows debug config with eager mode",
        "user": {
            "login": "juanpaez22",
            "id": 32758223,
            "node_id": "MDQ6VXNlcjMyNzU4MjIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32758223?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juanpaez22",
            "html_url": "https://github.com/juanpaez22",
            "followers_url": "https://api.github.com/users/juanpaez22/followers",
            "following_url": "https://api.github.com/users/juanpaez22/following{/other_user}",
            "gists_url": "https://api.github.com/users/juanpaez22/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juanpaez22/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juanpaez22/subscriptions",
            "organizations_url": "https://api.github.com/users/juanpaez22/orgs",
            "repos_url": "https://api.github.com/users/juanpaez22/repos",
            "events_url": "https://api.github.com/users/juanpaez22/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juanpaez22/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "souptc",
                "id": 11306809,
                "node_id": "MDQ6VXNlcjExMzA2ODA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/souptc",
                "html_url": "https://github.com/souptc",
                "followers_url": "https://api.github.com/users/souptc/followers",
                "following_url": "https://api.github.com/users/souptc/following{/other_user}",
                "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
                "organizations_url": "https://api.github.com/users/souptc/orgs",
                "repos_url": "https://api.github.com/users/souptc/repos",
                "events_url": "https://api.github.com/users/souptc/events{/privacy}",
                "received_events_url": "https://api.github.com/users/souptc/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-24T19:58:02Z",
        "updated_at": "2022-07-11T22:21:17Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nWhen importing onnxruntime built from source for Windows in debug config with eager mode, we get a DLL load error for the module onnxruntime_pybind11_state.\r\n\r\n**Urgency**\r\nBlocking testing in windows debug\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.12.0\r\n- Python version: 3.9.13\r\n- Visual Studio version (if applicable): NA\r\n- GCC/Compiler version (if compiling from source): Clang 14\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**To Reproduce**\r\nBuild from source:\r\n1. Create and activate a venv\r\n2. Install prereqs: `pip install setuptools wheel numpy typing_extensions torch`\r\n3. Build for windows in debug mode: `python ..\\onnxruntime\\tools\\ci_build\\build.py --config Debug --build_dir .\\build --build_eager_mode --enable_training --build_wheel --parallel`\r\n\r\nThe build stage itself will succeed, but the python tests will fail with a similar DLL error.\r\n\r\nTo repro once build succeeds:\r\n1. Setup the python wheel (from Debug output dir): `python ..\\..\\..\\..\\onnxruntime\\setup.py bdist_wheel --enable_training`\r\n2. pip install the wheel: `pip install \"dist\\onnxruntime_training-1.12.0+cpu-cp39-cp39-win_amd64.whl\"`\r\n3. Try importing onnxruntime in interactive python shell\r\n```\r\n>>> import torch\r\n>>> import onnxruntime\r\n```\r\n\r\n**Expected behavior**\r\nShould be able to successfully import onnxruntime when built with Windows debug configuration and eager mode enabled\r\n\r\n**Screenshots**\r\nError during python test stage of build:\r\n![1ada2c31-e551-4c7a-80f1-7be3093c4f88](https://user-images.githubusercontent.com/32758223/175657895-aa34daf7-d8c9-4780-b8fc-23adca645aab.jpg)\r\n\r\nError during import after installing wheel:\r\n![image](https://user-images.githubusercontent.com/32758223/175658499-8e089f01-05a5-4340-802d-32e4d1731d47.png)\r\n\r\n\r\n**Additional context**\r\nBoth stack traces suggest that the error is specifically related to the onnxruntime_pybind11_state module.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11985/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11986",
        "id": 1284229216,
        "node_id": "I_kwDOCVq1mM5Mi8hg",
        "number": 11986,
        "title": "Scan performs worse than LSTM for CUDA EP",
        "user": {
            "login": "rakib-hasan",
            "id": 1003393,
            "node_id": "MDQ6VXNlcjEwMDMzOTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1003393?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rakib-hasan",
            "html_url": "https://github.com/rakib-hasan",
            "followers_url": "https://api.github.com/users/rakib-hasan/followers",
            "following_url": "https://api.github.com/users/rakib-hasan/following{/other_user}",
            "gists_url": "https://api.github.com/users/rakib-hasan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rakib-hasan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rakib-hasan/subscriptions",
            "organizations_url": "https://api.github.com/users/rakib-hasan/orgs",
            "repos_url": "https://api.github.com/users/rakib-hasan/repos",
            "events_url": "https://api.github.com/users/rakib-hasan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rakib-hasan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-24T22:03:08Z",
        "updated_at": "2022-07-12T17:36:52Z",
        "closed_at": "2022-07-12T17:36:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "A scan model seems to run slower than an equivalent LSTM model even though the scan is supposed to be doing less amount of computation than LSTM.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- ONNX Runtime installed from (source or binary): Binary\r\n- ONNX Runtime version: ORT-1.11.1\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: cuda-11.6\r\n- GPU model and memory: T4, 16GB\r\n\r\n**To Reproduce**\r\n1. Start a TRT container (just to compare how TRT behaves for the same models): `docker run --gpus all -it --rm --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -v /home:/home nvcr.io/nvidia/tensorrt:22.04-py3`\r\n2. Install onnxruntime: `python3 -m pip install onnxruntime-gpu`\r\n3. Run the script with the attached models in the same directory:\r\n\r\n```\r\nimport numpy as np\r\nimport onnxruntime as ort\r\nimport time\r\n\r\nort.set_default_logger_severity(3)\r\n\r\nmax_iters = 200\r\nsequence = 500\r\nbatches = [64,128]\r\nmodels = [\"LSTM.onnx\", \"Scan.onnx\"]\r\nproviders = [\"CUDAExecutionProvider\", \"TensorrtExecutionProvider\"]\r\n\r\nfor ep in providers:\r\n  for model in models:\r\n    # all the setup\r\n    dt = np.float32\r\n    trt_opts = {}\r\n    trt_opts = {\"trt_max_workspace_size\": \"4294967296\"}\r\n    ep_w_opts = ()\r\n    if \"Tensorrt\" in ep:\r\n      ep_w_opts = (ep, trt_opts)\r\n    else:\r\n      ep_w_opts = ep # just cuda ep name\r\n\r\n    # now create an ORT session\r\n    sess = ort.InferenceSession(model, providers=[ep_w_opts])\r\n    for batch in batches:\r\n      print(f\"{max_iters},{sequence},{batch},{ep},{model}\", end='', flush=True)\r\n      inputs = {}\r\n      inputs[\"input\"] = np.zeros((sequence, batch, 64), dtype=dt)\r\n      # do a warm-up run first\r\n      r = sess.run(None, inputs)\r\n      start_time = time.time()\r\n      for iter in range(max_iters):\r\n        r = sess.run(None, inputs)\r\n\r\n      print(f\",{((time.time() - start_time)/max_iters)}\")\r\n    sess = None\r\n```\r\n\r\n**Expected behavior**\r\nScan model is supposed to be running faster than LSTM models (as it does for TRT EP). But you can see that for CUDA EP, it runs about 6x slower.\r\nThe performance comparison on my end:\r\n![image](https://user-images.githubusercontent.com/1003393/175697893-6896f2eb-4775-4c0d-bba3-ea6ceaaaf02c.png)\r\n[LSTM_vs_Scan_models.zip](https://github.com/microsoft/onnxruntime/files/8981694/LSTM_vs_Scan_models.zip)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11986/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11987",
        "id": 1284294646,
        "node_id": "PR_kwDOCVq1mM46V1Ui",
        "number": 11987,
        "title": "On device training CI pipeline",
        "user": {
            "login": "baijumeswani",
            "id": 12852605,
            "node_id": "MDQ6VXNlcjEyODUyNjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12852605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/baijumeswani",
            "html_url": "https://github.com/baijumeswani",
            "followers_url": "https://api.github.com/users/baijumeswani/followers",
            "following_url": "https://api.github.com/users/baijumeswani/following{/other_user}",
            "gists_url": "https://api.github.com/users/baijumeswani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/baijumeswani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/baijumeswani/subscriptions",
            "organizations_url": "https://api.github.com/users/baijumeswani/orgs",
            "repos_url": "https://api.github.com/users/baijumeswani/repos",
            "events_url": "https://api.github.com/users/baijumeswani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/baijumeswani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-24T22:55:53Z",
        "updated_at": "2022-07-25T17:07:18Z",
        "closed_at": "2022-07-25T17:07:17Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11987",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11987",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11987.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11987.patch",
            "merged_at": "2022-07-25T17:07:17Z"
        },
        "body": "This pull request creates a new on device training CI pipeline that runs on linux gpu.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11987/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11988",
        "id": 1284294866,
        "node_id": "PR_kwDOCVq1mM46V1Xq",
        "number": 11988,
        "title": "AVX2 U8S8 overflow fix",
        "user": {
            "login": "chenfucn",
            "id": 1316708,
            "node_id": "MDQ6VXNlcjEzMTY3MDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1316708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chenfucn",
            "html_url": "https://github.com/chenfucn",
            "followers_url": "https://api.github.com/users/chenfucn/followers",
            "following_url": "https://api.github.com/users/chenfucn/following{/other_user}",
            "gists_url": "https://api.github.com/users/chenfucn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chenfucn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chenfucn/subscriptions",
            "organizations_url": "https://api.github.com/users/chenfucn/orgs",
            "repos_url": "https://api.github.com/users/chenfucn/repos",
            "events_url": "https://api.github.com/users/chenfucn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chenfucn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2022-06-24T22:56:21Z",
        "updated_at": "2022-07-05T15:58:07Z",
        "closed_at": "2022-07-05T15:58:07Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11988",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11988",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11988.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11988.patch",
            "merged_at": null
        },
        "body": "**Description**: Add a graph optimization that convert u8s8 matrix multiplication for QAttention operator to u8u8 if needed\r\n\r\nWorking on expanding this to other operators\r\n\r\n**Motivation and Context**\r\n\r\nX64 platforms provide better performance computing u8s8 matrix multiplications. Unfortunately, AVX2/AVX512 CPUs suffers from value overflow problems described in:\r\nhttps://www.intel.com/content/www/us/en/develop/documentation/onednn-developer-guide-and-reference/top/advanced-topics/nuances-of-int8-computations.html\r\n\r\nIn this change we added a session option \"session.x64quantprecision\" (default off). We convert u8s8 matrix multiplication in QAttention operators to u8u8 when the following conditions are all satisfied:\r\n\r\n1. Current CPU is AVX2 or AVX512.\r\n2. \"session.x64quantprecision\" is on.\r\n3. Constant weight tensor contains value outside of [-64, 63].\r\n\r\nNote:\r\n1. Currently working on expanding this to support other operators.\r\n2. When weight tensor is not constant, QDQS8ToU8Transformer should already convert it to u8.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11988/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11989",
        "id": 1284373364,
        "node_id": "PR_kwDOCVq1mM46WA6h",
        "number": 11989,
        "title": "convert_beam_search supports large gpt2 model",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-25T00:06:06Z",
        "updated_at": "2022-06-28T17:02:36Z",
        "closed_at": "2022-06-28T17:02:35Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11989",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11989",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11989.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11989.patch",
            "merged_at": "2022-06-28T17:02:35Z"
        },
        "body": "**Description**: \r\n(1) add --run_shape_inference to make shape inference optional\r\n(2) add --vocab_mask to make the input optional\r\n(3) add --overwrite in gpt2 convert_to_onnx to allow overwrite existed raw onnx from PyTorch\r\n(4) save gpt2 model tensors to one external data file by default\r\n(5) group convert_beam_search arguments to multiple groups\r\n(6) make --decoder_onnx optional for gpt2 model\r\n(7) replace print by logger\r\n(8) update shape inference function to support external data.\r\n(9) when saving external data, show warning if onnx version < 1.12\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11989/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11990",
        "id": 1284532809,
        "node_id": "PR_kwDOCVq1mM46Wisx",
        "number": 11990,
        "title": "Add ConvTranspose2D to WebGL backend",
        "user": {
            "login": "101arrowz",
            "id": 29579245,
            "node_id": "MDQ6VXNlcjI5NTc5MjQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/29579245?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/101arrowz",
            "html_url": "https://github.com/101arrowz",
            "followers_url": "https://api.github.com/users/101arrowz/followers",
            "following_url": "https://api.github.com/users/101arrowz/following{/other_user}",
            "gists_url": "https://api.github.com/users/101arrowz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/101arrowz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/101arrowz/subscriptions",
            "organizations_url": "https://api.github.com/users/101arrowz/orgs",
            "repos_url": "https://api.github.com/users/101arrowz/repos",
            "events_url": "https://api.github.com/users/101arrowz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/101arrowz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 23,
        "created_at": "2022-06-25T09:57:09Z",
        "updated_at": "2022-07-27T20:57:12Z",
        "closed_at": "2022-07-27T20:57:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11990",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11990",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11990.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11990.patch",
            "merged_at": "2022-07-27T20:57:12Z"
        },
        "body": "**Description**: Adds support for the ConvTranspose operator to the WebGL backend. Like Conv, this currently only supports two-dimensional ConvTranspose.\r\n\r\n**Motivation and Context**\r\n- I'm trying to get [Wav2Lip](https://github.com/Rudrabha/Wav2Lip) working with GPU acceleration in web browsers, and ConvTranspose is used in various spots so it's needed to run that model.\r\n- Fixes #9257\r\n\r\nI cannot guarantee how well this works - I have verified that it works for Wav2Lip but was unable to set up the unit testing infrastructure, so I couldn't write any tests. However, as far as I can tell, all the options work consistently with PyTorch's implementation (within ~0.001% tolerance).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11990/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11991",
        "id": 1284573054,
        "node_id": "I_kwDOCVq1mM5MkQd-",
        "number": 11991,
        "title": "converting pth to onnx with onnx.js",
        "user": {
            "login": "jonychoi",
            "id": 51044058,
            "node_id": "MDQ6VXNlcjUxMDQ0MDU4",
            "avatar_url": "https://avatars.githubusercontent.com/u/51044058?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jonychoi",
            "html_url": "https://github.com/jonychoi",
            "followers_url": "https://api.github.com/users/jonychoi/followers",
            "following_url": "https://api.github.com/users/jonychoi/following{/other_user}",
            "gists_url": "https://api.github.com/users/jonychoi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jonychoi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jonychoi/subscriptions",
            "organizations_url": "https://api.github.com/users/jonychoi/orgs",
            "repos_url": "https://api.github.com/users/jonychoi/repos",
            "events_url": "https://api.github.com/users/jonychoi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jonychoi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-25T12:25:09Z",
        "updated_at": "2022-06-27T17:45:53Z",
        "closed_at": "2022-06-27T17:45:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello, I want to convert .pth or .pt file to .onnx file with onnx.js.\r\nIs there any solution with this?\r\n\r\nAny comments are welcome. Thanks:)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11991/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11992",
        "id": 1284590510,
        "node_id": "I_kwDOCVq1mM5MkUuu",
        "number": 11992,
        "title": "Any interest in hosting the Rust bindings",
        "user": {
            "login": "boydjohnson",
            "id": 4340785,
            "node_id": "MDQ6VXNlcjQzNDA3ODU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4340785?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/boydjohnson",
            "html_url": "https://github.com/boydjohnson",
            "followers_url": "https://api.github.com/users/boydjohnson/followers",
            "following_url": "https://api.github.com/users/boydjohnson/following{/other_user}",
            "gists_url": "https://api.github.com/users/boydjohnson/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/boydjohnson/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/boydjohnson/subscriptions",
            "organizations_url": "https://api.github.com/users/boydjohnson/orgs",
            "repos_url": "https://api.github.com/users/boydjohnson/repos",
            "events_url": "https://api.github.com/users/boydjohnson/events{/privacy}",
            "received_events_url": "https://api.github.com/users/boydjohnson/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 14,
        "created_at": "2022-06-25T13:26:42Z",
        "updated_at": "2023-04-20T01:54:49Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "This repo has csharp, java, js, objectivec bindings. There are rust bindings at https://github.com/nbigaouette/onnxruntime-rs/. The maintainer isn't able to put in the time now and the community is trying to decide how best to organize themselves. This is the coordinating issue (https://github.com/nbigaouette/onnxruntime-rs/issues/112). One idea that was floated was to host the rust bindings here. It would give them greater visibility and attention. \r\n\r\nWould you host the Rust bindings along with the other bindings in this repo? I could provide most of the work needed.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992/reactions",
            "total_count": 16,
            "+1": 16,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11992/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11993",
        "id": 1284745902,
        "node_id": "I_kwDOCVq1mM5Mk6qu",
        "number": 11993,
        "title": "inference is different on linux and windows",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-25T23:45:42Z",
        "updated_at": "2022-06-29T13:26:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10 / linux\r\n- ONNX Runtime installed from (source or binary): by pip install on linux and intall on windows by Nuget software packages with vs 2019\r\n- ONNX Runtime version:1.6 GPU\r\n- Python version:3.6\r\n- Visual Studio version (if applicable): vs 2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2 / 8.0\r\n- GPU model and memory: 2080ti\r\n\r\nwth th same onnx model, i run on linux there is no warings,but on windows it occurs as follows with c# code:\r\n i have no solutions about it , that's wired,i am sure i use the same onnx model\r\n\r\n2022-06-26 07:39:46.5797282 [I:onnxruntime:, inference_session.cc:230 onnxruntime::InferenceSession::ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\r\n2022-06-26 07:39:46.5952765 [I:onnxruntime:, inference_session.cc:1081 onnxruntime::InferenceSession::Initialize] Initializing session.\r\n2022-06-26 07:39:46.5975383 [I:onnxruntime:, inference_session.cc:1106 onnxruntime::InferenceSession::Initialize] Adding default CPU execution provider.\r\n2022-06-26 07:39:46.6024628 [I:onnxruntime:, reshape_fusion.cc:37 onnxruntime::ReshapeFusion::ApplyImpl] Total fused reshape node count: 0\r\n2022-06-26 07:39:46.6070077 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.0.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6103350 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.0.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6131179 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.0.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6157532 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.1.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6183754 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.1.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6223225 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.2.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6252255 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.1.2.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6279200 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.2.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6304345 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.2.4.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6330252 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.2.4.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6358892 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.2.5.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6388152 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.2.5.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6431981 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.0.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6461263 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.1.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6491511 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.2.se.conv2.bias'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6523510 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer 'backbone.stages.3.1.se.conv2.weight'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6568253 [I:onnxruntime:, graph.cc:3096 onnxruntime::Graph::CleanUnusedInitializers] Removing initializer '446'. It is no longer used by any node.\r\n2022-06-26 07:39:46.6601788 [I:onnxruntime:, reshape_fusion.cc:37 onnxruntime::ReshapeFusion::ApplyImpl] Total fused reshape node count: 0\r\n2022-06-26 07:39:46.6654744 [I:onnxruntime:, reshape_fusion.cc:37 onnxruntime::ReshapeFusion::ApplyImpl] Total fused reshape node count: 0\r\n2022-06-26 07:39:46.6955955 [I:onnxruntime:, session_state_utils.cc:100 onnxruntime::session_state_utils::SaveInitializedTensors] Saving initialized tensors.\r\n2022-06-26 07:39:46.6988725 [I:onnxruntime:, session_state_utils.cc:170 onnxruntime::session_state_utils::SaveInitializedTensors] [Memory] SessionStateInitializer statically allocates 768 bytes for Cpu\r\n\r\n2022-06-26 07:39:46.7011915 [I:onnxruntime:, session_state_utils.cc:170 onnxruntime::session_state_utils::SaveInitializedTensors] [Memory] SessionStateInitializer statically allocates 6707968 bytes for Cuda\r\n\r\n2022-06-26 07:39:46.7110036 [I:onnxruntime:, session_state_utils.cc:212 onnxruntime::session_state_utils::SaveInitializedTensors] Done saving initialized tensors\r\n2022-06-26 07:39:46.7142777 [I:onnxruntime:, inference_session.cc:1256 onnxruntime::InferenceSession::Initialize] Session successfully initialized.\r\n2022-06-26 07:39:46.7988220 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 375 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8081576 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 376 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8143254 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 417 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8194568 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 418 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8240057 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 419 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8297787 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 420 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8342443 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 421 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8390132 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 422 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8441175 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 463 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8487403 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 464 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8535423 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 465 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8588892 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer 466 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8646969 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8718163 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8771748 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.11.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8819013 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.12.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8868071 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.12.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8921859 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.12.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.8969171 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.12.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9015792 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.14.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9072555 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.15.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9119771 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.15.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9166707 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.15.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9218073 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.15.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9289717 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.18.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9366731 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.18.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9445339 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.3.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9492543 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.3.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9562599 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.6.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9633014 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.6.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9707937 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.8.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9755314 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer cnn.ConvNet.8.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9801341 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer rnn.0.embedding.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9856676 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer rnn.0.embedding.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9904876 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer rnn.1.embedding.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:46.9958298 [W:onnxruntime:, graph.cc:1069 onnxruntime::Graph::Graph] Initializer rnn.1.embedding.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\r\n2022-06-26 07:39:47.0060425 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0086717 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0104373 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0121946 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0139488 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0163449 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0183537 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0203830 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0221312 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0238841 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0256255 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0273589 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0291331 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0308753 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0336761 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0356924 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0374322 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0393556 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0412086 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0431101 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0448481 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0466624 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0493076 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0510403 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0530491 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n2022-06-26 07:39:47.0549263 [W:onnxruntime:CSharpOnnxRuntime, fallback_cpu_capability.h:140 onnxruntime::GetCpuPreferedNodes] Force fallback to CPU execution for node:\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11993/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11994",
        "id": 1284790568,
        "node_id": "I_kwDOCVq1mM5MlFko",
        "number": 11994,
        "title": "Inconsistent result to NumPy and PyTorch when consecutively casting a float tensor to int32 and then to bool",
        "user": {
            "login": "lazycal",
            "id": 7333325,
            "node_id": "MDQ6VXNlcjczMzMzMjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7333325?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lazycal",
            "html_url": "https://github.com/lazycal",
            "followers_url": "https://api.github.com/users/lazycal/followers",
            "following_url": "https://api.github.com/users/lazycal/following{/other_user}",
            "gists_url": "https://api.github.com/users/lazycal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lazycal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lazycal/subscriptions",
            "organizations_url": "https://api.github.com/users/lazycal/orgs",
            "repos_url": "https://api.github.com/users/lazycal/repos",
            "events_url": "https://api.github.com/users/lazycal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lazycal/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-26T03:44:04Z",
        "updated_at": "2022-08-12T08:37:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n`[-0.2, -0.1, 0, 0.1, 0.2].cast(int32).cast(bool)` returns `[ True,  True, False,  True,  True]` in ORT, but should be `[ False, False, False, False, False]`.\r\n\r\nSome dataponts:\r\n- When I also return the intermediate result of cast(int32) as the model output, the problem disappears.\r\n- ORT's result is the same as directly casting to bool.\r\n\r\nSo I guess ORT does a fusion optimization here that mistakenly rewrite `cast(int32).cast(bool)` to `cast(bool)`.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: 3.7.11\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: RTX 2080, 8GB\r\n\r\n**To Reproduce**\r\nRun the following script.\r\n```python\r\nimport torch\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport numpy as np\r\n\r\n\r\nfor ret_intermediate in [True, False]:\r\n    print(f'----->Testing model with ret_intermediate={ret_intermediate}...')\r\n\r\n    class Model(torch.nn.Module):\r\n        def forward(self, x):\r\n            y = x.to(torch.int32)\r\n            if ret_intermediate:\r\n                return y.to(torch.bool), y\r\n            else:\r\n                return (y.to(torch.bool), )\r\n\r\n    model = Model()\r\n    x = torch.tensor([-0.2, -0.1, 0, 0.1, 0.2])\r\n    output_names = ['o0', 'o1'] if ret_intermediate else ['o0']\r\n    model_name = \"output.onnx\"\r\n    torch.onnx.export(model, (x,), model_name,\r\n                      input_names=[\"i0\"], output_names=output_names, opset_version=14)\r\n    onnx_model = onnx.load(model_name)\r\n    onnx.checker.check_model(onnx_model, full_check=True)\r\n\r\n    sess_options = ort.SessionOptions()\r\n    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\r\n    sess = ort.InferenceSession(\"output.onnx\", sess_options=sess_options, providers=[\r\n        'CPUExecutionProvider'])\r\n    y_ort = sess.run(output_names, {'i0': x.numpy()})[0]\r\n\r\n    y_tch = model(x)[0]\r\n    y_np = x.numpy().astype(np.int32).astype(bool)\r\n    np.testing.assert_allclose(y_np, y_tch, rtol=1e-02,\r\n                               atol=1e-02, err_msg='numpy vs torch')  # always pass\r\n    np.testing.assert_allclose(y_ort, y_tch, rtol=1e-02,\r\n                               atol=1e-02, err_msg='ort vs torch')  # failed\r\n    print('----->Passed')\r\n```\r\n**Expected behavior**\r\nBe consistent to NumPy and PyTorch.\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/7333325/175798253-9a30d132-3ab9-4246-a795-9213ff79fdd4.png)\r\n**Additional context**\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11994/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/11995",
        "id": 1284824551,
        "node_id": "PR_kwDOCVq1mM46XeHK",
        "number": 11995,
        "title": "Add FastGelu to kernel explorer for profiling.",
        "user": {
            "login": "zhangyaobit",
            "id": 1034716,
            "node_id": "MDQ6VXNlcjEwMzQ3MTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1034716?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zhangyaobit",
            "html_url": "https://github.com/zhangyaobit",
            "followers_url": "https://api.github.com/users/zhangyaobit/followers",
            "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}",
            "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions",
            "organizations_url": "https://api.github.com/users/zhangyaobit/orgs",
            "repos_url": "https://api.github.com/users/zhangyaobit/repos",
            "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zhangyaobit/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-26T06:43:21Z",
        "updated_at": "2022-06-30T14:35:44Z",
        "closed_at": "2022-06-30T14:35:43Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/11995",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/11995",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/11995.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/11995.patch",
            "merged_at": "2022-06-30T14:35:43Z"
        },
        "body": "**Description**:\r\nAdd FastGelu to kernel explorer for profiling.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve?\r\n- If it fixes an open issue, please link to the issue here.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11995/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11996",
        "id": 1284878304,
        "node_id": "I_kwDOCVq1mM5Mla_g",
        "number": 11996,
        "title": " failed to initialize a session in the GPU environment",
        "user": {
            "login": "liulhdarks",
            "id": 7029328,
            "node_id": "MDQ6VXNlcjcwMjkzMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7029328?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/liulhdarks",
            "html_url": "https://github.com/liulhdarks",
            "followers_url": "https://api.github.com/users/liulhdarks/followers",
            "following_url": "https://api.github.com/users/liulhdarks/following{/other_user}",
            "gists_url": "https://api.github.com/users/liulhdarks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/liulhdarks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/liulhdarks/subscriptions",
            "organizations_url": "https://api.github.com/users/liulhdarks/orgs",
            "repos_url": "https://api.github.com/users/liulhdarks/repos",
            "events_url": "https://api.github.com/users/liulhdarks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/liulhdarks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-26T10:58:36Z",
        "updated_at": "2022-06-28T17:38:02Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nError report when initializing a onnxruntime session in the GPU environment.\r\n```\r\n[2022-06-26 18:42:25] device: GPU\r\n[2022-06-26 18:42:25] use CUDAExecutionProvider\r\n[2022-06-26 18:42:26] Traceback (most recent call last):\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/./inferences/eas_service.py\", line 88, in <module>\r\n[2022-06-26 18:42:26]     server.init()\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/./inferences/eas_service.py\", line 58, in init\r\n[2022-06-26 18:42:26]     self.onnx_infer = Gpt2OnnxInference(model_root_path)\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/inferences/gpt2_onnx_inference.py\", line 78, in __init__\r\n[2022-06-26 18:42:26]     self.initialize()\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/inferences/gpt2_onnx_inference.py\", line 85, in initialize\r\n[2022-06-26 18:42:26]     self.ort_session = create_ort_session(os.path.join(self.model_root_path, \"gpt2_beam_search.onnx\"), True)\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/inferences/gpt2_onnx_inference.py\", line 52, in create_ort_session\r\n[2022-06-26 18:42:26]     ort_session = InferenceSession(model_path, sess_options, providers=execution_providers)\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/ENV/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 335, in __init__\r\n[2022-06-26 18:42:26]     self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n[2022-06-26 18:42:26]   File \"/home/admin/docker_ml/workspace/predictor/gpt2_completion_model_gpu_onnx_demo_v1/ENV/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 381, in _create_inference_session\r\n[2022-06-26 18:42:26]     sess.initialize_session(providers, provider_options, disabled_optimizers)\r\n[2022-06-26 18:42:26] RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:122 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:116 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] CUDA failure 3: initialization error ; GPU=-598013440 ; hostname=gpt2-completion-model-gpu-onnx-demo-v1-9c5b54d55-4bdnr ; expr=cudaSetDevice(info_.device_id); \r\n```\r\nCode\r\n```\r\ndef create_ort_session(model_path, use_gpu):\r\n    import onnxruntime\r\n    from onnxruntime import SessionOptions, InferenceSession, __version__ as ort_version, GraphOptimizationLevel, \\\r\n        get_available_providers\r\n\r\n    print(\"device:\", onnxruntime.get_device())\r\n    sess_options = SessionOptions()\r\n    sess_options.graph_optimization_level = GraphOptimizationLevel.ORT_DISABLE_ALL\r\n    execution_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if use_gpu else ['CPUExecutionProvider']\r\n    if use_gpu:\r\n        if 'CUDAExecutionProvider' not in get_available_providers():\r\n            raise RuntimeError(\"CUDAExecutionProvider is not avaiable for --use_gpu!\")\r\n        else:\r\n            print(\"use CUDAExecutionProvider\")\r\n\r\n    ort_session = InferenceSession(model_path, sess_options, providers=execution_providers)\r\n    return ort_session\r\n\r\nif __name__ == \"__main__\":\r\n   session = create_ort_session(\"....\", True)\r\n```\r\nIs there a problem with CUDA and cuDNN versions?\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux \r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: 3.9.4\r\n- CUDA version: 11.2\r\n- cuDNN version: v8.2.4.15\r\n- cudnn toolkit: 11.3\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11996/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11997",
        "id": 1285137333,
        "node_id": "I_kwDOCVq1mM5MmaO1",
        "number": 11997,
        "title": "The test time of sess.run does not match the time of profile",
        "user": {
            "login": "yeliang2258",
            "id": 30516196,
            "node_id": "MDQ6VXNlcjMwNTE2MTk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/30516196?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yeliang2258",
            "html_url": "https://github.com/yeliang2258",
            "followers_url": "https://api.github.com/users/yeliang2258/followers",
            "following_url": "https://api.github.com/users/yeliang2258/following{/other_user}",
            "gists_url": "https://api.github.com/users/yeliang2258/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yeliang2258/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yeliang2258/subscriptions",
            "organizations_url": "https://api.github.com/users/yeliang2258/orgs",
            "repos_url": "https://api.github.com/users/yeliang2258/repos",
            "events_url": "https://api.github.com/users/yeliang2258/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yeliang2258/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2185567573,
                "node_id": "MDU6TGFiZWwyMTg1NTY3NTcz",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/more%20info%20needed",
                "name": "more info needed",
                "color": "CFB717",
                "default": false,
                "description": "issues that cannot be triaged until more information is submitted by the original user"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-27T02:17:46Z",
        "updated_at": "2022-07-01T17:37:16Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\nI have a quantized model with Q and DQ, the time I test with sess.run and the time recorded by the profile do not match, it looks like the time tested by sess.run is wrong. But FP32 and test time and profile time seem to match.\r\nMy session time test method is:\r\n```\r\nfor i in range(100):\r\n    pred_onnx = sess.run(None, {input_name_1:data_1, input_name_2:data_2})[0]\r\nstart = time.time()\r\nfor i in range(1000):\r\n    pred_onnx = sess.run(None, {input_name_1:data_1, input_name_2:data_2})[0]\r\nend = time.time()\r\nper_time = (end - start) / 1000\r\n```\r\n\r\nMy test result is:\r\nFp32 model test time：3.63\r\nFP32 profile time：4.01\r\nINT8 model test time：0.88\r\nINT8 profile time：2.73\r\n\r\nI have tested several int8 models and all have this problem.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- ONNX Runtime installed from (source or binary): binary\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: python3.7\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11997/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11998",
        "id": 1285174582,
        "node_id": "I_kwDOCVq1mM5MmjU2",
        "number": 11998,
        "title": "build with cuda 11.0 /cudnn 8.0",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-27T03:18:19Z",
        "updated_at": "2022-06-27T06:27:13Z",
        "closed_at": "2022-06-27T06:27:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is. To avoid repetition please make sure this is not one of the known issues mentioned on the respective release page.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.6.0\r\n- Python version:\r\n- Visual Studio version (if applicable):vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.0/8.0\r\n- GPU model and memory:1060\r\n\r\ncommand:\r\n.\\build.bat --build_shared_lib --config Release   --use_cuda --cudnn_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\" --cuda_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\"   --cuda_version 11.0\r\nerror warings:\r\nonnxruntime\\gsl\\gsl-lite.hpp(2598): warning : calling a __host__ function from a __host__ __\r\ndevice__ function is not allowed\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11998/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11999",
        "id": 1285175311,
        "node_id": "I_kwDOCVq1mM5MmjgP",
        "number": 11999,
        "title": "build C#api with cuda 11.0 /cudnn 8.0",
        "user": {
            "login": "cqray1990",
            "id": 32585434,
            "node_id": "MDQ6VXNlcjMyNTg1NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/32585434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cqray1990",
            "html_url": "https://github.com/cqray1990",
            "followers_url": "https://api.github.com/users/cqray1990/followers",
            "following_url": "https://api.github.com/users/cqray1990/following{/other_user}",
            "gists_url": "https://api.github.com/users/cqray1990/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cqray1990/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cqray1990/subscriptions",
            "organizations_url": "https://api.github.com/users/cqray1990/orgs",
            "repos_url": "https://api.github.com/users/cqray1990/repos",
            "events_url": "https://api.github.com/users/cqray1990/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cqray1990/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-27T03:19:29Z",
        "updated_at": "2023-03-20T19:03:33Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.6.0\r\n- Python version:\r\n- Visual Studio version (if applicable):vs2019\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.0/8.0\r\n- GPU model and memory:1060\r\n\r\ncommand:\r\n.\\build.bat --build_shared_lib  --build_nuget --parallel  --use_cuda --cudnn_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\" --cuda_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\"   --cuda_version 11.0\r\n\r\n\r\n6: [----------] 1 test from TestSessionOptions (0 ms total)\r\n6:\r\n6: [----------] Global test environment tear-down\r\n6: [==========] 1 test from 1 test suite ran. (0 ms total)\r\n6: [  PASSED  ] 1 test.\r\n6/6 Test #6: onnxruntime_api_tests_without_env ......   Passed    0.03 sec\r\n\r\n100% tests passed, 0 tests failed out of 6\r\n\r\nTotal Test time (real) = 104.62 sec\r\n2022-05-27 10:13:39,129 util.run [DEBUG] - Subprocess completed. Return code: 0\r\n2022-05-27 10:13:39,129 util.run [INFO] - Running subprocess in 'C:\\pythonrun\\csharp'\r\n['dotnet', 'restore', 'OnnxRuntime.CSharp.sln', '--configfile', 'Nuget.CSharp.config']\r\n\r\nC:onnxruntime\\csharp\\OnnxRuntime.DesktopOnly.CSharp.sln.metaproj : error MSB4126: 指定的解决方案配置“Debug|x64”无效。请\r\n使用 Configuration 和 Platform 属性指定有效的解决方案配置(例如 MSBuild.exe Solution.sln /p:Configuration=Debug /p:Platform=\"Any CPU\")，或者将\r\n这些属性保留为空，以使用默认的解决方案配置。 [C:onnxruntime\\csharp\\OnnxRuntime.DesktopOnly.CSharp.sln]\r\n\r\nAfter build,i didn't find nuget files, there is not two nuget files, like Microsoft.ML.OnnxRuntime.Managed.1.6.0-dev-20210307-0735-9126faa35.nupkg and located at .\\build\\Windows\\Release\\Release\\nuget-artifacts\r\n\r\n  \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11999/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12000",
        "id": 1285678402,
        "node_id": "PR_kwDOCVq1mM46aN4A",
        "number": 12000,
        "title": "Add the possibility to quantize MatMul per-tensor when per_channel=True",
        "user": {
            "login": "regisss",
            "id": 15324346,
            "node_id": "MDQ6VXNlcjE1MzI0MzQ2",
            "avatar_url": "https://avatars.githubusercontent.com/u/15324346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/regisss",
            "html_url": "https://github.com/regisss",
            "followers_url": "https://api.github.com/users/regisss/followers",
            "following_url": "https://api.github.com/users/regisss/following{/other_user}",
            "gists_url": "https://api.github.com/users/regisss/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/regisss/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/regisss/subscriptions",
            "organizations_url": "https://api.github.com/users/regisss/orgs",
            "repos_url": "https://api.github.com/users/regisss/repos",
            "events_url": "https://api.github.com/users/regisss/events{/privacy}",
            "received_events_url": "https://api.github.com/users/regisss/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1607058914,
                "node_id": "MDU6TGFiZWwxNjA3MDU4OTE0",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/quantization",
                "name": "quantization",
                "color": "C2E0C6",
                "default": false,
                "description": "issues related to quantization"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 13,
        "created_at": "2022-06-27T11:42:25Z",
        "updated_at": "2022-08-19T23:23:27Z",
        "closed_at": null,
        "author_association": "FIRST_TIME_CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12000",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12000",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12000.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12000.patch",
            "merged_at": null
        },
        "body": "**Description**: When quantizing a model with `per_channel=True`, we should have the possibility to quantize linear layers in a `per_tensor` way as it does not make sense to quantize them per-feature. This PR adds this functionality to the `MatMul` operator: users just have to specify `extra_options[\"QDQOpTypePerChannelSupportToAxis\"][\"MatMul\"] = None` to quantize all layers per-channel except the linear ones.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? Linear layers are not independent across features. Thus, we should be able to quantize convolutional layers per channel and linear ones per tensor at the same time.\r\n- It fixes #10283 and #11890.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12000/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12002",
        "id": 1285879159,
        "node_id": "I_kwDOCVq1mM5MpPV3",
        "number": 12002,
        "title": "build for iOS error: ld: library not found for -latomic",
        "user": {
            "login": "JuntaoLiu01",
            "id": 28097118,
            "node_id": "MDQ6VXNlcjI4MDk3MTE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/28097118?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JuntaoLiu01",
            "html_url": "https://github.com/JuntaoLiu01",
            "followers_url": "https://api.github.com/users/JuntaoLiu01/followers",
            "following_url": "https://api.github.com/users/JuntaoLiu01/following{/other_user}",
            "gists_url": "https://api.github.com/users/JuntaoLiu01/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JuntaoLiu01/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JuntaoLiu01/subscriptions",
            "organizations_url": "https://api.github.com/users/JuntaoLiu01/orgs",
            "repos_url": "https://api.github.com/users/JuntaoLiu01/repos",
            "events_url": "https://api.github.com/users/JuntaoLiu01/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JuntaoLiu01/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-27T14:17:46Z",
        "updated_at": "2022-07-27T22:03:02Z",
        "closed_at": "2022-07-27T22:03:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nld: library not found for -latomic\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 11.6.2\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: 1.10.0\r\n- Python version: 3.8.12\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\ngit clone --depth=1 --branch v1.10.0 https://github.com.cnpmjs.org/microsoft/onnxruntime.git\r\n./build.sh --config MinSizeRel --use_xcode --ios --ios_sysroot iphoneos --osx_arch arm64 --apple_deploy_target 12.0\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12002/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12003",
        "id": 1286062250,
        "node_id": "I_kwDOCVq1mM5Mp8Cq",
        "number": 12003,
        "title": "Issue with NeMo MTEncDecModel model in ONNX IOBinding",
        "user": {
            "login": "evros-chris",
            "id": 37453466,
            "node_id": "MDQ6VXNlcjM3NDUzNDY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/37453466?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/evros-chris",
            "html_url": "https://github.com/evros-chris",
            "followers_url": "https://api.github.com/users/evros-chris/followers",
            "following_url": "https://api.github.com/users/evros-chris/following{/other_user}",
            "gists_url": "https://api.github.com/users/evros-chris/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/evros-chris/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/evros-chris/subscriptions",
            "organizations_url": "https://api.github.com/users/evros-chris/orgs",
            "repos_url": "https://api.github.com/users/evros-chris/repos",
            "events_url": "https://api.github.com/users/evros-chris/events{/privacy}",
            "received_events_url": "https://api.github.com/users/evros-chris/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2186357781,
                "node_id": "MDU6TGFiZWwyMTg2MzU3Nzgx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:CUDA",
                "name": "ep:CUDA",
                "color": "0052CC",
                "default": false,
                "description": "issues related to the CUDA execution provider"
            },
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2022-06-27T16:37:11Z",
        "updated_at": "2023-06-20T08:26:54Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nI face the following error when trying to export the [MTEncDecModel](https://github.com/NVIDIA/NeMo/blob/r1.2.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py) model to ONNX and bind inputs and outputs directly to a PyTorch tensor. I have raised this issue [here](https://github.com/NVIDIA/NeMo/issues/4339) in the NVIDA/NeMo github and I was recommended to fill an ORT issue for this.\r\n\r\n\r\n**System information**\r\n- Environment location: Docker on Kubernetes\r\n- Image: nvcr.io/nvidia/nemo: 1.6.1\r\n- Additionally install: pip install onnxruntime-gpu==1.11.1\r\n\r\n\r\n**To Reproduce**\r\nTo reproduce run the following code which is simple greedy search:\r\n```python\r\nimport torch\r\nimport numpy as np\r\nimport onnxruntime\r\nfrom nemo.collections.nlp.models import MTEncDecModel\r\n\r\n# load the model from pretrained\r\nmodel = MTEncDecModel.from_pretrained('nmt_en_de_transformer24x6')\r\n\r\n# export all model components to onnx:\r\nmodel.encoder.export('encoder.onnx')\r\nmodel.decoder.export('decoder.onnx')\r\nmodel.log_softmax.export('classifier.onnx')\r\n\r\n# initialise all the onnx sessions and bindings:\r\nencoder_session = onnxruntime.InferenceSession('encoder.onnx', providers=['CUDAExecutionProvider'])\r\ndecoder_session = onnxruntime.InferenceSession('decoder.onnx', providers=['CUDAExecutionProvider'])\r\nclassifier_session = onnxruntime.InferenceSession('classifier.onnx', providers=['CUDAExecutionProvider'])\r\n\r\nencoder_session_binding = encoder_session.io_binding()\r\ndecoder_session_binding = decoder_session.io_binding()\r\nclassifier_session_binding = classifier_session.io_binding()\r\n\r\n# preprocess the data using the original nemo model for simplicity:\r\nTEXT = ['good morning', 'hello world']\r\nsrc_ids, src_mask = model.prepare_inference_batch(TEXT)\r\n\r\n# bind encoder inputs and outputs to a PyTorch tensor\r\nsrc_ids_tensor, src_mask_tensor = src_ids.contiguous(), src_mask.contiguous()\r\n\r\nencoder_session_binding.bind_input(\r\n    name='input_ids',\r\n    device_type='cuda',\r\n    device_id=0,\r\n    element_type=np.int64,\r\n    shape=tuple(src_ids_tensor.shape),\r\n    buffer_ptr=src_ids_tensor.data_ptr(),\r\n)\r\nencoder_session_binding.bind_input(\r\n    name='encoder_mask',\r\n    device_type='cuda',\r\n    device_id=0,\r\n    element_type=np.int64,\r\n    shape=tuple(src_mask_tensor.shape),\r\n    buffer_ptr=src_mask_tensor.data_ptr(),\r\n)\r\n\r\nencoder_hidden_state_shape = (src_ids.shape[0], src_ids.shape[1], 1024)\r\nencoder_hidden_state = torch.empty(encoder_hidden_state_shape, dtype=torch.float32, device='cuda:0').contiguous()\r\nencoder_session_binding.bind_output(\r\n    name='last_hidden_states',\r\n    device_type='cuda',\r\n    device_id=0,\r\n    element_type=np.float32,\r\n    shape=tuple(encoder_hidden_state.shape),\r\n    buffer_ptr=encoder_hidden_state.data_ptr(),\r\n)\r\n\r\nencoder_session.run_with_iobinding(encoder_session_binding)\r\n\r\n# simple greedy search:\r\nMAX_GENERATION_DELTA = 5\r\nBOS = model.encoder_tokenizer.bos_id\r\nEOS = model.encoder_tokenizer.eos_id\r\nPAD = model.encoder_tokenizer.pad_id\r\n\r\ndef decode(tgt: torch.tensor, embeding: torch.tensor, src_mask: torch.tensor, decoder_hidden_state: torch.tensor) -> torch.tensor:\r\n    # bind decoder inputs and outputs to a PyTorch tensor\r\n    tgt_tensor = tgt.contiguous()\r\n    embeding_tensor = embeding.contiguous()\r\n    src_mask_tensor = src_mask.contiguous()\r\n    decoder_hidden_state_tensor = decoder_hidden_state.contiguous()\r\n    decoder_mask_tensor = (tgt != PAD).long().contiguous()\r\n    \r\n    decoder_session_binding.bind_input(\r\n        name='input_ids',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.int64,\r\n        shape=tuple(tgt_tensor.shape),\r\n        buffer_ptr=tgt_tensor.data_ptr(),\r\n    )\r\n\r\n    decoder_session_binding.bind_input(\r\n        name='decoder_mask',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.int64,\r\n        shape=tuple(decoder_mask_tensor.shape),\r\n        buffer_ptr=decoder_mask_tensor.data_ptr(),\r\n    )\r\n\r\n    decoder_session_binding.bind_input(\r\n        name='encoder_mask',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.int64,\r\n        shape=tuple(src_mask_tensor.shape),\r\n        buffer_ptr=src_mask_tensor.data_ptr(),\r\n    )\r\n\r\n    decoder_session_binding.bind_input(\r\n        name='encoder_embeddings',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.float32,\r\n        shape=tuple(embeding_tensor.shape),\r\n        buffer_ptr=embeding_tensor.data_ptr(),\r\n    )\r\n\r\n    decoder_hidden_state_ortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(decoder_hidden_state.cpu().numpy(), 'cuda', 0)\r\n    decoder_session_binding.bind_ortvalue_input('decoder_mems', decoder_hidden_state_ortvalue)\r\n    \r\n    decoder_hidden_state_shape = (embeding.shape[0], 8, decoder_hidden_state.shape[2]+1, 1024)\r\n    decoder_hidden_state_tensor = torch.empty(decoder_hidden_state_shape, dtype=torch.float32, device='cuda:0').contiguous()\r\n    decoder_session_binding.bind_output(\r\n        name='last_hidden_states',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.float32,\r\n        shape=tuple(decoder_hidden_state_tensor.shape),\r\n        buffer_ptr=decoder_hidden_state_tensor.data_ptr(),\r\n    )\r\n    decoder_session.run_with_iobinding(decoder_session_binding)\r\n\r\n    # bind classifier inputs and outputs to a PyTorch tensor\r\n    classifier_session_binding.bind_input(\r\n        name='hidden_states',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.int64,\r\n        shape=tuple(decoder_hidden_state[:,-1,-1:].shape),\r\n        buffer_ptr=decoder_hidden_state[:,-1,-1:].data_ptr(),\r\n    )\r\n    log_probs_shape = (embeding.shape[0], 1, 32000)\r\n    log_probs_tensor = torch.empty(log_probs_shape, dtype=torch.float32, device='cuda:0').contiguous()\r\n    classifier_session_binding.bind_output(\r\n        name='log_probs',\r\n        device_type='cuda',\r\n        device_id=0,\r\n        element_type=np.int64,\r\n        shape=tuple(log_probs_tensor.shape),\r\n        buffer_ptr=log_probs_tensor.data_ptr(),\r\n    )\r\n\r\n    classifier_session.run_with_iobinding(classifier_session_binding)\r\n\r\n    return log_probs_tensor, decoder_hidden_state_tensor\r\n\r\nmax_out_len = encoder_hidden_state.shape[1] + MAX_GENERATION_DELTA\r\ntgt=torch.full((encoder_hidden_state.shape[0], max_out_len), PAD)\r\ntgt[:, 0] = BOS\r\ndecoder_hidden_state = torch.ones(encoder_hidden_state.shape[0], 8, 0, encoder_hidden_state.shape[-1]).to(torch.float32)\r\n\r\nfor i in range(1, max_out_len):\r\n    log_probs, decoder_hidden_state = decode(tgt[:, :i], encoder_hidden_state, src_mask, decoder_hidden_state)\r\n    next_tokens = log_probs[:, -1].argmax(axis=1)\r\n    tgt[:, i] = next_tokens\r\n    if ((tgt == EOS).sum(axis=1) > 0).all():\r\n        break\r\n```\r\n\r\n**Error**\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_11932/3881801035.py in <module>\r\n      5 \r\n      6 for i in range(1, max_out_len):\r\n----> 7     log_probs, decoder_hidden_state = decode(tgt[:, :i], encoder_hidden_state, src_mask, decoder_hidden_state)\r\n      8     next_tokens = log_probs[:, -1].argmax(axis=1)\r\n      9     tgt[:, i] = next_tokens\r\n\r\n/tmp/ipykernel_11932/2200653428.py in decode(tgt, embeding, src_mask, decoder_hidden_state)\r\n     65         buffer_ptr=decoder_hidden_state_tensor.data_ptr(),\r\n     66     )\r\n---> 67     decoder_session.run_with_iobinding(decoder_session_binding)\r\n     68 \r\n     69     # bind classifier inputs and outputs to a PyTorch tensor\r\n\r\n/opt/conda/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py in run_with_iobinding(self, iobinding, run_options)\r\n    274          :param run_options: See :class:`onnxruntime.RunOptions`.\r\n    275         \"\"\"\r\n--> 276         self._sess.run_with_iobinding(iobinding._iobinding, run_options)\r\n    277 \r\n    278 \r\n\r\nRuntimeError: Error in execution: Non-zero status code returned while running MatMul node. Name:'MatMul_104' Status Message: CUBLAS error executing cublasGemmHelper( Base::CublasHandle(), transB, transA, static_cast<int>(helper.N()), static_cast<int>(helper.M()), static_cast<int>(helper.K()), &alpha, reinterpret_cast<const CudaT*>(right_X->template Data<T>()), ldb, reinterpret_cast<const CudaT*>(left_X->template Data<T>()), lda, &zero, reinterpret_cast<CudaT*>(Y->template MutableData<T>()), ldc, device_prop)\r\n```\r\n\r\n**Additional context**\r\nDecoder_mems are a concatenation of outputs of each attention block from the previous decode iteration. These are cached and returned to help speed up subsequent decode iterations. As the NVIDIA engineer said [here](https://github.com/NVIDIA/NeMo/issues/4339), NeMo uses kind of a trick to support effectively empty array with second last dim as 0. Trying to pass a continuous version of that array usually causes issues. That's way I used an `ortvalue` only to bind decoder_mems.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12003/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12004",
        "id": 1286134538,
        "node_id": "PR_kwDOCVq1mM46bu5n",
        "number": 12004,
        "title": "Eager mode: implement resize_ operation",
        "user": {
            "login": "jamill",
            "id": 2045976,
            "node_id": "MDQ6VXNlcjIwNDU5NzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2045976?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamill",
            "html_url": "https://github.com/jamill",
            "followers_url": "https://api.github.com/users/jamill/followers",
            "following_url": "https://api.github.com/users/jamill/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamill/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamill/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamill/subscriptions",
            "organizations_url": "https://api.github.com/users/jamill/orgs",
            "repos_url": "https://api.github.com/users/jamill/repos",
            "events_url": "https://api.github.com/users/jamill/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamill/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-27T17:35:06Z",
        "updated_at": "2022-07-01T02:14:38Z",
        "closed_at": "2022-07-01T02:14:38Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12004",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12004",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12004.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12004.patch",
            "merged_at": "2022-07-01T02:14:38Z"
        },
        "body": "**Description**: Implement the `resize_` operation for eager mode\r\n\r\nImplement the [resize_](https://pytorch.org/docs/stable/generated/torch.Tensor.resize_.html) operation.\r\n\r\nThis is the set of initial commits that implements part of the functionality to see\r\nif this is the right direction.\r\n\r\nThe native CPU implementation of `resize_` can be found at:\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Resize.cpp\r\n\r\n> Resizes self tensor to the specified size. If the number of elements is larger than the current storage size, then the underlying storage is resized to fit the new number of elements. If the number of elements is smaller, the underlying storage is not changed. Existing elements are preserved but any new memory is uninitialized.\r\n\r\nNote that this is different than [reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape), which returns a tensor with the same number of elements.\r\n\r\n**Motivation and Context**\r\nExpand eager mode support to include `resize_` [PyTorch function](https://pytorch.org/docs/stable/generated/torch.Tensor.resize_.html).  Resize functionality will be used as building blocks for future functionality, such as resizing output tensors for `out=` operations.\r\n\r\nAn example PyTorch script of the functionality this enables is:\r\n\r\n```py\r\nimport onnxruntime_pybind11_state as torch_ort\r\nimport torch\r\n\r\nort_tensor = torch.tensor([]).to(torch_ort.device())\r\nort_tensor.resize_(torch.Size([2,2]))\r\n```\r\n\r\nThe resize functionality will be the basis for supporting resizing the output tensor for `out=` style PyTorch functions in future commits.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12004/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12005",
        "id": 1286148660,
        "node_id": "PR_kwDOCVq1mM46bx0G",
        "number": 12005,
        "title": "[js/react_native] Upgrade react native packages to fix security vulnerabilities",
        "user": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-27T17:48:39Z",
        "updated_at": "2022-06-27T20:46:43Z",
        "closed_at": "2022-06-27T20:46:43Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12005",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12005",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12005.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12005.patch",
            "merged_at": null
        },
        "body": "Upgrades react and react-native packages to fix security vulnerabilities reported by dependabot.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12005/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12006",
        "id": 1286169299,
        "node_id": "PR_kwDOCVq1mM46b2Jc",
        "number": 12006,
        "title": "Fix WinML Tests are still targetting deprecated (deleted) experimental signal op definitions",
        "user": {
            "login": "smk2007",
            "id": 6754002,
            "node_id": "MDQ6VXNlcjY3NTQwMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6754002?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smk2007",
            "html_url": "https://github.com/smk2007",
            "followers_url": "https://api.github.com/users/smk2007/followers",
            "following_url": "https://api.github.com/users/smk2007/following{/other_user}",
            "gists_url": "https://api.github.com/users/smk2007/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smk2007/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smk2007/subscriptions",
            "organizations_url": "https://api.github.com/users/smk2007/orgs",
            "repos_url": "https://api.github.com/users/smk2007/repos",
            "events_url": "https://api.github.com/users/smk2007/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smk2007/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-27T18:09:00Z",
        "updated_at": "2022-07-06T16:55:13Z",
        "closed_at": "2022-06-27T23:35:51Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12006",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12006",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12006.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12006.patch",
            "merged_at": "2022-06-27T23:35:51Z"
        },
        "body": "Fix WinML Tests are still targetting deprecated (deleted) experimental signal op definitions\r\n\r\nIssue: Experimental signal ops were upstreamed to ONNX, and have been integrated into ORT. As a part of that integration, the old experimental ops have been deprecated.\r\n\r\nFix: Redirect the tests exercising the experimental ops to the newly integrated official ONNX signal ops (ie: opset 17, default domain).\r\n\r\nIn addition one test has been removed which the tested legacy signal op behavior of accepting shapes of rank 2, without a dimension for real/complex parts.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12006/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12007",
        "id": 1286314122,
        "node_id": "PR_kwDOCVq1mM46cVc6",
        "number": 12007,
        "title": "avoid duplicate input/output info in value info when serialize to graph proto",
        "user": {
            "login": "souptc",
            "id": 11306809,
            "node_id": "MDQ6VXNlcjExMzA2ODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/11306809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/souptc",
            "html_url": "https://github.com/souptc",
            "followers_url": "https://api.github.com/users/souptc/followers",
            "following_url": "https://api.github.com/users/souptc/following{/other_user}",
            "gists_url": "https://api.github.com/users/souptc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/souptc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/souptc/subscriptions",
            "organizations_url": "https://api.github.com/users/souptc/orgs",
            "repos_url": "https://api.github.com/users/souptc/repos",
            "events_url": "https://api.github.com/users/souptc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/souptc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-27T20:26:20Z",
        "updated_at": "2022-08-10T00:46:33Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12007",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12007",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12007.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12007.patch",
            "merged_at": null
        },
        "body": "**Description**: Avoid duplicate input/output info when serialize value info in graph proot.\r\n\r\n**Motivation and Context**\r\nfix issue #11921 \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12007/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12008",
        "id": 1286414218,
        "node_id": "PR_kwDOCVq1mM46csEu",
        "number": 12008,
        "title": "[C# Tests] Add support for double tensor output in TestPreTrainedModels.",
        "user": {
            "login": "edgchen1",
            "id": 18449977,
            "node_id": "MDQ6VXNlcjE4NDQ5OTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/18449977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/edgchen1",
            "html_url": "https://github.com/edgchen1",
            "followers_url": "https://api.github.com/users/edgchen1/followers",
            "following_url": "https://api.github.com/users/edgchen1/following{/other_user}",
            "gists_url": "https://api.github.com/users/edgchen1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/edgchen1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/edgchen1/subscriptions",
            "organizations_url": "https://api.github.com/users/edgchen1/orgs",
            "repos_url": "https://api.github.com/users/edgchen1/repos",
            "events_url": "https://api.github.com/users/edgchen1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/edgchen1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-27T21:25:43Z",
        "updated_at": "2022-07-06T16:54:33Z",
        "closed_at": "2022-06-28T01:49:20Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12008",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12008",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12008.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12008.patch",
            "merged_at": "2022-06-28T01:49:19Z"
        },
        "body": "**Description**\r\nAdd support for comparing double tensor output in TestPreTrainedModels.\r\n\r\n**Motivation and Context**\r\nFix some test failures for ONNX tests that have double tensor outputs.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12008/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12009",
        "id": 1286544402,
        "node_id": "I_kwDOCVq1mM5MrxwS",
        "number": 12009,
        "title": "onnxruntime and onnx protobuf version confliction",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4419012097,
                "node_id": "LA_kwDOCVq1mM8AAAABB2TGAQ",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/api",
                "name": "api",
                "color": "F9D0C4",
                "default": false,
                "description": "issues related to all other APIs: C, C++, Python, etc."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2022-06-27T23:06:47Z",
        "updated_at": "2023-03-29T18:00:49Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n\r\nWhen I pip install onnxruntime, it will upgrade protobuf. I can see errors like `onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 4.21.2 which is incompatible.`\r\n\r\nI think it is better to set onnxruntime 1.12 requires protobuf<=3.20.1,>=3.12.2 as well.\r\n\r\n**Urgency**\r\nIf there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\r\nnone\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- ONNX Runtime installed from (source or binary): source\r\n- ONNX Runtime version: \r\n- Python version: 3.8\r\n- Visual Studio version (if applicable):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior.\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation.\r\n```\r\n$ pip install /data/git/onnxruntime/build/master/Release/dist/onnxruntime_gpu-1.12.0-cp38-cp38-linux_x86_64.whl --force-reinstall\r\nProcessing /data/git/onnxruntime/build/master/Release/dist/onnxruntime_gpu-1.12.0-cp38-cp38-linux_x86_64.whl\r\nCollecting protobuf\r\n  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\r\n     |████████████████████████████████| 407 kB 12.1 MB/s\r\nCollecting coloredlogs\r\n  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\nCollecting packaging\r\n  Using cached packaging-21.3-py3-none-any.whl (40 kB)\r\nCollecting sympy\r\n  Using cached sympy-1.10.1-py3-none-any.whl (6.4 MB)\r\nCollecting numpy>=1.22.4\r\n  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n     |████████████████████████████████| 17.1 MB 123.3 MB/s\r\nCollecting flatbuffers\r\n  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\r\nCollecting humanfriendly>=9.1\r\n  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\nCollecting pyparsing!=3.0.5,>=2.0.2\r\n  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\r\nCollecting mpmath>=0.19\r\n  Using cached mpmath-1.2.1-py3-none-any.whl (532 kB)\r\nWARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\nInstalling collected packages: pyparsing, mpmath, humanfriendly, sympy, protobuf, packaging, numpy, flatbuffers, coloredlogs, onnxruntime-gpu\r\n  Attempting uninstall: pyparsing\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: pyparsing 3.0.9\r\n    Uninstalling pyparsing-3.0.9:\r\n      Successfully uninstalled pyparsing-3.0.9\r\n  Attempting uninstall: mpmath\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: mpmath 1.2.1\r\n    Uninstalling mpmath-1.2.1:\r\n      Successfully uninstalled mpmath-1.2.1\r\n  Attempting uninstall: humanfriendly\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: humanfriendly 10.0\r\n    Uninstalling humanfriendly-10.0:\r\n      Successfully uninstalled humanfriendly-10.0\r\n  Attempting uninstall: sympy\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: sympy 1.10.1\r\n    Uninstalling sympy-1.10.1:\r\n      Successfully uninstalled sympy-1.10.1\r\n  Attempting uninstall: protobuf\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: protobuf 3.19.0\r\n    Uninstalling protobuf-3.19.0:\r\n      Successfully uninstalled protobuf-3.19.0\r\n  Attempting uninstall: packaging\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: packaging 21.3\r\n    Uninstalling packaging-21.3:\r\n      Successfully uninstalled packaging-21.3\r\n  Attempting uninstall: numpy\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: numpy 1.23.0\r\n    Uninstalling numpy-1.23.0:\r\n      Successfully uninstalled numpy-1.23.0\r\n  Attempting uninstall: flatbuffers\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: flatbuffers 2.0\r\n    Uninstalling flatbuffers-2.0:\r\n      Successfully uninstalled flatbuffers-2.0\r\n  Attempting uninstall: coloredlogs\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: coloredlogs 15.0.1\r\n    Uninstalling coloredlogs-15.0.1:\r\n      Successfully uninstalled coloredlogs-15.0.1\r\n  Attempting uninstall: onnxruntime-gpu\r\n    WARNING: Ignoring invalid distribution -umpy (/disk/conda3/envs/py38/lib/python3.8/site-packages)\r\n    Found existing installation: onnxruntime-gpu 1.12.0\r\n    Uninstalling onnxruntime-gpu-1.12.0:\r\n      Successfully uninstalled onnxruntime-gpu-1.12.0\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nonnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 4.21.2 which is incompatible.\r\nSuccessfully installed coloredlogs-15.0.1 flatbuffers-2.0 humanfriendly-10.0 mpmath-1.2.1 numpy-1.23.0 onnxruntime-gpu-1.12.0 packaging-21.3 protobuf-4.21.2 pyparsing-3.0.9 sympy-1.10.1\r\n```\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12009/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12010",
        "id": 1286588327,
        "node_id": "PR_kwDOCVq1mM46dRv0",
        "number": 12010,
        "title": "DML EP ResNet50 opset 15 fails in ONNX checker for FusedBatchNormalization lacking training_mode attribute",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-28T00:04:45Z",
        "updated_at": "2022-07-06T16:54:26Z",
        "closed_at": "2022-06-28T02:41:34Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12010",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12010",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12010.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12010.patch",
            "merged_at": "2022-06-28T02:41:34Z"
        },
        "body": "**Description**: ResNet 50 fails to execute with opset 15 (opset 12 works fine) via the DML EP because the ONNX checker/validator code sees an unrecognized \"training_mode\" attribute. The fusion code unifies BatchNorm + Relu and copies the attributes, including new default values for attributes that aren't even in the model (you won't find \"training_mode\" in the file). This just adds that attribute to `FusedBatchNormalization` under `com.microsoft.dml` (and so shouldn't affect other EP's).\r\n\r\n**Motivation and Context**\r\n- *Why is this change required? What problem does it solve?*  A popular model fails.\r\n- *If it fixes an open issue, please link to the issue here.* NA",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12010/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12011",
        "id": 1286638193,
        "node_id": "I_kwDOCVq1mM5MsIpx",
        "number": 12011,
        "title": "how to build onnxruntime from source with dnnl? ",
        "user": {
            "login": "wangyunxiaa",
            "id": 41035013,
            "node_id": "MDQ6VXNlcjQxMDM1MDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/41035013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyunxiaa",
            "html_url": "https://github.com/wangyunxiaa",
            "followers_url": "https://api.github.com/users/wangyunxiaa/followers",
            "following_url": "https://api.github.com/users/wangyunxiaa/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyunxiaa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyunxiaa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyunxiaa/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyunxiaa/orgs",
            "repos_url": "https://api.github.com/users/wangyunxiaa/repos",
            "events_url": "https://api.github.com/users/wangyunxiaa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyunxiaa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 1630303001,
                "node_id": "MDU6TGFiZWwxNjMwMzAzMDAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/ep:oneDNN",
                "name": "ep:oneDNN",
                "color": "0052CC",
                "default": false,
                "description": "questions/issues related to DNNL EP"
            },
            {
                "id": 2159809301,
                "node_id": "MDU6TGFiZWwyMTU5ODA5MzAx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/build",
                "name": "build",
                "color": "D93F0B",
                "default": false,
                "description": "build issues; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-06-28T01:26:59Z",
        "updated_at": "2022-07-15T01:17:46Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "when I build onnxruntime with commond ./build.sh --config=MinSizeRel --minimal_build --build_shared_lib --use_dnnl --skip_tests --parallel, I got error The dependency target \"onnxruntime_providers_shared\" of target \"onnxruntime_providers_dnnl\" does not exist\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Centos\r\n- ONNX Runtime installed from (source or binary):source\r\n- ONNX Runtime version:1.11.0\r\n- Python version:3.8.5\r\n- Visual Studio version (if applicable):NO\r\n- GCC/Compiler version (if compiling from source):9.3.0\r\n- CUDA/cuDNN version:No\r\n- GPU model and memory:No",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12011/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12013",
        "id": 1286709565,
        "node_id": "PR_kwDOCVq1mM46dq0P",
        "number": 12013,
        "title": "[java] First part of the JNI error handling rewrite",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 18,
        "created_at": "2022-06-28T03:20:01Z",
        "updated_at": "2022-07-12T22:30:08Z",
        "closed_at": "2022-07-12T22:16:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12013",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12013",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12013.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12013.patch",
            "merged_at": "2022-07-12T22:16:55Z"
        },
        "body": "**Description**: This fixes error handling in the JNI code in OnnxMap, OnnxSequence, OnnxRuntime, RunOptions. SessionOptions and OrtEnvironment are correct as is.\r\n\r\nThe bulk of the work will be in rewriting OnnxTensor, OnnxSparseTensor (after the merge of #10653) and OrtSession, along with the helper methods in OrtJniUtil. I plan to tackle those in separate PRs to reduce the amount of code to review.\r\n\r\n**Motivation and Context**\r\n- Why is this change required? What problem does it solve? The current native interop code doesn't return control to Java immediately on throwing an exception from an ORT error code, which can cause incorrect interactions with native ORT, and issues with exception propagation on the Java side.\r\n- If it fixes an open issue, please link to the issue here. Partial work towards solving #11451.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12013/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12014",
        "id": 1286711867,
        "node_id": "I_kwDOCVq1mM5Msao7",
        "number": 12014,
        "title": "FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory",
        "user": {
            "login": "thapgan",
            "id": 12047186,
            "node_id": "MDQ6VXNlcjEyMDQ3MTg2",
            "avatar_url": "https://avatars.githubusercontent.com/u/12047186?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thapgan",
            "html_url": "https://github.com/thapgan",
            "followers_url": "https://api.github.com/users/thapgan/followers",
            "following_url": "https://api.github.com/users/thapgan/following{/other_user}",
            "gists_url": "https://api.github.com/users/thapgan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thapgan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thapgan/subscriptions",
            "organizations_url": "https://api.github.com/users/thapgan/orgs",
            "repos_url": "https://api.github.com/users/thapgan/repos",
            "events_url": "https://api.github.com/users/thapgan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thapgan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2286118846,
                "node_id": "MDU6TGFiZWwyMjg2MTE4ODQ2",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/stale",
                "name": "stale",
                "color": "C5DEF5",
                "default": false,
                "description": "issues that have not been addressed in a while; categorized by a bot"
            },
            {
                "id": 3066979818,
                "node_id": "MDU6TGFiZWwzMDY2OTc5ODE4",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/platform:web",
                "name": "platform:web",
                "color": "FEF2C0",
                "default": false,
                "description": "issues related to ONNX Runtime web; typically submitted using template"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2022-06-28T03:23:43Z",
        "updated_at": "2023-02-13T19:19:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I try to build onnxruntime for web. I'm stuck on Heap Memory problem.\r\n\r\nEnv:\r\nNode: 16.15.1\r\nPython: 3.10.5\r\nRAM: 16GB\r\n![heap error](https://user-images.githubusercontent.com/12047186/176085194-df4cc215-7686-4875-83e8-8e0391a02bef.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12014/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12015",
        "id": 1287022262,
        "node_id": "I_kwDOCVq1mM5Mtma2",
        "number": 12015,
        "title": "Update the ROIAlign op to the current ONNX spec",
        "user": {
            "login": "samurdhikaru",
            "id": 97725867,
            "node_id": "U_kgDOBdMtqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97725867?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/samurdhikaru",
            "html_url": "https://github.com/samurdhikaru",
            "followers_url": "https://api.github.com/users/samurdhikaru/followers",
            "following_url": "https://api.github.com/users/samurdhikaru/following{/other_user}",
            "gists_url": "https://api.github.com/users/samurdhikaru/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/samurdhikaru/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/samurdhikaru/subscriptions",
            "organizations_url": "https://api.github.com/users/samurdhikaru/orgs",
            "repos_url": "https://api.github.com/users/samurdhikaru/repos",
            "events_url": "https://api.github.com/users/samurdhikaru/events{/privacy}",
            "received_events_url": "https://api.github.com/users/samurdhikaru/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-28T08:59:37Z",
        "updated_at": "2022-07-01T02:11:47Z",
        "closed_at": "2022-07-01T02:11:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe ROIAlign op in ONNX Runtime seems to be still compliant to the older [RoiAlign-10](https://github.com/onnx/onnx/blob/main/docs/Changelog.md#RoiAlign-10) ONNX spec. It would be really helpful if this is updated to conform to the [newer ROIAlign spec](https://github.com/onnx/onnx/blob/main/docs/Operators.md#RoiAlign).\r\n\r\nThe difference between the two versions is that there is an additional attribute in the newer spec called `coordinate_transformation_mode` which allows for the input coordinate shift behavior to be user-configured. This is somewhat frustrating because the current ONNX Runtime implementation [chooses NOT to do half-pixel alignment,](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/core/providers/cuda/object_detection/roialign_impl.cu#L109) which is the non-default behavior according to the newer spec. So there doesn't seem to be a straightforward way to emulate the default behavior of the current ROIAlign spec on ONNX Runtime.\r\n\r\n**System information**\r\n- ONNX Runtime v1.11.1 \r\n\r\n**Describe the solution you'd like**\r\nIt seems that bringing the ROIAlign op to be conformant to the new spec is quite straightforward: there is a boolean `continuous_coordinate` which is [hard-coded to be `false`](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/core/providers/cuda/object_detection/roialign_impl.cu#L109); this could be set to a user-provided boolean attribute instead.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12015/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12016",
        "id": 1287197334,
        "node_id": "PR_kwDOCVq1mM46fReC",
        "number": 12016,
        "title": "Add targets files for new .net6 frameworks",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-28T11:25:41Z",
        "updated_at": "2022-07-06T16:51:37Z",
        "closed_at": "2022-07-01T16:13:55Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12016",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12016",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12016.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12016.patch",
            "merged_at": "2022-07-01T16:13:55Z"
        },
        "body": "**Description**: \r\nAdd targets file for .net 6 frameworks so the native library can be correctly found.\r\n\r\nRemove net6.0-maccatalyst for now - may require different build of native library to work\r\n\r\n**Motivation and Context**\r\nFix issue with .net6 usage.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12016/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12017",
        "id": 1287272478,
        "node_id": "I_kwDOCVq1mM5Mujge",
        "number": 12017,
        "title": "create op ",
        "user": {
            "login": "zyxcambridge",
            "id": 1818981,
            "node_id": "MDQ6VXNlcjE4MTg5ODE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1818981?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zyxcambridge",
            "html_url": "https://github.com/zyxcambridge",
            "followers_url": "https://api.github.com/users/zyxcambridge/followers",
            "following_url": "https://api.github.com/users/zyxcambridge/following{/other_user}",
            "gists_url": "https://api.github.com/users/zyxcambridge/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zyxcambridge/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zyxcambridge/subscriptions",
            "organizations_url": "https://api.github.com/users/zyxcambridge/orgs",
            "repos_url": "https://api.github.com/users/zyxcambridge/repos",
            "events_url": "https://api.github.com/users/zyxcambridge/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zyxcambridge/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2022-06-28T12:30:50Z",
        "updated_at": "2022-06-28T22:23:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "/home/zyx/Desktop/pointpillars_pytorch_trt/pytorch/tools/onnxruntime/onnxruntime/contrib_ops/cuda/cuda_voxel_generator.cu(299): error: explicit stream argument not provided in kernel launch\r\n\r\n/home/zyx/Desktop/pointpillars_pytorch_trt/pytorch/tools/onnxruntime/onnxruntime/contrib_ops/cuda/cuda_voxel_generator.cu(317): error: explicit stream argument not provided in kernel launch\r\n\r\n2 errors detected in the compilation of \"/home/zyx/Desktop/pointpillars_pytorch_trt/pytorch/tools/onnxruntime/onnxruntime/contrib_ops/cuda/cuda_voxel_generator.cu\".\r\nCMakeFiles/onnxruntime_providers_cuda.dir/build.make:2427: recipe for target 'CMakeFiles/onnxruntime_providers_cuda.dir/home/zyx/Desktop/pointpillars_pytorch_trt/pytorch/tools/onnxruntime/onnxruntime/contrib_ops/cuda/cuda_voxel_generator.cu.o' failed\r\nmake[2]: *** [CMakeFiles/onnxruntime_providers_cuda.dir/home/zyx/Desktop/pointpillars_pytorch_trt/pytorch/tools/onnxruntime/onnxruntime/contrib_ops/cuda/cuda_voxel_generator.cu.o] Error 1\r\nCMakeFiles/Makefile2:1808: recipe for target 'CMakeFiles/onnxruntime_providers_cuda.dir/all' failed\r\nmake[1]: *** [CMakeFiles/onnxruntime_providers_cuda.dir/all] Error 2\r\nMakefile:165: recipe for target 'all' failed\r\n\r\n\r\n\r\n#include <torch/serialize/tensor.h>\r\n#include <vector>\r\n#include <cuda.h>\r\n#include <cuda_runtime_api.h>\r\n#include <iostream>\r\n#include \"voxel_generator.h\"\r\n\r\n#include \"core/providers/cuda/cuda_kernel.h\"\r\n#include \"core/providers/cuda/math/unary_elementwise_ops_impl.h\"\r\n#include \"core/providers/cuda/cuda_common.h\"\r\n#include \"core/providers/cuda/cuda_execution_provider.h\"\r\n#include \"contrib_ops/cuda/transformers/beam_search.h\"\r\n#include \"contrib_ops/cuda/transformers/beam_search_device_helper.h\"\r\n#include \"contrib_ops/cuda/transformers/dump_cuda_tensor.h\"\r\nusing namespace std;\r\n\r\n\r\nnamespace onnxruntime {\r\nnamespace contrib {\r\nnamespace cuda {\r\n\r\n\r\nclass VoxelGeneratorV1 final : public OpKernel {\r\n public:\r\n  explicit VoxelGeneratorV1(const OpKernelInfo& info) : OpKernel(info) {}\r\n  Status Compute(OpKernelContext* ctx) const override;\r\n  \r\n private:\r\n  using Base = CudaKernel;\r\n  using CublasHandle = cublasHandle_t;\r\n\r\n  template <typename T>\r\n//  struct ComputeImpl;\r\n};\r\n\r\nONNX_OPERATOR_KERNEL_EX(\r\n    VoxelGeneratorV1,\r\n    kMSDomain,\r\n    1,\r\n    kCpuExecutionProvider,\r\n    KernelDefBuilder()\r\n        .InputMemoryType(OrtMemTypeCPUInput, 0)    // 'points' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 1)    // 'ValidInput' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 2)    // 'voxel_size' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 3)    // 'point_cloud_range' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 4)    // 'max_num_points' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 5)    // 'max_voxels' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 6)    // 'batch_size' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 7)    // 'center_offset' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 8)    // 'cluster_offset' needs to be on CPU\r\n        .InputMemoryType(OrtMemTypeCPUInput, 9)\r\n        .TypeConstraint(\"T\", BuildKernelDefConstraints<float, double, MLFloat16>()),\r\n    VoxelGeneratorV1);\r\n\r\nstd::vector<torch::Tensor>\r\nVoxelGeneratorV1(torch::Tensor points, torch::Tensor ValidInput, std::vector<float> voxel_size,\r\n                 std::vector<float> point_cloud_range, int max_num_points, int max_voxels, int batch_size,\r\n                 int center_offset, int cluster_offset, int supplement)\r\n{\r\n  CHECK_INPUT(points);\r\n  CHECK_INPUT(ValidInput);\r\n  auto inputType = points.scalar_type();\r\n\r\n  int inCols = points.size(1);\r\n  int num_features = inCols;\r\n  int outCols = num_features;\r\n  if(cluster_offset !=0) outCols += 3;\r\n  if(center_offset !=0) outCols += 3;\r\n  int N = points.size(0);\r\n\r\n  const int NDim = 3;\r\n  std::vector<int> grid_size(3);\r\n  for (int i = 0; i < NDim; ++i) {\r\n    grid_size[i] =\r\n        round((point_cloud_range[NDim + i] - point_cloud_range[i]) / voxel_size[i]);\r\n  }\r\n\r\n  int cuda_idx = points.device().index();\r\n  auto options = torch::TensorOptions({at::kCUDA, cuda_idx}).dtype(torch::kInt32);\r\n\r\n  torch::Tensor voxels = torch::zeros({max_voxels * batch_size, max_num_points, outCols}, torch::dtype(inputType).device(points.device())); //init 0\r\n  torch::Tensor coors = torch::zeros({max_voxels * batch_size, 3}, options) - 1;  //init -1\r\n  torch::Tensor num_points_per_voxel = torch::zeros({max_voxels * batch_size, }, options); //init 0\r\n  torch::Tensor ValidOutput = torch::zeros({batch_size, }, options); //init 0\r\n\r\n  float bev_map = (float)(grid_size[0] * grid_size[1] * sizeof(float)) / 1024 / 1024;\r\n  int value_map_z = 40.0 / bev_map;//限制映射图的尺寸，超过40M只用一层\r\n\r\n  value_map_z = std::max(value_map_z, 1);\r\n  value_map_z = std::min(value_map_z, grid_size[2]);\r\n  int mapsize = grid_size[0] * grid_size[1] * value_map_z;\r\n\r\n  torch::Tensor map_tensor  = torch::zeros({batch_size, mapsize}, options) - 1;\r\n  int* map_tensor_rw = map_tensor.data_ptr<int>();\r\n\r\n  torch::Tensor addr_tensor  = torch::zeros({batch_size*max_voxels, }, options) - 1;\r\n  int* addr_tensor_rw = addr_tensor.data_ptr<int>();\r\n\r\n  const int listBytes = N * sizeof(VoxelGeneratorSpace::HashEntry);\r\n  torch::Tensor list_tensor = torch::zeros({listBytes / 4, }, options);\r\n  VoxelGeneratorSpace::HashEntry* list_tensor_rw = reinterpret_cast<VoxelGeneratorSpace::HashEntry*>(list_tensor.data_ptr<int>());\r\n\r\n  const int *ValidInput_ptr = ValidInput.data_ptr<int>();\r\n  int *coors_ptr = coors.data_ptr<int>();\r\n  int *num_points_per_voxel_ptr = num_points_per_voxel.data_ptr<int>();\r\n  int *ValidOutput_ptr = ValidOutput.data_ptr<int>();\r\n\r\n\r\n  if(inputType == torch::kFloat32)\r\n  {\r\n    const float *points_ptr = points.data_ptr<float>();\r\n    float *voxels_ptr = voxels.data_ptr<float>();\r\n\r\n    VoxelGeneratorSpace::cuda_points_to_voxel(points_ptr, ValidInput_ptr,\r\n                                              coors_ptr, num_points_per_voxel_ptr, voxels_ptr, ValidOutput_ptr,\r\n                                              map_tensor_rw, addr_tensor_rw, list_tensor_rw,\r\n                                              point_cloud_range, voxel_size, grid_size,\r\n                                              batch_size, N, inCols, outCols,\r\n                                              cluster_offset, center_offset, supplement, max_voxels, max_num_points, value_map_z);\r\n  }\r\n  else if(inputType == torch::kHalf)\r\n  {\r\n    const __half *points_ptr = reinterpret_cast<__half*>(points.data_ptr<at::Half>());\r\n    __half *voxels_ptr   = reinterpret_cast<__half*>(voxels.data_ptr<at::Half>());\r\n\r\n    VoxelGeneratorSpace::cuda_points_to_voxel_fp16(points_ptr, ValidInput_ptr,\r\n                                                   coors_ptr, num_points_per_voxel_ptr, voxels_ptr, ValidOutput_ptr,\r\n                                                   map_tensor_rw, addr_tensor_rw, list_tensor_rw,\r\n                                                   point_cloud_range, voxel_size, grid_size,\r\n                                                   batch_size, N, inCols, outCols,\r\n                                                   cluster_offset, center_offset, supplement, max_voxels, max_num_points, value_map_z);\r\n  }\r\n  else\r\n  {\r\n    cout<< \"error inputs type in VoxelGeneratorV1: \" << inputType << endl;\r\n  }\r\n\r\n  return {voxels.contiguous(), coors.contiguous(), ValidOutput.contiguous(), num_points_per_voxel};\r\n}\r\n\r\n\r\nStatus VoxelGeneratorV1::Compute(OpKernelContext* ctx) const {\r\n  //\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 0)    // 'points' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 1)    // 'ValidInput' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 2)    // 'voxel_size' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 3)    // 'point_cloud_range' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 4)    // 'max_num_points' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 5)    // 'max_voxels' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 6)    // 'batch_size' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 7)    // 'center_offset' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 8)    // 'cluster_offset' needs to be on CPU\r\n//  .InputMemoryType(OrtMemTypeCPUInput, 9)    // 'supplement' needs to be on CPUstd::vector<float> voxel_size,\r\n// std::vector<float> point_cloud_range, int max_num_points, int max_voxels, int batch_size,\r\n// int center_offset, int cluster_offset, int supplement\r\n\r\n  torch::Tensor points = context->Input<Tensor>(0);\r\n  torch::Tensor ValidInput = context->Input<Tensor>(1);\r\n  std::vector<float> voxel_size = context->Input<Tensor>(2);\r\n  std::vector<float> point_cloud_range = context->Input<Tensor>(3);\r\n  int max_num_points = context->Input<Tensor>(4);\r\n  int max_voxels = context->Input<Tensor>(5);\r\n  int batch_size = context->Input<Tensor>(6);\r\n  int center_offset = context->Input<Tensor>(7);\r\n  int cluster_offset = context->Input<Tensor>(8);\r\n  int supplement = context->Input<Tensor>(9);\r\n  VoxelGeneratorV1(points,ValidInput,point_cloud_range,max_num_points,\r\n                   max_voxels,batch_size,center_offset,cluster_offset,supplement);\r\n\r\n  return Status::OK();\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n}  // namespace cuda\r\n}  // namespace contrib\r\n}  // namespace onnxruntime\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12017/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12018",
        "id": 1287664047,
        "node_id": "PR_kwDOCVq1mM46g1_s",
        "number": 12018,
        "title": "Update create_ort_attribute to set the tensor dimension and value correctly.",
        "user": {
            "login": "WilBrady",
            "id": 25513670,
            "node_id": "MDQ6VXNlcjI1NTEzNjcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/25513670?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilBrady",
            "html_url": "https://github.com/WilBrady",
            "followers_url": "https://api.github.com/users/WilBrady/followers",
            "following_url": "https://api.github.com/users/WilBrady/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilBrady/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilBrady/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilBrady/subscriptions",
            "organizations_url": "https://api.github.com/users/WilBrady/orgs",
            "repos_url": "https://api.github.com/users/WilBrady/repos",
            "events_url": "https://api.github.com/users/WilBrady/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilBrady/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-28T17:23:56Z",
        "updated_at": "2022-07-11T15:18:05Z",
        "closed_at": "2022-07-11T15:18:04Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12018",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12018",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12018.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12018.patch",
            "merged_at": "2022-07-11T15:18:04Z"
        },
        "body": "**Description**: Eager support for fill_ and update create_ort_attribute to set the tensor dimension and value correctly. \r\n\r\n**Motivation and Context**\r\nWhile testing new aten to onnx operation mappings for eager mode fill_, I discovered attribute creation was setting float for all values and not updating the tensor dimension after clearing it out. fill_ needs the dimension and type set correctly.\r\n\r\nAlso, i updated the mapping of `mm` to `mm.out` as `mm` uses `mm.out` on the aten side, so by mapping `mm.out` we get support for both.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12018/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12019",
        "id": 1287698586,
        "node_id": "I_kwDOCVq1mM5MwLia",
        "number": 12019,
        "title": "Resize with mode linear is missing output elements",
        "user": {
            "login": "diyessi",
            "id": 8300383,
            "node_id": "MDQ6VXNlcjgzMDAzODM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8300383?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diyessi",
            "html_url": "https://github.com/diyessi",
            "followers_url": "https://api.github.com/users/diyessi/followers",
            "following_url": "https://api.github.com/users/diyessi/following{/other_user}",
            "gists_url": "https://api.github.com/users/diyessi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diyessi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diyessi/subscriptions",
            "organizations_url": "https://api.github.com/users/diyessi/orgs",
            "repos_url": "https://api.github.com/users/diyessi/repos",
            "events_url": "https://api.github.com/users/diyessi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diyessi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 2014185961,
                "node_id": "MDU6TGFiZWwyMDE0MTg1OTYx",
                "url": "https://api.github.com/repos/microsoft/onnxruntime/labels/core%20runtime",
                "name": "core runtime",
                "color": "006B75",
                "default": false,
                "description": "issues related to core runtime"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2022-06-28T17:57:48Z",
        "updated_at": "2023-04-24T22:18:21Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\n`Resize` with `mode=\"linear\"` and a specified output shape has garbage in the last output tensor elements. I see this for multiple coordinate transformation modes and input and output shapes. For a trivial example, with an input size of `[1,1,1,1]` on a float input tensor whose single element is 1.0, resizing to `[1, 2, 2, 1]` I get output\r\n```\r\n[[[[[ 1.]\r\n    [ 1.]]\r\n\r\n   [[ 5.]\r\n    [10.]]]]]\r\n```\r\nwhere the `[5, 10]` is wrong. I am running a number of these tests, using `i^2+1` as inputs, so these particular outputs seem likely to be uninitialized memory from earlier inputs. I also see bunches of NaNs in the bad elements.\r\n\r\n**Urgency**\r\nNone\r\n\r\n**System information**\r\n- Ubuntu 20.04.4 LTS (GNU/Linux 5.11.0-1028-azure x86_64)\r\n- ONNX Runtime installed from binary (pip onnxruntime          1.11.1)\r\n- ONNX Runtime version: 1.11.1\r\n- Python version: 3.8.10\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**To Reproduce**\r\nI can give you a branch of a simple repo if you need one.\r\n\r\n**Expected behavior**\r\nIn this case, all elements should be 1.\r\n\r\n**Additional context**\r\n`nearest` mode doesn't seem to have any problems. I was actually trying to use ONNX Runtime to generate gold values for testing my own implementation for an accelerator and for creating a doc PR for the ONNX specification.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12019/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020/events",
        "html_url": "https://github.com/microsoft/onnxruntime/pull/12020",
        "id": 1287706286,
        "node_id": "PR_kwDOCVq1mM46g_A4",
        "number": 12020,
        "title": "Add eager support for aten:: equal.",
        "user": {
            "login": "WilBrady",
            "id": 25513670,
            "node_id": "MDQ6VXNlcjI1NTEzNjcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/25513670?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WilBrady",
            "html_url": "https://github.com/WilBrady",
            "followers_url": "https://api.github.com/users/WilBrady/followers",
            "following_url": "https://api.github.com/users/WilBrady/following{/other_user}",
            "gists_url": "https://api.github.com/users/WilBrady/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WilBrady/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WilBrady/subscriptions",
            "organizations_url": "https://api.github.com/users/WilBrady/orgs",
            "repos_url": "https://api.github.com/users/WilBrady/repos",
            "events_url": "https://api.github.com/users/WilBrady/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WilBrady/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-28T18:06:11Z",
        "updated_at": "2022-07-14T14:23:30Z",
        "closed_at": "2022-06-30T19:46:15Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/pulls/12020",
            "html_url": "https://github.com/microsoft/onnxruntime/pull/12020",
            "diff_url": "https://github.com/microsoft/onnxruntime/pull/12020.diff",
            "patch_url": "https://github.com/microsoft/onnxruntime/pull/12020.patch",
            "merged_at": "2022-06-30T19:46:15Z"
        },
        "body": "**Description**: Extend eager mode support to include aten::equal.\r\n\r\n**Motivation and Context**\r\nExtend eager mode support.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12020/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12021",
        "id": 1287706939,
        "node_id": "I_kwDOCVq1mM5MwNk7",
        "number": 12021,
        "title": "Nullptr returned by OrtGetApiBase()->GetApi(ORT_API_VERSION)",
        "user": {
            "login": "janhuang6",
            "id": 35048993,
            "node_id": "MDQ6VXNlcjM1MDQ4OTkz",
            "avatar_url": "https://avatars.githubusercontent.com/u/35048993?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/janhuang6",
            "html_url": "https://github.com/janhuang6",
            "followers_url": "https://api.github.com/users/janhuang6/followers",
            "following_url": "https://api.github.com/users/janhuang6/following{/other_user}",
            "gists_url": "https://api.github.com/users/janhuang6/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/janhuang6/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/janhuang6/subscriptions",
            "organizations_url": "https://api.github.com/users/janhuang6/orgs",
            "repos_url": "https://api.github.com/users/janhuang6/repos",
            "events_url": "https://api.github.com/users/janhuang6/events{/privacy}",
            "received_events_url": "https://api.github.com/users/janhuang6/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2022-06-28T18:06:57Z",
        "updated_at": "2022-11-27T07:00:05Z",
        "closed_at": "2022-06-30T16:34:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**Describe the bug**\r\nUsing visual studio C++ on windows calling onnxruntime, the Global api_ pointer in onnxruntime_cxx_api.h is always Nullptr. And my program crashed immediately after it started.\r\n\r\n**Urgency**\r\nUrgent!! This is blocking my project that is due by end of June 2022.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 11\r\n- ONNX Runtime installed from (source or binary): binary. Installed by this command \"Install-Package Microsoft.ML.OnnxRuntime.Gpu -Version 1.11.0\".\r\n- ONNX Runtime version: 1.11.0\r\n- Python version: Using C++ (no Python involved)\r\n- Visual Studio version: Microsoft Visual Studio Community 2022 (64-bit) - Version 17.1.3\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: Program crashed before CUDA/cuDNN is used.\r\n- GPU model and memory: Program crashed before GPU is used.\r\n\r\n**To Reproduce**\r\n- Describe steps/code to reproduce the behavior: I downloaded and installed onnxruntime pre-build library on windows using this command \"Install-Package Microsoft.ML.OnnxRuntime.Gpu -Version 1.11.0\". Then build my project by linking with onnxruntime library. That was ok. But runs crashing because it could not Ort::InitApi() due to Nullptr Ort::Global::api_\r\n\r\n- Attach the ONNX model to the issue (where applicable) to expedite investigation. Onnxruntime could not be properly initiated, crashing upon calling Ort::InitApp(). So the issue is independent of ONNX model.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen: Expect this global variable Ort::Global::api_ is properly set by onnxruntime on windows, visual studio environment.\r\n\r\n**Screenshots**\r\nYes screenshot is attached.\r\n\r\n**Additional context**\r\nThis issue is wasting a lot of developer's time. Tried different user's applications, the same problem. I also attach one of the many applications that encountered the problem. Please let me know where the problem is. Thank you!\r\n\r\n![image](https://user-images.githubusercontent.com/35048993/176249572-d48a05fc-1be2-4137-a4d7-74b6de31ccbe.png)\r\n\r\n```\r\n\r\n#include <onnxruntime_cxx_api.h>\r\n\r\n#include <opencv2/dnn/dnn.hpp>\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <opencv2/imgproc.hpp>\r\n\r\n#include <chrono>\r\n#include <cmath>\r\n#include <exception>\r\n#include <fstream>\r\n#include <iostream>\r\n#include <limits>\r\n#include <numeric>\r\n#include <string>\r\n#include <vector>\r\n\r\ntemplate <typename T>\r\nT vectorProduct(const std::vector<T>& v)\r\n{\r\n    return accumulate(v.begin(), v.end(), 1, std::multiplies<T>());\r\n}\r\n\r\n/**\r\n * @brief Operator overloading for printing vectors\r\n * @tparam T\r\n * @param os\r\n * @param v\r\n * @return std::ostream&\r\n */\r\ntemplate <typename T>\r\nstd::ostream& operator<<(std::ostream& os, const std::vector<T>& v)\r\n{\r\n    os << \"[\";\r\n    for (int i = 0; i < v.size(); ++i)\r\n    {\r\n        os << v[i];\r\n        if (i != v.size() - 1)\r\n        {\r\n            os << \", \";\r\n        }\r\n    }\r\n    os << \"]\";\r\n    return os;\r\n}\r\n\r\nstd::vector<std::string> readLabels(std::string& labelFilepath)\r\n{\r\n    std::vector<std::string> labels;\r\n    std::string line;\r\n    std::ifstream fp(labelFilepath);\r\n    while (std::getline(fp, line))\r\n    {\r\n        labels.push_back(line);\r\n    }\r\n    return labels;\r\n}\r\n\r\nint main(int argc, char* argv[])\r\n{\r\n    bool useCUDA{true};\r\n    const char* useCUDAFlag = \"--use_cuda\";\r\n    const char* useCPUFlag = \"--use_cpu\";\r\n    if (argc == 1)\r\n    {\r\n        useCUDA = false;\r\n    }\r\n    else if ((argc == 2) && (strcmp(argv[1], useCUDAFlag) == 0))\r\n    {\r\n        useCUDA = true;\r\n    }\r\n    else if ((argc == 2) && (strcmp(argv[1], useCUDAFlag) != 0))\r\n    {\r\n        useCUDA = false;\r\n    }\r\n    else\r\n    {\r\n        throw std::runtime_error{\"Too many arguments.\"};\r\n    }\r\n\r\n    if (useCUDA)\r\n    {\r\n        std::cout << \"Inference Execution Provider: CUDA\" << std::endl;\r\n    }\r\n    else\r\n    {\r\n        std::cout << \"Inference Execution Provider: CPU\" << std::endl;\r\n    }\r\n\r\n    std::string instanceName{\"audio2mesh-inference\"};\r\n    std::string modelFilepath{\"../data/models/squeezenet1.1-7.onnx\"};\r\n    std::string imageFilepath{\r\n        \"../data/images/european-bee-eater-2115564_1920.jpg\"};\r\n    std::string labelFilepath{\"../data/labels/synset.txt\"};\r\n\r\n    std::vector<std::string> labels{readLabels(labelFilepath)};\r\n\r\n    Ort::InitApi();\r\n    Ort::Env env(OrtLoggingLevel::ORT_LOGGING_LEVEL_WARNING,\r\n                \"audio2mesh-inference\");\r\n    Ort::SessionOptions sessionOptions;\r\n    sessionOptions.SetIntraOpNumThreads(1);\r\n    if (useCUDA)\r\n    {\r\n        // Using CUDA backend\r\n        // https://github.com/microsoft/onnxruntime/blob/v1.8.2/include/onnxruntime/core/session/onnxruntime_cxx_api.h#L329\r\n        OrtCUDAProviderOptions cuda_options;\r\n        memset(&cuda_options, 0, sizeof(OrtCUDAProviderOptions));\r\n        sessionOptions.AppendExecutionProvider_CUDA(cuda_options);\r\n    }\r\n\r\n    // Sets graph optimization level\r\n    // Available levels are\r\n    // ORT_DISABLE_ALL -> To disable all optimizations\r\n    // ORT_ENABLE_BASIC -> To enable basic optimizations (Such as redundant node\r\n    // removals) ORT_ENABLE_EXTENDED -> To enable extended optimizations\r\n    // (Includes level 1 + more complex optimizations like node fusions)\r\n    // ORT_ENABLE_ALL -> To Enable All possible optimizations\r\n    sessionOptions.SetGraphOptimizationLevel(\r\n        GraphOptimizationLevel::ORT_ENABLE_EXTENDED);\r\n\r\n    Ort::Session session(env, (const wchar_t*)modelFilepath.c_str(), sessionOptions); // cast from _Elem* to wchar_t*, JH. May need fix\r\n\r\n    Ort::AllocatorWithDefaultOptions allocator;\r\n\r\n    size_t numInputNodes = session.GetInputCount();\r\n    size_t numOutputNodes = session.GetOutputCount();\r\n\r\n    std::cout << \"Number of Input Nodes: \" << numInputNodes << std::endl;\r\n    std::cout << \"Number of Output Nodes: \" << numOutputNodes << std::endl;\r\n\r\n    const char* inputName = session.GetInputName(0, allocator);\r\n    std::cout << \"Input Name: \" << inputName << std::endl;\r\n\r\n    Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);\r\n    auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();\r\n\r\n    ONNXTensorElementDataType inputType = inputTensorInfo.GetElementType();\r\n    std::cout << \"Input Type: \" << inputType << std::endl;\r\n\r\n    std::vector<int64_t> inputDims = inputTensorInfo.GetShape();\r\n    std::cout << \"Input Dimensions: \" << inputDims << std::endl;\r\n\r\n    const char* outputName = session.GetOutputName(0, allocator);\r\n    std::cout << \"Output Name: \" << outputName << std::endl;\r\n\r\n    Ort::TypeInfo outputTypeInfo = session.GetOutputTypeInfo(0);\r\n    auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();\r\n\r\n    ONNXTensorElementDataType outputType = outputTensorInfo.GetElementType();\r\n    std::cout << \"Output Type: \" << outputType << std::endl;\r\n\r\n    std::vector<int64_t> outputDims = outputTensorInfo.GetShape();\r\n    std::cout << \"Output Dimensions: \" << outputDims << std::endl;\r\n\r\n    cv::Mat imageBGR = cv::imread(imageFilepath, cv::ImreadModes::IMREAD_COLOR);\r\n    cv::Mat resizedImageBGR, resizedImageRGB, resizedImage, preprocessedImage;\r\n    cv::resize(imageBGR, resizedImageBGR,\r\n               cv::Size((int)inputDims.at(3), (int)inputDims.at(2)),\r\n               cv::InterpolationFlags::INTER_CUBIC);\r\n    cv::cvtColor(resizedImageBGR, resizedImageRGB,\r\n                 cv::ColorConversionCodes::COLOR_BGR2RGB);\r\n    resizedImageRGB.convertTo(resizedImage, CV_32F, 1.0 / 255);\r\n\r\n    cv::Mat channels[3];\r\n    cv::split(resizedImage, channels);\r\n    // Normalization per channel\r\n    // Normalization parameters obtained from\r\n    // https://github.com/onnx/models/tree/master/vision/classification/squeezenet\r\n    channels[0] = (channels[0] - 0.485) / 0.229;\r\n    channels[1] = (channels[1] - 0.456) / 0.224;\r\n    channels[2] = (channels[2] - 0.406) / 0.225;\r\n    cv::merge(channels, 3, resizedImage);\r\n    // HWC to CHW\r\n    cv::dnn::blobFromImage(resizedImage, preprocessedImage);\r\n\r\n    size_t inputTensorSize = vectorProduct(inputDims);\r\n    std::vector<float> inputTensorValues(inputTensorSize);\r\n    inputTensorValues.assign(preprocessedImage.begin<float>(),\r\n                             preprocessedImage.end<float>());\r\n\r\n    size_t outputTensorSize = vectorProduct(outputDims);\r\n    assert((\"Output tensor size should equal to the label set size.\",\r\n            labels.size() == outputTensorSize));\r\n    std::vector<float> outputTensorValues(outputTensorSize);\r\n\r\n    std::vector<const char*> inputNames{inputName};\r\n    std::vector<const char*> outputNames{outputName};\r\n    std::vector<Ort::Value> inputTensors;\r\n    std::vector<Ort::Value> outputTensors;\r\n\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(\r\n        OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n    inputTensors.push_back(Ort::Value::CreateTensor<float>(\r\n        memoryInfo, inputTensorValues.data(), inputTensorSize, inputDims.data(),\r\n        inputDims.size()));\r\n    outputTensors.push_back(Ort::Value::CreateTensor<float>(\r\n        memoryInfo, outputTensorValues.data(), outputTensorSize,\r\n        outputDims.data(), outputDims.size()));\r\n\r\n    session.Run(Ort::RunOptions{nullptr}, inputNames.data(),\r\n                inputTensors.data(), 1, outputNames.data(),\r\n                outputTensors.data(), 1);\r\n\r\n    int predId = 0;\r\n    float activation = 0;\r\n    float maxActivation = std::numeric_limits<float>::lowest();\r\n    float expSum = 0;\r\n    for (int i = 0; i < labels.size(); i++)\r\n    {\r\n        activation = outputTensorValues.at(i);\r\n        expSum += std::exp(activation);\r\n        if (activation > maxActivation)\r\n        {\r\n            predId = i;\r\n            maxActivation = activation;\r\n        }\r\n    }\r\n    std::cout << \"Predicted Label ID: \" << predId << std::endl;\r\n    std::cout << \"Predicted Label: \" << labels.at(predId) << std::endl;\r\n    std::cout << \"Uncalibrated Confidence: \" << std::exp(maxActivation) / expSum\r\n              << std::endl;\r\n\r\n    // Measure latency\r\n    int numTests{100};\r\n    std::chrono::steady_clock::time_point begin =\r\n        std::chrono::steady_clock::now();\r\n    for (int i = 0; i < numTests; i++)\r\n    {\r\n        session.Run(Ort::RunOptions{nullptr}, inputNames.data(),\r\n                    inputTensors.data(), 1, outputNames.data(),\r\n                    outputTensors.data(), 1);\r\n    }\r\n    std::chrono::steady_clock::time_point end =\r\n        std::chrono::steady_clock::now();\r\n    std::cout << \"Minimum Inference Latency: \"\r\n              << std::chrono::duration_cast<std::chrono::milliseconds>(end -\r\n                                                                       begin)\r\n                         .count() /\r\n                     static_cast<float>(numTests)\r\n              << \" ms\" << std::endl;\r\n}\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12021/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023",
        "repository_url": "https://api.github.com/repos/microsoft/onnxruntime",
        "labels_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023/labels{/name}",
        "comments_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023/comments",
        "events_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023/events",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12023",
        "id": 1288020209,
        "node_id": "I_kwDOCVq1mM5MxaDx",
        "number": 12023,
        "title": "This is a question that should be a discussion",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2022-06-28T23:59:08Z",
        "updated_at": "2022-06-28T23:59:28Z",
        "closed_at": "2022-06-28T23:59:28Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12023/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    }
]