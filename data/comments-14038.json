[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1368306161",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14038#issuecomment-1368306161",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14038",
        "id": 1368306161,
        "node_id": "IC_kwDOCVq1mM5RjrHx",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-01T00:32:15Z",
        "updated_at": "2023-01-01T00:33:27Z",
        "author_association": "MEMBER",
        "body": "There are a few session options might help:\r\nhttps://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\r\n\r\n*gpu_mem_limit*: set some limt.\r\n*arena_extend_strategy*: kSameAsRequested (1)\r\n*cudnn_conv_algo_search*: HEURISTIC (1) or DEFAULT (2)\r\n*cudnn_conv_use_max_workspace*: 0\r\n\r\nFor example, set *arena_extend_strategy* to SameAsRequested could avoid allocating memory more than needed. Use a few images to warm up the service. Note that, first image might apply cudnn conv algo search, which might need a lot of workspace memory. Change *cudnn_conv_algo_search* and *cudnn_conv_use_max_workspace* could reduce memory usage (it could also impact speed since only a subset of algo is searched). I think *gpu_mem_limit* might also impact cudnn workspace.\r\n\r\nRun option of memory.enable_memory_arena_shrinkage could be used to shrink arena memory, see [example](https://github.com/microsoft/onnxruntime/blob/9e649d1ac482357c111a72b288a5b7d5cedb3902/onnxruntime/test/python/onnxruntime_test_python.py#L1240-L1241). \r\n\r\nTry the following sequences to see whether it could help.\r\n* run a warm up image (this will start conv algo search).\r\n* use memory.enable_memory_arena_shrinkage only once and run another warm up image (If memory usage is reduced, cause is cuDNN workspace can be reduced).\r\n* run another warm up image (without arena shrinkage). Memory usage shall not increase.\r\n* serve real traffic  (without arena shrinkage).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1368306161/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]