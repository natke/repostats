[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1174425525",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12078#issuecomment-1174425525",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12078",
        "id": 1174425525,
        "node_id": "IC_kwDOCVq1mM5GAE-1",
        "user": {
            "login": "OriAlpha",
            "id": 41699212,
            "node_id": "MDQ6VXNlcjQxNjk5MjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/41699212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/OriAlpha",
            "html_url": "https://github.com/OriAlpha",
            "followers_url": "https://api.github.com/users/OriAlpha/followers",
            "following_url": "https://api.github.com/users/OriAlpha/following{/other_user}",
            "gists_url": "https://api.github.com/users/OriAlpha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/OriAlpha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/OriAlpha/subscriptions",
            "organizations_url": "https://api.github.com/users/OriAlpha/orgs",
            "repos_url": "https://api.github.com/users/OriAlpha/repos",
            "events_url": "https://api.github.com/users/OriAlpha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/OriAlpha/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-04T22:13:10Z",
        "updated_at": "2022-07-04T22:13:10Z",
        "author_association": "NONE",
        "body": "Some more logs while model was converted: \r\n```\r\nExporting ONNX model to ./baseline_large_encoder_decoder_init.onnxbatch_size=4 encode_sequence_length=11, max_diff=2.765655517578125e-05\r\nbatch_size=1 encode_sequence_length=2, max_diff=1.1444091796875e-05\r\nbatch_size=3 encode_sequence_length=1, max_diff=1.3113021850585938e-05\r\nbatch_size=8 encode_sequence_length=5, max_diff=2.5510787963867188e-05\r\nPyTorch and OnnxRuntime results max difference = 2.765655517578125e-05\r\nExporting ONNX model to ./baseline_large_decoder.onnx\r\nbatch_size=4, encode_sequence_length=11, past_decode_sequence_length=3, max_diff=8.0108642578125e-05\r\nbatch_size=1, encode_sequence_length=2, past_decode_sequence_length=5, max_diff=0.00012254714965820312\r\nbatch_size=3, encode_sequence_length=1, past_decode_sequence_length=1, max_diff=9.524822235107422e-05\r\nbatch_size=8, encode_sequence_length=5, past_decode_sequence_length=2, max_diff=0.000392913818359375\r\nPyTorch and OnnxRuntime results max difference = 0.000392913818359375\r\nPyTorch and OnnxRuntime results are NOT close\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1174425525/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178365251",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12078#issuecomment-1178365251",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12078",
        "id": 1178365251,
        "node_id": "IC_kwDOCVq1mM5GPG1D",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-07T23:25:50Z",
        "updated_at": "2022-07-07T23:27:15Z",
        "author_association": "MEMBER",
        "body": "@OriApha, Could you use a set of inputs to evaluate the accuracy (for classification tasks) or other metrics of your task.\r\n\r\nIn above example, output difference of 4e-4 is probably acceptable for some scenario. That means the output might not be exactly same, but results could be very close in many cases.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1178365251/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179813316",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12078#issuecomment-1179813316",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12078",
        "id": 1179813316,
        "node_id": "IC_kwDOCVq1mM5GUoXE",
        "user": {
            "login": "OriAlpha",
            "id": 41699212,
            "node_id": "MDQ6VXNlcjQxNjk5MjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/41699212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/OriAlpha",
            "html_url": "https://github.com/OriAlpha",
            "followers_url": "https://api.github.com/users/OriAlpha/followers",
            "following_url": "https://api.github.com/users/OriAlpha/following{/other_user}",
            "gists_url": "https://api.github.com/users/OriAlpha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/OriAlpha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/OriAlpha/subscriptions",
            "organizations_url": "https://api.github.com/users/OriAlpha/orgs",
            "repos_url": "https://api.github.com/users/OriAlpha/repos",
            "events_url": "https://api.github.com/users/OriAlpha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/OriAlpha/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-10T22:35:53Z",
        "updated_at": "2022-07-10T22:38:24Z",
        "author_association": "NONE",
        "body": "I acutally did the some evaluate, but i noticied one the issue. When i pass a sentence to the model. The model does not paraphases complete sentence, it only does half sentence. This is why i was seeing the performance issue. But may be i am passing inputs in a wrong way. The way i was passing input was in list of strings. \r\ni..e.,\r\n```\r\ninputs_sent = [sentence1,sentence2,sentence3]\r\nfor ii in range(len(inputs_sent)):\r\n   inputs = tokenizer(src_text[ii], max_length=max_length, padding='max_length', return_tensors=\"pt\", truncation=True)\r\n\r\n  inputs = {\r\n          \"input_ids\": input_ids.cpu().numpy().astype(np.int32),\r\n          \"max_length\": np.array([max_length], dtype=np.int32),\r\n          \"min_length\": np.array([min_length], dtype=np.int32),\r\n          \"num_beams\": np.array([num_beams], dtype=np.int32),\r\n          \"num_return_sequences\": np.array([num_return_sequences], dtype=np.int32),\r\n          \"length_penalty\": np.array([length_penalty], dtype=np.float32),\r\n          \"repetition_penalty\": np.array([repetition_penalty], dtype=np.float32),\r\n          \"vocab_mask\": vocab_mask\r\n      }\r\nresult = ort_session.run(None, inputs)\r\n(batch_size, num_sequences, max_length) = sequences.shape\r\n    ort_decoded_sequences = []\r\n    for i in range(batch_size):\r\n        for j in range(num_sequences):\r\n            decoded_sequence = tokenizer.decode(sequences[i][j], skip_special_tokens=True)\r\n            ort_decoded_sequences.append(decoded_sequence)\r\n            print(decoded_sequence)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1179813316/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1186041097",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12078#issuecomment-1186041097",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12078",
        "id": 1186041097,
        "node_id": "IC_kwDOCVq1mM5GsY0J",
        "user": {
            "login": "OriAlpha",
            "id": 41699212,
            "node_id": "MDQ6VXNlcjQxNjk5MjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/41699212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/OriAlpha",
            "html_url": "https://github.com/OriAlpha",
            "followers_url": "https://api.github.com/users/OriAlpha/followers",
            "following_url": "https://api.github.com/users/OriAlpha/following{/other_user}",
            "gists_url": "https://api.github.com/users/OriAlpha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/OriAlpha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/OriAlpha/subscriptions",
            "organizations_url": "https://api.github.com/users/OriAlpha/orgs",
            "repos_url": "https://api.github.com/users/OriAlpha/repos",
            "events_url": "https://api.github.com/users/OriAlpha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/OriAlpha/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-16T00:46:10Z",
        "updated_at": "2022-07-16T01:01:10Z",
        "author_association": "NONE",
        "body": "So far with my inputs i could see \r\n```\r\nTorch and ORT result is  different\r\nORT {'test_times': 1, 'latency_variance': '0.00', 'latency_90_percentile': '5406.18', 'latency_95_percentile': '5406.18', 'latency_99_percentile': '5406.18', 'average_latency_ms': '5406.18', 'QPS': '0.18', 'parity': False}\r\n```\r\nIs there any parameters, I could change and run tests again?? @tianleiwu\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1186041097/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1229261133",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12078#issuecomment-1229261133",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12078",
        "id": 1229261133,
        "node_id": "IC_kwDOCVq1mM5JRQlN",
        "user": {
            "login": "OriAlpha",
            "id": 41699212,
            "node_id": "MDQ6VXNlcjQxNjk5MjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/41699212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/OriAlpha",
            "html_url": "https://github.com/OriAlpha",
            "followers_url": "https://api.github.com/users/OriAlpha/followers",
            "following_url": "https://api.github.com/users/OriAlpha/following{/other_user}",
            "gists_url": "https://api.github.com/users/OriAlpha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/OriAlpha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/OriAlpha/subscriptions",
            "organizations_url": "https://api.github.com/users/OriAlpha/orgs",
            "repos_url": "https://api.github.com/users/OriAlpha/repos",
            "events_url": "https://api.github.com/users/OriAlpha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/OriAlpha/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-27T20:30:28Z",
        "updated_at": "2022-08-27T22:27:30Z",
        "author_association": "NONE",
        "body": "```\r\nstart testing model...\r\n--------------------------------------------------\r\nTest PyTorch model and beam search with huggingface transformers...\r\ninput_ids tensor([[   259,  33644,    287,    259,  13439,    628,    807,  49285,    261,\r\n            259,  59569,  24901,    263,    783,  38186,    344,    259,   6097,\r\n            259, 120629,    304,    259,   1616,  55094,  12842,    305,    783,\r\n           2101,   2121, 214630,   7670,    702,  17358,    305,   8253,   9610,\r\n            261,    287,    259, 189663,    304,  28816,    305,  18623,    261,\r\n            305,    281,   8057,    259,  44326,    304,    259, 129447,    305,\r\n           6174,   9610,    305,   3182,    260,      1]])\r\nhuggingface transformers outputs:\r\nsequences tensor([[     0, 250099,    260,    259,  33644,    287,    259,  13439,    628,\r\n            807,  49285,    261,    259,  59569,  24901,    263,    783,  38186,\r\n            259, 120629,    304,    259,   1616,  55094,  12842, 250098,    260,\r\n            259,  33644,    287,    259,  13439,    628,    807,  49285,    261,\r\n            259,  59569,  24901,    263,    783,  38186,    259, 120629,    304,\r\n            259,   1616,  55094,  12842, 250097]])\r\n0: <extra_id_0>. Since the early 20th century, tiger populations have lost 93% of their historic range <extra_id_1>. Since the early 20th century, tiger populations have lost 93% of their historic range <extra_id_2>\r\n--------------------------------------------------\r\nTesting beam search with onnxruntime...\r\nORT outputs:\r\nsequences [[[     0 250099    783   2101   2121 175663    345    702    259 129447\r\n      305   8253   9610    305   3182    260    259  33644    287    259\r\n    13439    628    807  49285    261    259  59569  24901    263    783\r\n    38186   1388    259 120629    304    259   1616  55094  12842 250098\r\n      259  59569  24901    263    783   2101   2121 214630   7670    702]]]\r\nbatch 0 sequence 0: <extra_id_0> have been exterminated from Southeast and Central Asia and China. Since the early 20th century, tiger populations have lost about 93% of their historic range <extra_id_1> tiger populations have been extirpated from\r\n--------------------------------------------------\r\nTorch Sequences:\r\ntensor([[[     0, 250099,    260,    259,  33644,    287,    259,  13439,\r\n             628,    807,  49285,    261,    259,  59569,  24901,    263,\r\n             783,  38186,    259, 120629,    304,    259,   1616,  55094,\r\n           12842, 250098,    260,    259,  33644,    287,    259,  13439,\r\n             628,    807,  49285,    261,    259,  59569,  24901,    263,\r\n             783,  38186,    259, 120629,    304,    259,   1616,  55094,\r\n           12842, 250097]]])\r\n['<extra_id_0>. Since the early 20th century, tiger populations have lost 93% of their historic range <extra_id_1>. Since the early 20th century, tiger populations have lost 93% of their historic range <extra_id_2>']\r\n--------------------------------------------------\r\nORT Sequences:\r\ntensor([[[     0, 250099,    783,   2101,   2121, 175663,    345,    702,\r\n             259, 129447,    305,   8253,   9610,    305,   3182,    260,\r\n             259,  33644,    287,    259,  13439,    628,    807,  49285,\r\n             261,    259,  59569,  24901,    263,    783,  38186,   1388,\r\n             259, 120629,    304,    259,   1616,  55094,  12842, 250098,\r\n             259,  59569,  24901,    263,    783,   2101,   2121, 214630,\r\n            7670,    702]]])\r\n['<extra_id_0> have been exterminated from Southeast and Central Asia and China. Since the early 20th century, tiger populations have lost about 93% of their historic range <extra_id_1> tiger populations have been extirpated from']\r\n--------------------------------------------------\r\nTorch and ORT result is  different\r\nORT {'test_times': 1, 'latency_variance': '0.00', 'latency_90_percentile': '7002.78', 'latency_95_percentile': '7002.78', 'latency_99_percentile': '7002.78', 'average_latency_ms': '7002.78', 'QPS': '0.14', 'parity': False}\r\n\r\n```\r\nI have made more testing paraphases doesnt look good. \r\nORGINIAL_SENTENCE : \r\n```\r\n\"Since the early 20th century, tiger populations have lost at least 93% of their historic range and have been extirpated from Western and Central Asia, the islands of Java and Bali, and in large areas of Southeast and South Asia and China.\"\r\n```\r\n\r\nI have used mt5 large model for testing. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1229261133/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]