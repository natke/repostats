[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1585081904",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16305#issuecomment-1585081904",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16305",
        "id": 1585081904,
        "node_id": "IC_kwDOCVq1mM5eem4w",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-09T20:16:02Z",
        "updated_at": "2023-06-09T20:16:02Z",
        "author_association": "MEMBER",
        "body": "Please, ensure correct usage of ORT API, make sure that when you create tensors, you pass buffer lengths either in number elements or in bytes, as documented (common mistake).\r\n\r\nIt does not look it is crashing. My understanding Run() returns an error. You are running out of memory. If you are running on CPU, you may want to [disable memory arena](https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/onnxruntime_cxx_api.h#L562), you only need this for GPU.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1585081904/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1586559885",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16305#issuecomment-1586559885",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16305",
        "id": 1586559885,
        "node_id": "IC_kwDOCVq1mM5ekPuN",
        "user": {
            "login": "mlruns",
            "id": 131228873,
            "node_id": "U_kgDOB9JkyQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/131228873?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mlruns",
            "html_url": "https://github.com/mlruns",
            "followers_url": "https://api.github.com/users/mlruns/followers",
            "following_url": "https://api.github.com/users/mlruns/following{/other_user}",
            "gists_url": "https://api.github.com/users/mlruns/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mlruns/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mlruns/subscriptions",
            "organizations_url": "https://api.github.com/users/mlruns/orgs",
            "repos_url": "https://api.github.com/users/mlruns/repos",
            "events_url": "https://api.github.com/users/mlruns/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mlruns/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-12T04:30:24Z",
        "updated_at": "2023-06-12T04:37:37Z",
        "author_association": "NONE",
        "body": "Thanks for your response. As I am running on CPU, I tried using disable memory arena in session options . I got this error\r\n\r\nMessage: \r\n\r\n2023-06-11 23:53:14.1898754 [ onnxruntime::SequentialExecutor::Execute] Non-zero status code returned while running DynamicQuantizeMatMul node. Name:'/image_encoder/2/attn/MatMul_quant' Status Message: bad allocation\r\nunknown file: error: C++ exception with description \"Non-zero status code returned while running DynamicQuantizeMatMul node. Name:'/image_encoder/2/attn/MatMul_quant' Status Message: bad allocation\" thrown in the test body.\r\n\r\n  Stack Trace: \r\n, sequential_executor.cc:368 line 368\r\n```\r\n\r\nstd::vector<SEGMENT_RESULT> run_SAM_ONNX_model_on_image\r\n (const SharedClasses::CLynxImage& image, const std::string& encoder_ONNX_filename, const std::string& decoder_ONNX_filename, int model_in_x, int model_in_y, RECT bbox, int cls)\r\n{\r\n\r\n    //std::vector<SEGMENT_RESULT> output;\r\n\r\n    //cv::setNumThreads(0);\r\n\r\n    // We use ORT_API_MANUAL_INIT to allow for delay-loading the OnnxRuntime dll.\r\n    // It's unclear whether its safe to just blindly call InitApi() every time it might be required;\r\n    // for now, test the (private) global api_ pointer to make sure.\r\n    if (!Ort::Global<void>::api_)\r\n    {\r\n        Ort::InitApi();\r\n    }\r\n\r\n    SharedClasses::CLynxImage working_copy;\r\n    image.copyTo(working_copy);\r\n    cv::Mat cv_image;\r\n    link_lynx_to_CV_mat(working_copy, cv_image);\r\n    cv::cvtColor(cv_image, cv_image, cv::COLOR_GRAY2RGB);\r\n    int EncoderInputSize = 1024;\r\n    cv::Mat resized_image = ResizeLongestSide_apply_image(cv_image, EncoderInputSize);\r\n\r\n    int pad_h = EncoderInputSize - resized_image.rows;\r\n    int pad_w = EncoderInputSize - resized_image.cols;\r\n\r\n    cv::Mat padded_image;\r\n    cv::copyMakeBorder(resized_image, padded_image, 0, pad_h, 0, pad_w, cv::BorderTypes::BORDER_CONSTANT, cv::Scalar(0, 0, 0));\r\n\r\n    std::vector<SEGMENT_RESULT> output;\r\n\r\n\r\n\r\n    // setting up onnxruntime env\r\n    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"example-model-explorer\");\r\n\r\n    //std::vector<int64_t> EncoderOutputShape, EncoderInputShape;\r\n    Ort::AllocatorWithDefaultOptions allocator;\r\n    Ort::MemoryInfo memory_info_handler = Ort::MemoryInfo::CreateCpu(\r\n        OrtArenaAllocator, OrtMemTypeDefault\r\n    );\r\n\r\n#ifdef ORTCHAR_T\r\n    std::basic_string<ORTCHAR_T> encoder_model_file = std::basic_string<ORTCHAR_T>(encoder_ONNX_filename.begin(), encoder_ONNX_filename.end());\r\n    std::basic_string<ORTCHAR_T> decoder_model_file = std::basic_string<ORTCHAR_T>(decoder_ONNX_filename.begin(), decoder_ONNX_filename.end());\r\n\r\n#else\r\n    auto& model_file = encoder_ONNX_filename;\r\n    auto& model_file = decoder_ONNX_filename;\r\n#endif\r\n    Ort::SessionOptions session_options;\r\n    session_options.SetInterOpNumThreads(1).SetIntraOpNumThreads(1);\r\n    session_options.DisableCpuMemArena();\r\n    //session_options.SetInterOpNumThreads(std::thread::hardware_concurrency());\r\n    //session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);\r\n    std::unique_ptr <Ort::Session> encoder_session = std::make_unique <Ort::Session>(env, encoder_model_file.c_str(), session_options);\r\n    if (encoder_session->GetInputCount() != 1 || encoder_session->GetOutputCount() != 1) {\r\n        auto a = 1;\r\n    }\r\n    auto EncoderOutputShape = encoder_session->GetOutputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape();\r\n    auto EncoderInputShape = encoder_session->GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape();\r\n    //EncoderInputShape = std::vector<int64_t>{1,3, 1024, 1024 };\r\n    //auto EncoderInputShape = encoder_session.GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetShape();\r\n    //resize before blob for python/c++ reproducability\r\n    \r\n    Ort::Session decoder_session = Ort::Session(env, decoder_model_file.c_str(), session_options);\r\n\r\n    //std::vector<uint8_t> inputTensorValues(EncoderInputShape[0] * EncoderInputShape[1] * EncoderInputShape[2] *\r\n    //    EncoderInputShape[3]);\r\n\r\n    if (padded_image.size() != cv::Size(EncoderInputShape[3], EncoderInputShape[2])) {\r\n        //std::cerr << \"Image size not match\" << std::endl;\r\n        //std::cout << \"Image width : \" << Image.cols << \" Image height : \" << Image.rows << std::endl;\r\n\r\n\r\n        //return output;\r\n    }\r\n    if (padded_image.channels() != 3) {\r\n        //std::cerr << \"Input image is not a 3-channel image\" << std::endl;\r\n        //return output;\r\n    }\r\n    \r\n    auto blob = cv::dnn::blobFromImage(padded_image, 1.0, cv::Size(EncoderInputShape[3], EncoderInputShape[2]));\r\n    std::vector<uint8_t> inputTensorValues(blob.total());\r\n    inputTensorValues.assign((uint8_t*)blob.data, (uint8_t*)blob.data + blob.total() * blob.channels());\r\n\r\n    std::vector<Ort::Value> inputTensor;\r\n    Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(\r\n        OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);\r\n    inputTensor.push_back(Ort::Value::CreateTensor<uint8_t>(memoryInfo, inputTensorValues.data(), inputTensorValues.size(), EncoderInputShape.data(), EncoderInputShape.size()));\r\n std::vector<float>image_embedding = std::vector<float>(EncoderOutputShape[0] * EncoderOutputShape[1] * EncoderOutputShape[2] * EncoderOutputShape[3]);\r\n\r\n    auto outputTensorPre = Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, image_embedding.data(), image_embedding.size(),\r\n        EncoderOutputShape.data(), EncoderOutputShape.size());\r\n    assert(outputTensorPre.IsTensor() && outputTensorPre.HasValue());\r\n\r\n    //const char* inputNamesPre[] = { \"\"}, * outputNamesPre[] = {\"output\"};\r\n\r\n    auto* inputName = encoder_session->GetInputName(0, allocator);\r\n    auto* outputName = encoder_session->GetOutputName(0, allocator);\r\n    \r\n    const char* inputNames[] = { inputName };\r\n    const char* outputNames[] = { outputName };\r\n    \r\n    Ort::RunOptions run_options;\r\n    run_options.SetRunLogVerbosityLevel(1);\r\n    //encoder_session->Run(run_options, inputNames, &inputTensor, 1, outputNames, &outputTensorPre,\r\n      //  1);\r\n    auto output_tensors = encoder_session->Run(Ort::RunOptions{ nullptr }, inputNames, inputTensor.data(), inputTensor.size(), outputNames, 1);\r\n\r\n    //running decoder session\r\n\r\n    const char* DecoderInputNames[6]{ \"image_embeddings\", \"point_coords\",   \"point_labels\",\r\n                             \"mask_input\", \"has_mask_input\", \"orig_im_size\" },\r\n        * DecoderOutputNames[3]{ \"masks\", \"iou_predictions\", \"low_res_masks\" };\r\n\r\n\r\n    float inputPointsValues[] = { bbox.left,bbox.right,bbox.top,bbox.bottom };\r\n    float inputLabelsValues[] = {cls };\r\n\r\n    const size_t maskInputSize = 256 * 256;\r\n\r\n    float maskInputValues[maskInputSize], hasMaskValues[] = { 0 },\r\n        orig_im_size_values[] = { (float)cv_image.rows, (float)cv_image.cols };\r\n    \r\n    memset(maskInputValues, 0, sizeof(maskInputValues));\r\n\r\n    std::vector<int64_t> inputPointShape = { 1, 3, 2 }, pointLabelsShape = { 1, 3 },\r\n        maskInputShape = { 1, 1, 256, 256 }, hasMaskInputShape = { 1 },\r\n        origImSizeShape = { 2 };\r\n\r\n    std::vector<Ort::Value> inputTensorsSam;\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, (float*)image_embedding.data(), image_embedding.size(),\r\n        EncoderOutputShape.data(), EncoderOutputShape.size()));\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, inputPointsValues, 2 * 3, inputPointShape.data(), inputPointShape.size()));\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, inputLabelsValues, 1 * 3, pointLabelsShape.data(), pointLabelsShape.size()));\r\n\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, maskInputValues, maskInputSize, maskInputShape.data(), maskInputShape.size()));\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, hasMaskValues, 1, hasMaskInputShape.data(), hasMaskInputShape.size()));\r\n    inputTensorsSam.push_back(Ort::Value::CreateTensor<float>(\r\n        memory_info_handler, orig_im_size_values, 2, origImSizeShape.data(), origImSizeShape.size()));\r\n\r\n    Ort::RunOptions runOptionsSam;\r\n\r\n    auto DecoderOutputTensors = decoder_session.Run(runOptionsSam, DecoderInputNames, inputTensorsSam.data(),\r\n        inputTensorsSam.size(), DecoderOutputNames, 3);\r\n    \r\n    auto masks = DecoderOutputTensors[0].GetTensorMutableData<float>();\r\n\tauto iou_predictions = DecoderOutputTensors[1].GetTensorMutableData<float>();\r\n\tauto low_res_masks = DecoderOutputTensors[2].GetTensorMutableData<float>();\r\n\r\n\r\n\tOrt::Value& masks_ = DecoderOutputTensors[0];\r\n\tOrt::Value& iou_predictions_ = DecoderOutputTensors[1];\r\n\tOrt::Value& low_res_masks_ = DecoderOutputTensors[2];\r\n\r\n\tauto mask_dims = masks_.GetTypeInfo().GetTensorTypeAndShapeInfo().GetShape();\r\n\tauto iou_pred_dims = iou_predictions_.GetTypeInfo().GetTensorTypeAndShapeInfo().GetShape();\r\n\tauto low_res_dims = low_res_masks_.GetTypeInfo().GetTensorTypeAndShapeInfo().GetShape();\r\n    \r\n\r\n    const unsigned int Resizemasks_batch = mask_dims.at(0);\r\n    const unsigned int Resizemasks_nums = mask_dims.at(1);\r\n    const unsigned int Resizemasks_width = mask_dims.at(2);\r\n    const unsigned int Resizemasks_height = mask_dims.at(3);\r\n\r\n    //std::vector<SEGMENT_RESULT> output;\r\n    for (unsigned int index = 0; index < Resizemasks_nums; index++)\r\n    {\r\n        //cv::Mat mask(cv_image.rows, cv_image.cols, CV_8UC1);\r\n        std::vector<std::vector<unsigned char>> mask;\r\n\r\n        for (unsigned int i = 0; i < cv_image.rows; i++)\r\n        {\r\n            for (unsigned int j = 0; j < cv_image.cols; j++)\r\n            {\r\n\r\n                mask[i][j] = masks[i * cv_image.cols + j + index * cv_image.rows * cv_image.cols] > 0 ? 255 : 0;\r\n            }\r\n        }\r\n        SEGMENT_RESULT mat_info;\r\n        mat_info.mask = mask;\r\n        mat_info.iou_pred = *(iou_predictions++);\r\n        output.emplace_back(mat_info);\r\n    }\r\n return output;\r\n}\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1586559885/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1597507808",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16305#issuecomment-1597507808",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16305",
        "id": 1597507808,
        "node_id": "IC_kwDOCVq1mM5fOAjg",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-19T17:10:39Z",
        "updated_at": "2023-06-19T17:11:35Z",
        "author_association": "MEMBER",
        "body": "ORT had a size calculation overflow bug in one of the scenarios, you may try to your code with 1.15.1 that was just released.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1597507808/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1597510438",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16305#issuecomment-1597510438",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16305",
        "id": 1597510438,
        "node_id": "IC_kwDOCVq1mM5fOBMm",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-19T17:13:02Z",
        "updated_at": "2023-06-19T17:13:02Z",
        "author_association": "MEMBER",
        "body": "From the usage perspective, I am curious to know what makes you allocate Ort::Session on the heap while everything else on the stack?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1597510438/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]