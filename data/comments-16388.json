[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595138317",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16388#issuecomment-1595138317",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16388",
        "id": 1595138317,
        "node_id": "IC_kwDOCVq1mM5fE-EN",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-16T18:48:07Z",
        "updated_at": "2023-06-16T18:48:07Z",
        "author_association": "MEMBER",
        "body": "The prebuilt onnx runtime packages do not support CUDA 12.0. You will need to build it from source. We can only support one CUDA major version(12.x or 11.x) in the prebuilt packages. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595138317/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595180180",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16388#issuecomment-1595180180",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16388",
        "id": 1595180180,
        "node_id": "IC_kwDOCVq1mM5fFISU",
        "user": {
            "login": "sesevasa64",
            "id": 57566157,
            "node_id": "MDQ6VXNlcjU3NTY2MTU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/57566157?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sesevasa64",
            "html_url": "https://github.com/sesevasa64",
            "followers_url": "https://api.github.com/users/sesevasa64/followers",
            "following_url": "https://api.github.com/users/sesevasa64/following{/other_user}",
            "gists_url": "https://api.github.com/users/sesevasa64/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sesevasa64/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sesevasa64/subscriptions",
            "organizations_url": "https://api.github.com/users/sesevasa64/orgs",
            "repos_url": "https://api.github.com/users/sesevasa64/repos",
            "events_url": "https://api.github.com/users/sesevasa64/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sesevasa64/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-16T19:20:42Z",
        "updated_at": "2023-06-16T19:20:42Z",
        "author_association": "NONE",
        "body": "> The prebuilt onnx runtime packages do not support CUDA 12.0. You will need to build it from source. We can only support one CUDA major version(12.x or 11.x) in the prebuilt packages.\r\n\r\nSorry, this version of CUDA is taken from nvidia-smi, which is wrong I guess\r\nI can reproduce this issue on my local pc in WSL with CUDA 11.8 installed\r\nGoogle Colab with CUDA 11.8 is also crashing \r\n\r\n`nvcc --version` output on my pc:\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2022 NVIDIA Corporation\r\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\r\nCuda compilation tools, release 11.8, V11.8.89\r\nBuild cuda_11.8.r11.8/compiler.31833905_0\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595180180/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595451956",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/16388#issuecomment-1595451956",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/16388",
        "id": 1595451956,
        "node_id": "IC_kwDOCVq1mM5fGKo0",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-16T23:16:31Z",
        "updated_at": "2023-06-17T00:14:37Z",
        "author_association": "MEMBER",
        "body": "I did some investigation on the colab ([example notebook](https://colab.research.google.com/drive/12pIlpPx8Vrzebfd8s7IOWf0BWKEc_F7P?usp=sharing)):\r\n\r\nUsing a script in https://github.com/microsoft/onnxruntime/issues/11092#issuecomment-1484756347 to run in colab.\r\n\r\nWhen import torch first, cuda and cudnn are loaded from torch package:\r\n```\r\n/usr/local/lib/python3.10/dist-packages/torch/lib/libcublas.so.11\r\n/usr/local/lib/python3.10/dist-packages/torch/lib/libcublasLt.so.11\r\n/usr/local/lib/python3.10/dist-packages/torch/lib/libcudnn.so.8\r\n```\r\n\r\nWhen import ort first, cuda and cudnn are loaded from system installed:\r\n```\r\n/usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11\r\n/usr/local/cuda/targets/x86_64-linux/lib/libcublasLt.so.11\r\n/lib/x86_64-linux-gnu/libcudnn.so.8\r\n```\r\nSince the torch installed in the colab is built with CUDA 11.8, let's assume the only different DLL is cuDNN. \r\n\r\n`torch.backends.cudnn.version()` show `8700` so torch 2.0.1 uses cuDNN 8.7\r\n\r\n`pathlib.Path('/lib/x86_64-linux-gnu/libcudnn.so.8').resolve()` shows that `/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0`, so the one used by ORT is cuDNN 8.9.\r\n\r\nTwo solutions: \r\n(1) Try install same cuDNN version (8.7) used in torch to the system. To simulate this in colab, add the following before `import onnxruntime`:\r\n```\r\n!pip install nvidia-cudnn-cu11==8.7.0.84\r\nfrom ctypes import *\r\n_= cdll.LoadLibrary(\"/usr/local/lib/python3.10/dist-packages/nvidia/cudnn/lib/libcudnn.so.8\")\r\n```\r\n(2) If you are not able to install cuDNN, try add the following to preload same cuDNN before `import onnxruntime`:\r\n```\r\nfrom ctypes import *\r\n_ = cdll.LoadLibrary(\"/usr/local/lib/python3.10/dist-packages/torch/lib/libcudnn.so.8\")\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1595451956/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]