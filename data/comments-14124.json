[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1371250848",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14124#issuecomment-1371250848",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14124",
        "id": 1371250848,
        "node_id": "IC_kwDOCVq1mM5Ru6Cg",
        "user": {
            "login": "faxu",
            "id": 20780999,
            "node_id": "MDQ6VXNlcjIwNzgwOTk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/20780999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/faxu",
            "html_url": "https://github.com/faxu",
            "followers_url": "https://api.github.com/users/faxu/followers",
            "following_url": "https://api.github.com/users/faxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/faxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/faxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/faxu/subscriptions",
            "organizations_url": "https://api.github.com/users/faxu/orgs",
            "repos_url": "https://api.github.com/users/faxu/repos",
            "events_url": "https://api.github.com/users/faxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/faxu/received_events",
            "type": "User",
            "site_admin": true
        },
        "created_at": "2023-01-04T18:03:20Z",
        "updated_at": "2023-01-04T18:03:20Z",
        "author_association": "MEMBER",
        "body": "The onnxrutime-gpu package includes CUDA and TensorRT, as we see these are the most popular used GPUs for ML workloads. We also have a separate package for Windows DirectML - pypi-[onnxruntime-directml](https://pypi.org/project/onnxruntime-directml/) / nuget-[Microsoft.ML.OnnxRuntime.DirectML](https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.DirectML)\r\n\r\nYou can find all the supported EPs here: https://onnxruntime.ai/docs/execution-providers/#summary-of-supported-execution-providers\r\n\r\nWe also have a matrix on https://onnxruntime.ai/ to help find the recommended build/pkg based on deployment target. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1371250848/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]