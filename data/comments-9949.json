[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988394157",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9949#issuecomment-988394157",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9949",
        "id": 988394157,
        "node_id": "IC_kwDOCVq1mM466bKt",
        "user": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-08T01:00:07Z",
        "updated_at": "2021-12-08T01:00:07Z",
        "author_association": "MEMBER",
        "body": "ONNX Runtime Transformer optimizer can't run with fp16 model. I suggest exporting a model to fp32 and optimize it using an [optimizer](https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/transformers) with a model type 'bert'.\r\n\r\nIf you need a smaller memory footprint on runtime, you can try to disable memory arena and memory pattern as follows,\r\n\r\nsession_option = onnxruntime.SessionOptions()\r\nsession_option.enable_mem_pattern = False\r\nsession_option.enable_cpu_mem_arena = False\r\nthe_session = onnxruntime.InferenceSession(model_dir, session_option)\r\n\r\nBut there will be a trade-off between memory and latency.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988394157/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988442476",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9949#issuecomment-988442476",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9949",
        "id": 988442476,
        "node_id": "IC_kwDOCVq1mM466m9s",
        "user": {
            "login": "Oxi84",
            "id": 25420033,
            "node_id": "MDQ6VXNlcjI1NDIwMDMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/25420033?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Oxi84",
            "html_url": "https://github.com/Oxi84",
            "followers_url": "https://api.github.com/users/Oxi84/followers",
            "following_url": "https://api.github.com/users/Oxi84/following{/other_user}",
            "gists_url": "https://api.github.com/users/Oxi84/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Oxi84/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Oxi84/subscriptions",
            "organizations_url": "https://api.github.com/users/Oxi84/orgs",
            "repos_url": "https://api.github.com/users/Oxi84/repos",
            "events_url": "https://api.github.com/users/Oxi84/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Oxi84/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-08T02:35:05Z",
        "updated_at": "2021-12-08T02:36:52Z",
        "author_association": "NONE",
        "body": "Is this normal that onxx uses more GPU memory than pytorch.\r\n\r\nThanks for the answer  and I have found:\r\n1) optimising with model type \"bert\" does not decrease memory usage - maybe even increases. I mean GPU memory\r\n2) I applied these options and they do not make any difference,  GPU memory usage is the same and much larger using pytorch.\r\n\r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988442476/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988557723",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9949#issuecomment-988557723",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9949",
        "id": 988557723,
        "node_id": "IC_kwDOCVq1mM467DGb",
        "user": {
            "login": "hanbitmyths",
            "id": 35605090,
            "node_id": "MDQ6VXNlcjM1NjA1MDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/35605090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hanbitmyths",
            "html_url": "https://github.com/hanbitmyths",
            "followers_url": "https://api.github.com/users/hanbitmyths/followers",
            "following_url": "https://api.github.com/users/hanbitmyths/following{/other_user}",
            "gists_url": "https://api.github.com/users/hanbitmyths/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hanbitmyths/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hanbitmyths/subscriptions",
            "organizations_url": "https://api.github.com/users/hanbitmyths/orgs",
            "repos_url": "https://api.github.com/users/hanbitmyths/repos",
            "events_url": "https://api.github.com/users/hanbitmyths/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hanbitmyths/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-12-08T07:13:45Z",
        "updated_at": "2021-12-08T07:20:45Z",
        "author_association": "MEMBER",
        "body": "ONNX Runtime consumes more memory than PyTorch for transformer models. You can try [benchmark](https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/transformers#benchmarkpy) to check performance against PyTorch.\r\n\r\nONNX Runtime CUDA EP also provides [a configuration options](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#gpu_mem_limit). 'arena_extend_strategy' and 'gpu_mem_limit' options can help reduce GPU memory footprint.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/988557723/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100843610",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9949#issuecomment-1100843610",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9949",
        "id": 1100843610,
        "node_id": "IC_kwDOCVq1mM5BnYpa",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2022-04-17T09:54:05Z",
        "updated_at": "2022-04-17T09:54:05Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100843610/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]