[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1514585065",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15585#issuecomment-1514585065",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15585",
        "id": 1514585065,
        "node_id": "IC_kwDOCVq1mM5aRrvp",
        "user": {
            "login": "lucasjinreal",
            "id": 21303438,
            "node_id": "MDQ6VXNlcjIxMzAzNDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21303438?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lucasjinreal",
            "html_url": "https://github.com/lucasjinreal",
            "followers_url": "https://api.github.com/users/lucasjinreal/followers",
            "following_url": "https://api.github.com/users/lucasjinreal/following{/other_user}",
            "gists_url": "https://api.github.com/users/lucasjinreal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lucasjinreal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lucasjinreal/subscriptions",
            "organizations_url": "https://api.github.com/users/lucasjinreal/orgs",
            "repos_url": "https://api.github.com/users/lucasjinreal/repos",
            "events_url": "https://api.github.com/users/lucasjinreal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lucasjinreal/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-19T11:41:58Z",
        "updated_at": "2023-04-19T12:20:44Z",
        "author_association": "NONE",
        "body": "tried onnxruntime 1.14.1, also didn't see any speedup on cuda fp16. 1.14.1 even slower than 1.13.\r\n\r\n\r\nTested both on python or C++, same behavior:\r\n\r\n```\r\n‚ûú python .\\scripts\\test_ort.py .\\models\\body3d_full_fp16.onnx\r\n0.046171860694885256\r\nüêç(base) üëΩ Administrator in  ‚Ä¶\\xx on ÓÇ† main [?] took 34s\r\n‚ûú python .\\scripts\\test_ort.py .\\models\\body3d_full.onnx\r\n0.04198937177658081\r\n```\r\n\r\nthe inputs changed to according fp16 already, but the fp16 speed slower than fp32, am using latest 1.14.1 python version.\r\n \r\nSame bahavior on C++ side, Please take a look!! @microsoft @faxu",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1514585065/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1515123949",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15585#issuecomment-1515123949",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15585",
        "id": 1515123949,
        "node_id": "IC_kwDOCVq1mM5aTvTt",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-19T17:40:26Z",
        "updated_at": "2023-04-19T17:40:26Z",
        "author_association": "MEMBER",
        "body": "@jinfagang, you will need run some profiling:\r\nhttps://onnxruntime.ai/docs/performance/tune-performance/profiling-tools.html\r\nand Nvidia profiling tools like nvprof, nsight etc.\r\n\r\nPossible cause: some nodes are placed in CPU after converting to fp16; ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1515123949/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1515626435",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15585#issuecomment-1515626435",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15585",
        "id": 1515626435,
        "node_id": "IC_kwDOCVq1mM5aVp_D",
        "user": {
            "login": "lucasjinreal",
            "id": 21303438,
            "node_id": "MDQ6VXNlcjIxMzAzNDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21303438?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lucasjinreal",
            "html_url": "https://github.com/lucasjinreal",
            "followers_url": "https://api.github.com/users/lucasjinreal/followers",
            "following_url": "https://api.github.com/users/lucasjinreal/following{/other_user}",
            "gists_url": "https://api.github.com/users/lucasjinreal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lucasjinreal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lucasjinreal/subscriptions",
            "organizations_url": "https://api.github.com/users/lucasjinreal/orgs",
            "repos_url": "https://api.github.com/users/lucasjinreal/repos",
            "events_url": "https://api.github.com/users/lucasjinreal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lucasjinreal/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-20T02:33:53Z",
        "updated_at": "2023-04-20T02:33:53Z",
        "author_association": "NONE",
        "body": "@tianleiwu hi, thanks, I profiled the model, found no CPU ops, all runing on CUDA, we might need a futher look?\r\n\r\n![image](https://user-images.githubusercontent.com/21303438/233242736-b3ef8ad1-630a-4dd7-85aa-f8ae169152ae.png)\r\n\r\nBTW, the model is a very simple conv: hrnetw48 widely used in pose estimation.\r\n\r\nAnd my GPU is 2060.\r\n\r\nPlease give me some more advise.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1515626435/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1516948100",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15585#issuecomment-1516948100",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15585",
        "id": 1516948100,
        "node_id": "IC_kwDOCVq1mM5aasqE",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-20T21:05:14Z",
        "updated_at": "2023-04-20T21:05:14Z",
        "author_association": "MEMBER",
        "body": "@lucasjinreal, a few things to do:\r\n(1) Test script shall skip the first inference (since it will trigger cudnn algorithm search), then measure 1000 inferences to get average latency.\r\n(2) Compare the profiling results of FP32 and FP16 to see latency of same Conv node.\r\n\r\nThe CUDA EP uses cuDNN for convolution.\r\n\r\nYou might also try [TensorRT EP](https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1516948100/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]