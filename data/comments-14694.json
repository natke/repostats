[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1434340144",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14694#issuecomment-1434340144",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14694",
        "id": 1434340144,
        "node_id": "IC_kwDOCVq1mM5Vfksw",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-02-17T09:03:33Z",
        "updated_at": "2023-02-17T09:16:36Z",
        "author_association": "MEMBER",
        "body": "The transformer optimizer script has limitations. For example prune graph does not work when there is subgraph: see [here](https://github.com/microsoft/onnxruntime/blob/0dda42b46cd491f5b658d291078cd81388c1db5a/onnxruntime/python/tools/transformers/onnx_model.py#L763).\r\n\r\nA walkaround is to optimize decoder model and decoder with past state separately. Example of export and optimize two models separately:\r\nhttps://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/models/t5/convert_to_onnx.py\r\n\r\nThen combine them into subgraphs (and also consolidate weights since two subgraphs share some weights) . An example of such approach is a script that converts GPT2 or T5 to use beam search:\r\nhttps://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/convert_generation.py\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1434340144/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1434667414",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14694#issuecomment-1434667414",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14694",
        "id": 1434667414,
        "node_id": "IC_kwDOCVq1mM5Vg0mW",
        "user": {
            "login": "fxmarty",
            "id": 9808326,
            "node_id": "MDQ6VXNlcjk4MDgzMjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9808326?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fxmarty",
            "html_url": "https://github.com/fxmarty",
            "followers_url": "https://api.github.com/users/fxmarty/followers",
            "following_url": "https://api.github.com/users/fxmarty/following{/other_user}",
            "gists_url": "https://api.github.com/users/fxmarty/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fxmarty/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fxmarty/subscriptions",
            "organizations_url": "https://api.github.com/users/fxmarty/orgs",
            "repos_url": "https://api.github.com/users/fxmarty/repos",
            "events_url": "https://api.github.com/users/fxmarty/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fxmarty/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-02-17T13:42:14Z",
        "updated_at": "2023-02-17T13:42:14Z",
        "author_association": "CONTRIBUTOR",
        "body": "@tianleiwu Thanks a lot for your answer! So if I understand correctly, an optimization that is normally done when `ort.GraphOptimizationLevel>=ORT_ENABLE_BASIC` is not performed when having subgraphs, and thus the `CleanUnusedInitializersAndNodeArgs` warnings are triggered at a later stage only when the ONNX has subgraphs?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1434667414/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1435342259",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14694#issuecomment-1435342259",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14694",
        "id": 1435342259,
        "node_id": "IC_kwDOCVq1mM5VjZWz",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-02-17T22:21:18Z",
        "updated_at": "2023-02-17T22:21:18Z",
        "author_association": "MEMBER",
        "body": "@fxmarty,\r\n\r\nYou can try load the model and save optimized model from onnxruntime. When you create session option, there is a field to export optimized model path.  Example code:\r\nhttps://github.com/microsoft/onnxruntime/blob/8372c86e7f15ed0d8d47e1e0afc115c30db39252/onnxruntime/python/tools/transformers/optimizer.py#L104\r\n\r\nI think that shall be able to remove unused initializer.\r\n\r\nTo fix the root cause, that need update the transformers optimizer script to handle subgraph nicely. We can add this to our backlog.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1435342259/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1598429295",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/14694#issuecomment-1598429295",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/14694",
        "id": 1598429295,
        "node_id": "IC_kwDOCVq1mM5fRhhv",
        "user": {
            "login": "veriff-javiervgd",
            "id": 98743827,
            "node_id": "U_kgDOBeK2Ew",
            "avatar_url": "https://avatars.githubusercontent.com/u/98743827?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/veriff-javiervgd",
            "html_url": "https://github.com/veriff-javiervgd",
            "followers_url": "https://api.github.com/users/veriff-javiervgd/followers",
            "following_url": "https://api.github.com/users/veriff-javiervgd/following{/other_user}",
            "gists_url": "https://api.github.com/users/veriff-javiervgd/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/veriff-javiervgd/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/veriff-javiervgd/subscriptions",
            "organizations_url": "https://api.github.com/users/veriff-javiervgd/orgs",
            "repos_url": "https://api.github.com/users/veriff-javiervgd/repos",
            "events_url": "https://api.github.com/users/veriff-javiervgd/events{/privacy}",
            "received_events_url": "https://api.github.com/users/veriff-javiervgd/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-20T09:26:10Z",
        "updated_at": "2023-06-20T09:26:10Z",
        "author_association": "NONE",
        "body": "This warning has to do with [graph level optimization](https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html) in the `onnxruntime` session. ONNX has 3 levels of graph optimization: Basic, Extended and Layout Optimizations. You can define your optimization level with the following enums:\r\n\r\n```\r\nonnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\r\nonnxruntime.GraphOptimizationLevel.ORT_ENABLE_BASIC\r\nonnxruntime.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\r\nonnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n```\r\n\r\nIf you disable graph optimizations, `ORT_DISABLE_ALL`,  in the session's options then you will remove those warnings:\r\n\r\n```python\r\n# Session options\r\nsess_options = onnxruntime.SessionOptions()\r\nsess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\r\n\r\n# ONNX session setup\r\nsession = onnxruntime.InferenceSession(\r\n    \"model.onnx\", \r\n    providers=[\"CPUExecutionProvider\"], \r\n    sess_options=sess_options\r\n)\r\n```\r\n\r\nAnother way is to use the default graph optimization and just to increase the severity of the logger to filter out noisy warnings:\r\n\r\n```python\r\n# Session options\r\nsess_options = onnxruntime.SessionOptions()\r\nsess_options.log_severity_level = 3\r\n\r\n# ONNX session setup\r\nsession = onnxruntime.InferenceSession(\r\n    \"model.onnx\", \r\n    providers=[\"CPUExecutionProvider\"], \r\n    sess_options=sess_options\r\n)\r\n```\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1598429295/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]