[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1474763724",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15106#issuecomment-1474763724",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15106",
        "id": 1474763724,
        "node_id": "IC_kwDOCVq1mM5X5xvM",
        "user": {
            "login": "anonymoussky",
            "id": 124943617,
            "node_id": "U_kgDOB3J9AQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/124943617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anonymoussky",
            "html_url": "https://github.com/anonymoussky",
            "followers_url": "https://api.github.com/users/anonymoussky/followers",
            "following_url": "https://api.github.com/users/anonymoussky/following{/other_user}",
            "gists_url": "https://api.github.com/users/anonymoussky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anonymoussky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anonymoussky/subscriptions",
            "organizations_url": "https://api.github.com/users/anonymoussky/orgs",
            "repos_url": "https://api.github.com/users/anonymoussky/repos",
            "events_url": "https://api.github.com/users/anonymoussky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anonymoussky/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-18T07:47:55Z",
        "updated_at": "2023-03-18T07:49:54Z",
        "author_association": "NONE",
        "body": "\"quantize_static(output_filename,output_filename[:-4]+\"int8_static_aUwS_U8S8_NOatt_cmn2fr_cacheint8_QOperator.onnx\",weight_type=QuantType.QInt8,activation_type=QuantType.QUInt8,calibration_data_reader=dr, quant_format=QuantFormat.QOperator)\"\r\n\r\n            quant_format: QuantFormat{QOperator, QDQ}.\r\n                QOperator format quantizes the model with quantized operators directly.\r\n                QDQ format quantize the model by inserting QuantizeLinear/DeQuantizeLinear on the tensor.\r\n\r\nIt looks like \"quant_format=QuantFormat.QOperator\" will cost less memory than \"quant_format=QuantFormat.QDQ\", but it still consumes a lot of memory. Are there any other parameters that I need to set to consume much less memory?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1474763724/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1475476344",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15106#issuecomment-1475476344",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15106",
        "id": 1475476344,
        "node_id": "IC_kwDOCVq1mM5X8ft4",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-20T01:18:41Z",
        "updated_at": "2023-03-20T01:18:41Z",
        "author_association": "MEMBER",
        "body": "Could you please try disabling arena: https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.SessionOptions.enable_cpu_mem_arena",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1475476344/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1475720927",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15106#issuecomment-1475720927",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15106",
        "id": 1475720927,
        "node_id": "IC_kwDOCVq1mM5X9bbf",
        "user": {
            "login": "anonymoussky",
            "id": 124943617,
            "node_id": "U_kgDOB3J9AQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/124943617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anonymoussky",
            "html_url": "https://github.com/anonymoussky",
            "followers_url": "https://api.github.com/users/anonymoussky/followers",
            "following_url": "https://api.github.com/users/anonymoussky/following{/other_user}",
            "gists_url": "https://api.github.com/users/anonymoussky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anonymoussky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anonymoussky/subscriptions",
            "organizations_url": "https://api.github.com/users/anonymoussky/orgs",
            "repos_url": "https://api.github.com/users/anonymoussky/repos",
            "events_url": "https://api.github.com/users/anonymoussky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anonymoussky/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-20T07:04:12Z",
        "updated_at": "2023-03-20T07:05:35Z",
        "author_association": "NONE",
        "body": "> Could you please try disabling arena: https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.SessionOptions.enable_cpu_mem_arena\r\n\r\nThank you so much for your reply. Could you please tell me how to disable arena or point out to me an example somewhere. BTW, there are some other options: enable_cpu_mem_arena,  enable_mem_pattern,  enable_mem_pattern, should I disable all of them?\r\n\r\nI try to use quantize_static to quantize the fp32 model into int8 model as below. Is the following code correct to disable arena? thank you\r\n\r\n    from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat\r\n    options = ort.SessionOptions()\r\n    options.enable_cpu_mem_arena=False\r\n\r\n    dr = RandomDataReader()\r\n    quantize_static(output_filename,output_filename[:-4]+\"int8_static_aUwS_U8S8_att99fr_cmn200fr_cacheint8_QOperator_memArenaFalse.onnx\",weight_type=QuantType.QInt8,activation_type=QuantType.QUInt8,calibration_data_reader=dr, quant_format=QuantFormat.QOperator)\r\n    os.system(\"python -m onnxruntime.tools.convert_onnx_models_to_ort --optimization_style Fixed --target_platform arm --enable_type_reduction exp/tavs_net/debug\")\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1475720927/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1480561345",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15106#issuecomment-1480561345",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15106",
        "id": 1480561345,
        "node_id": "IC_kwDOCVq1mM5YP5LB",
        "user": {
            "login": "jchen351",
            "id": 73297588,
            "node_id": "MDQ6VXNlcjczMjk3NTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/73297588?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jchen351",
            "html_url": "https://github.com/jchen351",
            "followers_url": "https://api.github.com/users/jchen351/followers",
            "following_url": "https://api.github.com/users/jchen351/following{/other_user}",
            "gists_url": "https://api.github.com/users/jchen351/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jchen351/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jchen351/subscriptions",
            "organizations_url": "https://api.github.com/users/jchen351/orgs",
            "repos_url": "https://api.github.com/users/jchen351/repos",
            "events_url": "https://api.github.com/users/jchen351/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jchen351/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-23T03:49:14Z",
        "updated_at": "2023-03-23T03:49:14Z",
        "author_association": "MEMBER",
        "body": "@anonymoussky  Can you try optimize your model file via InferenceSession with SessionOptions() and than quantize the model?\r\n``` python\r\n# First optimize your model file via InferenceSession with SessionOptions()\r\nfrom onnxruntime import InferenceSession, SessionOptions\r\nsess_option = SessionOptions()\r\nsess_option.optimized_model_filepath = optimized_filename\r\nsess_option.enable_cpu_mem_arena = False\r\n_ = InferenceSession(original_filename, sess_option, providers=[\"CPUExecutionProvider\"])\r\n# Then quantize using your example\r\ndr = RandomDataReader()\r\nquantize_static(optimized_filename, optimized_filename[:-4]+\"int8_static_aUwS_U8S8_att99fr_cmn200fr_cacheint8_QOperator_memArenaFalse.onnx\",weight_type=QuantType.QInt8,activation_type=QuantType.QUInt8,calibration_data_reader=dr, quant_format=QuantFormat.QOperator)\r\n# ...\r\n```\r\nPlease let me know if that helps. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1480561345/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1487469835",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15106#issuecomment-1487469835",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15106",
        "id": 1487469835,
        "node_id": "IC_kwDOCVq1mM5YqP0L",
        "user": {
            "login": "anonymoussky",
            "id": 124943617,
            "node_id": "U_kgDOB3J9AQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/124943617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anonymoussky",
            "html_url": "https://github.com/anonymoussky",
            "followers_url": "https://api.github.com/users/anonymoussky/followers",
            "following_url": "https://api.github.com/users/anonymoussky/following{/other_user}",
            "gists_url": "https://api.github.com/users/anonymoussky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anonymoussky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anonymoussky/subscriptions",
            "organizations_url": "https://api.github.com/users/anonymoussky/orgs",
            "repos_url": "https://api.github.com/users/anonymoussky/repos",
            "events_url": "https://api.github.com/users/anonymoussky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anonymoussky/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-28T19:15:40Z",
        "updated_at": "2023-03-28T19:15:40Z",
        "author_association": "NONE",
        "body": "> @anonymoussky Can you try optimize your model file via InferenceSession with SessionOptions() and than quantize the model?\r\n> \r\n> ```python\r\n> # First optimize your model file via InferenceSession with SessionOptions()\r\n> from onnxruntime import InferenceSession, SessionOptions\r\n> sess_option = SessionOptions()\r\n> sess_option.optimized_model_filepath = optimized_filename\r\n> sess_option.enable_cpu_mem_arena = False\r\n> _ = InferenceSession(original_filename, sess_option, providers=[\"CPUExecutionProvider\"])\r\n> # Then quantize using your example\r\n> dr = RandomDataReader()\r\n> quantize_static(optimized_filename, optimized_filename[:-4]+\"int8_static_aUwS_U8S8_att99fr_cmn200fr_cacheint8_QOperator_memArenaFalse.onnx\",weight_type=QuantType.QInt8,activation_type=QuantType.QUInt8,calibration_data_reader=dr, quant_format=QuantFormat.QOperator)\r\n> # ...\r\n> ```\r\n> \r\n> Please let me know if that helps.\r\n\r\nThank you very much for your help. However, the runtime model still consumes same level of dynamic usage memory on CPU even I disable arena as you suggested. Meanwhile, I import my onnx model into https://netron.app/.  There are lots of dequantization operations (convert back from int8 to fp32), and some operations, e.g., softmax, is operated on fp32, rather than int8. Could you guide me how to convert the model in a fully int8 operations? Thank you ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1487469835/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]