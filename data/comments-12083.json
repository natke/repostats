[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175382124",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1175382124",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1175382124,
        "node_id": "IC_kwDOCVq1mM5GDuhs",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-05T18:48:20Z",
        "updated_at": "2022-07-05T18:48:20Z",
        "author_association": "CONTRIBUTOR",
        "body": "TensorRT EP can achieve performance parity with native TensorRT. One of the benefits to use TensorRT EP is to run models that can't run in native TensorRT if there are TensorRT unsupported ops in the model. Those ops will fallback to other EPs like CUDA or CPU in OnnxRuntime automatically.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175382124/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175718549",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1175718549",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1175718549,
        "node_id": "IC_kwDOCVq1mM5GFAqV",
        "user": {
            "login": "hafidh561",
            "id": 46504516,
            "node_id": "MDQ6VXNlcjQ2NTA0NTE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/46504516?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hafidh561",
            "html_url": "https://github.com/hafidh561",
            "followers_url": "https://api.github.com/users/hafidh561/followers",
            "following_url": "https://api.github.com/users/hafidh561/following{/other_user}",
            "gists_url": "https://api.github.com/users/hafidh561/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hafidh561/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hafidh561/subscriptions",
            "organizations_url": "https://api.github.com/users/hafidh561/orgs",
            "repos_url": "https://api.github.com/users/hafidh561/repos",
            "events_url": "https://api.github.com/users/hafidh561/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hafidh561/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-06T02:47:27Z",
        "updated_at": "2022-07-06T02:47:27Z",
        "author_association": "NONE",
        "body": "> TensorRT EP can achieve performance parity with native TensorRT. One of the benefits to use TensorRT EP is to run models that can't run in native TensorRT if there are TensorRT unsupported ops in the model. Those ops will fallback to other EPs like CUDA or CPU in OnnxRuntime automatically.\r\n\r\nIs there any benchmark for it?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175718549/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1254935311",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1254935311",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1254935311,
        "node_id": "IC_kwDOCVq1mM5KzMsP",
        "user": {
            "login": "fxmarty",
            "id": 9808326,
            "node_id": "MDQ6VXNlcjk4MDgzMjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9808326?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fxmarty",
            "html_url": "https://github.com/fxmarty",
            "followers_url": "https://api.github.com/users/fxmarty/followers",
            "following_url": "https://api.github.com/users/fxmarty/following{/other_user}",
            "gists_url": "https://api.github.com/users/fxmarty/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fxmarty/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fxmarty/subscriptions",
            "organizations_url": "https://api.github.com/users/fxmarty/orgs",
            "repos_url": "https://api.github.com/users/fxmarty/repos",
            "events_url": "https://api.github.com/users/fxmarty/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fxmarty/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-22T12:11:47Z",
        "updated_at": "2022-09-22T12:11:47Z",
        "author_association": "CONTRIBUTOR",
        "body": "Any reproducible benchmark on this?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1254935311/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1285425725",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1285425725",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1285425725,
        "node_id": "IC_kwDOCVq1mM5Mngo9",
        "user": {
            "login": "fxmarty",
            "id": 9808326,
            "node_id": "MDQ6VXNlcjk4MDgzMjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9808326?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fxmarty",
            "html_url": "https://github.com/fxmarty",
            "followers_url": "https://api.github.com/users/fxmarty/followers",
            "following_url": "https://api.github.com/users/fxmarty/following{/other_user}",
            "gists_url": "https://api.github.com/users/fxmarty/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fxmarty/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fxmarty/subscriptions",
            "organizations_url": "https://api.github.com/users/fxmarty/orgs",
            "repos_url": "https://api.github.com/users/fxmarty/repos",
            "events_url": "https://api.github.com/users/fxmarty/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fxmarty/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-20T12:09:46Z",
        "updated_at": "2022-10-20T12:09:46Z",
        "author_association": "CONTRIBUTOR",
        "body": "@pommedeterresautee Maybe you have some insights on this? I read https://github.com/ELS-RD/transformer-deploy/blob/d397869e95ee07570c47edefec01bdc673391b65/docs/faq.md#why-dont-you-support-gpu-quantization-on-onnx-runtime-instead-of-tensorrt , but it's not clear to me why ONNX Runtime + `TensorrtExecutionProvider` would be worse than Tensor RT native, given that you start from an onnx QDQ model? I had no issue with fp32 and int8 (static) quantized models with the Tensor RT execution provider.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1285425725/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]