[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/717428024",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/5586#issuecomment-717428024",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/5586",
        "id": 717428024,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcxNzQyODAyNA==",
        "user": {
            "login": "xuhao1",
            "id": 5087930,
            "node_id": "MDQ6VXNlcjUwODc5MzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5087930?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xuhao1",
            "html_url": "https://github.com/xuhao1",
            "followers_url": "https://api.github.com/users/xuhao1/followers",
            "following_url": "https://api.github.com/users/xuhao1/following{/other_user}",
            "gists_url": "https://api.github.com/users/xuhao1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xuhao1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xuhao1/subscriptions",
            "organizations_url": "https://api.github.com/users/xuhao1/orgs",
            "repos_url": "https://api.github.com/users/xuhao1/repos",
            "events_url": "https://api.github.com/users/xuhao1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xuhao1/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-10-27T18:10:56Z",
        "updated_at": "2020-10-27T18:12:28Z",
        "author_association": "NONE",
        "body": "> **Describe the bug**\r\n> Attempting to perform static quantization on a model fails with the following error:\r\n> \r\n> ```\r\n> [...]\r\n>   File \"/home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/calibrate.py\", line 175, in calculate_scale_zeropoint\r\n>     clip_min = next_node.attribute[0].f\r\n> IndexError: list index (0) out of range\r\n> ```\r\n> \r\n> **Urgency**\r\n> none\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Linux\r\n> * ONNX Runtime installed from (source or binary): binary installed with pip3\r\n> * ONNX Runtime version: 1.5.2\r\n> * Python version: 3.7.3\r\n> * Visual Studio version (if applicable): not applicable\r\n> * GCC/Compiler version (if compiling from source): not applicable\r\n> * CUDA/cuDNN version: not applicable\r\n> * GPU model and memory: not applicable\r\n> \r\n> **To Reproduce**\r\n> I used this code to perform the quantization:\r\n> \r\n> ```\r\n> import onnx\r\n> from onnxruntime.quantization import quantize_dynamic, QuantType\r\n> from onnxruntime.quantization import quantize_static, calibrate, CalibrationDataReader\r\n> import cv2\r\n> import numpy as np\r\n> \r\n> \r\n> class NFDataReader(CalibrationDataReader):\r\n>     def __init__(self):\r\n>         self.augmented_model_path = \"augmented_model.onnx\"\r\n>         self.enum_data_dicts = []\r\n>         self.datasize = 0\r\n>         mean = np.float32(np.array([0.485, 0.456, 0.406]))\r\n>         std = np.float32(np.array([0.229, 0.224, 0.225]))\r\n>         mean = mean / std\r\n>         std = std * 255.0\r\n> \r\n>         for i in range(1):\r\n>             image = cv2.imread(f\"{i}.png\")\r\n>             image = image[:,:,::-1] * 1 / std - mean\r\n>             image = np.expand_dims(image, 0).astype(np.float32)\r\n>             image = np.transpose(image, (0,3,1,2))\r\n>             self.enum_data_dicts.append({\"input\": image})\r\n>         self.datasize = len(self.enum_data_dicts)\r\n>         self.enum_data_dicts = iter(self.enum_data_dicts)\r\n> \r\n>     def get_next(self):\r\n>         return next(self.enum_data_dicts, None)\r\n> \r\n> model_fp32 = 'lm_model3.onnx'\r\n> model_quant = 'lm_model3_quant.onnx'\r\n> # run it\r\n> dr = NFDataReader()\r\n> quantized_model = quantize_static(model_input=model_fp32, model_output=model_quant, calibration_data_reader=dr, weight_type=QuantType.QUInt8)\r\n> ```\r\n> \r\n> Running the code without the `np.transpose` line and an adjusted input name works for the resnet model provided [here](https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/quantization/E2E_example_model) so the issue seems to be model dependent.\r\n> \r\n> The attached zip file ([quant.zip](https://github.com/microsoft/onnxruntime/files/5434798/quant.zip)) contains the original ONNX model, the png file as well as the code.\r\n> \r\n> **Expected behavior**\r\n> I expected a quantized model to be produced rather than an error to occur.\r\n> \r\n> **Screenshots**\r\n> The full stack trace:\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"quant_model.py\", line 34, in <module>\r\n>     quantized_model = quantize_static(model_input=model_fp32, model_output=model_quant, calibration_data_reader=dr, weight_type=QuantType.QUInt8)\r\n>   File \"/home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/quantize.py\", line 171, in quantize_static\r\n>     nodes_to_exclude)\r\n>   File \"/home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/calibrate.py\", line 260, in calibrate\r\n>     quantization_params_dict = calibrater.calculate_quantization_params(dict_for_quantization)\r\n>   File \"/home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/calibrate.py\", line 230, in calculate_quantization_params\r\n>     node_params = self.calculate_scale_zeropoint(child, node_thresholds[0], node_thresholds[1])\r\n>   File \"/home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/calibrate.py\", line 175, in calculate_scale_zeropoint\r\n>     clip_min = next_node.attribute[0].f\r\n> IndexError: list index (0) out of range\r\n> ```\r\n> \r\n> **Additional context**\r\n> \r\n> The model was originally converted from pytorch using opset 11. It has a MobileNet V3 backend based on the geffnet implementation, with UNet-like layers on top to do heatmap regression, containing Conv2D and bilinear upscale layers. The definition of the model (it uses `inference=False`) can be found [here](https://github.com/emilianavt/OpenSeeFace/blob/e18598cc4a321cfd64ef27283b8b8f8464b3980a/model.py#L134). Other than static quantization, the ONNX model works fine with onnxruntime.\r\n\r\nI also found this issue when quantize landmark model in OpenSeeFace, and I solved it by hard code the source code of home/emiliana/env/lib/python3.7/site-packages/onnxruntime/quantization/calibrate.py to clip min = 0, max = 6 since in your network, all clip is from 0 to 6.\r\n\r\nIn addition, ONNX quant does not speed up the landmark model at all on my cpu(E5) but makes result worse even after calibration with whole dataset.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/717428024/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/745217274",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/5586#issuecomment-745217274",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/5586",
        "id": 745217274,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc0NTIxNzI3NA==",
        "user": {
            "login": "j-paulus",
            "id": 20085087,
            "node_id": "MDQ6VXNlcjIwMDg1MDg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/20085087?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/j-paulus",
            "html_url": "https://github.com/j-paulus",
            "followers_url": "https://api.github.com/users/j-paulus/followers",
            "following_url": "https://api.github.com/users/j-paulus/following{/other_user}",
            "gists_url": "https://api.github.com/users/j-paulus/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/j-paulus/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/j-paulus/subscriptions",
            "organizations_url": "https://api.github.com/users/j-paulus/orgs",
            "repos_url": "https://api.github.com/users/j-paulus/repos",
            "events_url": "https://api.github.com/users/j-paulus/events{/privacy}",
            "received_events_url": "https://api.github.com/users/j-paulus/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-12-15T11:04:05Z",
        "updated_at": "2020-12-15T11:05:31Z",
        "author_association": "NONE",
        "body": "I can confirm the bug. It is possible to reproduce it by modifying the example from #5499 with an additional clamp() operation in the model:\r\n\r\n```\r\nimport numpy as np\r\nimport torch\r\nfrom onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType\r\nfrom onnxruntime.quantization.calibrate import CalibrationDataReader\r\n\r\nclass CalibrationDataProvider(CalibrationDataReader):\r\n    def __init__(self):\r\n        super(CalibrationDataProvider, self).__init__()\r\n        self.counter = 0\r\n\r\n    def get_next(self):\r\n        if self.counter > 2:\r\n            return None\r\n        else:\r\n            self.counter += 1\r\n            return {'x': np.random.randn(2, 4).astype(np.float32)}\r\n\r\nclass Model(torch.nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.n = int(1)\r\n\r\n    def forward(self, x):\r\n        f = x.shape[0]\r\n        y = x.reshape(-1, f)\r\n        z = y.clamp(min=-1.0, max=1.0)  # this is the problem now\r\n        return z\r\n\r\nmodel = Model().float()\r\n\r\ndummy_input = (torch.randn(2, 4), )\r\ntorch.onnx.export(\r\n    model,\r\n    dummy_input,\r\n    'model.onnx',\r\n    input_names=('x',),\r\n    export_params=True,\r\n    training=False,\r\n    opset_version=11)\r\n\r\ncdr = CalibrationDataProvider()\r\n\r\nquantize_static(model_input='model.onnx',\r\n                model_output='model_q.onnx',\r\n                calibration_data_reader=cdr)\r\n```\r\n\r\nThis simple model shows that the `Clip`-node has an empty `attributes` list and the `min` and `max` parameters are in fact additional inputs. Maybe this is relevant for the bug.\r\n\r\nONNX Runtime version 1.6.0.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/745217274/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/775618149",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/5586#issuecomment-775618149",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/5586",
        "id": 775618149,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3NTYxODE0OQ==",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-09T02:51:11Z",
        "updated_at": "2021-02-09T02:51:11Z",
        "author_association": "MEMBER",
        "body": "Fixed in #6541 ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/775618149/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]