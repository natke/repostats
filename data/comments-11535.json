[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1127926475",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11535#issuecomment-1127926475",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11535",
        "id": 1127926475,
        "node_id": "IC_kwDOCVq1mM5DOsrL",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-16T17:13:27Z",
        "updated_at": "2022-05-16T17:13:27Z",
        "author_association": "MEMBER",
        "body": "Please disable ORT optimization in session option as below,\r\nsess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1127926475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1128073029",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11535#issuecomment-1128073029",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11535",
        "id": 1128073029,
        "node_id": "IC_kwDOCVq1mM5DPQdF",
        "user": {
            "login": "PeterZhizhin",
            "id": 5682184,
            "node_id": "MDQ6VXNlcjU2ODIxODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5682184?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PeterZhizhin",
            "html_url": "https://github.com/PeterZhizhin",
            "followers_url": "https://api.github.com/users/PeterZhizhin/followers",
            "following_url": "https://api.github.com/users/PeterZhizhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/PeterZhizhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PeterZhizhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PeterZhizhin/subscriptions",
            "organizations_url": "https://api.github.com/users/PeterZhizhin/orgs",
            "repos_url": "https://api.github.com/users/PeterZhizhin/repos",
            "events_url": "https://api.github.com/users/PeterZhizhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PeterZhizhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-16T19:52:07Z",
        "updated_at": "2022-05-16T19:52:30Z",
        "author_association": "NONE",
        "body": "Same problem. Here is the updated script and it's output:\r\n```\r\n$ python3.8 test_crash.py  transformer_encoder_layer_shape_inferred_quantized.onnx \r\n2022-05-16 22:38:44.582468528 [W:onnxruntime:Default, tensorrt_execution_provider.h:59 log] [2022-05-16 19:38:44 WARNING] external/onnx-tensorrt/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n2022-05-16 22:38:44.583072461 [E:onnxruntime:Default, tensorrt_execution_provider.h:57 log] [2022-05-16 19:38:44   ERROR] layer.fc2.bias_quantized: invalid weights type of Int8\r\nSegmentation fault\r\n```\r\n\r\nHere is the script:\r\n```python\r\nimport onnxruntime as rt\r\nimport argparse\r\nimport os\r\n\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('model_path', default='transformer_encoder_layer_shape_inferred_quantized.onnx')\r\n    parser.add_argument('--cuda-device', type=int, default=None)\r\n    return parser.parse_args()\r\n\r\n\r\ndef main():\r\n    args = parse_args()\r\n\r\n    if args.cuda_device is not None:\r\n        os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda_device)\r\n\r\n    os.environ['ORT_TENSORRT_INT8_ENABLE'] = '1'\r\n\r\n    session_options = rt.SessionOptions()\r\n    session_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_DISABLE_ALL\r\n    session = rt.InferenceSession(args.model_path, session_options, ['TensorrtExecutionProvider'])\r\n\r\n    print('Success!')\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nHere is how the graph looks like in Netron, the problematic block is on the left of the `Add` operation.\r\n![image](https://user-images.githubusercontent.com/5682184/168669878-0894796f-93f8-47b2-a2df-71c3f5b9556b.png)\r\n\r\nHere is how the weights look like in the block, they are all `int8` weights:\r\n![image](https://user-images.githubusercontent.com/5682184/168670344-27fad4c4-a0d6-49fb-99d1-2325bd6f0bcb.png)\r\n\r\nSimilarly, all these operations don't have the Quantize-Dequantize chain, only Dequantize operation is there:\r\n![image](https://user-images.githubusercontent.com/5682184/168671347-59a9f608-d002-4301-a3b7-dd1ba3abe348.png)\r\n\r\n\r\nI have quantized a BERT model from Huggingface using this script: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/nlp/bert/trt/e2e_tensorrt_bert_example.py\r\nAnd looking at a similar operation from the `qdq_model.onnx` result there, the weights are `float32` in the output of the `e2e_tensorrt_bert_example.py`.\r\n![image](https://user-images.githubusercontent.com/5682184/168670790-ad1ff8a3-c163-49e4-b76e-fcd4bb91d57a.png)\r\n\r\nI don't know if it's connected, but it very well might be.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1128073029/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1128086125",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11535#issuecomment-1128086125",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11535",
        "id": 1128086125,
        "node_id": "IC_kwDOCVq1mM5DPTpt",
        "user": {
            "login": "PeterZhizhin",
            "id": 5682184,
            "node_id": "MDQ6VXNlcjU2ODIxODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5682184?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PeterZhizhin",
            "html_url": "https://github.com/PeterZhizhin",
            "followers_url": "https://api.github.com/users/PeterZhizhin/followers",
            "following_url": "https://api.github.com/users/PeterZhizhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/PeterZhizhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PeterZhizhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PeterZhizhin/subscriptions",
            "organizations_url": "https://api.github.com/users/PeterZhizhin/orgs",
            "repos_url": "https://api.github.com/users/PeterZhizhin/repos",
            "events_url": "https://api.github.com/users/PeterZhizhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PeterZhizhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-16T20:07:59Z",
        "updated_at": "2022-05-16T20:07:59Z",
        "author_association": "NONE",
        "body": "It works with adding `extra_options={'AddQDQPairToWeight': True}` to `onnxruntime.quantization.quantize_static`, but the model size is equal to the model with FP32 weights, is it expected?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1128086125/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]