[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070384534",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1070384534",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1070384534,
        "node_id": "IC_kwDOCVq1mM4_zMWW",
        "user": {
            "login": "wschin",
            "id": 3524474,
            "node_id": "MDQ6VXNlcjM1MjQ0NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3524474?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wschin",
            "html_url": "https://github.com/wschin",
            "followers_url": "https://api.github.com/users/wschin/followers",
            "following_url": "https://api.github.com/users/wschin/following{/other_user}",
            "gists_url": "https://api.github.com/users/wschin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wschin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wschin/subscriptions",
            "organizations_url": "https://api.github.com/users/wschin/orgs",
            "repos_url": "https://api.github.com/users/wschin/repos",
            "events_url": "https://api.github.com/users/wschin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wschin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T06:58:40Z",
        "updated_at": "2022-03-17T06:58:40Z",
        "author_association": "MEMBER",
        "body": "ORT has TensorRT as its execution provider. It means if you do\r\n```python\r\nexecution_providers = ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\r\nsession = onnxrunitme.InferenceSession(model_path, sess_options, providers=execution_providers)\r\n```\r\nTensorRT can be invoked and its unsupported ops will automatically fallback to ORT's CUDA kernels.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070384534/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070391426",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1070391426",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1070391426,
        "node_id": "IC_kwDOCVq1mM4_zOCC",
        "user": {
            "login": "jinfagang",
            "id": 21303438,
            "node_id": "MDQ6VXNlcjIxMzAzNDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21303438?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jinfagang",
            "html_url": "https://github.com/jinfagang",
            "followers_url": "https://api.github.com/users/jinfagang/followers",
            "following_url": "https://api.github.com/users/jinfagang/following{/other_user}",
            "gists_url": "https://api.github.com/users/jinfagang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jinfagang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jinfagang/subscriptions",
            "organizations_url": "https://api.github.com/users/jinfagang/orgs",
            "repos_url": "https://api.github.com/users/jinfagang/repos",
            "events_url": "https://api.github.com/users/jinfagang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jinfagang/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T07:10:42Z",
        "updated_at": "2022-03-17T07:11:02Z",
        "author_association": "NONE",
        "body": "@wschin  thanks, have u ever tested on a quantized GPT onnx model? I know it have tensorrt provider. Just want make sure does the ops I mentioned above supported or not?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1070391426/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1071088876",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1071088876",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1071088876,
        "node_id": "IC_kwDOCVq1mM4_14Ts",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T16:58:55Z",
        "updated_at": "2022-03-17T16:58:55Z",
        "author_association": "MEMBER",
        "body": "TRT doesn't support dynamic quantization. It supports static quantization with QDQ format. Here is an example: https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/nlp/bert/trt. TRT does performance optimization for BERT model, but not for GPT* yet.\r\n\r\n@stevenlix ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1071088876/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1071125282",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1071125282",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1071125282,
        "node_id": "IC_kwDOCVq1mM4_2BMi",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-17T17:29:05Z",
        "updated_at": "2022-03-17T17:29:41Z",
        "author_association": "MEMBER",
        "body": "GPT model quantization is planned to be supported in next TRT major release in this year. If you want to try BERT quantization in ORT-TRT, please follow the steps in above link. There are a few other examples for CNN models in the quantization directory.\r\nPlease don't use optimized models for CPU/CUDA in TRT since TRT has its own optimization approach and fused nodes for CPU/CUDA won't work in TRT.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1071125282/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1072091620",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1072091620",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1072091620,
        "node_id": "IC_kwDOCVq1mM4_5tHk",
        "user": {
            "login": "jinfagang",
            "id": 21303438,
            "node_id": "MDQ6VXNlcjIxMzAzNDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/21303438?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jinfagang",
            "html_url": "https://github.com/jinfagang",
            "followers_url": "https://api.github.com/users/jinfagang/followers",
            "following_url": "https://api.github.com/users/jinfagang/following{/other_user}",
            "gists_url": "https://api.github.com/users/jinfagang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jinfagang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jinfagang/subscriptions",
            "organizations_url": "https://api.github.com/users/jinfagang/orgs",
            "repos_url": "https://api.github.com/users/jinfagang/repos",
            "events_url": "https://api.github.com/users/jinfagang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jinfagang/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-18T07:14:53Z",
        "updated_at": "2022-03-18T07:14:53Z",
        "author_association": "NONE",
        "body": "@stevenlix  thanks for the information, that sounds very promising! When would be the next TensorRT major comes out?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1072091620/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257702711",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10888#issuecomment-1257702711",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10888",
        "id": 1257702711,
        "node_id": "IC_kwDOCVq1mM5K9wU3",
        "user": {
            "login": "fxmarty",
            "id": 9808326,
            "node_id": "MDQ6VXNlcjk4MDgzMjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9808326?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fxmarty",
            "html_url": "https://github.com/fxmarty",
            "followers_url": "https://api.github.com/users/fxmarty/followers",
            "following_url": "https://api.github.com/users/fxmarty/following{/other_user}",
            "gists_url": "https://api.github.com/users/fxmarty/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fxmarty/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fxmarty/subscriptions",
            "organizations_url": "https://api.github.com/users/fxmarty/orgs",
            "repos_url": "https://api.github.com/users/fxmarty/repos",
            "events_url": "https://api.github.com/users/fxmarty/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fxmarty/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-09-26T08:47:33Z",
        "updated_at": "2022-09-26T08:47:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "> TRT doesn't support dynamic quantization. It supports static quantization with QDQ format. Here is an example: https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/nlp/bert/trt. TRT does performance optimization for BERT model, but not for GPT* yet.\r\n> \r\n> @stevenlix\r\n\r\nAny idea why is that @yufenglee ? Maybe because operations as `MatMulInteger` can not be consumed by Tensor RT? Would the PR for QDQ for dynamic quantization https://github.com/microsoft/onnxruntime/pull/12705 allow dynamically quantized models to be used with TRT?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1257702711/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]