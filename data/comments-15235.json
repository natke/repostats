[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1487609280",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1487609280",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1487609280,
        "node_id": "IC_kwDOCVq1mM5Yqx3A",
        "user": {
            "login": "guschmue",
            "id": 22941064,
            "node_id": "MDQ6VXNlcjIyOTQxMDY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/22941064?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guschmue",
            "html_url": "https://github.com/guschmue",
            "followers_url": "https://api.github.com/users/guschmue/followers",
            "following_url": "https://api.github.com/users/guschmue/following{/other_user}",
            "gists_url": "https://api.github.com/users/guschmue/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guschmue/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guschmue/subscriptions",
            "organizations_url": "https://api.github.com/users/guschmue/orgs",
            "repos_url": "https://api.github.com/users/guschmue/repos",
            "events_url": "https://api.github.com/users/guschmue/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guschmue/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-28T21:21:47Z",
        "updated_at": "2023-03-28T21:21:47Z",
        "author_association": "MEMBER",
        "body": "If you can use python the code below should work.\r\nFor everything else you'd need to implement beam search and pre-processing. There is a good example here:\r\nhttps://xenova.github.io/transformers.js/\r\n\r\nIn 1-2 weeks we'll have some model that combines everything into a single model.\r\n\r\n```\r\nimport argparse\r\nimport numpy as np\r\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\r\nfrom optimum.onnxruntime import ORTModelForSpeechSeq2Seq\r\nfrom transformers import AutoProcessor, pipeline\r\nfrom datasets import load_dataset\r\n\r\n\r\ndef run_whisper(model_name, use_onnx=False):\r\n    # load model and processor\r\n    if use_onnx:\r\n        model_path = f\"optimum/whisper-{model_name}.en\"\r\n        # processor = AutoProcessor.from_pretrained(model_path)\r\n        processor = WhisperProcessor.from_pretrained(model_path)\r\n        model = ORTModelForSpeechSeq2Seq.from_pretrained(model_path)\r\n        model.config.forced_decoder_ids = None\r\n    else:\r\n        model_path = f\"openai/whisper-{model_name}.en\"\r\n        processor = WhisperProcessor.from_pretrained(model_path)\r\n        model = WhisperForConditionalGeneration.from_pretrained(model_path)\r\n        model.config.forced_decoder_ids = None\r\n\r\n    # load dummy dataset and read audio files\r\n    ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\r\n\r\n    for i in range(0, 5):\r\n        sample = ds[i][\"audio\"]\r\n        input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\r\n\r\n        # generate token ids\r\n        predicted_ids = model.generate(input_features)\r\n        print(ds[i][\"text\"])\r\n\r\n        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\r\n        print(transcription)\r\n        print(\"--\")\r\n\r\n\r\ndef get_args():\r\n    \"\"\"Parse commandline.\"\"\"\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--model\", default=\"tiny\", help=\"path to model\")\r\n    parser.add_argument(\"--onnx\", action=\"store_true\", help=\"use onnxruntime\")\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\ndef main():\r\n    args = get_args()\r\n    run_whisper(args.model, args.onnx)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1487609280/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1488508452",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1488508452",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1488508452,
        "node_id": "IC_kwDOCVq1mM5YuNYk",
        "user": {
            "login": "DK013",
            "id": 22991490,
            "node_id": "MDQ6VXNlcjIyOTkxNDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/22991490?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DK013",
            "html_url": "https://github.com/DK013",
            "followers_url": "https://api.github.com/users/DK013/followers",
            "following_url": "https://api.github.com/users/DK013/following{/other_user}",
            "gists_url": "https://api.github.com/users/DK013/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DK013/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DK013/subscriptions",
            "organizations_url": "https://api.github.com/users/DK013/orgs",
            "repos_url": "https://api.github.com/users/DK013/repos",
            "events_url": "https://api.github.com/users/DK013/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DK013/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-29T12:26:17Z",
        "updated_at": "2023-03-29T12:33:02Z",
        "author_association": "NONE",
        "body": "@guschmue Thanks for the example. Appreciate it.\r\n\r\nI'm trying to avoid python since in my usecase I need the whisper functionality in electron and I want to keep things on the client side. so making install with all the python runtime and torch etc is just too much to ask. I tried the C++ implementation using ggml format models from [this repository](https://github.com/ggerganov/whisper.cpp). But it only works on CPU. There's [another repository](https://github.com/Const-me/Whisper) which ports that C++ lib to work with DirectX11. But his port is made of old code and doesn't do a very good job on the realtime transcription.\r\n\r\nAs for transformer.js, I already tried an implementation and it works great, except the only problem again is it works CPU only. Which is not good if I want to use say a bit larger model like whisper-small to implement a realtime speech recognizer.\r\n\r\nRight now to me it feels the best solution will be to use onnxruntime to work in a C# console app so I can make use of DirectML to support all GPUs and use that cli discretely from my electron application.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1488508452/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489429244",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1489429244",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1489429244,
        "node_id": "IC_kwDOCVq1mM5YxuL8",
        "user": {
            "login": "natke",
            "id": 3302433,
            "node_id": "MDQ6VXNlcjMzMDI0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3302433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/natke",
            "html_url": "https://github.com/natke",
            "followers_url": "https://api.github.com/users/natke/followers",
            "following_url": "https://api.github.com/users/natke/following{/other_user}",
            "gists_url": "https://api.github.com/users/natke/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/natke/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/natke/subscriptions",
            "organizations_url": "https://api.github.com/users/natke/orgs",
            "repos_url": "https://api.github.com/users/natke/repos",
            "events_url": "https://api.github.com/users/natke/events{/privacy}",
            "received_events_url": "https://api.github.com/users/natke/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-29T22:41:31Z",
        "updated_at": "2023-03-29T22:41:31Z",
        "author_association": "MEMBER",
        "body": "If you can wait a couple of weeks @DK013, you can use the single model solution that Guenther mentions above. I think this will be the easiest way for you to run in your environment.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489429244/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489447147",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1489447147",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1489447147,
        "node_id": "IC_kwDOCVq1mM5Yxyjr",
        "user": {
            "login": "guschmue",
            "id": 22941064,
            "node_id": "MDQ6VXNlcjIyOTQxMDY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/22941064?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guschmue",
            "html_url": "https://github.com/guschmue",
            "followers_url": "https://api.github.com/users/guschmue/followers",
            "following_url": "https://api.github.com/users/guschmue/following{/other_user}",
            "gists_url": "https://api.github.com/users/guschmue/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guschmue/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guschmue/subscriptions",
            "organizations_url": "https://api.github.com/users/guschmue/orgs",
            "repos_url": "https://api.github.com/users/guschmue/repos",
            "events_url": "https://api.github.com/users/guschmue/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guschmue/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-29T22:58:01Z",
        "updated_at": "2023-03-29T22:58:01Z",
        "author_association": "MEMBER",
        "body": "Since @DK013 wants to run this under directml - there is most likely some work on directml end to make the e2e model work.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489447147/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489614721",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1489614721",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1489614721,
        "node_id": "IC_kwDOCVq1mM5YybeB",
        "user": {
            "login": "DK013",
            "id": 22991490,
            "node_id": "MDQ6VXNlcjIyOTkxNDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/22991490?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DK013",
            "html_url": "https://github.com/DK013",
            "followers_url": "https://api.github.com/users/DK013/followers",
            "following_url": "https://api.github.com/users/DK013/following{/other_user}",
            "gists_url": "https://api.github.com/users/DK013/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DK013/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DK013/subscriptions",
            "organizations_url": "https://api.github.com/users/DK013/orgs",
            "repos_url": "https://api.github.com/users/DK013/repos",
            "events_url": "https://api.github.com/users/DK013/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DK013/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-30T02:59:42Z",
        "updated_at": "2023-03-30T02:59:42Z",
        "author_association": "NONE",
        "body": "@guschmue @natke I guess I have to wait. there's no other way. Thanks guys for reaching out. I'll be waiting for the news.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1489614721/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1501046693",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1501046693",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1501046693,
        "node_id": "IC_kwDOCVq1mM5ZeCel",
        "user": {
            "login": "DK013",
            "id": 22991490,
            "node_id": "MDQ6VXNlcjIyOTkxNDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/22991490?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DK013",
            "html_url": "https://github.com/DK013",
            "followers_url": "https://api.github.com/users/DK013/followers",
            "following_url": "https://api.github.com/users/DK013/following{/other_user}",
            "gists_url": "https://api.github.com/users/DK013/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DK013/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DK013/subscriptions",
            "organizations_url": "https://api.github.com/users/DK013/orgs",
            "repos_url": "https://api.github.com/users/DK013/repos",
            "events_url": "https://api.github.com/users/DK013/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DK013/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-09T05:36:53Z",
        "updated_at": "2023-04-09T05:38:06Z",
        "author_association": "NONE",
        "body": "@guschmue @natke since crome 113 is gonna support webGPU without any flags needed and I heard onnxruntime is gonna release support for WebGPU as well, this gives me hope of using transformerjs directly in the electron app without needing to building a seperate C# console app since the biggest problem with ML.NET right now is lack of tokenizers and building one from scratch is a task for me. Maybe with this I can tweak transformerjs to support bigger models for whisper now. When can we expect this update? since electron already support WebGPU using chromium flags I would like to go ahead and start coding and testing as soon as possible.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1501046693/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1503681646",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1503681646",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1503681646,
        "node_id": "IC_kwDOCVq1mM5ZoFxu",
        "user": {
            "login": "guschmue",
            "id": 22941064,
            "node_id": "MDQ6VXNlcjIyOTQxMDY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/22941064?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guschmue",
            "html_url": "https://github.com/guschmue",
            "followers_url": "https://api.github.com/users/guschmue/followers",
            "following_url": "https://api.github.com/users/guschmue/following{/other_user}",
            "gists_url": "https://api.github.com/users/guschmue/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guschmue/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guschmue/subscriptions",
            "organizations_url": "https://api.github.com/users/guschmue/orgs",
            "repos_url": "https://api.github.com/users/guschmue/repos",
            "events_url": "https://api.github.com/users/guschmue/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guschmue/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-11T16:04:37Z",
        "updated_at": "2023-04-11T16:04:37Z",
        "author_association": "MEMBER",
        "body": "The PR for webgpu is here https://github.com/microsoft/onnxruntime/pull/14579.\r\nWe will try to support whisper on webgpu but we are not sure yet if all ops are fully optimized in 1.15.\r\nAnd we close to have an end to end model that includes pre/post processing for whisper, basically raw pcm in, text out.\r\n\r\nFor tokenizers: ort-web ships with most tokenizers by including the tokenizers from onnxruntime-extensions. But the way this works right now is that the tokenizers are called in graph what makes the api mapping from huggingface hard. We might fix that in the near future by allowing to call the tokenizers out of graph via api call.\r\nAnd we need to pull in a newer version for onnxruntime-extensions to get the tokenizer/decoder for whisper which would be in the next release.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1503681646/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1550236684",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1550236684",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1550236684,
        "node_id": "IC_kwDOCVq1mM5cZrwM",
        "user": {
            "login": "guschmue",
            "id": 22941064,
            "node_id": "MDQ6VXNlcjIyOTQxMDY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/22941064?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/guschmue",
            "html_url": "https://github.com/guschmue",
            "followers_url": "https://api.github.com/users/guschmue/followers",
            "following_url": "https://api.github.com/users/guschmue/following{/other_user}",
            "gists_url": "https://api.github.com/users/guschmue/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/guschmue/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/guschmue/subscriptions",
            "organizations_url": "https://api.github.com/users/guschmue/orgs",
            "repos_url": "https://api.github.com/users/guschmue/repos",
            "events_url": "https://api.github.com/users/guschmue/events{/privacy}",
            "received_events_url": "https://api.github.com/users/guschmue/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-05-16T19:26:54Z",
        "updated_at": "2023-05-16T19:26:54Z",
        "author_association": "MEMBER",
        "body": "forgot to update this issue: whisper for ort-web with some instructions are now here:\r\nhttps://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/ort-whisper\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1550236684/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1654066134",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/15235#issuecomment-1654066134",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/15235",
        "id": 1654066134,
        "node_id": "IC_kwDOCVq1mM5ilwvW",
        "user": {
            "login": "nums11",
            "id": 20541831,
            "node_id": "MDQ6VXNlcjIwNTQxODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/20541831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nums11",
            "html_url": "https://github.com/nums11",
            "followers_url": "https://api.github.com/users/nums11/followers",
            "following_url": "https://api.github.com/users/nums11/following{/other_user}",
            "gists_url": "https://api.github.com/users/nums11/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nums11/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nums11/subscriptions",
            "organizations_url": "https://api.github.com/users/nums11/orgs",
            "repos_url": "https://api.github.com/users/nums11/repos",
            "events_url": "https://api.github.com/users/nums11/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nums11/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-07-27T17:21:50Z",
        "updated_at": "2023-07-27T17:21:50Z",
        "author_association": "MEMBER",
        "body": "Closing as resolved.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1654066134/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]